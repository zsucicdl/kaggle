{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 71485,
     "databundleVersionId": 8059942,
     "sourceType": "competition"
    },
    {
     "sourceId": 8070853,
     "sourceType": "datasetVersion",
     "datasetId": 4762179
    },
    {
     "sourceId": 8078642,
     "sourceType": "datasetVersion",
     "datasetId": 4767886
    }
   ],
   "dockerImageVersionId": 30673,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "#### Thank you for exploring my notebook.\nIn this notebook, I used TfidfVectorizer and Polars to generate features, and used LightGBM as the scoring model.\n\nIn addition, I used both Chinese and English as code comments.\n\n##### update: version 2 \n1. Add more data Preprocessing function\n2. LGBMClassifier  -->  LGBMRegressor\n3. CV:  0.7646  --> 0.7871\n4. LB:  0.772 --> 0.786\n\n##### update: version 4\n1. Add code comments\n2. Using kappa as the early stop metric\n3. CV:  0.7889\n4. LB:  0.787\n\n##### update: version 5\n1. Using kappa as LGBMRegressor objective\n2. CV:  0.7990",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Import",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import re\nimport copy\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport lightgbm as lgb\nfrom tqdm.auto import tqdm,trange\nfrom lightgbm import log_evaluation, early_stopping\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T07:56:25.486026Z",
     "iopub.execute_input": "2024-04-09T07:56:25.486812Z",
     "iopub.status.idle": "2024-04-09T07:56:30.342215Z",
     "shell.execute_reply.started": "2024-04-09T07:56:25.486777Z",
     "shell.execute_reply": "2024-04-09T07:56:30.341078Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T06:52:57.820855Z",
     "start_time": "2024-05-18T06:52:56.747196Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": "## Load Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "columns = [  \n",
    "    (\n",
    "        pl.col(\"full_text\").str.split(by=\"\\n\\n\").alias(\"paragraph\")\n",
    "    ),\n",
    "]\n",
    "PATH = \"/home/zvonimir/kaggle/input/learning-agency-lab-automated-essay-scoring-2/\"\n",
    "# 载入训练集和测试集，同时对full_text数据使用\\n\\n字符分割为列表，重命名为paragraph\n",
    "# Load training and testing sets, while using \\ n \\ n character segmentation to list and renaming to paragraph for full_text data\n",
    "train = pl.read_csv(PATH + \"train.csv\").with_columns(columns)\n",
    "test = pl.read_csv(PATH + \"test.csv\").with_columns(columns)\n",
    "# 显示训练集中的第一个样本数据\n",
    "# Display the first sample data in the training set\n",
    "train.head(1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T07:56:30.344235Z",
     "iopub.execute_input": "2024-04-09T07:56:30.344775Z",
     "iopub.status.idle": "2024-04-09T07:56:31.067402Z",
     "shell.execute_reply.started": "2024-04-09T07:56:30.34474Z",
     "shell.execute_reply": "2024-04-09T07:56:31.066369Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T06:52:57.928779Z",
     "start_time": "2024-05-18T06:52:57.821664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (1, 4)\n",
       "┌──────────┬─────────────────────────────────┬───────┬─────────────────────────────────┐\n",
       "│ essay_id ┆ full_text                       ┆ score ┆ paragraph                       │\n",
       "│ ---      ┆ ---                             ┆ ---   ┆ ---                             │\n",
       "│ str      ┆ str                             ┆ i64   ┆ list[str]                       │\n",
       "╞══════════╪═════════════════════════════════╪═══════╪═════════════════════════════════╡\n",
       "│ 000d118  ┆ Many people have car where the… ┆ 3     ┆ [\"Many people have car where t… │\n",
       "└──────────┴─────────────────────────────────┴───────┴─────────────────────────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>essay_id</th><th>full_text</th><th>score</th><th>paragraph</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;000d118&quot;</td><td>&quot;Many people have car where the…</td><td>3</td><td>[&quot;Many people have car where they live. The thing they don&#x27;t know is that when you use a car alot of thing can happen like you can get in accidet or the smoke that the car has is bad to breath on if someone is walk but in VAUBAN,Germany they dont have that proble because 70 percent of vauban&#x27;s families do not own cars,and 57 percent sold a car to move there. Street parkig ,driveways and home garages are forbidden on the outskirts of freiburd that near the French and Swiss borders. You probaly won&#x27;t see a car in Vauban&#x27;s streets because they are completely &quot;car free&quot; but If some that lives in VAUBAN that owns a car ownership is allowed,but there are only two places that you can park a large garages at the edge of the development,where a car owner buys a space but it not cheap to buy one they sell the space for you car for $40,000 along with a home. The vauban people completed this in 2006 ,they said that this an example of a growing trend in Europe,The untile states and some where else are suburban life from auto use this is called &quot;smart planning&quot;. The current efforts to drastically reduce greenhouse gas emissions from tailes the passengee cars are responsible for 12 percent of greenhouse gas emissions in Europe and up to 50 percent in some car intensive in the United States. I honeslty think that good idea that they did that is Vaudan because that makes cities denser and better for walking and in VAUBAN there are 5,500 residents within a rectangular square mile. In the artical David Gold berg said that &quot;All of our development since World war 2 has been centered on the cars,and that will have to change&quot; and i think that was very true what David Gold said because alot thing we need cars to do we can go anyway were with out cars beacuse some people are a very lazy to walk to place thats why they alot of people use car and i think that it was a good idea that that they did that in VAUBAN so people can see how we really don&#x27;t need car to go to place from place because we can walk from were we need to go or we can ride bycles with out the use of a car. It good that they are doing that if you thik about your help the earth in way and thats a very good thing to. In the United states ,the Environmental protection Agency is promoting what is called &quot;car reduced&quot;communtunties,and the legislators are starting to act,if cautiously. Maany experts expect pubic transport serving suburbs to play a much larger role in a new six years federal transportation bill to approved this year. In previous bill,80 percent of appropriations have by law gone to highways and only 20 percent to other transports. There many good reason why they should do this.    &quot;]</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": "## Features engineering",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### 1.Preprocessing",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def removeHTML(x):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',x)\ndef dataPreprocessing(x):\n    # 将单词转化为小写\n    # Convert words to lowercase\n    x = x.lower()\n    # Remove HTML\n    # 移除html\n    x = removeHTML(x)\n    # 删除以@作为首字母的字符串\n    # Delete strings starting with @\n    x = re.sub(\"@\\w+\", '',x)\n    # 删除数字\n    # Delete Numbers\n    x = re.sub(\"'\\d+\", '',x)\n    x = re.sub(\"\\d+\", '',x)\n    # 删除网址\n    # Delete URL\n    x = re.sub(\"http\\w+\", '',x)\n    # 将连续空白符替换为一个空格字符\n    # Replace consecutive empty spaces with a single space character\n    x = re.sub(r\"\\s+\", \" \", x)\n    # 替换连续的句号和逗号为一个\n    # Replace consecutive commas and periods with one comma and period character\n    x = re.sub(r\"\\.+\", \".\", x)\n    x = re.sub(r\"\\,+\", \",\", x)\n    # 去除开头结尾的空白符\n    # Remove empty characters at the beginning and end\n    x = x.strip()\n    return x",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T07:56:31.068681Z",
     "iopub.execute_input": "2024-04-09T07:56:31.069117Z",
     "iopub.status.idle": "2024-04-09T07:56:31.078698Z",
     "shell.execute_reply.started": "2024-04-09T07:56:31.069079Z",
     "shell.execute_reply": "2024-04-09T07:56:31.077541Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T06:52:57.931444Z",
     "start_time": "2024-05-18T06:52:57.929322Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": "### 2.Paragraph Features",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 段落特征\n# paragraph features\ndef Paragraph_Preprocess(tmp):\n    # 将段落列表扩展为一行行的数据\n    # Expand the paragraph list into several lines of data\n    tmp = tmp.explode('paragraph')\n    # 段落预处理\n    # Paragraph preprocessing\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(dataPreprocessing))\n    # 计算每一个段落的长度\n    # Calculate the length of each paragraph\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x)).alias(\"paragraph_len\"))\n    # 计算每一个段落中句子的数量和单词的数量\n    # Calculate the number of sentences and words in each paragraph\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x.split('.'))).alias(\"paragraph_sentence_cnt\"),\n                    pl.col('paragraph').map_elements(lambda x: len(x.split(' '))).alias(\"paragraph_word_cnt\"),)\n    return tmp\n# feature_eng\nparagraph_fea = ['paragraph_len','paragraph_sentence_cnt','paragraph_word_cnt']\ndef Paragraph_Eng(train_tmp):\n    aggs = [\n        # 统计段落长度大于和小于 i 值的个数\n        # Count the number of paragraph lengths greater than and less than the i-value\n        *[pl.col('paragraph').filter(pl.col('paragraph_len') >= i).count().alias(f\"paragraph_{i}_cnt\") for i in [50,75,100,125,150,175,200,250,300,350,400,500,600,700] ], \n        *[pl.col('paragraph').filter(pl.col('paragraph_len') <= i).count().alias(f\"paragraph_{i}_cnt\") for i in [25,49]], \n        # 其他\n        # other\n        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in paragraph_fea],\n        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in paragraph_fea],\n        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in paragraph_fea],\n        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in paragraph_fea],\n        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in paragraph_fea],\n        ]\n    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n    df = df.to_pandas()\n    return df\ntmp = Paragraph_Preprocess(train)\ntrain_feats = Paragraph_Eng(tmp)\ntrain_feats['score'] = train['score']\n# 获取特征名称\n# Obtain feature names\nfeature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\nprint('Features Number: ',len(feature_names))\ntrain_feats.head(3)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T07:56:31.080499Z",
     "iopub.execute_input": "2024-04-09T07:56:31.081189Z",
     "iopub.status.idle": "2024-04-09T07:56:39.738877Z",
     "shell.execute_reply.started": "2024-04-09T07:56:31.081155Z",
     "shell.execute_reply": "2024-04-09T07:56:39.737577Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T06:52:59.843834Z",
     "start_time": "2024-05-18T06:52:57.932040Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6431/894338899.py:9: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('paragraph').map_elements(dataPreprocessing))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Number:  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6431/894338899.py:12: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x)).alias(\"paragraph_len\"))\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  essay_id  paragraph_50_cnt  paragraph_75_cnt  paragraph_100_cnt  \\\n",
       "0  000d118                 1                 1                  1   \n",
       "1  000fe60                 5                 5                  5   \n",
       "2  001ab80                 4                 4                  4   \n",
       "\n",
       "   paragraph_125_cnt  paragraph_150_cnt  paragraph_175_cnt  paragraph_200_cnt  \\\n",
       "0                  1                  1                  1                  1   \n",
       "1                  5                  5                  5                  4   \n",
       "2                  4                  4                  4                  4   \n",
       "\n",
       "   paragraph_250_cnt  paragraph_300_cnt  ...  paragraph_len_min  \\\n",
       "0                  1                  1  ...               2640   \n",
       "1                  3                  3  ...                184   \n",
       "2                  4                  4  ...                476   \n",
       "\n",
       "   paragraph_sentence_cnt_min  paragraph_word_cnt_min  paragraph_len_first  \\\n",
       "0                          14                     491                 2640   \n",
       "1                           3                      37                  184   \n",
       "2                           5                      85                  576   \n",
       "\n",
       "   paragraph_sentence_cnt_first  paragraph_word_cnt_first  paragraph_len_last  \\\n",
       "0                            14                       491                2640   \n",
       "1                             4                        37                 235   \n",
       "2                             5                       101                 476   \n",
       "\n",
       "   paragraph_sentence_cnt_last  paragraph_word_cnt_last  score  \n",
       "0                           14                      491      3  \n",
       "1                            3                       46      3  \n",
       "2                            5                       85      4  \n",
       "\n",
       "[3 rows x 33 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>paragraph_50_cnt</th>\n",
       "      <th>paragraph_75_cnt</th>\n",
       "      <th>paragraph_100_cnt</th>\n",
       "      <th>paragraph_125_cnt</th>\n",
       "      <th>paragraph_150_cnt</th>\n",
       "      <th>paragraph_175_cnt</th>\n",
       "      <th>paragraph_200_cnt</th>\n",
       "      <th>paragraph_250_cnt</th>\n",
       "      <th>paragraph_300_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>paragraph_len_min</th>\n",
       "      <th>paragraph_sentence_cnt_min</th>\n",
       "      <th>paragraph_word_cnt_min</th>\n",
       "      <th>paragraph_len_first</th>\n",
       "      <th>paragraph_sentence_cnt_first</th>\n",
       "      <th>paragraph_word_cnt_first</th>\n",
       "      <th>paragraph_len_last</th>\n",
       "      <th>paragraph_sentence_cnt_last</th>\n",
       "      <th>paragraph_word_cnt_last</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2640</td>\n",
       "      <td>14</td>\n",
       "      <td>491</td>\n",
       "      <td>2640</td>\n",
       "      <td>14</td>\n",
       "      <td>491</td>\n",
       "      <td>2640</td>\n",
       "      <td>14</td>\n",
       "      <td>491</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>184</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>476</td>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>576</td>\n",
       "      <td>5</td>\n",
       "      <td>101</td>\n",
       "      <td>476</td>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": "### 3.Sentence Features",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# sentence feature\ndef Sentence_Preprocess(tmp):\n    # 对full_text预处理，并且使用句号分割出文本的句子\n    # Preprocess full_text and use periods to segment sentences in the text\n    tmp = tmp.with_columns(pl.col('full_text').map_elements(dataPreprocessing).str.split(by=\".\").alias(\"sentence\"))\n    tmp = tmp.explode('sentence')\n    # 计算句子的长度\n    # Calculate the length of a sentence\n    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x)).alias(\"sentence_len\"))\n    # 筛选出句子长度大于15的那一部分数据\n    # Filter out the portion of data with a sentence length greater than 15\n    tmp = tmp.filter(pl.col('sentence_len')>=15)\n    # 统计每一句中单词的数量\n    # Count the number of words in each sentence\n    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x.split(' '))).alias(\"sentence_word_cnt\"))\n    \n    return tmp\n# feature_eng\nsentence_fea = ['sentence_len','sentence_word_cnt']\ndef Sentence_Eng(train_tmp):\n    aggs = [\n        # 统计句子长度大于 i 的句子个数\n        # Count the number of sentences with a length greater than i\n        *[pl.col('sentence').filter(pl.col('sentence_len') >= i).count().alias(f\"sentence_{i}_cnt\") for i in [15,50,100,150,200,250,300] ], \n        # 其他\n        # other\n        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in sentence_fea],\n        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in sentence_fea],\n        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in sentence_fea],\n        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in sentence_fea],\n        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in sentence_fea],\n        ]\n    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n    df = df.to_pandas()\n    return df\n\ntmp = Sentence_Preprocess(train)\n# 将新生成的特征数据和之前生成的特征数据合并\n# Merge the newly generated feature data with the previously generated feature data\ntrain_feats = train_feats.merge(Sentence_Eng(tmp), on='essay_id', how='left')\n\nfeature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\nprint('Features Number: ',len(feature_names))\ntrain_feats.head(3)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T07:56:39.744544Z",
     "iopub.execute_input": "2024-04-09T07:56:39.744918Z",
     "iopub.status.idle": "2024-04-09T07:56:48.078384Z",
     "shell.execute_reply.started": "2024-04-09T07:56:39.744889Z",
     "shell.execute_reply": "2024-04-09T07:56:48.077563Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T06:53:01.742848Z",
     "start_time": "2024-05-18T06:52:59.844812Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Number:  48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6431/4199542533.py:9: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x)).alias(\"sentence_len\"))\n",
      "/tmp/ipykernel_6431/4199542533.py:15: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x.split(' '))).alias(\"sentence_word_cnt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  essay_id  paragraph_50_cnt  paragraph_75_cnt  paragraph_100_cnt  \\\n",
       "0  000d118                 1                 1                  1   \n",
       "1  000fe60                 5                 5                  5   \n",
       "2  001ab80                 4                 4                  4   \n",
       "\n",
       "   paragraph_125_cnt  paragraph_150_cnt  paragraph_175_cnt  paragraph_200_cnt  \\\n",
       "0                  1                  1                  1                  1   \n",
       "1                  5                  5                  5                  4   \n",
       "2                  4                  4                  4                  4   \n",
       "\n",
       "   paragraph_250_cnt  paragraph_300_cnt  ...  sentence_len_max  \\\n",
       "0                  1                  1  ...               593   \n",
       "1                  3                  3  ...               250   \n",
       "2                  4                  4  ...               237   \n",
       "\n",
       "   sentence_word_cnt_max  sentence_len_mean  sentence_word_cnt_mean  \\\n",
       "0                    127         202.076923               38.692308   \n",
       "1                     49          96.823529               20.470588   \n",
       "2                     47         126.708333               23.875000   \n",
       "\n",
       "   sentence_len_min  sentence_word_cnt_min  sentence_len_first  \\\n",
       "0                36                      7                  36   \n",
       "1                27                      7                  62   \n",
       "2                58                     10                 144   \n",
       "\n",
       "   sentence_word_cnt_first  sentence_len_last  sentence_word_cnt_last  \n",
       "0                        7                 47                      10  \n",
       "1                       13                124                      25  \n",
       "2                       27                 58                      10  \n",
       "\n",
       "[3 rows x 50 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>paragraph_50_cnt</th>\n",
       "      <th>paragraph_75_cnt</th>\n",
       "      <th>paragraph_100_cnt</th>\n",
       "      <th>paragraph_125_cnt</th>\n",
       "      <th>paragraph_150_cnt</th>\n",
       "      <th>paragraph_175_cnt</th>\n",
       "      <th>paragraph_200_cnt</th>\n",
       "      <th>paragraph_250_cnt</th>\n",
       "      <th>paragraph_300_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence_len_max</th>\n",
       "      <th>sentence_word_cnt_max</th>\n",
       "      <th>sentence_len_mean</th>\n",
       "      <th>sentence_word_cnt_mean</th>\n",
       "      <th>sentence_len_min</th>\n",
       "      <th>sentence_word_cnt_min</th>\n",
       "      <th>sentence_len_first</th>\n",
       "      <th>sentence_word_cnt_first</th>\n",
       "      <th>sentence_len_last</th>\n",
       "      <th>sentence_word_cnt_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>593</td>\n",
       "      <td>127</td>\n",
       "      <td>202.076923</td>\n",
       "      <td>38.692308</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>49</td>\n",
       "      <td>96.823529</td>\n",
       "      <td>20.470588</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>62</td>\n",
       "      <td>13</td>\n",
       "      <td>124</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>237</td>\n",
       "      <td>47</td>\n",
       "      <td>126.708333</td>\n",
       "      <td>23.875000</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>144</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 50 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": "### 4.Word Features",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# word feature\ndef Word_Preprocess(tmp):\n    # 对full_text预处理，并且使用空格符分割出文本的单词\n    # Preprocess full_text and use spaces to separate words from the text\n    tmp = tmp.with_columns(pl.col('full_text').map_elements(dataPreprocessing).str.split(by=\" \").alias(\"word\"))\n    tmp = tmp.explode('word')\n    # 计算每一个的单词长度\n    # Calculate the length of each word\n    tmp = tmp.with_columns(pl.col('word').map_elements(lambda x: len(x)).alias(\"word_len\"))\n    # 删除单词长度为0的数据\n    # Delete data with a word length of 0\n    tmp = tmp.filter(pl.col('word_len')!=0)\n    \n    return tmp\n# feature_eng\ndef Word_Eng(train_tmp):\n    aggs = [\n        # 统计单词长度大于 i+1 的单词个数\n        # Count the number of words with a length greater than i+1\n        *[pl.col('word').filter(pl.col('word_len') >= i+1).count().alias(f\"word_{i+1}_cnt\") for i in range(15) ], \n        # 其他\n        # other\n        pl.col('word_len').max().alias(f\"word_len_max\"),\n        pl.col('word_len').mean().alias(f\"word_len_mean\"),\n        pl.col('word_len').std().alias(f\"word_len_std\"),\n        pl.col('word_len').quantile(0.25).alias(f\"word_len_q1\"),\n        pl.col('word_len').quantile(0.50).alias(f\"word_len_q2\"),\n        pl.col('word_len').quantile(0.75).alias(f\"word_len_q3\"),\n        ]\n    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n    df = df.to_pandas()\n    return df\n\ntmp = Word_Preprocess(train)\n# 将新生成的特征数据和之前生成的特征数据合并\n# Merge the newly generated feature data with the previously generated feature data\ntrain_feats = train_feats.merge(Word_Eng(tmp), on='essay_id', how='left')\n\nfeature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\nprint('Features Number: ',len(feature_names))\ntrain_feats.head(3)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T07:56:48.079702Z",
     "iopub.execute_input": "2024-04-09T07:56:48.080779Z",
     "iopub.status.idle": "2024-04-09T07:57:04.320546Z",
     "shell.execute_reply.started": "2024-04-09T07:56:48.080745Z",
     "shell.execute_reply": "2024-04-09T07:57:04.319246Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T06:53:04.796050Z",
     "start_time": "2024-05-18T06:53:01.743240Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "/tmp/ipykernel_6431/2451516412.py:9: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('word').map_elements(lambda x: len(x)).alias(\"word_len\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Number:  69\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  essay_id  paragraph_50_cnt  paragraph_75_cnt  paragraph_100_cnt  \\\n",
       "0  000d118                 1                 1                  1   \n",
       "1  000fe60                 5                 5                  5   \n",
       "2  001ab80                 4                 4                  4   \n",
       "\n",
       "   paragraph_125_cnt  paragraph_150_cnt  paragraph_175_cnt  paragraph_200_cnt  \\\n",
       "0                  1                  1                  1                  1   \n",
       "1                  5                  5                  5                  4   \n",
       "2                  4                  4                  4                  4   \n",
       "\n",
       "   paragraph_250_cnt  paragraph_300_cnt  ...  word_12_cnt  word_13_cnt  \\\n",
       "0                  1                  1  ...            6            6   \n",
       "1                  3                  3  ...            0            0   \n",
       "2                  4                  4  ...           14           10   \n",
       "\n",
       "   word_14_cnt  word_15_cnt  word_len_max  word_len_mean  word_len_std  \\\n",
       "0            5            2            25       4.378819      2.538495   \n",
       "1            0            0            11       4.012048      2.060968   \n",
       "2            5            2            15       4.574545      2.604621   \n",
       "\n",
       "   word_len_q1  word_len_q2  word_len_q3  \n",
       "0          3.0          4.0          5.0  \n",
       "1          2.0          4.0          5.0  \n",
       "2          3.0          4.0          5.0  \n",
       "\n",
       "[3 rows x 71 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>paragraph_50_cnt</th>\n",
       "      <th>paragraph_75_cnt</th>\n",
       "      <th>paragraph_100_cnt</th>\n",
       "      <th>paragraph_125_cnt</th>\n",
       "      <th>paragraph_150_cnt</th>\n",
       "      <th>paragraph_175_cnt</th>\n",
       "      <th>paragraph_200_cnt</th>\n",
       "      <th>paragraph_250_cnt</th>\n",
       "      <th>paragraph_300_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>word_12_cnt</th>\n",
       "      <th>word_13_cnt</th>\n",
       "      <th>word_14_cnt</th>\n",
       "      <th>word_15_cnt</th>\n",
       "      <th>word_len_max</th>\n",
       "      <th>word_len_mean</th>\n",
       "      <th>word_len_std</th>\n",
       "      <th>word_len_q1</th>\n",
       "      <th>word_len_q2</th>\n",
       "      <th>word_len_q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>4.378819</td>\n",
       "      <td>2.538495</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.012048</td>\n",
       "      <td>2.060968</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4.574545</td>\n",
       "      <td>2.604621</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 71 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": "### 5.Tf-idf features",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# TfidfVectorizer parameter\nvectorizer = TfidfVectorizer(\n            tokenizer=lambda x: x,\n            preprocessor=lambda x: x,\n            token_pattern=None,\n            strip_accents='unicode',\n            analyzer = 'word',\n            ngram_range=(1,3),\n            min_df=0.05,\n            max_df=0.95,\n            sublinear_tf=True,\n)\n# 将全部数据集都填充进TfidfVectorizer里，这可能会造成泄露和过于乐观的CV分数\n# Fit all datasets into TfidfVector,this may cause leakage and overly optimistic CV scores\ntrain_tfid = vectorizer.fit_transform([i for i in train['full_text']])\n# 转换为数组\n# Convert to array\ndense_matrix = train_tfid.toarray()\n# 转换为dataframe\n# Convert to dataframe\ndf = pd.DataFrame(dense_matrix)\n# 重命名特征\n# rename features\ntfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\ndf.columns = tfid_columns\ndf['essay_id'] = train_feats['essay_id']\n# 将新生成的特征数据和之前生成的特征数据合并\n# Merge the newly generated feature data with the previously generated feature data\ntrain_feats = train_feats.merge(df, on='essay_id', how='left')\n\nfeature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\nprint('Features Number: ',len(feature_names))\ntrain_feats.head(3)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T07:57:04.322087Z",
     "iopub.execute_input": "2024-04-09T07:57:04.322438Z",
     "iopub.status.idle": "2024-04-09T07:58:46.872477Z",
     "shell.execute_reply.started": "2024-04-09T07:57:04.322408Z",
     "shell.execute_reply": "2024-04-09T07:58:46.871183Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T06:53:21.196478Z",
     "start_time": "2024-05-18T06:53:04.796560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Number:  3360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  essay_id  paragraph_50_cnt  paragraph_75_cnt  paragraph_100_cnt  \\\n",
       "0  000d118                 1                 1                  1   \n",
       "1  000fe60                 5                 5                  5   \n",
       "2  001ab80                 4                 4                  4   \n",
       "\n",
       "   paragraph_125_cnt  paragraph_150_cnt  paragraph_175_cnt  paragraph_200_cnt  \\\n",
       "0                  1                  1                  1                  1   \n",
       "1                  5                  5                  5                  4   \n",
       "2                  4                  4                  4                  4   \n",
       "\n",
       "   paragraph_250_cnt  paragraph_300_cnt  ...  tfid_3281  tfid_3282  tfid_3283  \\\n",
       "0                  1                  1  ...        0.0        0.0        0.0   \n",
       "1                  3                  3  ...        0.0        0.0        0.0   \n",
       "2                  4                  4  ...        0.0        0.0        0.0   \n",
       "\n",
       "   tfid_3284  tfid_3285  tfid_3286  tfid_3287  tfid_3288  tfid_3289  tfid_3290  \n",
       "0        0.0        0.0        0.0   0.034738   0.071064        0.0        0.0  \n",
       "1        0.0        0.0        0.0   0.000000   0.000000        0.0        0.0  \n",
       "2        0.0        0.0        0.0   0.000000   0.000000        0.0        0.0  \n",
       "\n",
       "[3 rows x 3362 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>paragraph_50_cnt</th>\n",
       "      <th>paragraph_75_cnt</th>\n",
       "      <th>paragraph_100_cnt</th>\n",
       "      <th>paragraph_125_cnt</th>\n",
       "      <th>paragraph_150_cnt</th>\n",
       "      <th>paragraph_175_cnt</th>\n",
       "      <th>paragraph_200_cnt</th>\n",
       "      <th>paragraph_250_cnt</th>\n",
       "      <th>paragraph_300_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>tfid_3281</th>\n",
       "      <th>tfid_3282</th>\n",
       "      <th>tfid_3283</th>\n",
       "      <th>tfid_3284</th>\n",
       "      <th>tfid_3285</th>\n",
       "      <th>tfid_3286</th>\n",
       "      <th>tfid_3287</th>\n",
       "      <th>tfid_3288</th>\n",
       "      <th>tfid_3289</th>\n",
       "      <th>tfid_3290</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034738</td>\n",
       "      <td>0.071064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3362 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": "## Train\n* I have trained and saved the model\n* you can choose to retrain or load the model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# idea from https://www.kaggle.com/code/rsakata/optimize-qwk-by-lgb/notebook#QWK-objective\n\ndef quadratic_weighted_kappa(y_true, y_pred):\n    y_true = y_true + a\n    y_pred = (y_pred + a).clip(1, 6).round()\n    qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n    return 'QWK', qwk, True\ndef qwk_obj(y_true, y_pred):\n    labels = y_true + a\n    preds = y_pred + a\n    preds = preds.clip(1, 6)\n    f = 1/2*np.sum((preds-labels)**2)\n    g = 1/2*np.sum((preds-a)**2+b)\n    df = preds - labels\n    dg = preds - a\n    grad = (df/g - f*dg/g**2)*len(labels)\n    hess = np.ones(len(labels))\n    return grad, hess\na = 2.948\nb = 1.092",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T07:58:46.873961Z",
     "iopub.execute_input": "2024-04-09T07:58:46.874395Z",
     "iopub.status.idle": "2024-04-09T07:58:46.88386Z",
     "shell.execute_reply.started": "2024-04-09T07:58:46.874365Z",
     "shell.execute_reply": "2024-04-09T07:58:46.882575Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T06:53:21.199107Z",
     "start_time": "2024-05-18T06:53:21.196957Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "LOAD = False\n",
    "models = []\n",
    "if LOAD:\n",
    "    for i in range(5):\n",
    "        models.append(lgb.Booster(model_file=f'../input/lal-lgb-baseline-4/fold_{i}.txt'))\n",
    "else:\n",
    "    # oof用于存储每一次模型对验证集的预测结果\n",
    "    # OOF is used to store the prediction results of each model on the validation set\n",
    "    oof = []\n",
    "    x= train_feats\n",
    "    y= train_feats['score'].values\n",
    "    # 5 fold\n",
    "    kfold = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    callbacks = [log_evaluation(period=25), early_stopping(stopping_rounds=75,first_metric_only=True)]\n",
    "    for fold_id, (trn_idx, val_idx) in tqdm(enumerate(kfold.split(x.copy(), y.copy().astype(str)))):\n",
    "            # 创建模型\n",
    "            # create model\n",
    "            model = lgb.LGBMRegressor(\n",
    "                objective = qwk_obj,\n",
    "                metrics = 'None',\n",
    "                learning_rate = 0.1,\n",
    "                max_depth = 5,\n",
    "                num_leaves = 10,\n",
    "                colsample_bytree=0.5,\n",
    "                reg_alpha = 0.1,\n",
    "                reg_lambda = 0.8,\n",
    "                n_estimators=1024,\n",
    "                random_state=42,\n",
    "                verbosity = - 1)\n",
    "            # 分别取出5 kfold分割的训练集和验证集\n",
    "            # Take out the training and validation sets for 5 kfold segmentation separately\n",
    "            X_train = train_feats.iloc[trn_idx][feature_names]\n",
    "            Y_train = train_feats.iloc[trn_idx]['score'] - a\n",
    "\n",
    "            X_val = train_feats.iloc[val_idx][feature_names]\n",
    "            Y_val = train_feats.iloc[val_idx]['score'] - a\n",
    "            print('\\nFold_{} Training ================================\\n'.format(fold_id+1))\n",
    "            # 训练模型\n",
    "            # Training model\n",
    "            lgb_model = model.fit(X_train,\n",
    "                                  Y_train,\n",
    "                                  eval_names=['train', 'valid'],\n",
    "                                  eval_set=[(X_train, Y_train), (X_val, Y_val)],\n",
    "                                  eval_metric=quadratic_weighted_kappa,\n",
    "                                  callbacks=callbacks,)\n",
    "            # 使用训练完成的模型对验证集进行预测\n",
    "            # Use the trained model to predict the validation set\n",
    "            pred_val = lgb_model.predict(\n",
    "                X_val, num_iteration=lgb_model.best_iteration_)\n",
    "            df_tmp = train_feats.iloc[val_idx][['essay_id', 'score']].copy()\n",
    "            df_tmp['pred'] = pred_val + a\n",
    "            oof.append(df_tmp)\n",
    "            # 保存模型参数\n",
    "            # Save model parameters\n",
    "            models.append(model.booster_)\n",
    "            lgb_model.booster_.save_model(f'fold_{fold_id}.txt')\n",
    "    df_oof = pd.concat(oof)\n",
    "    "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T07:58:46.885746Z",
     "iopub.execute_input": "2024-04-09T07:58:46.886781Z",
     "iopub.status.idle": "2024-04-09T07:58:47.039463Z",
     "shell.execute_reply.started": "2024-04-09T07:58:46.886746Z",
     "shell.execute_reply": "2024-04-09T07:58:47.03821Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T06:54:15.090463Z",
     "start_time": "2024-05-18T06:53:21.199539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3768c369b0074b1f87cc7a817d3a44de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold_1 Training ================================\n",
      "\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[25]\ttrain's QWK: 0.750601\tvalid's QWK: 0.742375\n",
      "[50]\ttrain's QWK: 0.795632\tvalid's QWK: 0.779325\n",
      "[75]\ttrain's QWK: 0.81359\tvalid's QWK: 0.792583\n",
      "[100]\ttrain's QWK: 0.826584\tvalid's QWK: 0.799451\n",
      "[125]\ttrain's QWK: 0.834344\tvalid's QWK: 0.801623\n",
      "[150]\ttrain's QWK: 0.843072\tvalid's QWK: 0.8\n",
      "[175]\ttrain's QWK: 0.85002\tvalid's QWK: 0.7999\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttrain's QWK: 0.832841\tvalid's QWK: 0.803195\n",
      "Evaluated only: QWK\n",
      "\n",
      "Fold_2 Training ================================\n",
      "\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[25]\ttrain's QWK: 0.753578\tvalid's QWK: 0.736747\n",
      "[50]\ttrain's QWK: 0.797361\tvalid's QWK: 0.773929\n",
      "[75]\ttrain's QWK: 0.814807\tvalid's QWK: 0.787045\n",
      "[100]\ttrain's QWK: 0.826414\tvalid's QWK: 0.791377\n",
      "[125]\ttrain's QWK: 0.834943\tvalid's QWK: 0.794532\n",
      "[150]\ttrain's QWK: 0.84254\tvalid's QWK: 0.794919\n",
      "[175]\ttrain's QWK: 0.84903\tvalid's QWK: 0.792718\n",
      "[200]\ttrain's QWK: 0.855001\tvalid's QWK: 0.795496\n",
      "[225]\ttrain's QWK: 0.861604\tvalid's QWK: 0.795617\n",
      "[250]\ttrain's QWK: 0.86851\tvalid's QWK: 0.795173\n",
      "[275]\ttrain's QWK: 0.873469\tvalid's QWK: 0.795881\n",
      "[300]\ttrain's QWK: 0.878515\tvalid's QWK: 0.796725\n",
      "[325]\ttrain's QWK: 0.88355\tvalid's QWK: 0.795322\n",
      "[350]\ttrain's QWK: 0.888663\tvalid's QWK: 0.794566\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[375]\ttrain's QWK: 0.892292\tvalid's QWK: 0.792954\n",
      "Early stopping, best iteration is:\n",
      "[309]\ttrain's QWK: 0.880704\tvalid's QWK: 0.797795\n",
      "Evaluated only: QWK\n",
      "\n",
      "Fold_3 Training ================================\n",
      "\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[25]\ttrain's QWK: 0.751028\tvalid's QWK: 0.749026\n",
      "[50]\ttrain's QWK: 0.795279\tvalid's QWK: 0.776472\n",
      "[75]\ttrain's QWK: 0.813943\tvalid's QWK: 0.785741\n",
      "[100]\ttrain's QWK: 0.825779\tvalid's QWK: 0.790656\n",
      "[125]\ttrain's QWK: 0.836298\tvalid's QWK: 0.793577\n",
      "[150]\ttrain's QWK: 0.844051\tvalid's QWK: 0.797673\n",
      "[175]\ttrain's QWK: 0.850227\tvalid's QWK: 0.796699\n",
      "[200]\ttrain's QWK: 0.85698\tvalid's QWK: 0.796737\n",
      "[225]\ttrain's QWK: 0.862447\tvalid's QWK: 0.795808\n",
      "[250]\ttrain's QWK: 0.867192\tvalid's QWK: 0.796222\n",
      "[275]\ttrain's QWK: 0.87284\tvalid's QWK: 0.797571\n",
      "[300]\ttrain's QWK: 0.878344\tvalid's QWK: 0.797241\n",
      "Early stopping, best iteration is:\n",
      "[240]\ttrain's QWK: 0.865166\tvalid's QWK: 0.798292\n",
      "Evaluated only: QWK\n",
      "\n",
      "Fold_4 Training ================================\n",
      "\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[25]\ttrain's QWK: 0.751544\tvalid's QWK: 0.74474\n",
      "[50]\ttrain's QWK: 0.795474\tvalid's QWK: 0.78008\n",
      "[75]\ttrain's QWK: 0.814382\tvalid's QWK: 0.789794\n",
      "[100]\ttrain's QWK: 0.826222\tvalid's QWK: 0.792647\n",
      "[125]\ttrain's QWK: 0.834572\tvalid's QWK: 0.79549\n",
      "[150]\ttrain's QWK: 0.842831\tvalid's QWK: 0.799224\n",
      "[175]\ttrain's QWK: 0.850045\tvalid's QWK: 0.800506\n",
      "[200]\ttrain's QWK: 0.856392\tvalid's QWK: 0.804307\n",
      "[225]\ttrain's QWK: 0.862065\tvalid's QWK: 0.804729\n",
      "[250]\ttrain's QWK: 0.867795\tvalid's QWK: 0.806522\n",
      "[275]\ttrain's QWK: 0.873416\tvalid's QWK: 0.805199\n",
      "[300]\ttrain's QWK: 0.878607\tvalid's QWK: 0.80532\n",
      "[325]\ttrain's QWK: 0.88207\tvalid's QWK: 0.805836\n",
      "[350]\ttrain's QWK: 0.886936\tvalid's QWK: 0.804889\n",
      "[375]\ttrain's QWK: 0.891912\tvalid's QWK: 0.803685\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[310]\ttrain's QWK: 0.880425\tvalid's QWK: 0.806793\n",
      "Evaluated only: QWK\n",
      "\n",
      "Fold_5 Training ================================\n",
      "\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[25]\ttrain's QWK: 0.757071\tvalid's QWK: 0.704067\n",
      "[50]\ttrain's QWK: 0.80079\tvalid's QWK: 0.749293\n",
      "[75]\ttrain's QWK: 0.819281\tvalid's QWK: 0.763009\n",
      "[100]\ttrain's QWK: 0.830981\tvalid's QWK: 0.770767\n",
      "[125]\ttrain's QWK: 0.83948\tvalid's QWK: 0.775172\n",
      "[150]\ttrain's QWK: 0.846658\tvalid's QWK: 0.780939\n",
      "[175]\ttrain's QWK: 0.854057\tvalid's QWK: 0.779716\n",
      "[200]\ttrain's QWK: 0.858131\tvalid's QWK: 0.78329\n",
      "[225]\ttrain's QWK: 0.864273\tvalid's QWK: 0.784936\n",
      "[250]\ttrain's QWK: 0.869265\tvalid's QWK: 0.786406\n",
      "[275]\ttrain's QWK: 0.874696\tvalid's QWK: 0.786831\n",
      "[300]\ttrain's QWK: 0.880414\tvalid's QWK: 0.787273\n",
      "[325]\ttrain's QWK: 0.885282\tvalid's QWK: 0.786305\n",
      "[350]\ttrain's QWK: 0.889797\tvalid's QWK: 0.785879\n",
      "Early stopping, best iteration is:\n",
      "[286]\ttrain's QWK: 0.877787\tvalid's QWK: 0.789035\n",
      "Evaluated only: QWK\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": "### CV",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if LOAD:\n    print('acc: ',0.6275495464263015)\n    print('kappa: ',0.7990509565910948)\nelse:\n    acc = accuracy_score(df_oof['score'], df_oof['pred'].clip(1, 6).round())\n    kappa = cohen_kappa_score(df_oof['score'], df_oof['pred'].clip(1, 6).round(), weights=\"quadratic\")\n    print('acc: ',acc)\n    print('kappa: ',kappa)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T07:58:47.041049Z",
     "iopub.execute_input": "2024-04-09T07:58:47.041533Z",
     "iopub.status.idle": "2024-04-09T07:58:47.05337Z",
     "shell.execute_reply.started": "2024-04-09T07:58:47.041496Z",
     "shell.execute_reply": "2024-04-09T07:58:47.052122Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T06:54:15.103079Z",
     "start_time": "2024-05-18T06:54:15.090909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.6275495464263015\n",
      "kappa:  0.7990509565910948\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": "## Submission",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Paragraph\ntmp = Paragraph_Preprocess(test)\ntest_feats = Paragraph_Eng(tmp)\n# Sentence\ntmp = Sentence_Preprocess(test)\ntest_feats = test_feats.merge(Sentence_Eng(tmp), on='essay_id', how='left')\n# Word\ntmp = Word_Preprocess(test)\ntest_feats = test_feats.merge(Word_Eng(tmp), on='essay_id', how='left')\n# Tfidf\ntest_tfid = vectorizer.transform([i for i in test['full_text']])\ndense_matrix = test_tfid.toarray()\ndf = pd.DataFrame(dense_matrix)\ntfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\ndf.columns = tfid_columns\ndf['essay_id'] = test_feats['essay_id']\ntest_feats = test_feats.merge(df, on='essay_id', how='left')\n# Features number\nfeature_names = list(filter(lambda x: x not in ['essay_id','score'], test_feats.columns))\nprint('Features number: ',len(feature_names))\ntest_feats.head(3)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T07:58:47.054733Z",
     "iopub.execute_input": "2024-04-09T07:58:47.055224Z",
     "iopub.status.idle": "2024-04-09T07:58:47.303949Z",
     "shell.execute_reply.started": "2024-04-09T07:58:47.055162Z",
     "shell.execute_reply": "2024-04-09T07:58:47.302486Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T06:54:15.203978Z",
     "start_time": "2024-05-18T06:54:15.103450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features number:  3360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6431/894338899.py:9: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('paragraph').map_elements(dataPreprocessing))\n",
      "/tmp/ipykernel_6431/894338899.py:12: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x)).alias(\"paragraph_len\"))\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "/tmp/ipykernel_6431/4199542533.py:9: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x)).alias(\"sentence_len\"))\n",
      "/tmp/ipykernel_6431/4199542533.py:15: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x.split(' '))).alias(\"sentence_word_cnt\"))\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "/tmp/ipykernel_6431/2451516412.py:9: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('word').map_elements(lambda x: len(x)).alias(\"word_len\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  essay_id  paragraph_50_cnt  paragraph_75_cnt  paragraph_100_cnt  \\\n",
       "0  000d118                 1                 1                  1   \n",
       "1  000fe60                 5                 5                  5   \n",
       "2  001ab80                 4                 4                  4   \n",
       "\n",
       "   paragraph_125_cnt  paragraph_150_cnt  paragraph_175_cnt  paragraph_200_cnt  \\\n",
       "0                  1                  1                  1                  1   \n",
       "1                  5                  5                  5                  4   \n",
       "2                  4                  4                  4                  4   \n",
       "\n",
       "   paragraph_250_cnt  paragraph_300_cnt  ...  tfid_3281  tfid_3282  tfid_3283  \\\n",
       "0                  1                  1  ...        0.0        0.0        0.0   \n",
       "1                  3                  3  ...        0.0        0.0        0.0   \n",
       "2                  4                  4  ...        0.0        0.0        0.0   \n",
       "\n",
       "   tfid_3284  tfid_3285  tfid_3286  tfid_3287  tfid_3288  tfid_3289  tfid_3290  \n",
       "0        0.0        0.0        0.0   0.034738   0.071064        0.0        0.0  \n",
       "1        0.0        0.0        0.0   0.000000   0.000000        0.0        0.0  \n",
       "2        0.0        0.0        0.0   0.000000   0.000000        0.0        0.0  \n",
       "\n",
       "[3 rows x 3361 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>paragraph_50_cnt</th>\n",
       "      <th>paragraph_75_cnt</th>\n",
       "      <th>paragraph_100_cnt</th>\n",
       "      <th>paragraph_125_cnt</th>\n",
       "      <th>paragraph_150_cnt</th>\n",
       "      <th>paragraph_175_cnt</th>\n",
       "      <th>paragraph_200_cnt</th>\n",
       "      <th>paragraph_250_cnt</th>\n",
       "      <th>paragraph_300_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>tfid_3281</th>\n",
       "      <th>tfid_3282</th>\n",
       "      <th>tfid_3283</th>\n",
       "      <th>tfid_3284</th>\n",
       "      <th>tfid_3285</th>\n",
       "      <th>tfid_3286</th>\n",
       "      <th>tfid_3287</th>\n",
       "      <th>tfid_3288</th>\n",
       "      <th>tfid_3289</th>\n",
       "      <th>tfid_3290</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034738</td>\n",
       "      <td>0.071064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3361 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": "prediction = test_feats[['essay_id']].copy()\nprediction['score'] = 0\npred_test = models[0].predict(test_feats[feature_names]) + a\nfor i in range(4):\n    pred_now = models[i+1].predict(test_feats[feature_names]) + a\n    pred_test = np.add(pred_test,pred_now)\n# 最终预测结果需要除以5，因为使用了5个模型的预测结果相加\n# The final prediction result needs to be divided by 5 because the prediction results of 5 models were added together\npred_test = pred_test/5\nprint(pred_test)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T07:58:47.305725Z",
     "iopub.execute_input": "2024-04-09T07:58:47.306253Z",
     "iopub.status.idle": "2024-04-09T07:58:47.401326Z",
     "shell.execute_reply.started": "2024-04-09T07:58:47.306221Z",
     "shell.execute_reply": "2024-04-09T07:58:47.400047Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T06:54:15.257320Z",
     "start_time": "2024-05-18T06:54:15.204572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0644339  2.98101418 4.59023141]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": "# 将预测结果四舍五入为整数，限定范围为1-6（文章评分范围）\n# Round the prediction result to an integer and limit it to a range of 1-6 (score range)\npred_test = pred_test.clip(1, 6).round()\nprediction['score'] = pred_test\nprediction.to_csv('submission.csv', index=False)\nprediction.head(3)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-09T07:58:47.403128Z",
     "iopub.execute_input": "2024-04-09T07:58:47.403575Z",
     "iopub.status.idle": "2024-04-09T07:58:47.421226Z",
     "shell.execute_reply.started": "2024-04-09T07:58:47.40353Z",
     "shell.execute_reply": "2024-04-09T07:58:47.420101Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T06:54:15.262840Z",
     "start_time": "2024-05-18T06:54:15.258552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  essay_id  score\n",
       "0  000d118    2.0\n",
       "1  000fe60    3.0\n",
       "2  001ab80    5.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": "## Reference Notebook\n#### I would like to give thanks to the authors of these public notebooks. I have learned a lot from you.\n* https://www.kaggle.com/code/davidjlochner/base-tfidf-lgbm\n* https://www.kaggle.com/code/yunsuxiaozi/aes2-0-baseline-naivebayesclassifier\n* https://www.kaggle.com/code/finlay/llm-detect-0-to-1\n* https://www.kaggle.com/code/awqatak/silver-bullet-single-model-165-features\n* https://www.kaggle.com/code/hiarsl/feature-engineering-sentence-paragraph-features\n* https://www.kaggle.com/code/rsakata/optimize-qwk-by-lgb/notebook#QWK-objective",
   "metadata": {}
  }
 ]
}
