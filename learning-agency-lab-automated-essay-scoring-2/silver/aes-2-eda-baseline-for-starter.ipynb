{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 71485,
     "databundleVersionId": 8059942,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30684,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFA500\"><b><span style='color:#FFA500'></span></b> <b>1. Initial Setting</b></div>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "#### <b><span style='color:#FFA500'> | </span> Import Libraries</b>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import os\nimport gc \nimport ctypes\nimport random\nimport time\nimport re\nimport copy\nfrom tqdm.auto import tqdm, trange\nfrom sklearn.decomposition import PCA\n\nimport pandas as pd, numpy as np\nimport polars as pl # For Feature Engineering\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\nos.environ['CUDA_VISIBLE_DEVICES'] = '0,1' # For GPU T4x2\n\nimport lightgbm as lgb\nfrom lightgbm import early_stopping, log_evaluation\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import cohen_kappa_score\n\nimport warnings \nwarnings.filterwarnings('ignore')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:03.575982Z",
     "iopub.execute_input": "2024-05-13T11:57:03.576347Z",
     "iopub.status.idle": "2024-05-13T11:57:07.350516Z",
     "shell.execute_reply.started": "2024-05-13T11:57:03.576316Z",
     "shell.execute_reply": "2024-05-13T11:57:07.349676Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### <b><span style='color:#FFA500'> | </span> Configure</b>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class CFG:\n    SEED = 2024\n    VER = 4\n    LOAD_MODELS_FROM = None\n    BASE_PATH = '/kaggle/input/learning-agency-lab-automated-essay-scoring-2/'",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:07.352065Z",
     "iopub.execute_input": "2024-05-13T11:57:07.352499Z",
     "iopub.status.idle": "2024-05-13T11:57:07.356839Z",
     "shell.execute_reply.started": "2024-05-13T11:57:07.352474Z",
     "shell.execute_reply": "2024-05-13T11:57:07.355876Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### <b><span style='color:#FFA500'> | </span> Clean Memory</b>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "Clean = True\n\ndef clean_memory():\n    if Clean:\n        ctypes.CDLL('libc.so.6').malloc_trim(0)\n        gc.collect()\n        \nclean_memory()        ",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:07.357887Z",
     "iopub.execute_input": "2024-05-13T11:57:07.358167Z",
     "iopub.status.idle": "2024-05-13T11:57:07.449159Z",
     "shell.execute_reply.started": "2024-05-13T11:57:07.358144Z",
     "shell.execute_reply": "2024-05-13T11:57:07.447985Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### <b><span style='color:#FFA500'> | </span> Seed Everything</b>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def seed_everything(): # To proudce simliar result in each run \n    random.seed(CFG.SEED)\n    np.random.seed(CFG.SEED)\n    os.environ['PYTHONHASHSEED'] = str(CFG.SEED)\n    \nseed_everything()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:07.451637Z",
     "iopub.execute_input": "2024-05-13T11:57:07.452105Z",
     "iopub.status.idle": "2024-05-13T11:57:07.458586Z",
     "shell.execute_reply.started": "2024-05-13T11:57:07.452072Z",
     "shell.execute_reply": "2024-05-13T11:57:07.457687Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFA500\"><b><span style='color:#FFA500'></span></b> <b>2. Road and Read Data</b></div>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "#### <b><span style='color:#FFA500'> | </span> Meta Data</b>\n\n\n- **`[train/test].csv`**\n  - `essay_id`: The unique ID of the essay\n  - `full_text`: The full essay reponse\n  - `score`: Holistic score of the essay on a 1-6 scale\n  \n  \n- **`sample_submission.csv`**\n  - `essay_id`: The unique ID of the essay\n  - `score`: The predicted holistic score of the essay on a 1-6 scale\n  \n  \n> [Link to the Holistic Scoring Rubric](https://storage.googleapis.com/kaggle-forum-message-attachments/2733927/20538/Rubric_%20Holistic%20Essay%20Scoring.pdf)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "#### <b><span style='color:#FFA500'> | </span> Train Data</b>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "df_train = pd.read_csv(CFG.BASE_PATH + 'train.csv')\n\nprint('Shape of Train: ', df_train.shape)\nprint(display(df_train.head()))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:07.459792Z",
     "iopub.execute_input": "2024-05-13T11:57:07.460042Z",
     "iopub.status.idle": "2024-05-13T11:57:08.805746Z",
     "shell.execute_reply.started": "2024-05-13T11:57:07.46002Z",
     "shell.execute_reply": "2024-05-13T11:57:08.804777Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df_train.info()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:08.807175Z",
     "iopub.execute_input": "2024-05-13T11:57:08.807566Z",
     "iopub.status.idle": "2024-05-13T11:57:08.829525Z",
     "shell.execute_reply.started": "2024-05-13T11:57:08.807532Z",
     "shell.execute_reply": "2024-05-13T11:57:08.828616Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "categorical_columns = df_train.select_dtypes(include=['object','category']).columns\ncategorical_summary = df_train[categorical_columns].describe()\ncategorical_summary",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:08.830673Z",
     "iopub.execute_input": "2024-05-13T11:57:08.830993Z",
     "iopub.status.idle": "2024-05-13T11:57:08.886748Z",
     "shell.execute_reply.started": "2024-05-13T11:57:08.83097Z",
     "shell.execute_reply": "2024-05-13T11:57:08.885896Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(12,6))\nsns.countplot(x=df_train['score'])\nplt.title('Distribution of Score')\nplt.xlabel('Score of Essay')\nplt.ylabel('Frequency')\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:08.887813Z",
     "iopub.execute_input": "2024-05-13T11:57:08.888109Z",
     "iopub.status.idle": "2024-05-13T11:57:09.163927Z",
     "shell.execute_reply.started": "2024-05-13T11:57:08.888083Z",
     "shell.execute_reply": "2024-05-13T11:57:09.162933Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "As you know, It seems like Score of Essay is imbalance. So I'm gonna use Cross Validation(Stratified CV)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "#### <b><span style='color:#FFA500'> | </span> Test Data</b>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "df_test = pd.read_csv(CFG.BASE_PATH + 'test.csv')\n\nprint('Shape of Test: ', df_test.shape)\nprint(display(df_test.head()))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:09.165346Z",
     "iopub.execute_input": "2024-05-13T11:57:09.165651Z",
     "iopub.status.idle": "2024-05-13T11:57:09.181598Z",
     "shell.execute_reply.started": "2024-05-13T11:57:09.165625Z",
     "shell.execute_reply": "2024-05-13T11:57:09.180699Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df_train.iloc[0].full_text",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:09.18602Z",
     "iopub.execute_input": "2024-05-13T11:57:09.186306Z",
     "iopub.status.idle": "2024-05-13T11:57:09.192505Z",
     "shell.execute_reply.started": "2024-05-13T11:57:09.186282Z",
     "shell.execute_reply": "2024-05-13T11:57:09.191437Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "ðŸ“Œ **Check Out**\n\n- 3 Test set is just placeholder\n- Public Test set is 30% of the test data\n- Private Test set is other 70% of the test data\n\n- The Private Score is based on other 70% of the test data, So it is different with public score ",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "#### <b><span style='color:#FFA500'> | </span> Pandas -> Polars</b>\n\nðŸ“Œ **Why Polars??**\n- Unlike DL, in ML, we have to make features\n- But, There are 17307 sample. So it will take times a lot \n- Polras is much effective than pandas when extracting features from data\n- Before Learning ML, we're gonna return to Pandas DataFrame(ex: df.to_pandas)\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# os.path.join(CFG.BASE_PATH,'train.csv')\n# CFG.BASE_PATH + 'train.csv'\n\ntrain = pl.from_pandas(df_train).with_columns(\n    pl.col('full_text').str.split(by='\\n\\n').alias('paragraph'))\ntest = pl.read_csv(os.path.join(CFG.BASE_PATH,'test.csv')).with_columns(\n    pl.col('full_text').str.split(by='\\n\\n').alias('paragraph')\n)\n\nschema_train = train.schema # MetaData\nschema_test = test.schema # MetaData",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:09.193759Z",
     "iopub.execute_input": "2024-05-13T11:57:09.194056Z",
     "iopub.status.idle": "2024-05-13T11:57:09.460234Z",
     "shell.execute_reply.started": "2024-05-13T11:57:09.194027Z",
     "shell.execute_reply": "2024-05-13T11:57:09.459192Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFA500\"><b><span style='color:#FFA500'></span></b> <b>3. Feature Engineering</b></div>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "#### <b><span style='color:#FFA500'> | </span> Preprocessing</b>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def removeHTML(x):\n    html = re.compile(r'<.*?>')\n    return html.sub(r'',x) # html -> ''\n\ndef dataPreprocessing(x):\n    \n    x = x.lower()\n    # remove html\n    x = removeHTML(x)\n    \n    #remove string with starting @\n    x = re.sub(\"@\\w+\",'',x)\n    \n    # remove number\n    x = re.sub(\"'\\d+\",'',x)\n    x = re.sub(\"\\d+\",'',x)\n    \n    # remove url\n    x = re.sub(\"http\\w+\",'',x)\n    \n    # Replace consecutive empty spaces with a single empty spaces\n    x = re.sub(r'\\s+', \" \", x)\n    \n    # Replace consecutive commas and periods with a single comma and period\n    x = re.sub(r'\\.+', \".\",x)\n    x = re.sub(r'\\,+', \".\",x)\n    # Remove empty character at the beginning and end\n    x = x.strip()\n    return x",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:09.462628Z",
     "iopub.execute_input": "2024-05-13T11:57:09.463044Z",
     "iopub.status.idle": "2024-05-13T11:57:09.469549Z",
     "shell.execute_reply.started": "2024-05-13T11:57:09.46301Z",
     "shell.execute_reply": "2024-05-13T11:57:09.468776Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### <b><span style='color:#FFA500'> | </span> Paragraph Features</b>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "paragraph_features = ['paragraph_len','paragraph_sentence_cnt','paragraph_word_cnt']\n\ndef Paragraph_Features(x):\n    # Expand the paragraph list to several lines of data\n    x = x.explode('paragraph') \n    \n    print('Paragraph Preprocessing')\n    x = x.with_columns(\n         pl.col('paragraph').map_elements(dataPreprocessing)\n    )\n    \n    print('Caculate the length of each paragraph')\n    x = x.with_columns(\n         pl.col('paragraph').map_elements(lambda x: len(x)).alias(\"paragraph_len\")\n    )\n    \n    print('Caculate the number of sentences and words in each paragraph')\n    x = x.with_columns(\n         pl.col('paragraph').map_elements(lambda x: len(x.split('.'))).alias('paragraph_sentence_cnt'),\n         pl.col('paragraph').map_elements(lambda x: len(x.split(' '))).alias('paragraph_word_cnt')\n    )\n    return x",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:09.471003Z",
     "iopub.execute_input": "2024-05-13T11:57:09.471471Z",
     "iopub.status.idle": "2024-05-13T11:57:09.4809Z",
     "shell.execute_reply.started": "2024-05-13T11:57:09.471446Z",
     "shell.execute_reply": "2024-05-13T11:57:09.48013Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%time\n\ntrain_feats = Paragraph_Features(train)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:09.482032Z",
     "iopub.execute_input": "2024-05-13T11:57:09.482544Z",
     "iopub.status.idle": "2024-05-13T11:57:15.642918Z",
     "shell.execute_reply.started": "2024-05-13T11:57:09.482517Z",
     "shell.execute_reply": "2024-05-13T11:57:15.641949Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(12,6))\ntmp = train_feats.to_pandas()\nsns.pairplot(data=tmp.drop(columns=['essay_id','full_text','paragraph']), hue='score', palette='bright')\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:15.644492Z",
     "iopub.execute_input": "2024-05-13T11:57:15.644914Z",
     "iopub.status.idle": "2024-05-13T11:57:53.385096Z",
     "shell.execute_reply.started": "2024-05-13T11:57:15.644868Z",
     "shell.execute_reply": "2024-05-13T11:57:53.383751Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(12,6))\nplt.subplot(1,3,1)\nsns.boxplot(y=tmp['paragraph_len'], x=tmp['score'])\nplt.title(\"Distribution of paragraph_len\")\nplt.xlabel('paragraph_len')\nplt.ylabel('Frequency')\n\nplt.subplot(1,3,2)\nsns.boxplot(y=tmp['paragraph_sentence_cnt'], x=tmp['score'])\nplt.title(\"Distribution of paragraph_sentence_cnt\")\nplt.xlabel('paragraph_sentence_cnt')\nplt.ylabel('Frequency')\n\n\nplt.subplot(1,3,3)\nsns.boxplot(y=tmp['paragraph_word_cnt'], x=tmp['score'])\nplt.title(\"Distribution of paragraph_word_cnt\")\nplt.xlabel('paragraph_word_cnt')\nplt.ylabel('Frequency')\n\n\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:53.386407Z",
     "iopub.execute_input": "2024-05-13T11:57:53.387235Z",
     "iopub.status.idle": "2024-05-13T11:57:54.264257Z",
     "shell.execute_reply.started": "2024-05-13T11:57:53.3872Z",
     "shell.execute_reply": "2024-05-13T11:57:54.26328Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def Paragraph_aggregation(x):    \n    \n    print('Aggregation')\n    aggs = [\n    *[pl.col('paragraph').filter(pl.col('paragraph_len') >= i).count().alias(f'paragraph_{i}_cnt') for i in [100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600]],\n    \n    *[pl.col(feat).max().alias(f'{feat}_max') for feat in paragraph_features],\n    *[pl.col(feat).mean().alias(f'{feat}_mean') for feat in paragraph_features],\n    *[pl.col(feat).min().alias(f'{feat}_min') for feat in paragraph_features],\n    *[pl.col(feat).std().alias(f'{feat}_std') for feat in paragraph_features],\n    *[pl.col(feat).sum().alias(f'{feat}_sum') for feat in paragraph_features],\n    ]\n    \n    df = x.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n    \n    df = df.to_pandas() # polars -> pandas\n    \n    return df",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:54.265433Z",
     "iopub.execute_input": "2024-05-13T11:57:54.265774Z",
     "iopub.status.idle": "2024-05-13T11:57:54.274285Z",
     "shell.execute_reply.started": "2024-05-13T11:57:54.265739Z",
     "shell.execute_reply": "2024-05-13T11:57:54.273169Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%time\n\ntrain_feats = Paragraph_aggregation(train_feats)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:54.275372Z",
     "iopub.execute_input": "2024-05-13T11:57:54.27563Z",
     "iopub.status.idle": "2024-05-13T11:57:54.337061Z",
     "shell.execute_reply.started": "2024-05-13T11:57:54.275608Z",
     "shell.execute_reply": "2024-05-13T11:57:54.336331Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(12,6))\ntmp = train_feats.merge(df_train.drop(columns='full_text'), on='essay_id',  how='left') \ntmp = tmp.drop(columns='essay_id')\nfor i, col in enumerate(tmp.columns):\n    plt.subplot(3,3,i+1)\n    for idx in range(1,7):\n        sns.kdeplot(x=tmp[tmp['score']==idx][col], label=idx)\n        plt.legend()\n    if i == 8: break\nplt.tight_layout()\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:57:54.338082Z",
     "iopub.execute_input": "2024-05-13T11:57:54.338553Z",
     "iopub.status.idle": "2024-05-13T11:57:58.692694Z",
     "shell.execute_reply.started": "2024-05-13T11:57:54.338526Z",
     "shell.execute_reply": "2024-05-13T11:57:58.691688Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(12,6))\nplt.title('Correlation of Paragraph Feature with score')\ntmp = train_feats.merge(df_train.drop(columns='full_text'), on='essay_id',  how='left') \ntmp = tmp.drop(columns='essay_id')\nsns.heatmap(tmp.corr(), annot=True, cmap='coolwarm', fmt='.1f')\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:59:41.902218Z",
     "iopub.execute_input": "2024-05-13T11:59:41.903147Z",
     "iopub.status.idle": "2024-05-13T11:59:43.833457Z",
     "shell.execute_reply.started": "2024-05-13T11:59:41.903102Z",
     "shell.execute_reply": "2024-05-13T11:59:43.832481Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### <b><span style='color:#FFA500'> | </span> Sentence Features</b>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "sentence_features = ['sentence_len','sentence_word_cnt']\n\ndef Sentence_Features(x):\n    print('Preprocess full_text and use periods to segment sentences in the text')\n    x = x.with_columns(\n        pl.col('full_text').map_elements(lambda x: dataPreprocessing(x)).str.split(\".\").alias('sentence')\n    )\n    x = x.explode('sentence')\n    \n    print('Caculate the length of a sentence') \n    x = x.with_columns(\n        pl.col('sentence').map_elements(lambda x: len(x)).alias('sentence_len'))\n    \n    print('Count the number of words in each sentence')\n    x = x.with_columns(\n        pl.col('sentence').map_elements(lambda x: len(x.split(\" \"))).alias(\"sentence_word_cnt\"))\n\n    return x",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:58:00.81165Z",
     "iopub.execute_input": "2024-05-13T11:58:00.811978Z",
     "iopub.status.idle": "2024-05-13T11:58:00.818745Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%time \n\ntrain_feats2 = Sentence_Features(train)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:58:00.819835Z",
     "iopub.execute_input": "2024-05-13T11:58:00.820105Z",
     "iopub.status.idle": "2024-05-13T11:58:07.076793Z",
     "shell.execute_reply.started": "2024-05-13T11:58:00.820082Z",
     "shell.execute_reply": "2024-05-13T11:58:07.075691Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(12,6))\ntmp = train_feats2.to_pandas()\nsns.pairplot(data=tmp.drop(columns=['essay_id','full_text','sentence','paragraph']), hue='score', palette='bright')\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:58:07.078009Z",
     "iopub.execute_input": "2024-05-13T11:58:07.078314Z",
     "iopub.status.idle": "2024-05-13T11:59:25.873269Z",
     "shell.execute_reply.started": "2024-05-13T11:58:07.078289Z",
     "shell.execute_reply": "2024-05-13T11:59:25.872272Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\nsns.boxplot(y=tmp['sentence_len'], x=tmp['score'])\nplt.title(\"Distribution of sentence_len\")\nplt.xlabel('sentence_len')\nplt.ylabel('Frequency')\n\nplt.subplot(1,2,2)\nsns.boxplot(y=tmp['sentence_word_cnt'], x=tmp['score'])\nplt.title(\"Distribution of sentence_word_cnt\")\nplt.xlabel('sentence_word_cnt')\nplt.ylabel('Frequency')\n\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:59:25.874891Z",
     "iopub.execute_input": "2024-05-13T11:59:25.87567Z",
     "iopub.status.idle": "2024-05-13T11:59:26.494552Z",
     "shell.execute_reply.started": "2024-05-13T11:59:25.875634Z",
     "shell.execute_reply": "2024-05-13T11:59:26.493839Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def Sentence_aggregation(x):    \n    \n    print('Aggregation')\n    aggs = [\n    *[pl.col('sentence').filter(pl.col('sentence_len') >= i).count().alias(f'sentence_{i}_cnt') for i in [5,10,15,25,30,40,50,60,70,80,90,100]],\n    \n    *[pl.col(feat).max().alias(f'{feat}_max') for feat in sentence_features],\n    *[pl.col(feat).mean().alias(f'{feat}_mean') for feat in sentence_features],\n    *[pl.col(feat).min().alias(f'{feat}_min') for feat in sentence_features],\n    *[pl.col(feat).std().alias(f'{feat}_std') for feat in sentence_features],\n    *[pl.col(feat).sum().alias(f'{feat}_sum') for feat in sentence_features],   \n    ]\n    \n    df = x.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n    \n    df = df.to_pandas() # polars -> pandas\n    \n    return df",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:59:26.495791Z",
     "iopub.execute_input": "2024-05-13T11:59:26.496336Z",
     "iopub.status.idle": "2024-05-13T11:59:26.503976Z",
     "shell.execute_reply.started": "2024-05-13T11:59:26.49631Z",
     "shell.execute_reply": "2024-05-13T11:59:26.502788Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_feats2 = Sentence_aggregation(train_feats2)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:59:26.505266Z",
     "iopub.execute_input": "2024-05-13T11:59:26.505791Z",
     "iopub.status.idle": "2024-05-13T11:59:26.594979Z",
     "shell.execute_reply.started": "2024-05-13T11:59:26.50576Z",
     "shell.execute_reply": "2024-05-13T11:59:26.593944Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(12,6))\ntmp = train_feats2.merge(df_train.drop(columns='full_text'), on='essay_id',  how='left') \ntmp = tmp.drop(columns='essay_id')\nfor i, col in enumerate(tmp.columns):\n    plt.subplot(3,3,i+1)\n    for idx in range(1,7):\n        sns.kdeplot(x=tmp[tmp['score']==idx][col], label=idx)\n        plt.legend()\n    if i == 8: break\nplt.tight_layout()\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T12:00:00.440002Z",
     "iopub.execute_input": "2024-05-13T12:00:00.440982Z",
     "iopub.status.idle": "2024-05-13T12:00:04.73351Z",
     "shell.execute_reply.started": "2024-05-13T12:00:00.440942Z",
     "shell.execute_reply": "2024-05-13T12:00:04.732734Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(12,6))\nplt.title('Correlation of Sentence Feature with score')\ntmp = train_feats2.merge(df_train.drop(columns='full_text'), on='essay_id',  how='left') \ntmp = tmp.drop(columns='essay_id')\nsns.heatmap(tmp.corr(), annot=True, cmap='coolwarm', fmt='.1f')\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:59:30.930785Z",
     "iopub.execute_input": "2024-05-13T11:59:30.931201Z",
     "iopub.status.idle": "2024-05-13T11:59:32.520311Z",
     "shell.execute_reply.started": "2024-05-13T11:59:30.931163Z",
     "shell.execute_reply": "2024-05-13T11:59:32.519595Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### <b><span style='color:#FFA500'> | </span> Word Features</b>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "word_features = ['word_len',]\n\ndef Word_Features(x):\n    print('Preprocess full_text and use spaces to seperate words fro the text')\n    x = x.with_columns(\n        pl.col('full_text').map_elements(lambda x: dataPreprocessing(x)).str.split(\" \").alias('word')\n    )\n    x = x.explode('word')\n    \n    print('Caculate the length of a word') \n    x = x.with_columns(\n        pl.col('word').map_elements(lambda x: len(x)).alias('word_len'))\n    \n\n    return x",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:59:32.521396Z",
     "iopub.execute_input": "2024-05-13T11:59:32.521847Z",
     "iopub.status.idle": "2024-05-13T11:59:32.527887Z",
     "shell.execute_reply.started": "2024-05-13T11:59:32.521822Z",
     "shell.execute_reply": "2024-05-13T11:59:32.526538Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%time\n\ntrain_feats3 = Word_Features(train)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T12:00:20.903397Z",
     "iopub.execute_input": "2024-05-13T12:00:20.905939Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(12,6))\ntmp = train_feats3.to_pandas()\nsns.pairplot(data=tmp.drop(columns=['essay_id','full_text','sentence','paragraph','word']), hue='score', palette='bright')\nplt.show()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(12,6))\nsns.boxplot(y=tmp['word_len'], x=tmp['score'])\nplt.title(\"Distribution of word_len\")\nplt.xlabel('word_len')\nplt.ylabel('Frequency')\n\nplt.show()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def Word_aggregation(x):    \n    \n    print('Aggregation')\n    aggs = [\n    *[pl.col('word').filter(pl.col('word_len') >= i).count().alias(f'sentence_{i}_cnt') for i in [2.0,2.5,3.0,3.5,4.0,4.5,5.0,6.0]],\n    \n    *[pl.col(feat).max().alias(f'{feat}_max') for feat in word_features],\n    *[pl.col(feat).mean().alias(f'{feat}_mean') for feat in word_features],\n    *[pl.col(feat).min().alias(f'{feat}_min') for feat in word_features],\n    *[pl.col(feat).std().alias(f'{feat}_std') for feat in word_features],\n    *[pl.col(feat).sum().alias(f'{feat}_sum') for feat in word_features],   \n    ]\n    \n    df = x.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n    \n    df = df.to_pandas() # polars -> pandas\n    \n    return df",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_feats3 = Word_aggregation(train_feats3)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(12,6))\ntmp = train_feats3.merge(df_train.drop(columns='full_text'), on='essay_id',  how='left') \ntmp = tmp.drop(columns='essay_id')\nfor i, col in enumerate(tmp.columns):\n    plt.subplot(3,3,i+1)\n    for idx in range(1,7):\n        sns.kdeplot(x=tmp[tmp['score']==idx][col], label=idx)\n        plt.legend()\n    if i == 8: break\nplt.tight_layout()\nplt.show()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(12,6))\nplt.title('Correlation of Word Feature with score')\ntmp = train_feats3.merge(df_train.drop(columns='full_text'), on='essay_id',  how='left') \ntmp = tmp.drop(columns='essay_id')\nsns.heatmap(tmp.corr(), annot=True, cmap='coolwarm', fmt='.1f')\nplt.show()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### <b><span style='color:#FFA500'> | </span> Tf-idf features</b>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "tmp = train.with_columns(pl.col('full_text').map_elements(lambda x: dataPreprocessing(x)))",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# TfidfVectorizer parameter\nvectorizer = TfidfVectorizer(\n    tokenizer = lambda x: x,\n    preprocessor = lambda x: x,\n    token_pattern=None,\n    strip_accents='unicode',\n    analyzer= 'word',\n    ngram_range = (1,3),\n    min_df =0.05,\n    max_df=0.95,\n    sublinear_tf = True # Term Frequency Log Scaling \n)\n\n\n# Fit all datasets into TfidfVectorizer\ntrain_tfid = vectorizer.fit_transform([i for i in tmp['full_text']])\n\n              \n# Convert to array\ndense_matrix = train_tfid.toarray()\n\n# Convert to dataframe\ndf = pd.DataFrame(dense_matrix)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df['essay_id'] = df_train['essay_id'].values\n\nplt.figure(figsize=(12,6))\ntmp = df.merge(df_train.drop(columns='full_text'), on='essay_id',  how='left') \ntmp = tmp.drop(columns='essay_id')\n\nfor i in range(1,7):\n    plt.subplot(2,3,i)\n    sns.boxplot(x=tmp['score'] ,y = tmp[i])\n\nplt.show()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(14,10))\n\nplt.title(\"Histogram of TfidfVectorizer\")\nfor i in range(6):\n    plt.subplot(2,3,i+1)\n    plt.hist(x=df[i], bins=30, color='red', edgecolor='black')\n    \nplt.show()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFA500\"><b><span style='color:#FFA500'></span></b> <b>4. Save train.csv</b></div>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train = train_feats.merge(train_feats2, on='essay_id', how='left')\ntrain = train.merge(train_feats3, on='essay_id', how='left')\ntrain = train.merge(df, on='essay_id', how='left')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:59:39.013877Z",
     "iopub.status.idle": "2024-05-13T11:59:39.014187Z",
     "shell.execute_reply.started": "2024-05-13T11:59:39.014031Z",
     "shell.execute_reply": "2024-05-13T11:59:39.014045Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train.to_csv('train.csv', index=None)\ndisplay(train.head())",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-13T11:59:39.015109Z",
     "iopub.status.idle": "2024-05-13T11:59:39.015756Z",
     "shell.execute_reply.started": "2024-05-13T11:59:39.015571Z",
     "shell.execute_reply": "2024-05-13T11:59:39.015587Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
