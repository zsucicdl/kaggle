{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 71485,
     "databundleVersionId": 8059942,
     "sourceType": "competition"
    },
    {
     "sourceId": 8181806,
     "sourceType": "datasetVersion",
     "datasetId": 4838426
    }
   ],
   "dockerImageVersionId": 30683,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "Training: [https://www.kaggle.com/code/hashidoyuto/text-clustering-deberta-aes2-0/notebook](https://www.kaggle.com/code/hashidoyuto/text-clustering-deberta-aes2-0/notebook)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# Import & Config",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import os\nimport random\nimport glob\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset\n\nwarnings.simplefilter('ignore')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-21T06:52:26.961079Z",
     "iopub.execute_input": "2024-04-21T06:52:26.961759Z",
     "iopub.status.idle": "2024-04-21T06:52:49.191861Z",
     "shell.execute_reply.started": "2024-04-21T06:52:26.961722Z",
     "shell.execute_reply": "2024-04-21T06:52:49.190915Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class PATHS:\n    test_path = '/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv'\n    model_dir = '/kaggle/input/groupkfold-deberta-aes2-0/'",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-21T06:56:20.356918Z",
     "iopub.execute_input": "2024-04-21T06:56:20.357323Z",
     "iopub.status.idle": "2024-04-21T06:56:20.363194Z",
     "shell.execute_reply.started": "2024-04-21T06:56:20.357295Z",
     "shell.execute_reply": "2024-04-21T06:56:20.361397Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class CFG:\n    max_length = 512\n    num_labels = 6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-21T06:55:17.810289Z",
     "iopub.execute_input": "2024-04-21T06:55:17.810667Z",
     "iopub.status.idle": "2024-04-21T06:55:17.816991Z",
     "shell.execute_reply.started": "2024-04-21T06:55:17.810637Z",
     "shell.execute_reply": "2024-04-21T06:55:17.816059Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Define Tokenization & Load Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class Tokenize(object):\n    def __init__(self, test, model_path):\n        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n        self.test = test\n        \n    def get_dataset(self, df):\n        ds = Dataset.from_dict({\n                'essay_id': [e for e in df['essay_id']],\n                'full_text': [ft for ft in df['full_text']]\n            })\n        return ds\n        \n    def tokenize_function(self, example):\n        tokenized_inputs = self.tokenizer(\n            example['full_text'], truncation=True, max_length=CFG.max_length\n        )\n        return tokenized_inputs\n    \n    def __call__(self):\n        test_ds = self.get_dataset(self.test)\n        \n        tokenized_test = test_ds.map(\n            self.tokenize_function, batched=True\n        )\n        return tokenized_test, self.tokenizer",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-21T06:55:23.082658Z",
     "iopub.execute_input": "2024-04-21T06:55:23.083261Z",
     "iopub.status.idle": "2024-04-21T06:55:23.090448Z",
     "shell.execute_reply.started": "2024-04-21T06:55:23.083231Z",
     "shell.execute_reply": "2024-04-21T06:55:23.089221Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "test = pd.read_csv(PATHS.test_path)\n\nmodel_paths = glob.glob(PATHS.model_dir + '*fold*')\nmodel_paths.sort()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-21T06:56:24.488551Z",
     "iopub.execute_input": "2024-04-21T06:56:24.488927Z",
     "iopub.status.idle": "2024-04-21T06:56:24.503831Z",
     "shell.execute_reply.started": "2024-04-21T06:56:24.488902Z",
     "shell.execute_reply": "2024-04-21T06:56:24.50283Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Inference",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "predictions = []\nfor i, model_path in enumerate(model_paths):\n    tokenize = Tokenize(test, model_path)\n    tokenized_test, tokenizer = tokenize()\n    \n    model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=CFG.num_labels)\n    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n    \n    training_args = TrainingArguments(\n    \".\",\n    per_device_eval_batch_size=1,\n    report_to=\"none\",\n    fp16=True\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        data_collator=data_collator,\n        tokenizer=tokenizer,\n    )\n    \n    pre_preds = trainer.predict(tokenized_test).predictions\n    predictions.append(pre_preds)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-21T07:15:04.089356Z",
     "iopub.execute_input": "2024-04-21T07:15:04.089794Z",
     "iopub.status.idle": "2024-04-21T07:15:38.073405Z",
     "shell.execute_reply.started": "2024-04-21T07:15:04.089761Z",
     "shell.execute_reply": "2024-04-21T07:15:38.072281Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Hand in Submission",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "final_pred = np.array(0)\nfor p in predictions:\n    final_pred = final_pred + p\nfinal_pred = final_pred / 5\nfinal_pred = final_pred.argmax(axis=1) + 1\n\nsubmission = pd.DataFrame({\n    'essay_id': test['essay_id'].values,\n    'score': final_pred\n})\nsubmission.to_csv('submission.csv', index=False)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-21T07:21:54.389332Z",
     "iopub.execute_input": "2024-04-21T07:21:54.389733Z",
     "iopub.status.idle": "2024-04-21T07:21:54.400305Z",
     "shell.execute_reply.started": "2024-04-21T07:21:54.389707Z",
     "shell.execute_reply": "2024-04-21T07:21:54.399087Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "submission",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-21T07:21:54.705633Z",
     "iopub.execute_input": "2024-04-21T07:21:54.706742Z",
     "iopub.status.idle": "2024-04-21T07:21:54.719834Z",
     "shell.execute_reply.started": "2024-04-21T07:21:54.706681Z",
     "shell.execute_reply": "2024-04-21T07:21:54.718655Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
