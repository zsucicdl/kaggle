{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"},{"sourceId":1164617,"sourceType":"datasetVersion","datasetId":659784},{"sourceId":3712905,"sourceType":"datasetVersion","datasetId":2220792},{"sourceId":4610416,"sourceType":"datasetVersion","datasetId":2680195},{"sourceId":177531229,"sourceType":"kernelVersion"}],"dockerImageVersionId":30699,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Feature from Feedback Competion","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/omegaconf\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-14T05:00:53.342495Z","iopub.execute_input":"2024-05-14T05:00:53.3429Z","iopub.status.idle":"2024-05-14T05:00:53.354664Z","shell.execute_reply.started":"2024-05-14T05:00:53.342866Z","shell.execute_reply":"2024-05-14T05:00:53.353767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# basics\nimport os\nimport sys\nimport json\nfrom copy import deepcopy\nfrom itertools import chain\nfrom omegaconf import OmegaConf\n\n# Processing\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm.auto import tqdm\n\n# ipython\nfrom IPython.display import display\nfrom IPython.core.debugger import set_trace","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:00:53.356392Z","iopub.execute_input":"2024-05-14T05:00:53.356978Z","iopub.status.idle":"2024-05-14T05:00:53.987371Z","shell.execute_reply.started":"2024-05-14T05:00:53.356945Z","shell.execute_reply":"2024-05-14T05:00:53.986362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile create_datasets_main.py\n\nimport sys\nsys.path.append(\"../input/omegaconf\")\n\nimport os\nimport json\nimport re\nimport argparse\nfrom copy import deepcopy\n\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset, load_from_disk\nfrom tokenizers import AddedToken\nfrom transformers import AutoTokenizer\nfrom omegaconf import OmegaConf\n\n#--------------- Tokenizer ---------------------------------------------#\nNEW_TOKENS = [\n    \"[LF]\",\n]\n\ndef get_tokenizer(cfg):\n    \"\"\"load the tokenizer\"\"\"\n    tokenizer_path = cfg.model.backbone_path\n    print(f\"loading tokenizer from {tokenizer_path}\")\n    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n\n    # NEW TOKENS\n    print(\"adding new tokens...\")\n    tokens_to_add = []\n    for this_tok in NEW_TOKENS:\n        tokens_to_add.append(AddedToken(this_tok, lstrip=False, rstrip=False))\n    tokenizer.add_tokens(tokens_to_add)\n\n    print(f\"tokenizer len: {len(tokenizer)}\")\n    test_string = \"This is a test \\n [LF]!\"\n    tokenized_string = tokenizer.tokenize(test_string)\n    print(f\"tokenizer test: {tokenized_string}\")\n    return tokenizer\n\n#--------------- Dataset ----------------------------------------------#\n\n\nclass FeedbackDataset:\n    \"\"\"Dataset class for feedback prize effectiveness task\n    \"\"\"\n    def __init__(self, cfg):\n        # assign config\n        self.cfg = cfg\n\n        # label columns\n        self.target_names = cfg.model.target_names\n\n        # load tokenizer\n        self.load_tokenizer()\n\n\n    def load_tokenizer(self):\n        self.tokenizer = get_tokenizer(self.cfg)\n\n    def pre_process(self, df):\n        df[\"full_text\"] = df[\"full_text\"].apply(lambda x: re.sub(re.compile(r'\\n\\n'), \" [LF] \", x))\n        return df\n\n    def tokenize_function(self, examples):\n        tz = self.tokenizer(\n            examples[\"full_text\"],\n            padding=False,\n            truncation=True,\n            max_length=self.cfg.model.max_length,\n            add_special_tokens=True,\n            return_token_type_ids=True,\n        )\n        return tz\n\n    def compute_input_length(self, examples):\n        return {\"input_length\": [len(x) for x in examples[\"input_ids\"]]}\n\n    def get_dataset(self, df, mode='train'):\n        \"\"\"main api for creating the Feedback dataset\n        :param df: input annotation dataframe\n        :type df: pd.DataFrame\n        :param mode: check if required for train or infer, defaults to 'train'\n        :type mode: str, optional\n        :return: the created dataset\n        :rtype: Dataset\n        \"\"\"\n        df = self.pre_process(df)\n\n        print(f\"sample text:\")\n        print(\"==\"*40)\n        print(df.sample().full_text.values[0])\n        print(\"==\"*40)\n\n        task_dataset = Dataset.from_pandas(df)\n        task_dataset = task_dataset.map(self.tokenize_function, batched=True)\n        task_dataset = task_dataset.map(self.compute_input_length, batched=True)\n        try:\n            task_dataset = task_dataset.remove_columns(column_names=[\"__index_level_0__\"])\n        except Exception as e:\n            print(e)\n        return task_dataset\n\nif __name__ == \"__main__\":\n    ap = argparse.ArgumentParser()\n    ap.add_argument('--config_path', type=str, required=True)\n    ap.add_argument('--save_path', type=str, required=True)\n    ap.add_argument('--rank', type=int, required=True)\n    args = ap.parse_args()\n    \n    # read configuration\n    cfg = OmegaConf.load(args.config_path)\n    cfg_dict = OmegaConf.to_container(cfg, resolve=True)\n    print(\"==\"*40)\n    print(json.dumps(cfg_dict, indent=4))\n    print(\"==\"*40)\n    \n    # create the dataset\n    print(\"creating the dataset...\")\n    df = pd.read_csv(cfg.infer_params.input_path)\n    if \"train\" in cfg.infer_params.input_path:\n        df = df\n    # double test set to ensure successfully run in public mode.\n    if df.shape[0] < 10:\n        df = pd.concat([df, df], axis=0).reset_index(drop=True)\n    n_samples = len(df)\n    n_rank = 4\n    n_part_1 = n_samples // n_rank\n    n_part_2 = n_samples - n_part_1 * (n_rank - 1)\n\n    if args.rank < (n_rank - 1):\n        df = df.head(n_part_1 * (args.rank + 1)).tail(n_part_1).reset_index(drop=True)\n    elif args.rank == (n_rank - 1):\n        df = df.tail(n_part_2).reset_index(drop=True)\n\n    elif args.rank == n_rank:\n        df = df\n    print(df.head())\n    dataset_creator = FeedbackDataset(cfg)\n    infer_ds = dataset_creator.get_dataset(df, mode=\"infer\")\n    \n    # save dataset\n    infer_ds.save_to_disk(args.save_path.format(rank=args.rank))\n    \n    print(\"done!\")\n    print(\"==\"*40)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:00:53.989119Z","iopub.execute_input":"2024-05-14T05:00:53.989945Z","iopub.status.idle":"2024-05-14T05:00:54.000639Z","shell.execute_reply.started":"2024-05-14T05:00:53.989912Z","shell.execute_reply":"2024-05-14T05:00:53.999643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile fb_model_main.py\n\nimport pdb\nfrom copy import deepcopy\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.checkpoint\nfrom transformers import AutoConfig, AutoModel, BertConfig\nfrom transformers.models.bert.modeling_bert import BertAttention\n\n\n#-------- Model ------------------------------------------------------------------#\n\n\nclass MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n\n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n\n\nclass FeatureExtractor(nn.Module):\n    \"\"\"\n    extract features from backbone outputs\n        - multi-head attention mechanism\n        - weighted average of top transformer layers\n    \"\"\"\n\n    def __init__(self, config):\n        super(FeatureExtractor, self).__init__()\n\n        self.config = config\n        self.num_layers = config[\"num_layers\"]\n        self.num_features = config[\"hidden_size\"]\n\n        #------------ weighted-average ---------------------------------------------------#\n        init_amax = 5\n        weight_data = torch.linspace(-init_amax, init_amax, self.num_layers)\n        # weight_data = torch.tensor([1] * self.num_layers, dtype=torch.float)\n        weight_data = weight_data.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n        self.weights = nn.Parameter(weight_data, requires_grad=True)\n\n        #------------ multi-head attention -----------------------------------------------#\n        attention_config = BertConfig()\n        attention_config.update(\n            {\n                \"num_attention_heads\": 4,  # 4,\n                \"hidden_size\": self.num_features,\n                \"attention_probs_dropout_prob\": 0.0,\n                \"hidden_dropout_prob\": 0.0,\n                \"is_decoder\": False,\n            }\n        )\n        self.mha_layer_norm = nn.LayerNorm(self.num_features, 1e-7)\n        self.attention = BertAttention(attention_config, position_embedding_type=\"absolute\")\n\n        #------------ mean-pooling ------------------------------------------------------#\n        self.pool = MeanPooling()\n\n        #------------ Layer Normalization ------------------------------------------------#\n        self.layer_norm = nn.LayerNorm(self.num_features, 1e-7)\n\n    def forward(self, backbone_outputs, attention_mask):\n\n        #------------ Output Transformation ----------------------------------------------#\n        x = torch.stack(backbone_outputs.hidden_states[-self.num_layers:])\n        w = F.softmax(self.weights, dim=0)\n        encoder_layer = (w * x).sum(dim=0)  # (bs, max_len, hidden_size)\n\n        #------------ Multi-head attention  ----------------------------------------------#\n        extended_attention_mask = attention_mask[:, None, None, :]\n        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n        encoder_layer = self.mha_layer_norm(encoder_layer)\n        encoder_layer = self.attention(encoder_layer, extended_attention_mask)[0]\n\n        #------------ mean-pooling  ------------------------------------------------------#\n        features = self.pool(encoder_layer, attention_mask)  # mean pooling\n\n        #------------ layer-normalization  -----------------------------------------------#\n        features = self.layer_norm(features)  # (bs, num_features)\n\n        return features\n\n# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n# Model\n# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n\n\nclass FeedbackModel(nn.Module):\n    \"\"\"\n    The feedback-ells model with separate task specific heads\n    \"\"\"\n\n    def __init__(self, config):\n        print(\"initializing the feedback model...\")\n\n        super(FeedbackModel, self).__init__()\n        config = config[\"model\"]\n        self.config = config\n        self.target_names = config[\"target_names\"]\n        self.num_targets = len(self.target_names)\n\n        #----------------------------- Backbone -----------------------------------------#\n        backbone_config = AutoConfig.from_pretrained(self.config[\"backbone_path\"])\n        backbone_config.update(\n            {\n                \"hidden_dropout_prob\": 0.0,\n                \"attention_probs_dropout_prob\": 0.0,\n                \"use_cache\": False,\n            }\n        )\n\n        self.backbone = AutoModel.from_pretrained(self.config[\"backbone_path\"], config=backbone_config)\n\n        # resize model embeddings\n        print(\"resizing model embeddings...\")\n        print(f\"tokenizer length = {config['len_tokenizer']}\")\n        self.backbone.resize_token_embeddings(config[\"len_tokenizer\"])\n\n\n        #----------------------------- Feature Extractor ---------------------------------#\n        hidden_size = num_features = self.backbone.config.hidden_size\n        config[\"feature_extractor\"][\"hidden_size\"] = hidden_size\n\n        self.feature_extractors = nn.ModuleList(\n            [\n                FeatureExtractor(config[\"feature_extractor\"]) for i in range(self.num_targets)\n            ]\n        )\n\n        #----------------------------- Classifiers -------------------------------------#\n        self.classifiers = nn.ModuleList(\n            [\n                nn.Linear(num_features, 1) for i in range(self.num_targets)\n            ]\n        )\n\n    def encode(self, input_ids, attention_mask, token_type_ids):\n        outputs = self.backbone(\n            input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            output_hidden_states=True,\n        )\n        features = [extractor(outputs, attention_mask) for extractor in self.feature_extractors]\n        embeddings = torch.stack(features, dim=1)  # (batch, num_targets, num_features)\n\n        return embeddings\n\n    def forward(\n        self,\n        input_ids,\n        attention_mask,\n        token_type_ids,\n        labels=None,\n        aux_labels=None,\n        **kwargs\n    ):\n\n        # features\n        features = self.encode(\n            input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n        )  # (bs, num_targets, num_features)\n\n        # logits\n        logits = [classifier(features[:, idx]) for idx, classifier in enumerate(self.classifiers)]\n        logits = torch.cat(logits, dim=-1)  # (bs, num_features)\n\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:00:54.003344Z","iopub.execute_input":"2024-05-14T05:00:54.003701Z","iopub.status.idle":"2024-05-14T05:00:54.020905Z","shell.execute_reply.started":"2024-05-14T05:00:54.003669Z","shell.execute_reply":"2024-05-14T05:00:54.019959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile run_inference_main.py\nimport time\n\nt0 = time.perf_counter()\n\nimport sys\nsys.path.append(\"../input/omegaconf\")\n\nimport argparse\nimport gc\nimport json\nimport sys\nfrom dataclasses import dataclass\nfrom itertools import chain\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.utils.checkpoint\nfrom accelerate import Accelerator\nfrom datasets import load_from_disk\nfrom omegaconf import OmegaConf\nfrom tokenizers import AddedToken\nfrom torch.utils.data import DataLoader\nfrom tqdm.auto import tqdm\nfrom transformers import AutoTokenizer, DataCollatorWithPadding\n\n#### \ntry:\n    from fb_model_main import FeedbackModel\n\nexcept Exception as e:\n    print(e)\n    raise ImportError\n\n#--------------- Tokenizer ---------------------------------------------#\nNEW_TOKENS = [\n    \"[LF]\",\n]\n\n\ndef get_tokenizer(cfg):\n    \"\"\"load the tokenizer\"\"\"\n    tokenizer_path = cfg.model.backbone_path\n    print(f\"loading tokenizer from {tokenizer_path}\")\n    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n\n    # NEW TOKENS\n    print(\"adding new tokens...\")\n    tokens_to_add = []\n    for this_tok in NEW_TOKENS:\n        tokens_to_add.append(AddedToken(this_tok, lstrip=False, rstrip=False))\n    tokenizer.add_tokens(tokens_to_add)\n\n    print(f\"tokenizer len: {len(tokenizer)}\")\n\n    test_string = \"This is a test \\n [LF]!\"\n    tokenized_string = tokenizer.tokenize(test_string)\n    print(f\"tokenizer test: {tokenized_string}\")\n    return tokenizer\n\n#------ DataLoader --------------------------------------------------------------#\n\n@dataclass\nclass CustomDataCollatorWithPadding(DataCollatorWithPadding):\n    \"\"\"\n    data collector for seq classification\n    \"\"\"\n\n    tokenizer = None\n    padding = True\n    max_length = None\n    pad_to_multiple_of = None\n    return_tensors = \"pt\"\n\n    def __call__(self, features):\n        labels = None\n        if \"labels\" in features[0].keys():\n            labels = [feature[\"labels\"] for feature in features]\n\n        batch = self.tokenizer.pad(\n            features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors=None,\n        )\n\n        if labels is not None:\n            batch[\"labels\"] = labels\n\n        batch = {k: (torch.tensor(v, dtype=torch.float32) if k in [\"labels\", \"aux_labels\"] else torch.tensor(\n            v, dtype=torch.int64)) for k, v in batch.items()}\n        return batch\n\n\n#------ Inference Function ------------------------------------------------------#\ndef inference_fn(model, infer_dl):\n    all_preds = []\n    \n    accelerator = Accelerator()\n    model, infer_dl = accelerator.prepare(model, infer_dl)\n    model.eval()\n    \n    tk0 = tqdm(infer_dl, total=len(infer_dl))\n    for batch in tk0:\n        with torch.no_grad():\n            preds = model(**batch)                \n        all_preds.append(preds)\n\n    all_preds = [p.to('cpu').detach().numpy().tolist() for p in all_preds]\n    all_preds = np.array(list(chain(*all_preds)))   \n    \n    print(\"preds:\")\n    print(all_preds[0, :])\n    print(\"==\"*40)\n    return all_preds\n\n\n##################################################################################\n# Execution\n##################################################################################\n\nif __name__ == \"__main__\":\n    #--------------- config -----------------------------------------------------#\n    ap = argparse.ArgumentParser()\n    ap.add_argument('--config_path', type=str, required=True)\n    ap.add_argument('--dataset_path', type=str, required=True)\n    ap.add_argument('--checkpoints', nargs='+', type=str, required=True)\n    ap.add_argument('--save_path', type=str, required=True)\n    ap.add_argument('--num_thread', type=int, required=False, default=1)\n    args = ap.parse_args()\n    # ======= set 1 cpu ====== #\n    if args.num_thread > 0:\n        torch.set_num_threads(args.num_thread)\n    \n    # print(args.checkpoints)\n    \n    # read configuration\n    cfg = OmegaConf.load(args.config_path)\n    cfg_dict = OmegaConf.to_container(cfg, resolve=True)\n    print(\"==\"*40)\n    print(json.dumps(cfg_dict, indent=4))\n    print(\"==\"*40)\n    \n    #--------------- inputs ----------------------------------------------------#\n    # load the dataset\n    print(\"loading the dataset...\")\n    infer_ds = load_from_disk(args.dataset_path)\n    print(\"done!\")\n    \n    print(\"creating the dataloader...\")\n    tokenizer = get_tokenizer(cfg)\n    cfg_dict[\"model\"][\"len_tokenizer\"] = len(tokenizer)\n    data_collector = CustomDataCollatorWithPadding(tokenizer=tokenizer)\n\n    # sort valid dataset for faster evaluation\n    infer_ds = infer_ds.sort(\"input_length\")\n    SORTED_TEXT_IDS = infer_ds[\"essay_id\"]\n\n    infer_ds.set_format(\n        type=None,\n        columns=['input_ids', 'attention_mask', 'token_type_ids']\n    )\n\n    infer_dl = DataLoader(\n        infer_ds,\n        batch_size=cfg.infer_params.infer_bs,\n        shuffle=False,\n        collate_fn=data_collector,\n    )\n    print(\"data preparation done...\")\n    print(\"==\"*40)\n    \n    #--------------- inference ----------------------------------------------#\n    list_preds = []\n    for model_id, checkpoint in enumerate(args.checkpoints):\n        print(f\"infering from {checkpoint}\")\n\n        model = FeedbackModel(cfg_dict)\n        ckpt = torch.load(checkpoint, map_location=torch.device('cpu'))\n        print(f\"validation score for fold {model_id} = {ckpt['lb']}\")\n\n        model.load_state_dict(ckpt['state_dict'], strict=False)\n        ckpt_preds = inference_fn(model, infer_dl)\n        list_preds.append(ckpt_preds)\n    \n    # clean up\n    del model, infer_dl\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    # aggregation\n    if cfg.infer_params.agg_fn == \"mean\":\n        model_preds = np.mean(list_preds, axis=0)\n    else:\n        raise NotImplementedError\n        \n    preds_df = pd.DataFrame()\n    preds_df[\"essay_id\"] = SORTED_TEXT_IDS\n    \n    TARGET_NAMES = cfg.model.target_names\n    num_targets = len(TARGET_NAMES)\n\n    for i in range(num_targets):\n        preds_df[TARGET_NAMES[i]] = model_preds[:, i]\n        \n    # print\n    print(preds_df.head())\n        \n    # save predictions\n    print(f\"saving predictions to {args.save_path}\")\n    preds_df.to_csv(args.save_path, index=False)\n    import time\n    print(f\"done! {time.perf_counter() - t0:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:00:54.022543Z","iopub.execute_input":"2024-05-14T05:00:54.02291Z","iopub.status.idle":"2024-05-14T05:00:54.040209Z","shell.execute_reply.started":"2024-05-14T05:00:54.022877Z","shell.execute_reply":"2024-05-14T05:00:54.039229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os \nos.makedirs(\"./datasets\", exist_ok=True)\nos.makedirs(\"./predictions\", exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:00:54.042418Z","iopub.execute_input":"2024-05-14T05:00:54.043106Z","iopub.status.idle":"2024-05-14T05:00:54.053498Z","shell.execute_reply.started":"2024-05-14T05:00:54.043074Z","shell.execute_reply":"2024-05-14T05:00:54.052566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile eff_inference.yaml\n\nmodel:\n    backbone_path: /kaggle/input/debertav3xsmall/deberta-v3-xsmall\n    feature_extractor:\n        num_layers: 4\n    max_length: 448\n    target_names:\n        - cohesion\n        - syntax\n        - vocabulary\n        - phraseology\n        - grammar\n        - conventions\n    len_tokenizer: ???\n    loss_fn: mse\n\ninfer_params:\n    input_path: ../input/learning-agency-lab-automated-essay-scoring-2/test.csv\n    infer_bs: 4\n    agg_fn: mean","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:00:54.055235Z","iopub.execute_input":"2024-05-14T05:00:54.055549Z","iopub.status.idle":"2024-05-14T05:00:54.064138Z","shell.execute_reply.started":"2024-05-14T05:00:54.055519Z","shell.execute_reply":"2024-05-14T05:00:54.063176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n!python create_datasets_main.py \\\n--config_path eff_inference.yaml \\\n--save_path ./datasets/task_dataset_{rank} \\\n--rank=0","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:00:54.065386Z","iopub.execute_input":"2024-05-14T05:00:54.065751Z","iopub.status.idle":"2024-05-14T05:01:04.578203Z","shell.execute_reply.started":"2024-05-14T05:00:54.065705Z","shell.execute_reply":"2024-05-14T05:01:04.576943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n!python create_datasets_main.py \\\n--config_path eff_inference.yaml \\\n--save_path ./datasets/task_dataset_{rank} \\\n--rank=1","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:01:04.582668Z","iopub.execute_input":"2024-05-14T05:01:04.583035Z","iopub.status.idle":"2024-05-14T05:01:11.299655Z","shell.execute_reply.started":"2024-05-14T05:01:04.583005Z","shell.execute_reply":"2024-05-14T05:01:11.298408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python create_datasets_main.py \\\n--config_path eff_inference.yaml \\\n--save_path ./datasets/task_dataset_{rank} \\\n--rank=2","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:01:11.301028Z","iopub.execute_input":"2024-05-14T05:01:11.301343Z","iopub.status.idle":"2024-05-14T05:01:18.03743Z","shell.execute_reply.started":"2024-05-14T05:01:11.301312Z","shell.execute_reply":"2024-05-14T05:01:18.036458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python create_datasets_main.py \\\n--config_path eff_inference.yaml \\\n--save_path ./datasets/task_dataset_{rank} \\\n--rank=3","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:01:18.038748Z","iopub.execute_input":"2024-05-14T05:01:18.039023Z","iopub.status.idle":"2024-05-14T05:01:24.791473Z","shell.execute_reply.started":"2024-05-14T05:01:18.038997Z","shell.execute_reply":"2024-05-14T05:01:24.790409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile run.sh\n# export OMP_SCHEDULE=STATIC\n# export OMP_PROC_BIND=CLOSE\n# export GOMP_CPU_AFFINITY=\"N-M\"\n# export KMP_AFFINITY=granularity=fine,proclist=[0-0],explicit\npython run_inference_main.py \\\n--config_path eff_inference.yaml \\\n--dataset_path ./datasets/task_dataset_0 \\\n--checkpoints \\\n    /kaggle/input/eff-xsmall-448/eff_full_xsmall_448.pth.tar \\\n--save_path ./predictions/eff_preds_0.csv \\\n--num_thread 1 &\n\npython run_inference_main.py \\\n--config_path eff_inference.yaml \\\n--dataset_path ./datasets/task_dataset_1 \\\n--checkpoints \\\n    /kaggle/input/eff-xsmall-448/eff_full_xsmall_448.pth.tar \\\n--save_path ./predictions/eff_preds_1.csv \\\n--num_thread 1 &\n\npython run_inference_main.py \\\n--config_path eff_inference.yaml \\\n--dataset_path ./datasets/task_dataset_2 \\\n--checkpoints \\\n    /kaggle/input/eff-xsmall-448/eff_full_xsmall_448.pth.tar \\\n--save_path ./predictions/eff_preds_2.csv &\n\npython run_inference_main.py \\\n--config_path eff_inference.yaml \\\n--dataset_path ./datasets/task_dataset_3 \\\n--checkpoints \\\n    /kaggle/input/eff-xsmall-448/eff_full_xsmall_448.pth.tar \\\n--save_path ./predictions/eff_preds_3.csv &\n\nwait \necho \"All done\"","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:01:24.793194Z","iopub.execute_input":"2024-05-14T05:01:24.793588Z","iopub.status.idle":"2024-05-14T05:01:24.801436Z","shell.execute_reply.started":"2024-05-14T05:01:24.79355Z","shell.execute_reply":"2024-05-14T05:01:24.800604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sh run.sh","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:01:24.802534Z","iopub.execute_input":"2024-05-14T05:01:24.802896Z","iopub.status.idle":"2024-05-14T05:02:02.511249Z","shell.execute_reply.started":"2024-05-14T05:01:24.80286Z","shell.execute_reply":"2024-05-14T05:02:02.509981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eff_df_0 = pd.read_csv(\"./predictions/eff_preds_0.csv\")\n# eff_df_0 = eff_df_0.reset_index(drop=True)\n\neff_df_1 = pd.read_csv(\"./predictions/eff_preds_1.csv\")\neff_df_2 = pd.read_csv(\"./predictions/eff_preds_2.csv\")\neff_df_3 = pd.read_csv(\"./predictions/eff_preds_3.csv\")\n# eff_df_1 = eff_df_1.reset_index(drop=True)\n\neff_df = pd.concat([eff_df_0, eff_df_1, eff_df_2, eff_df_3], axis=0)\neff_df = eff_df.sort_values(by=\"essay_id\")\neff_df = eff_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:02:02.51357Z","iopub.execute_input":"2024-05-14T05:02:02.513911Z","iopub.status.idle":"2024-05-14T05:02:02.534857Z","shell.execute_reply.started":"2024-05-14T05:02:02.513878Z","shell.execute_reply":"2024-05-14T05:02:02.53413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_WEIGHTS = [1.0] #[0.34, 0.33, 0.33]\nprint(f\"sum of weights {np.sum(MODEL_WEIGHTS)}\")\n\nsubmission_df = pd.DataFrame()\n\npred_dfs  = [  \n    eff_df,\n]\n\nTARGET_COLS = [\"cohesion\", \"syntax\", \"vocabulary\", \"phraseology\", \"grammar\", \"conventions\"]\n\nsubmission_df[\"essay_id\"] =  pred_dfs[0][\"essay_id\"].values\nfor model_idx, model_preds in enumerate(pred_dfs):\n    if model_idx == 0:\n        for target in TARGET_COLS:\n            submission_df[target]  =  MODEL_WEIGHTS[model_idx] * model_preds[target]\n    else:\n        for target in TARGET_COLS:\n            submission_df[target]  +=  MODEL_WEIGHTS[model_idx] * model_preds[target] \n\neff_df\neff_df = eff_df.drop_duplicates(subset=['essay_id'], keep='first')\neff_df","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:02:02.536017Z","iopub.execute_input":"2024-05-14T05:02:02.536299Z","iopub.status.idle":"2024-05-14T05:02:02.566125Z","shell.execute_reply.started":"2024-05-14T05:02:02.536274Z","shell.execute_reply":"2024-05-14T05:02:02.565311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## feature engineering for text","metadata":{}},{"cell_type":"code","source":"import re\nimport polars as pl\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\nfrom sklearn.ensemble import VotingClassifier,VotingRegressor\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import cohen_kappa_score\nfrom tqdm.auto import tqdm,trange\nfrom lightgbm import log_evaluation, early_stopping\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score, classification_report\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:02:02.567125Z","iopub.execute_input":"2024-05-14T05:02:02.567394Z","iopub.status.idle":"2024-05-14T05:02:06.631943Z","shell.execute_reply.started":"2024-05-14T05:02:02.56737Z","shell.execute_reply":"2024-05-14T05:02:06.630951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:02:06.633045Z","iopub.execute_input":"2024-05-14T05:02:06.633332Z","iopub.status.idle":"2024-05-14T05:02:06.637583Z","shell.execute_reply.started":"2024-05-14T05:02:06.633306Z","shell.execute_reply":"2024-05-14T05:02:06.63671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FeatureEngineering():\n    def __init__(self):\n        self.columns = [\n            (pl.col(\"full_text\").str.split(by=\"\\n\\n\").alias(\"paragraph\"))\n        ]\n        self.train_dataset = pl.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv').with_columns(self.columns)\n        self.test_dataset = pl.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv').with_columns(self.columns)\n        # feature_eng\n        self.sentence_fea = ['sentence_len','sentence_word_cnt']\n        # feature_eng\n        self.paragraph_fea = ['paragraph_len','paragraph_sentence_cnt','paragraph_word_cnt']\n        self.vectorizer = TfidfVectorizer(tokenizer=lambda x: x,\n                                          preprocessor=lambda x: x,\n                                          token_pattern=None,\n                                          strip_accents='unicode',\n                                          analyzer = 'word',\n                                          ngram_range=(2,3),\n                                          min_df=0.05,\n                                          max_df=0.9,\n                                          sublinear_tf=True  \n        )\n    def removeHTML(self,x):\n        html=re.compile(r'<.*?>')\n        return html.sub(r'',x)\n    def dataPreprocessing(self,x):\n        x = x.lower()             # covert all letter to lower form\n        x = self.removeHTML(x)\n        x = re.sub(\"@\\w+\", '',x)\n        x = re.sub(\"'\\d+\", '',x)\n        x = re.sub(\"\\d+\", '',x)\n        x = re.sub(\"http\\w+\", '',x)\n        x = re.sub(r\"\\s+\", \" \",x) # replace any sequence of whitespace characters with a sigle whitespace\n        x = re.sub(r\"\\.+\", \".\",x) # replace any sequence of periods with a sigle periods\n        x = re.sub(r\"\\,+\", \",\",x) # replace any sequence of commas with a sigle comma\n        x = x.strip()\n        return x \n    def Paragraph_Preprocess(self,tmp):\n        tmp = tmp.explode('paragraph')\n        # preprocess\n        tmp = tmp.with_columns(pl.col('paragraph').map_elements(self.dataPreprocessing))\n        # paragraph_len\n        tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x:len(x)).alias(\"paragraph_len\"))\n        # filter\n        tmp = tmp.filter(pl.col('paragraph_len')>=25)\n        # paragraph_sentence_count/paragraph_word_count\n        tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x.split(\".\"))).alias(\"paragraph_sentence_cnt\"),\n                               pl.col('paragraph').map_elements(lambda x: len(x.split(\" \"))).alias(\"paragraph_word_cnt\")\n                              )\n        return tmp\n    def Paragraph_Eng(self,train_tmp):\n        aggs = [\n            # paragraph_len_cnt\n            *[pl.col('paragraph').filter(pl.col('paragraph_len')>=i)\n            .count().alias(f'paragraph_{i}_cnt') for i in [25,100,200,300,400,500,600,700]],\n            # other\n            *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in self.paragraph_fea],\n            *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in self.paragraph_fea],\n            *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in self.paragraph_fea],\n            *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in self.paragraph_fea],\n            *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in self.paragraph_fea],\n        ]\n        df = train_tmp.group_by([\"essay_id\"], maintain_order=True).agg(aggs).sort(\"essay_id\")\n        df = df.to_pandas()\n        print(\"done Paragraph_Eng +\",len(df.columns),\"features\")\n        return df\n    def Sentence_Preprocess(self,tmp):\n        tmp = tmp.with_columns(pl.col('full_text').map_elements(self.dataPreprocessing).str.split(by=\".\").alias(\"sentence\"))\n        tmp = tmp.explode('sentence')\n        # sentence_len\n        tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x)).alias(\"sentence_len\"))\n        # filter\n        tmp = tmp.filter(pl.col('sentence_len')>=15)\n        # sentence_word_cnt\n        tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x.split(' '))).alias(\"sentence_word_cnt\"))\n\n        return tmp\n    def Sentence_Eng(self,train_tmp):\n        aggs = [\n            # sentence_cnt\n            *[pl.col('sentence').filter(pl.col('sentence_len') >= i).count().alias(f\"sentence_{i}_cnt\") for i in [15,50,100,150,200,250,300] ], \n            # other\n            *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in self.sentence_fea],\n            *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in self.sentence_fea],\n            *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in self.sentence_fea],\n            *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in self.sentence_fea],\n            *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in self.sentence_fea],\n            ]\n        df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n        df = df.to_pandas()\n        print(\"done Sentence_Eng +\",len(df.columns),\"features\")\n        return df\n    # word feature\n    def Word_Preprocess(self,tmp):\n        tmp = tmp.with_columns(pl.col('full_text').map_elements(self.dataPreprocessing).str.split(by=\" \").alias(\"word\"))\n        tmp = tmp.explode('word')\n        # word_len\n        tmp = tmp.with_columns(pl.col('word').map_elements(lambda x: len(x)).alias(\"word_len\"))\n        # filter\n        tmp = tmp.filter(pl.col('word_len')!=0)\n\n        return tmp\n    # feature_eng\n    def Word_Eng(self,train_tmp):\n        aggs = [\n            # word_cnt\n            *[pl.col('word').filter(pl.col('word_len') >= i+1)\n              .count().alias(f\"word_{i+1}_cnt\") for i in range(15)], \n            # other\n            pl.col('word_len').max().alias(f\"word_len_max\"),\n            pl.col('word_len').mean().alias(f\"word_len_mean\"),\n            pl.col('word_len').std().alias(f\"word_len_std\"),\n            pl.col('word_len').quantile(0.25).alias(f\"word_len_q1\"),\n            pl.col('word_len').quantile(0.50).alias(f\"word_len_q2\"),\n            pl.col('word_len').quantile(0.75).alias(f\"word_len_q3\"),\n        ]\n        df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n        df = df.to_pandas()\n        print(\"done Word_Eng +\",len(df.columns),\"features\")\n        return df\n    def process(self):\n        tmp = self.Paragraph_Preprocess(self.train_dataset)\n        train_feats = self.Paragraph_Eng(tmp)\n        train_feats['score'] = self.train_dataset['score']\n        \n        tmp = self.Sentence_Preprocess(self.train_dataset)\n        train_feats = train_feats.merge(self.Sentence_Eng(tmp), on='essay_id', how='left')\n        \n        tmp = self.Word_Preprocess(self.train_dataset)\n        train_feats = train_feats.merge(self.Word_Eng(tmp), on='essay_id', how='left')\n        \n        train_tfid = self.vectorizer.fit_transform([i for i in self.train_dataset['full_text']])\n        dense_matrix = train_tfid.toarray()\n        df = pd.DataFrame(dense_matrix)\n        tfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\n        df.columns = tfid_columns\n#         print(df)\n#         print(\"----------------------------------------------------------\")\n        df['essay_id'] = train_feats['essay_id']\n        # merge\n        train_feats = train_feats.merge(df, on='essay_id', how='left')\n        print('feature_num: ',len(train_feats.columns)-2)\n        return train_feats\n    def process_test(self):\n        temp = self.Paragraph_Preprocess(self.test_dataset)\n        test_feats = self.Paragraph_Eng(temp)\n        \n        temp = self.Sentence_Preprocess(self.test_dataset)\n        test_feats = test_feats.merge(self.Sentence_Eng(temp), on='essay_id', how='left')\n        \n        temp = self.Word_Preprocess(self.test_dataset)\n        test_feats = test_feats.merge(self.Word_Eng(temp), on='essay_id', how='left')\n        \n        test_tfid = self.vectorizer.transform([i for i in self.test_dataset['full_text']])\n        dense_matrix = test_tfid.toarray()\n        df = pd.DataFrame(dense_matrix)\n        tfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\n        df.columns = tfid_columns\n#         print(df)\n        df['essay_id'] = test_feats['essay_id']\n        # merge\n        test_feats = test_feats.merge(df, on='essay_id', how='left')\n        print('feature_num: ',len(test_feats.columns)-2)\n        \n        return test_feats","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:02:06.638934Z","iopub.execute_input":"2024-05-14T05:02:06.639226Z","iopub.status.idle":"2024-05-14T05:02:06.793799Z","shell.execute_reply.started":"2024-05-14T05:02:06.639202Z","shell.execute_reply":"2024-05-14T05:02:06.792893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LGBM():\n    def __init__(self):\n        self.data_train = pl.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv')\n        self.data_test = pl.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv')\n        self.num_models = 3\n        self.acc_metrics = []\n        self.cohen_metrics = []\n        \n        # coef for cohen kappa score\n        self.a = 2.948\n        self.b = 1.092\n        \n        self.lgb_parameters = {  \n                                 'metrics': 'None',\n                                 'objective': self.qwk_obj,\n                                 'learning_rate': 0.05,\n                                 'max_depth': 5,\n                                 'num_leaves': 10, # should be a number smaller than \"max_depth\"^2\n                                 'colsample_bytree': 0.3,\n                                 'min_data_in_leaf': 100,\n                                 'reg_alpha': 0.7,\n                                 'reg_lambda' : 0.1,\n                                 'n_estimators': 700,\n                                 'extra_trees' : True,\n                                 'verbosity': -100,\n#                                  'device' : \"gpu\"\n        }\n        self.model = VotingRegressor(\n            estimators = [\n                            (f\"lgb_{i}\",lgb.LGBMRegressor(**self.lgb_parameters, random_state=i+40),)for i in range(self.num_models)\n                         ],\n                        n_jobs=-1\n        )\n        \n    def quadratic_weighted_kappa(self,y_true,y_pred):\n        y_true = y_true + self.a\n        y_pred = (y_pred + self.a).clip(1,6).round()\n#         print(y_true)\n#         print(y_pred)\n        qwk = cohen_kappa_score(y_true,y_pred,weights='quadratic')\n        \n        return \"QWK\",qwk,True\n    def qwk_obj(self,y_true,y_pred):\n        labels = y_true + self.a\n        preds = y_pred + self.a\n        preds = preds.clip(1,6)\n        f = 1/2 * np.sum((preds-labels)**2)\n        g = 1/2 * np.sum((preds-self.a)**2+self.b)\n        df = preds - labels\n        dg = preds - self.a\n        grad = (df/g - f*dg/g**2)*len(labels)\n        hess = np.ones(len(labels))\n        \n        return grad,hess\n    def split_folds(self, df):\n        feature_names = [col for col in df.columns if col not in ['essay_id', 'score']]\n        x = df[feature_names].values\n        y = df['score'].values\n        \n        kfold = KFold(n_splits=5, random_state=44, shuffle=True)\n        \n        return kfold.split(x, y)\n    \n    def fit(self, df,debug=False):\n        folds = self.split_folds(df)\n\n        for fold_id, (trn_idx, val_idx) in enumerate(folds):\n            if fold_id != 0 and debug==True:\n                break \n\n            X_train, X_val = df.iloc[trn_idx][feature_names], df.iloc[val_idx][feature_names]\n            Y_train, Y_val = df.iloc[trn_idx]['score'] - self.a, df.iloc[val_idx]['score'] - self.a\n            \n            print(f'\\nFold_{fold_id} Training ================================\\n')\n            \n            self.model.fit(X_train, Y_train)\n            pred_val = self.model.predict(X_val)\n            \n            df_tmp = df.iloc[val_idx][['essay_id', 'score']].copy()\n            df_tmp['pred'] = pred_val\n            \n            # plot confusion matrix\n            y_true = Y_val.values+np.ones_like(Y_val.shape)*self.a\n            y_pred = (pred_val + np.ones_like(pred_val)*self.a).clip(1,6).round()\n            cm = confusion_matrix(y_true,y_pred)\n            sns.heatmap(cm, \n                        annot=True,\n                        fmt='g', \n                        xticklabels=['1','2','3','4','5','6'],\n                        yticklabels=['1','2','3','4','6','6'])\n            plt.ylabel('Prediction',fontsize=13)\n            plt.xlabel('Actual',fontsize=13)\n            plt.title('Confusion Matrix',fontsize=17)\n            plt.show()\n                                  \n            cohen_score = self.quadratic_weighted_kappa(Y_val.values, df_tmp['pred'])\n            self.cohen_metrics.append(cohen_score[1])\n\n        average_cohen = np.mean(self.cohen_metrics)\n        print(f'Average Cohen all fold: {average_cohen:.4f}')\n    def save_model(self):\n        pass\n    def predict(self,df):\n        feature_names = list(filter(lambda x: x not in ['essay_id','score'], df.columns))\n        \n        predictions = self.model.predict(df[feature_names])\n        predictions += self.a\n        predictions = predictions.clip(1,6).round()\n#         predictions = self.model.predict(df[feature_names])\n        return predictions\n    def submit(self,df):\n        feature_names = list(filter(lambda x: x not in ['essay_id'], df.columns))\n        return self.data_test.select('essay_id').with_columns(score = (self.model.predict(df[feature_names])+self.a).clip(1, 6).round())","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:02:06.795316Z","iopub.execute_input":"2024-05-14T05:02:06.795672Z","iopub.status.idle":"2024-05-14T05:02:06.819893Z","shell.execute_reply.started":"2024-05-14T05:02:06.795639Z","shell.execute_reply":"2024-05-14T05:02:06.818956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FE = FeatureEngineering()\ntrain_feature = FE.process()\ntest_feature = FE.process_test()\ntest_feature = pd.merge(test_feature,eff_df,on='essay_id')\ntest_feature.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:02:06.820976Z","iopub.execute_input":"2024-05-14T05:02:06.821234Z","iopub.status.idle":"2024-05-14T05:03:47.389593Z","shell.execute_reply.started":"2024-05-14T05:02:06.821212Z","shell.execute_reply":"2024-05-14T05:03:47.388652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_feature = test_feature.drop(['essay_id'],axis=1)\ntest_feature","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:04:12.493237Z","iopub.execute_input":"2024-05-14T05:04:12.493597Z","iopub.status.idle":"2024-05-14T05:04:12.518994Z","shell.execute_reply.started":"2024-05-14T05:04:12.493567Z","shell.execute_reply":"2024-05-14T05:04:12.517968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## predict","metadata":{}},{"cell_type":"code","source":"from joblib import load\nmodel = load(f'/kaggle/input/train-lgbm-extra-feature-from-feedback-comp/saved_models/model.joblib')","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:04:22.803481Z","iopub.execute_input":"2024-05-14T05:04:22.803852Z","iopub.status.idle":"2024-05-14T05:06:34.514157Z","shell.execute_reply.started":"2024-05-14T05:04:22.803815Z","shell.execute_reply":"2024-05-14T05:06:34.507606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(test_feature)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:06:34.518393Z","iopub.execute_input":"2024-05-14T05:06:34.518876Z","iopub.status.idle":"2024-05-14T05:06:34.680995Z","shell.execute_reply.started":"2024-05-14T05:06:34.51883Z","shell.execute_reply":"2024-05-14T05:06:34.67976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## submission","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv')\nsubmission['score'] = pred\nsubmission['score']=submission['score'].astype(int)\nsubmission.to_csv(\"submission.csv\",index=None)\ndisplay(submission.head())","metadata":{"execution":{"iopub.status.busy":"2024-05-14T05:08:16.004551Z","iopub.execute_input":"2024-05-14T05:08:16.005253Z","iopub.status.idle":"2024-05-14T05:08:16.021912Z","shell.execute_reply.started":"2024-05-14T05:08:16.005222Z","shell.execute_reply":"2024-05-14T05:08:16.020989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}