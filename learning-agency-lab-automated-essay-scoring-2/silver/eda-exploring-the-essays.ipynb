{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 71485,
     "databundleVersionId": 8059942,
     "sourceType": "competition"
    },
    {
     "sourceId": 6374367,
     "sourceType": "datasetVersion",
     "datasetId": 3673005
    },
    {
     "sourceId": 6507976,
     "sourceType": "datasetVersion",
     "datasetId": 3762650
    },
    {
     "sourceId": 3693646,
     "sourceType": "datasetVersion",
     "datasetId": 2210196
    }
   ],
   "dockerImageVersionId": 30673,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Exploring the Essays\n\nIn this notebook, we perform some initial EDA on the essays. We will examine how the essays look like for various scores, then do some feature engineering to extract some meta-properties from the essays.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "!pip install -q autocorrect==1.1.0 pyspellchecker sentence-transformers py_readability_metrics",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T20:45:52.387863Z",
     "iopub.execute_input": "2024-04-03T20:45:52.389363Z",
     "iopub.status.idle": "2024-04-03T20:46:14.944609Z",
     "shell.execute_reply.started": "2024-04-03T20:45:52.389318Z",
     "shell.execute_reply": "2024-04-03T20:46:14.943009Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport pandas as pd\nfrom pandas.api.types import is_numeric_dtype\nimport re\nimport random\nimport string\nimport shutil\nimport warnings\nimport logging\nimport gc\nfrom tqdm.autonotebook import tqdm\nfrom collections import Counter\n\nfrom IPython.display import display, Markdown\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tag import pos_tag\nfrom nltk.tokenize import word_tokenize\nfrom autocorrect import Speller\nfrom spellchecker import SpellChecker\nfrom readability import Readability\n# import spacy\nfrom textblob import TextBlob\n\nfrom transformers import AutoTokenizer",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-04-03T21:14:11.563806Z",
     "iopub.execute_input": "2024-04-03T21:14:11.564425Z",
     "iopub.status.idle": "2024-04-03T21:14:11.577244Z",
     "shell.execute_reply.started": "2024-04-03T21:14:11.564379Z",
     "shell.execute_reply": "2024-04-03T21:14:11.575418Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "np.random.seed(42)\ntqdm.pandas()\n\nwarnings.simplefilter(\"ignore\")\n\nsns.set_palette('crest')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T21:18:04.627817Z",
     "iopub.execute_input": "2024-04-03T21:18:04.628853Z",
     "iopub.status.idle": "2024-04-03T21:18:04.63973Z",
     "shell.execute_reply.started": "2024-04-03T21:18:04.628794Z",
     "shell.execute_reply": "2024-04-03T21:18:04.63778Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df_train = pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\")\ndf_train.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T20:46:23.428987Z",
     "iopub.execute_input": "2024-04-03T20:46:23.42995Z",
     "iopub.status.idle": "2024-04-03T20:46:24.525794Z",
     "shell.execute_reply.started": "2024-04-03T20:46:23.429887Z",
     "shell.execute_reply": "2024-04-03T20:46:24.52421Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df_train.info()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T20:46:24.527749Z",
     "iopub.execute_input": "2024-04-03T20:46:24.528472Z",
     "iopub.status.idle": "2024-04-03T20:46:24.568645Z",
     "shell.execute_reply.started": "2024-04-03T20:46:24.528435Z",
     "shell.execute_reply": "2024-04-03T20:46:24.567426Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "SAMPLES_TESTING = None\n\nif SAMPLES_TESTING != None:\n    df_train = df_train.sample(SAMPLES_TESTING)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T20:46:24.571863Z",
     "iopub.execute_input": "2024-04-03T20:46:24.572312Z",
     "iopub.status.idle": "2024-04-03T20:46:24.584362Z",
     "shell.execute_reply.started": "2024-04-03T20:46:24.572279Z",
     "shell.execute_reply": "2024-04-03T20:46:24.582806Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df_train.shape",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T20:54:40.016796Z",
     "iopub.execute_input": "2024-04-03T20:54:40.01809Z",
     "iopub.status.idle": "2024-04-03T20:54:40.026782Z",
     "shell.execute_reply.started": "2024-04-03T20:54:40.01804Z",
     "shell.execute_reply": "2024-04-03T20:54:40.025437Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "ax = sns.countplot(data=df_train, x='score')\nax.set_title(\"Distribution of score\")\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T20:46:24.58658Z",
     "iopub.execute_input": "2024-04-03T20:46:24.5871Z",
     "iopub.status.idle": "2024-04-03T20:46:24.924689Z",
     "shell.execute_reply.started": "2024-04-03T20:46:24.587054Z",
     "shell.execute_reply": "2024-04-03T20:46:24.923411Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "scores = range(1,7)\n\ndef _display(t):\n    display(Markdown(t))\n\ndef display_essay(row):\n    _display(f\"**Essay {row['essay_id']}** (score = {row['score']})\")\n    _display(row['full_text'])\n\nnum_to_sample = 10\nfor score in scores:\n    _display(f\"# Sample Essays for Score = {score}\")\n    sample = df_train[df_train['score'] == score].sample(num_to_sample)\n    for i, row in sample.iterrows():\n        display_essay(row)\n        display()",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2024-04-03T20:46:24.926485Z",
     "iopub.execute_input": "2024-04-03T20:46:24.92685Z",
     "iopub.status.idle": "2024-04-03T20:46:26.255158Z",
     "shell.execute_reply.started": "2024-04-03T20:46:24.926818Z",
     "shell.execute_reply": "2024-04-03T20:46:26.253483Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Feature Engineering\n\nCode is modified from my CommonLit student summaries utility script: https://www.kaggle.com/code/mcpenguin/utility-commonlit-student-summaries#Feature-Engineering",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# word difficulty\nword_difficulty = pd.read_csv(\"/kaggle/input/word-difficulty/word-difficulty.csv\")\ndifficult_words_list = word_difficulty.loc[word_difficulty['I_Zscore'] > 0]\ndifficult_words_list = difficult_words_list.Word.unique().tolist()\ndifficult_words_list[:20]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T20:47:08.855811Z",
     "iopub.execute_input": "2024-04-03T20:47:08.856387Z",
     "iopub.status.idle": "2024-04-03T20:47:08.990815Z",
     "shell.execute_reply.started": "2024-04-03T20:47:08.856348Z",
     "shell.execute_reply": "2024-04-03T20:47:08.989018Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# nltk pos tags\ntags_df = pd.read_csv(\"/kaggle/input/ntlk-pos-tags/tags.csv\")\ntags_df.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T20:47:08.993686Z",
     "iopub.execute_input": "2024-04-03T20:47:08.994188Z",
     "iopub.status.idle": "2024-04-03T20:47:09.024861Z",
     "shell.execute_reply.started": "2024-04-03T20:47:08.994147Z",
     "shell.execute_reply": "2024-04-03T20:47:09.023355Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# set of stop words\nSTOP_WORDS = set(stopwords.words('english'))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T20:47:09.027186Z",
     "iopub.execute_input": "2024-04-03T20:47:09.028811Z",
     "iopub.status.idle": "2024-04-03T20:47:09.044384Z",
     "shell.execute_reply.started": "2024-04-03T20:47:09.028754Z",
     "shell.execute_reply": "2024-04-03T20:47:09.042174Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "USE_AUTOCORRECT = False",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T20:51:41.640076Z",
     "iopub.execute_input": "2024-04-03T20:51:41.640752Z",
     "iopub.status.idle": "2024-04-03T20:51:41.648462Z",
     "shell.execute_reply.started": "2024-04-03T20:51:41.640694Z",
     "shell.execute_reply": "2024-04-03T20:51:41.647011Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class FeatureEngineer:\n    \n    def __init__(self):\n        self.speller = Speller(lang='en')\n        self.spell_checker = SpellChecker()\n        \n        self.tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/debertav3base\")\n        \n        self.text_column = 'full_text'\n        \n        \n    def count_punctuation(self, row, specific_punctuation=None):\n        text = row[self.text_column]\n        if specific_punctuation is None:\n            punctuation_set = set(string.punctuation)\n        else:\n            punctuation_set = specific_punctuation\n\n        punctuation_count = sum(1 for char in text if char in punctuation_set)\n        return punctuation_count\n\n    # Count the digits in the text.\n    def count_numbers(self, row):\n        text = row[self.text_column]\n        numbers = re.findall(r'\\d+', text)\n        numbers_count = len(numbers)\n        return numbers_count\n\n    def count_text_length(self, df, col, tokenizer):\n        return df[col].progress_apply(lambda x: len(tokenizer.encode(x)))\n\n    def check_is_stop_word(self, word):\n        return word not in STOP_WORDS\n\n    def get_misspell_count(self, row):\n        text = row[self.text_column]\n        tokens = nltk.word_tokenize(text)\n        mis_tokens = [token for token in self.spell_checker.unknown(tokens) if token.isalpha()]\n        return len(mis_tokens)\n\n    def get_ngrams(self, token, n):\n        # Use the zip function to help us generate n-grams\n        # Concatentate the tokens into ngrams and return\n        ngrams = zip(*[token[i:] for i in range(n)])\n        return [\" \".join(ngram) for ngram in ngrams]\n\n    def filter_difficult_words(self, words):\n        return [word for word in words if word in difficult_words_list]\n\n    # advanced vocabulary\n    def get_difficult_words(self, text):\n        words = [word for word in word_tokenize(text) if word not in STOP_WORDS]\n        return set(self.filter_difficult_words(words)), words\n\n    def get_difficult_words_stats(self, row):\n        summary = row[self.text_column]\n        summary_difficult_words, all_words = self.get_difficult_words(summary)\n        return {\n            \"summary_difficult_words_count\": len(summary_difficult_words),\n        }\n\n    def get_readability_metrics(self, row):\n        text = row[self.text_column]\n        r = Readability(text)\n\n        flesch_kincaid_score = None\n        flesch_kincaid_grade_level = None    \n        flesch_score = None\n        flesch_ease = None\n        flesch_grade_levels = None\n        dale_chall_score = None\n        dale_chall_grade_levels = None\n        ari_score = None\n        ari_grade_levels = None\n        ari_ages = None\n        coleman_liau_score = None\n        coleman_liau_grade_level = None\n        gunning_fog_score = None\n        gunning_fog_grade_level = None\n        smog_score = None\n        smog_grade_level = None\n        spache_score = None\n        spache_grade_level = None\n        linsear_write_score = None\n        linsear_write_grade_level = None\n\n        if len(text.split()) > 120:\n            fk = r.flesch_kincaid()\n            flesch_kincaid_score = fk.score\n            flesch_kincaid_grade_level = fk.grade_level\n\n            f = r.flesch()\n            flesch_score = f.score\n            flesch_ease = f.ease\n            flesch_grade_levels = f.grade_levels\n\n            dc = r.dale_chall()\n            dale_chall_score = dc.score\n            dale_chall_grade_levels = dc.grade_levels\n\n            ari = r.ari()\n            ari_score = ari.score\n            ari_grade_levels = ari.grade_levels\n            ari_ages = ari.ages\n\n            cl = r.coleman_liau()\n            coleman_liau_score = cl.score\n            coleman_liau_grade_level = cl.grade_level\n\n            gf = r.gunning_fog()\n            gunning_fog_score = gf.score\n            gunning_fog_grade_level = gf.grade_level\n\n            sp = r.spache()\n            spache_score = sp.score\n            spache_grade_level = sp.grade_level\n\n            lw = r.linsear_write()\n            linsear_write_score = lw.score\n            linsear_write_grade_level = lw.grade_level\n\n        result = (\n            flesch_kincaid_score, \n            flesch_score,\n            dale_chall_score,\n            ari_score,\n            coleman_liau_score,\n            gunning_fog_score,\n            spache_score,\n            linsear_write_score,\n        )\n\n        return result\n    \n    def count_num_pos_tags(self, row, text_col_name):\n        result = {}\n        for tag in tags_df[\"abbrev\"]:\n            result[f\"count_{text_col_name}_{tag}\"] = 0\n            \n        result[f\"count_{text_col_name}_#\"] = 0\n\n        text = row[text_col_name]\n        word_tok_text = word_tokenize(text)\n        len_text = len(word_tok_text)\n        pair_pos_tags = pos_tag(word_tok_text)\n        for pair in pair_pos_tags:\n            tag = pair[1]\n            result[f\"count_{text_col_name}_{tag}\"] += 1\n\n        return result\n\n    def get_polarity_and_subjectivity(self, row):\n        text = row[self.text_column]\n        blob = TextBlob(str(text))\n        polarity = blob.sentiment.polarity\n        subjectivity = blob.sentiment.subjectivity\n        return {\n            'text_polarity': polarity,\n            'text_subjectivity': subjectivity\n        }\n    \n    def create_features(self, df):\n        df = df.applymap(lambda s: s.lower() if type(s) == str else s)\n    \n        # create corrected text summary \n        if USE_AUTOCORRECT:\n            print(\"Adding corrected summary text\")\n            df[self.text_column] = df[self.text_column].progress_apply(self.speller)\n\n        # number of punctuation\n        # punctuation_set -> !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\n        print(\"Adding number of punctuation\")\n        df['punctuation_count'] = df.progress_apply(lambda row: self.count_punctuation(row), axis=1)\n        df['full_stop_count'] = df.progress_apply(lambda row: self.count_punctuation(row, ['.']), axis=1)\n        df['comma_count'] = df.progress_apply(lambda row: self.count_punctuation(row, [',']), axis=1)\n        df['question_mark_count'] = df.progress_apply(lambda row: self.count_punctuation(row, ['?']), axis=1)\n        df['exclamation_mark_count'] = df.progress_apply(lambda row: self.count_punctuation(row, ['!']), axis=1)\n        df['colon_count'] = df.progress_apply(lambda row: self.count_punctuation(row, [':']), axis=1)\n        df['semicolon_count'] = df.progress_apply(lambda row: self.count_punctuation(row, [';']), axis=1)\n        df['brackets_count'] = df.progress_apply(lambda row: self.count_punctuation(row, ['(', ')', '[', ']', '{', '}']), axis=1)\n\n        # number of numbers\n        print(\"Adding number of numbers\")\n        df['number_count'] = df.progress_apply(lambda row: self.count_numbers(row), axis=1)\n\n        # number of misspells\n        print(\"Adding number of misspells\")\n        df['misspell_count'] = df.progress_apply(lambda row: self.get_misspell_count(row), axis=1)\n\n        # summary length + length ratio\n        df['text_length'] = self.count_text_length(df, self.text_column, self.tokenizer)\n\n        # get readability metrics\n        print(\"Adding readabililty metrics data\")\n        readability_metrics = [\n            \"flesch_kincaid_score\",   \n            \"flesch_score\",\n            \"dale_chall_score\",\n            \"ari_score\",\n            \"coleman_liau_score\",\n            \"gunning_fog_score\",\n            \"spache_score\",\n            \"linsear_write_score\",\n        ]\n        df[readability_metrics] = pd.DataFrame(\n            df.progress_apply(self.get_readability_metrics, axis=1).tolist(),\n            index=df.index).astype('float64')\n\n        # advanced vocabulary count\n        print(\"Adding advanced vocabulary data\")\n        summaries_difficult_words_stats_df = df.progress_apply(lambda x: pd.Series(self.get_difficult_words_stats(x)), axis=1)\n        summaries_difficult_words_stats_df.columns = [f\"ADV_{col}\" for col in summaries_difficult_words_stats_df.columns.values]\n        df = pd.concat([df, summaries_difficult_words_stats_df], axis=1)\n        \n        print(df.shape)\n\n        # get number of occurences of pos tags\n#         print(\"Adding number of pos tags data\")\n#         pos_tag_results = df.progress_apply(lambda row: self.count_num_pos_tags(row, self.text_column), axis=1).values.tolist()\n#         pos_tag_results = pd.DataFrame.from_records(pos_tag_results)\n#         df = pd.concat([df, pos_tag_results], axis=1)\n\n        # get polarity and subjectivity data\n#         print(\"Adding polarity and subjectivity data\")\n#         pol_subj_results = df.progress_apply(lambda row: self.get_polarity_and_subjectivity(row), axis=1).values.tolist()\n#         df = pd.concat([df, pd.DataFrame.from_records(pol_subj_results)], axis=1)\n\n        print(\"Done!\")\n        return df",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T21:15:49.712802Z",
     "iopub.execute_input": "2024-04-03T21:15:49.713298Z",
     "iopub.status.idle": "2024-04-03T21:15:49.758918Z",
     "shell.execute_reply.started": "2024-04-03T21:15:49.713262Z",
     "shell.execute_reply": "2024-04-03T21:15:49.757461Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "fe = FeatureEngineer()\n\nfeat_eng = fe.create_features(df_train)\n\ndel fe\ngc.collect()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T21:15:51.684706Z",
     "iopub.execute_input": "2024-04-03T21:15:51.685674Z",
     "iopub.status.idle": "2024-04-03T21:16:05.969993Z",
     "shell.execute_reply.started": "2024-04-03T21:15:51.685609Z",
     "shell.execute_reply": "2024-04-03T21:16:05.968467Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "feat_eng.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T21:16:09.026068Z",
     "iopub.execute_input": "2024-04-03T21:16:09.026499Z",
     "iopub.status.idle": "2024-04-03T21:16:09.05707Z",
     "shell.execute_reply.started": "2024-04-03T21:16:09.026464Z",
     "shell.execute_reply": "2024-04-03T21:16:09.055942Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def make_describe(df: pd.DataFrame):\n    describe =  pd.DataFrame(feat_eng.columns, columns=['param_name'])\n    \n    describe['count'] = describe['param_name'].apply(lambda col: df[col].count())\n    describe['missing_count'] = describe['param_name'].apply(lambda col: df[col].isna().sum())\n    describe['missing_%'] = describe['param_name'].apply(lambda col: df[col].isna().sum() / df[col].isna().count())\n    describe['unique_count'] = describe['param_name'].apply(lambda col: len(df[col].unique()))\n    describe['unique_values'] = describe['param_name'].apply(lambda col: df[col].unique() if len(df[col].unique()) < 30 else \"truncated\")\n    \n    describe['mean'] = describe['param_name'].apply(lambda col: df[col].mean() if is_numeric_dtype(df[col]) else np.nan)\n    describe['median'] = describe['param_name'].apply(lambda col: df[col].median() if is_numeric_dtype(df[col]) else np.nan)\n    describe['std'] = describe['param_name'].apply(lambda col: df[col].std() if is_numeric_dtype(df[col]) else np.nan)\n    describe['min'] = describe['param_name'].apply(lambda col: df[col].min() if is_numeric_dtype(df[col]) else np.nan)\n    for p in [5, 25, 50, 75, 95]: \n        describe[f'{p}%'] = describe['param_name'].apply(lambda col: df[col].quantile(p/100) if is_numeric_dtype(df[col]) else np.nan)\n    describe['max'] = describe['param_name'].apply(lambda col: df[col].max() if is_numeric_dtype(df[col]) else np.nan)\n    \n    return describe.style.background_gradient(\n        axis=1,\n    )",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2024-04-03T21:16:11.317596Z",
     "iopub.execute_input": "2024-04-03T21:16:11.318077Z",
     "iopub.status.idle": "2024-04-03T21:16:11.335571Z",
     "shell.execute_reply.started": "2024-04-03T21:16:11.318042Z",
     "shell.execute_reply": "2024-04-03T21:16:11.334284Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "make_describe(feat_eng)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T21:16:13.307592Z",
     "iopub.execute_input": "2024-04-03T21:16:13.308027Z",
     "iopub.status.idle": "2024-04-03T21:16:13.475727Z",
     "shell.execute_reply.started": "2024-04-03T21:16:13.307994Z",
     "shell.execute_reply": "2024-04-03T21:16:13.474297Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "feats = list(set(feat_eng.columns).difference(set(['essay_id', 'full_text', 'score'])))\n\nfig, axes = plt.subplots(nrows = len(feats) // 3 + 1, ncols = 3, figsize = (16, len(feats) * 1.6))\nplt.subplots_adjust(hspace = 0.5)\n\nfor feat, ax in zip(feats, axes.flat):\n    sns.boxenplot(data = feat_eng, x = 'score', y = feat, ax = ax)\n    ax.set_title(feat)\n    \nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-03T21:18:42.777693Z",
     "iopub.execute_input": "2024-04-03T21:18:42.778371Z",
     "iopub.status.idle": "2024-04-03T21:18:47.764423Z",
     "shell.execute_reply.started": "2024-04-03T21:18:42.778337Z",
     "shell.execute_reply": "2024-04-03T21:18:47.763167Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
