{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceType":"competition","sourceId":71485,"databundleVersionId":8059942},{"sourceType":"modelInstanceVersion","sourceId":11375,"databundleVersionId":7771683,"modelInstanceId":5172},{"sourceType":"modelInstanceVersion","sourceId":11373,"databundleVersionId":7771679,"modelInstanceId":5391},{"sourceType":"modelInstanceVersion","sourceId":10262,"databundleVersionId":7715875,"modelInstanceId":5172}],"dockerImageVersionId":30675,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":672.253242,"end_time":"2024-02-21T10:06:37.294427","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-21T09:55:25.041185","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Dependencies","metadata":{}},{"cell_type":"code","source":"# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n!pip install -q tensorflow-cpu\n!pip install -q -U keras-nlp tensorflow-hub\n!pip install -q -U keras>=3\n!pip install -U tensorflow-text","metadata":{"id":"WWEzVJR4Fx9g","papermill":{"duration":37.05282,"end_time":"2024-02-21T09:56:03.93859","exception":false,"start_time":"2024-02-21T09:55:26.88577","status":"completed"},"tags":[],"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-03T21:14:32.797082Z","iopub.execute_input":"2024-04-03T21:14:32.797395Z","iopub.status.idle":"2024-04-03T21:22:25.816337Z","shell.execute_reply.started":"2024-04-03T21:14:32.797367Z","shell.execute_reply":"2024-04-03T21:22:25.815433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jax\n\njax.devices()","metadata":{"id":"BK4MpHLKGujb","outputId":"a60376b8-0937-45fc-809b-33eaa92cbc6c","papermill":{"duration":8.126711,"end_time":"2024-02-21T09:56:12.097265","exception":false,"start_time":"2024-02-21T09:56:03.970554","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-03T21:22:25.818203Z","iopub.execute_input":"2024-04-03T21:22:25.818511Z","iopub.status.idle":"2024-04-03T21:22:34.11429Z","shell.execute_reply.started":"2024-04-03T21:22:25.818478Z","shell.execute_reply":"2024-04-03T21:22:34.113475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# The Keras 3 distribution API is only implemented for the JAX backend for now\nos.environ[\"KERAS_BACKEND\"] = \"jax\"\n# Pre-allocate 90% of TPU memory to minimize memory fragmentation and allocation\n# overhead\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9\"","metadata":{"id":"WEgg_OVIL2HY","papermill":{"duration":0.01342,"end_time":"2024-02-21T09:56:12.117529","exception":false,"start_time":"2024-02-21T09:56:12.104109","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-03T21:22:34.115391Z","iopub.execute_input":"2024-04-03T21:22:34.115745Z","iopub.status.idle":"2024-04-03T21:22:34.119949Z","shell.execute_reply.started":"2024-04-03T21:22:34.115715Z","shell.execute_reply":"2024-04-03T21:22:34.119148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading model","metadata":{"id":"wo1xkzr62hXN","papermill":{"duration":0.00603,"end_time":"2024-02-21T09:56:12.129531","exception":false,"start_time":"2024-02-21T09:56:12.123501","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import keras\nimport keras_nlp","metadata":{"id":"kFCmWEKdMA_Y","outputId":"57359fb1-ea3e-482a-aaf3-dcffc265a5ec","papermill":{"duration":8.153944,"end_time":"2024-02-21T09:56:20.315559","exception":false,"start_time":"2024-02-21T09:56:12.161615","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-03T21:22:34.121703Z","iopub.execute_input":"2024-04-03T21:22:34.121973Z","iopub.status.idle":"2024-04-03T21:22:45.143858Z","shell.execute_reply.started":"2024-04-03T21:22:34.121945Z","shell.execute_reply":"2024-04-03T21:22:45.142781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a device mesh with (1, 8) shape so that the weights are sharded across\n# all 8 TPUs.\ndevice_mesh = keras.distribution.DeviceMesh(\n    (1, 8),\n    [\"batch\", \"model\"],\n    devices=keras.distribution.list_devices())","metadata":{"id":"7gxEkpUiP1Qf","papermill":{"duration":0.012454,"end_time":"2024-02-21T09:56:20.375812","exception":false,"start_time":"2024-02-21T09:56:20.363358","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-03T21:22:45.144941Z","iopub.execute_input":"2024-04-03T21:22:45.145435Z","iopub.status.idle":"2024-04-03T21:22:45.150004Z","shell.execute_reply.started":"2024-04-03T21:22:45.145404Z","shell.execute_reply":"2024-04-03T21:22:45.14923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`LayoutMap` from the distribution API specifies how the weights and tensors should be sharded or replicated, using the string keys, for example, `token_embedding/embeddings` below, which are treated like regex to match tensor paths. Matched tensors are sharded with model dimensions (8 TPUs); others will be fully replicated.","metadata":{"id":"gTSJUwkC-7c6","papermill":{"duration":0.00582,"end_time":"2024-02-21T09:56:20.387661","exception":false,"start_time":"2024-02-21T09:56:20.381841","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_dim = \"model\"\n\nlayout_map = keras.distribution.LayoutMap(device_mesh)\n\n# Weights that match 'token_embedding/embeddings' will be sharded on 8 TPUs\nlayout_map[\"token_embedding/embeddings\"] = (None, model_dim)\n# Regex to match against the query, key and value matrices in the decoder\n# attention layers\nlayout_map[\"decoder_block.*attention.*(query|key|value).*kernel\"] = (\n    None, model_dim, None)\n\nlayout_map[\"decoder_block.*attention_output.*kernel\"] = (\n    None, None, model_dim)\nlayout_map[\"decoder_block.*ffw_gating.*kernel\"] = (model_dim, None)\nlayout_map[\"decoder_block.*ffw_linear.*kernel\"] = (None, model_dim)","metadata":{"id":"8Wgh8h0qQCcu","papermill":{"duration":0.013198,"end_time":"2024-02-21T09:56:20.406598","exception":false,"start_time":"2024-02-21T09:56:20.3934","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-03T21:22:45.15087Z","iopub.execute_input":"2024-04-03T21:22:45.151114Z","iopub.status.idle":"2024-04-03T21:22:45.167762Z","shell.execute_reply.started":"2024-04-03T21:22:45.151088Z","shell.execute_reply":"2024-04-03T21:22:45.167012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`ModelParallel` allows you to shard model weights or activation tensors across all devcies on the `DeviceMesh`. In this case, some of the Gemma 7B model weights are sharded across 8 TPU chips according the `layout_map` defined above. Now load the model in the distributed way.","metadata":{"id":"6n4Zlvk9ALhZ","papermill":{"duration":0.005938,"end_time":"2024-02-21T09:56:20.418485","exception":false,"start_time":"2024-02-21T09:56:20.412547","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_parallel = keras.distribution.ModelParallel(\n    device_mesh, layout_map, batch_dim_name=\"batch\")\n\nkeras.distribution.set_distribution(model_parallel)\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_7b_en\")","metadata":{"id":"bu48vUnbQj0p","outputId":"fd216acb-852c-46f4-e8ac-2d8f91362d24","papermill":{"duration":145.668669,"end_time":"2024-02-21T09:58:46.092826","exception":false,"start_time":"2024-02-21T09:56:20.424157","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-03T21:22:45.16874Z","iopub.execute_input":"2024-04-03T21:22:45.168998Z","iopub.status.idle":"2024-04-03T21:25:33.645678Z","shell.execute_reply.started":"2024-04-03T21:22:45.168972Z","shell.execute_reply":"2024-04-03T21:25:33.644406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now verify that the model has been partitioned correctly. Let's take `decoder_block_1` as an example.","metadata":{"id":"ORCOIawAvpZ1","papermill":{"duration":0.006357,"end_time":"2024-02-21T09:58:46.105898","exception":false,"start_time":"2024-02-21T09:58:46.099541","status":"completed"},"tags":[]}},{"cell_type":"code","source":"decoder_block_1 = gemma_lm.backbone.get_layer('decoder_block_1')\nprint(type(decoder_block_1))\nfor variable in decoder_block_1.weights:\n  print(f'{variable.path:<58}  {str(variable.shape):<16}  {str(variable.value.sharding.spec)}')","metadata":{"id":"DqT7TRHKvoMK","papermill":{"duration":0.014281,"end_time":"2024-02-21T09:58:46.126669","exception":false,"start_time":"2024-02-21T09:58:46.112388","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-03T21:25:33.646976Z","iopub.execute_input":"2024-04-03T21:25:33.647305Z","iopub.status.idle":"2024-04-03T21:25:33.653362Z","shell.execute_reply.started":"2024-04-03T21:25:33.647275Z","shell.execute_reply":"2024-04-03T21:25:33.652424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading Training Dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport random","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:25:33.654433Z","iopub.execute_input":"2024-04-03T21:25:33.654705Z","iopub.status.idle":"2024-04-03T21:25:33.673031Z","shell.execute_reply.started":"2024-04-03T21:25:33.654677Z","shell.execute_reply":"2024-04-03T21:25:33.672133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:25:33.675499Z","iopub.execute_input":"2024-04-03T21:25:33.67577Z","iopub.status.idle":"2024-04-03T21:25:34.476181Z","shell.execute_reply.started":"2024-04-03T21:25:33.675743Z","shell.execute_reply":"2024-04-03T21:25:34.475168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualization Of Training Dataset","metadata":{}},{"cell_type":"code","source":"train.size ###This will give the total number of elements (rows * columns) in DataFrame. ","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:25:34.477421Z","iopub.execute_input":"2024-04-03T21:25:34.477754Z","iopub.status.idle":"2024-04-03T21:25:34.483485Z","shell.execute_reply.started":"2024-04-03T21:25:34.477722Z","shell.execute_reply":"2024-04-03T21:25:34.482592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape ### We want the number of rows or columns separately","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:25:34.484476Z","iopub.execute_input":"2024-04-03T21:25:34.484771Z","iopub.status.idle":"2024-04-03T21:25:34.506709Z","shell.execute_reply.started":"2024-04-03T21:25:34.484739Z","shell.execute_reply":"2024-04-03T21:25:34.505897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display information about the train DataFrame\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:25:34.507591Z","iopub.execute_input":"2024-04-03T21:25:34.507858Z","iopub.status.idle":"2024-04-03T21:25:34.536788Z","shell.execute_reply.started":"2024-04-03T21:25:34.507831Z","shell.execute_reply":"2024-04-03T21:25:34.535855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe() # Generate descriptive statistics of the train DataFrame","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:25:34.537908Z","iopub.execute_input":"2024-04-03T21:25:34.538548Z","iopub.status.idle":"2024-04-03T21:25:34.551064Z","shell.execute_reply.started":"2024-04-03T21:25:34.538514Z","shell.execute_reply":"2024-04-03T21:25:34.550168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We have 17307 essays to train, but we will first try using few shot prompting.","metadata":{}},{"cell_type":"markdown","source":"# Reading Test Dataset","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\")\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:25:34.552367Z","iopub.execute_input":"2024-04-03T21:25:34.552955Z","iopub.status.idle":"2024-04-03T21:25:34.564549Z","shell.execute_reply.started":"2024-04-03T21:25:34.55292Z","shell.execute_reply":"2024-04-03T21:25:34.56357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualization Of Test Dataset","metadata":{}},{"cell_type":"code","source":"test.size ###This will give the total number of elements (rows * columns) in DataFrame. \n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:25:34.565539Z","iopub.execute_input":"2024-04-03T21:25:34.565813Z","iopub.status.idle":"2024-04-03T21:25:34.571067Z","shell.execute_reply.started":"2024-04-03T21:25:34.565784Z","shell.execute_reply":"2024-04-03T21:25:34.570279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape ### We want the number of rows or columns separately","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:25:34.572112Z","iopub.execute_input":"2024-04-03T21:25:34.572401Z","iopub.status.idle":"2024-04-03T21:25:34.585637Z","shell.execute_reply.started":"2024-04-03T21:25:34.572371Z","shell.execute_reply":"2024-04-03T21:25:34.584834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info() # Display information about the train DataFrame\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:25:34.586603Z","iopub.execute_input":"2024-04-03T21:25:34.587181Z","iopub.status.idle":"2024-04-03T21:25:34.600528Z","shell.execute_reply.started":"2024-04-03T21:25:34.587151Z","shell.execute_reply":"2024-04-03T21:25:34.599617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.describe() # Generate descriptive statistics of the train DataFrame","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:25:34.601786Z","iopub.execute_input":"2024-04-03T21:25:34.60237Z","iopub.status.idle":"2024-04-03T21:25:34.626227Z","shell.execute_reply.started":"2024-04-03T21:25:34.602337Z","shell.execute_reply":"2024-04-03T21:25:34.625358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prompt\n#### So that it gives better answer.\n#### We are using Few Shot Prompting Technique\n##### Which means we are using all the training dataset to give it in prompt as examples ","metadata":{}},{"cell_type":"code","source":"prompt = \"\"\"You are English Professor, an exceptionally intelligent Professor tasked with score english essay.\n\nEnglish Professor will be given a english essay, and will provide a precise score, adhering to the following rules:\n- English Professor guarantees to give a precise score, always within the range of 1 to 6.\n- Score will be concise and limited to a single number.\n- Only the final result will be provided, no additional information.\n- The score written in the \"Score\" section must be concise and only include the final result.\n- English Professor will always follow these rules.\n\n\n{examples}\n\n\n# English Essay\n{essay}\n\n# Answer (only one number between 0 and 999)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:38:35.468239Z","iopub.execute_input":"2024-04-03T21:38:35.468627Z","iopub.status.idle":"2024-04-03T21:38:35.47345Z","shell.execute_reply.started":"2024-04-03T21:38:35.468596Z","shell.execute_reply":"2024-04-03T21:38:35.472546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def out(model, examples_df: pd.DataFrame | None , df, template):\n    submission = {\"essay_id\": [], \"score\": []}\n\n    examples = \"\"\n    if examples_df is not None and not examples_df.empty:\n        examples = []\n        for idx, row in examples_df.iterrows():\n            examples.append(\"# English Essay\")\n            examples.append(str(row[\"full_text\"]))\n            examples.append(\"# Score (only one number between 1 and 6)\")\n            examples.append(str(row[\"score\"]))\n        examples = \"\\n\".join(examples)\n    \n    for idx, row in df.iterrows():\n        try:\n            model_input = prompt.format(examples=examples, essay=row[\"full_text\"])\n\n            output = gemma_lm.generate(prompt,max_length=3)\n            \n            output = int(re.sub(r\"[^0-9]\", \"\", output))\n\n            submission[\"essay_id\"].append(row[\"essay_id\"])\n            submission[\"score\"].append(output)\n        except Exception as e:\n            submission[\"essay_id\"].append(row[\"essay_id\"])\n            submission[\"score\"].append(random.randint(1, 6))\n            \n    submission_df = pd.DataFrame(submission)\n    submission_df[\"score\"] = submission_df[\"score\"].apply(lambda x: abs(x) % 1000)\n    return submission_df","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:44:02.439913Z","iopub.execute_input":"2024-04-03T21:44:02.441101Z","iopub.status.idle":"2024-04-03T21:44:02.448821Z","shell.execute_reply.started":"2024-04-03T21:44:02.44106Z","shell.execute_reply":"2024-04-03T21:44:02.447859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `out` function generates submissions based on provided examples, a main DataFrame, a template, and a machine learning model. Here's how it works:\n\n1. **Input Parameters:**\n   - `model`: The machine learning model used to generate answers.\n   - `examples_df`: A DataFrame containing example questions and answers (optional).\n   - `df`: The main DataFrame containing questions.\n   - `template`: A template string used to format questions and generate answers.\n\n2. **Example Formatting:**\n   - If `examples_df` is provided and not empty, the function formats it into a string.\n\n3. **Submission Generation:**\n   - For each row in the main DataFrame (`df`):\n     - It attempts to generate an answer using the provided template and model.\n     - If successful, it appends the answer to the submission dictionary.\n     - If an exception occurs during answer generation, it prints the exception and adds a random answer instead.\n\n4. **Final Submission DataFrame:**\n   - The function converts the submission dictionary into a DataFrame.\n   - It ensures that the answer values are within the range of 1 to 6\".\n\n5. **Output:**\n   - The function returns the submission DataFrame containing question IDs and their respective answers.\n","metadata":{}},{"cell_type":"markdown","source":"## We will trying with 10 examples in prompt","metadata":{}},{"cell_type":"code","source":"tr = train.iloc[:10] # Get the first row of the train DataFrame\n# tr_df = tr.to_frame().T # Convert the tr variable into a DataFrame with a single row\ntr","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:38:36.899925Z","iopub.execute_input":"2024-04-03T21:38:36.900543Z","iopub.status.idle":"2024-04-03T21:38:36.91008Z","shell.execute_reply.started":"2024-04-03T21:38:36.90051Z","shell.execute_reply":"2024-04-03T21:38:36.909169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = out(gemma_lm, tr, test, prompt)\noutput\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:44:05.852532Z","iopub.execute_input":"2024-04-03T21:44:05.853224Z","iopub.status.idle":"2024-04-03T21:44:06.015586Z","shell.execute_reply.started":"2024-04-03T21:44:05.853185Z","shell.execute_reply":"2024-04-03T21:44:06.014629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Into CSV","metadata":{}},{"cell_type":"code","source":"output.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:44:09.071768Z","iopub.execute_input":"2024-04-03T21:44:09.072943Z","iopub.status.idle":"2024-04-03T21:44:09.08008Z","shell.execute_reply.started":"2024-04-03T21:44:09.072903Z","shell.execute_reply":"2024-04-03T21:44:09.079166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## To Do In Future\n* Finetune the llm using train data\n* Do better Visualization","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}