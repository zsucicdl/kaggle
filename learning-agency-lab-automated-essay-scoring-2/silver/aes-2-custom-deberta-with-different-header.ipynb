{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 71485,
     "databundleVersionId": 8059942,
     "sourceType": "competition"
    },
    {
     "sourceId": 8307579,
     "sourceType": "datasetVersion",
     "datasetId": 4910099
    }
   ],
   "dockerImageVersionId": 30699,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "___\n**ðŸ“Œ Baseline From The Notebooks Below**\n\n>  **First NoteBook:** [DeBERTa-v3-SMALL Starter - CV 0.820 LB 0.800](https://www.kaggle.com/code/cdeotte/deberta-v3-small-starter-cv-0-820-lb-0-800) ðŸ™\n\n>  **Second NoteBook:** [Huge Ensemble](https://www.kaggle.com/code/thedevastator/huge-ensemble) ðŸ™\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Custom Model Structure",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "![](https://cdn.sanity.io/images/vr8gru94/production/2425dc0efd3f73a0bf57b3bf85a091c78619ec2c-1920x1110.png)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "- **Adding Mean Pooling on last hidden states**\n=> I've replaced the `ContextPooler` with a `mean pooling layer`\n\n- **Adding BiLSTM Layers** (Optional) - For me it was worsen CV scores\n- **Automatic Mixed Precision = False** - FP16 in some cases hurts the performance of transformers.\n\n- **Loss Function: MSE -> RMSE** (Optional)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "<div style=\"border-radius:10px; border: #FFA500 solid; padding: 15px; font-size:100%;\">\n\nðŸ“Œ **Improvement Ideas**\n\n- **Increase Pos Embeddings Size** - max_position_embeddings(512 -> 1024)\n    \n- **Utilizing Different Layers** - There are many ways to do this concat, mean pooling, max pooling, attention, lstm, hierarchical or parallel aggregation.\n   \n- **Unsupervised Data Augmentation** ex) persuade corpus\n\n- **LLRD** - LayerWise Learning Rate Decay(*Experiment: LLRD vs General Learning Rate Decay*)\n\n- **Ensembling Techniques** - Hill Climbing",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "___",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFA500\"><b><span style='color:#FFA500'></span></b> <b>1. Initial Setting</b></div>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import os \nos.environ['CUDA_IS_VISIBLE'] = '0,1'\nimport sys\nimport gc\nimport re\nimport ctypes\nimport random\nfrom tqdm import tqdm\nimport polars as pl\n\nimport numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.model_selection import StratifiedKFold\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.checkpoint import checkpoint\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, AutoConfig\nfrom transformers.modeling_utils import PretrainedConfig, PreTrainedModel\n\nfrom transformers import Trainer, TrainingArguments\nfrom datasets import Dataset\nimport warnings\nwarnings.filterwarnings('ignore')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:02:25.835326Z",
     "iopub.execute_input": "2024-05-03T11:02:25.835701Z",
     "iopub.status.idle": "2024-05-03T11:02:43.822722Z",
     "shell.execute_reply.started": "2024-05-03T11:02:25.83567Z",
     "shell.execute_reply": "2024-05-03T11:02:43.821937Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class CFG:\n    SEED = 2024\n    VER = 1\n    INFERENCE = True\n    gradient_checkpointing = False\n    FREEZING_EMBEDDINGS = True\n    FREEZE_LAYERS = 1 # Only freezing embedding\n    BASE_PATH = '/kaggle/input/learning-agency-lab-automated-essay-scoring-2/'\n    preset = '/kaggle/input/aes2-deberta-pooling'\n    MAX_LEN = 1024\n    TRAIN_BATCH = 4\n    EVAL_BATCH = 8\n    EPOCHS = 1",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "Clean = True\n\ndef clean_memory():\n    if Clean:\n        ctypes.CDLL('libc.so.6').malloc_trim(0)\n        gc.collect()\n        \nclean_memory()    ",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:02:43.832905Z",
     "iopub.execute_input": "2024-05-03T11:02:43.833396Z",
     "iopub.status.idle": "2024-05-03T11:02:44.127368Z",
     "shell.execute_reply.started": "2024-05-03T11:02:43.833365Z",
     "shell.execute_reply": "2024-05-03T11:02:44.126387Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def seed_everything():\n    random.seed(CFG.SEED)\n    os.environ['PYTHONHASHSEED'] = str(CFG.SEED)\n    np.random.seed(CFG.SEED)\n    torch.manual_seed(CFG.SEED)\n    torch.cuda.manual_seed(CFG.SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:02:44.128683Z",
     "iopub.execute_input": "2024-05-03T11:02:44.129406Z",
     "iopub.status.idle": "2024-05-03T11:02:44.137321Z",
     "shell.execute_reply.started": "2024-05-03T11:02:44.129373Z",
     "shell.execute_reply": "2024-05-03T11:02:44.136454Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFA500\"><b><span style='color:#FFA500'></span></b> <b>2. Road and Read Data</b></div>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "df_train = pd.read_csv(CFG.BASE_PATH + 'train.csv')\ndf_train = df_train.sort_values(by='essay_id')\ndf_train['label'] = df_train['score'] - 1\n\nskf = StratifiedKFold(n_splits=5, random_state=CFG.SEED, shuffle=True)\nfor i, (_, val_index) in enumerate(skf.split(df_train,df_train['score'])):\n    df_train.loc[val_index, 'fold'] = i\n\nprint('Shape of Train: ', df_train.shape)\nprint(display(df_train.head()))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:02:44.139588Z",
     "iopub.execute_input": "2024-05-03T11:02:44.139923Z",
     "iopub.status.idle": "2024-05-03T11:02:44.961425Z",
     "shell.execute_reply.started": "2024-05-03T11:02:44.1399Z",
     "shell.execute_reply": "2024-05-03T11:02:44.960477Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df_test = pd.read_csv(CFG.BASE_PATH + 'test.csv')\ndf_test = df_test.sort_values(by='essay_id')\nprint('Shape of Test: ', df_test.shape)\nprint(display(df_test.head()))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:02:44.96271Z",
     "iopub.execute_input": "2024-05-03T11:02:44.963062Z",
     "iopub.status.idle": "2024-05-03T11:02:44.977466Z",
     "shell.execute_reply.started": "2024-05-03T11:02:44.963031Z",
     "shell.execute_reply": "2024-05-03T11:02:44.976554Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "cList = {\n  \"ain't\": \"am not\",\"aren't\": \"are not\",\"can't\": \"cannot\",\"can't've\": \"cannot have\",\"'cause\": \"because\",  \"could've\": \"could have\",\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\"didn't\": \"did not\",\"doesn't\": \"does not\",\"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\"hasn't\": \"has not\",\n  \"haven't\": \"have not\",\"he'd\": \"he would\",\"he'd've\": \"he would have\",\"he'll\": \"he will\",\"he'll've\": \"he will have\",\"he's\": \"he is\",\n  \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"how's\": \"how is\",\"I'd\": \"I would\",\"I'd've\": \"I would have\",\"I'll\": \"I will\",\"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\",\n  \"isn't\": \"is not\",\"it'd\": \"it had\",\"it'd've\": \"it would have\",\"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\",\"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\n  \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\"needn't\": \"need not\",\"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n  \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\"she'll\": \"she will\",\"she'll've\": \"she will have\",\"she's\": \"she is\",\n  \"should've\": \"should have\",\"shouldn't\": \"should not\",\"shouldn't've\": \"should not have\",\"so've\": \"so have\",\"so's\": \"so is\",\"that'd\": \"that would\",\"that'd've\": \"that would have\",\"that's\": \"that is\",\"there'd\": \"there had\",\"there'd've\": \"there would have\",\"there's\": \"there is\",\"they'd\": \"they would\",\"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\"they're\": \"they are\",\"they've\": \"they have\",\"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we had\",\n  \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\n  \"weren't\": \"were not\",\"what'll\": \"what will\",\"what'll've\": \"what will have\",\n  \"what're\": \"what are\",\"what's\": \"what is\",\"what've\": \"what have\",\"when's\": \"when is\",\"when've\": \"when have\",\n  \"where'd\": \"where did\",\"where's\": \"where is\",\"where've\": \"where have\",\"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who's\": \"who is\",\"who've\": \"who have\",\"why's\": \"why is\",\n  \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\"would've\": \"would have\",\"wouldn't\": \"would not\",\n  \"wouldn't've\": \"would not have\",\"y'all\": \"you all\",\"y'alls\": \"you alls\",\"y'all'd\": \"you all would\",\n  \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you had\",\"you'd've\": \"you would have\",\"you'll\": \"you you will\",\"you'll've\": \"you you will have\",\"you're\": \"you are\",  \"you've\": \"you have\"\n   }",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:02:44.979114Z",
     "iopub.execute_input": "2024-05-03T11:02:44.979488Z",
     "iopub.status.idle": "2024-05-03T11:02:44.991813Z",
     "shell.execute_reply.started": "2024-05-03T11:02:44.979455Z",
     "shell.execute_reply": "2024-05-03T11:02:44.990903Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "c_re = re.compile('(%s)' % '|'.join(cList.keys()))\n\ndef expandContractions(text, c_re=c_re):\n    def replace(match):\n        return cList[match.group(0)]\n    return c_re.sub(replace, text)\n\ndef removeHTML(x):\n    html = re.compile(r'<.*?>')\n    return html.sub(r'',x) # html -> ''\n\ndef dataPreprocessing(x):\n    \n    x = x.lower()\n    # remove html\n    x = removeHTML(x)\n    \n    #remove string with starting @\n    x = re.sub(\"@\\w+\",'',x)\n    \n    # remove number\n    x = re.sub(\"'\\d+\",'',x)\n    x = re.sub(\"\\d+\",'',x)\n    \n    # remove url\n    x = re.sub(\"http\\w+\",'',x)\n    \n    # Replace consecutive empty spaces with a single empty spaces\n    x = re.sub(r'\\s+', \" \", x)\n    # Replace consecutive commas and periods with a single comma and period\n    x = expandContractions(x)\n    x = re.sub(r'\\.+', \".\",x)\n    x = re.sub(r'\\,+', \",\",x)\n    x = re.sub(r'[^\\w\\s.,;:\"\"''?!]', '', x)\n    # Remove empty character at the beginning and end\n    x = x.strip()\n    return x",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:02:44.992941Z",
     "iopub.execute_input": "2024-05-03T11:02:44.993266Z",
     "iopub.status.idle": "2024-05-03T11:02:45.011409Z",
     "shell.execute_reply.started": "2024-05-03T11:02:44.993236Z",
     "shell.execute_reply": "2024-05-03T11:02:45.010407Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train = pl.from_pandas(df_train)\ntest = pl.from_pandas(df_test)\n\ntrain = train.with_columns(\n         pl.col('full_text').map_elements(lambda x: dataPreprocessing(x))\n)\ndf_train = train.to_pandas()\n\ntest = test.with_columns(\n         pl.col('full_text').map_elements(lambda x: dataPreprocessing(x))\n)\ndf_test = test.to_pandas()\ndf_train['label'] = df_train['label'].astype('float32')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:02:45.012511Z",
     "iopub.execute_input": "2024-05-03T11:02:45.012849Z",
     "iopub.status.idle": "2024-05-03T11:03:00.58064Z",
     "shell.execute_reply.started": "2024-05-03T11:02:45.012819Z",
     "shell.execute_reply": "2024-05-03T11:03:00.579798Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "training_args = TrainingArguments(\n    output_dir = f'/output_v{CFG.VER}',\n    per_device_train_batch_size=CFG.TRAIN_BATCH,\n    per_device_eval_batch_size=CFG.EVAL_BATCH,\n    num_train_epochs= CFG.EPOCHS,\n    evaluation_strategy='steps',\n    save_strategy='steps',\n    logging_steps=125,\n    save_steps=250,\n    load_best_model_at_end=True,\n    weight_decay=1e-2, \n    fp16=False,# automatic mixed precision, AMP\n    learning_rate=2e-5, # 1e-5 -> 2e-5\n    lr_scheduler_type='linear',\n    optim='adamw_torch',\n    metric_for_best_model='qwk',\n    save_total_limit=1,\n    report_to='none',\n    gradient_checkpointing=CFG.gradient_checkpointing,\n    gradient_accumulation_steps=2,\n)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:03:00.581733Z",
     "iopub.execute_input": "2024-05-03T11:03:00.581987Z",
     "iopub.status.idle": "2024-05-03T11:03:00.664704Z",
     "shell.execute_reply.started": "2024-05-03T11:03:00.581965Z",
     "shell.execute_reply": "2024-05-03T11:03:00.663962Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    qwk = cohen_kappa_score(labels, predictions.clip(0,5).round(0), weights='quadratic')\n    results = {\n        'qwk': qwk\n    }\n    return results",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:03:00.665804Z",
     "iopub.execute_input": "2024-05-03T11:03:00.666139Z",
     "iopub.status.idle": "2024-05-03T11:03:00.672345Z",
     "shell.execute_reply.started": "2024-05-03T11:03:00.666109Z",
     "shell.execute_reply": "2024-05-03T11:03:00.671196Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFA500\"><b><span style='color:#FFA500'></span></b> <b>3. Pooling Introduction</b></div>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "**MeanPooling**",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9) #\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings  # 1 X 768",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:03:00.673559Z",
     "iopub.execute_input": "2024-05-03T11:03:00.674143Z",
     "iopub.status.idle": "2024-05-03T11:03:00.684872Z",
     "shell.execute_reply.started": "2024-05-03T11:03:00.674113Z",
     "shell.execute_reply": "2024-05-03T11:03:00.684093Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "**MeanMaxPooling**",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F16438831%2F952609a0cdb574a3621c438d960e1471%2Fmax%20pooling.JPG?generation=1714549387950952&alt=media)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class MeanMaxPooling(nn.Module):\n    def __init__(self):\n        super(MeanMaxPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        mean_pooling_embeddings = torch.mean(last_hidden_state, 1)\n        _, max_pooling_embeddings = torch.max(last_hidden_state, 1)\n        mean_max_embeddings = torch.cat((mean_pooling_embeddings, max_pooling_embeddings), 1)\n        return mean_max_embeddings # 1 X 1536",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:03:00.686019Z",
     "iopub.execute_input": "2024-05-03T11:03:00.68675Z",
     "iopub.status.idle": "2024-05-03T11:03:00.696858Z",
     "shell.execute_reply.started": "2024-05-03T11:03:00.68672Z",
     "shell.execute_reply": "2024-05-03T11:03:00.696063Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "**Attention Pooling** (https://www.kaggle.com/competitions/feedback-prize-english-language-learning/discussion/361678)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class AttentionPooling(nn.Module):\n    def __init__(self, in_dim):\n        super().__init__()\n        self.attention = nn.Sequential(\n           nn.Linear(in_dim, in_dim),\n           nn.LayerNorm(in_dim),\n           nn.GELU(),\n           nn.Linear(in_dim, 1),\n        )\n    def forward(self, last_hidden_state, attention_mask):\n        w = self.attention(last_hidden_state).float()\n        w[attention_mask==0]=float(\n        '-inf')\n        w = torch.softmax(w,1)\n        attention_embeddings = torch.sum(w * last_hidden_state, dim=1)\n        return attention_embeddings\n    ",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:03:00.700717Z",
     "iopub.execute_input": "2024-05-03T11:03:00.700973Z",
     "iopub.status.idle": "2024-05-03T11:03:00.712722Z",
     "shell.execute_reply.started": "2024-05-03T11:03:00.700952Z",
     "shell.execute_reply": "2024-05-03T11:03:00.711974Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFA500\"><b><span style='color:#FFA500'></span></b> <b>4. Customizing Model</b></div>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if CFG.INFERENCE is None:\n    config = AutoConfig.from_pretrained(CFG.preset)\n    config._name_or_path = CFG.preset\n    config.num_labels = 1\n    config.attention_probs_dropout_prob = 0.0 # For Regression\n    config.hidden_dropout_prob = 0.0 # For Regression\n    config.max_position_embeddings = 1024 # 512 -> 1024\n    # config.save_pretrained('./config.json')\n    base_model = AutoModelForSequenceClassification.from_pretrained(CFG.preset, config=config)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:03:00.713647Z",
     "iopub.execute_input": "2024-05-03T11:03:00.713904Z",
     "iopub.status.idle": "2024-05-03T11:03:01.502896Z",
     "shell.execute_reply.started": "2024-05-03T11:03:00.713883Z",
     "shell.execute_reply": "2024-05-03T11:03:01.501448Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class Custom_Model(nn.Module):\n    def __init__(self, model):\n        super().__init__()\n        self.base_model = model\n        \n        if CFG.FREEZING_EMBEDDINGS:\n            print('Freezing embeddings.')\n        for param in self.base_model.deberta.embeddings.parameters():\n            param.requires_grad = False\n        \n        if CFG.FREEZE_LAYERS > 0:\n            print(f'Freezing {CFG.FREEZE_LAYERS} layers')\n            for layer in self.base_model.deberta.encoder.layer[:CFG.FREEZE_LAYERS]:\n                for param in layer.parameters():\n                    param.requires_grad = False\n          \n        self.pooler1 = MeanPooling() # Optional \n        self.pooler2 = MeanMaxPooling() # Optional\n        self.pooler3 = AttentionPooling(self.base_model.config.hidden_size)\n        # self.LSTM = nn.LSTM(input_size=self.base_model.config.hidden_size, hidden_size=self.base_model.config.hidden_size // 2,\n        #                     num_layers=2, batch_first=True,dropout=self.base_model.config.hidden_dropout_prob, bidirectional=True)\n        self.fc1 = nn.Linear(in_features = self.base_model.config.hidden_size, out_features = 1)\n        self.fc2 = nn.Linear(in_features = self.base_model.config.hidden_size*2, out_features = 1)\n        \n    def forward(self, input_ids, attention_mask, labels=None):\n        output = self.base_model(input_ids=input_ids,\n                         attention_mask=attention_mask,\n                         labels = labels,\n                         output_hidden_states = True)\n        \n        #Mean Pooling\n        # pooled_output1 = self.pooler1(output.hidden_states[-1], attention_mask)\n        # logits = self.fc1(pooled_output1) \n        \n        # Mean-max Pooling\n        # pooled_output2 = self.pooler2(output.hidden_states[-1], attention_mask)\n        # logits = self.fc2(pooled_output2) \n        \n        # Attention Pooling\n        pooled_output3 = self.pooler3(output.hidden_states[-1], attention_mask)\n        logits = self.fc1(pooled_output3)\n        \n        # You can change MSE Loss -> RMSE Loss\n        if labels is not None:\n            loss_fct = nn.MSELoss()\n            mse_loss = loss_fct(logits.squeeze(), labels.squeeze())\n            rmse_loss = torch.sqrt(mse_loss)\n            return mse_loss, logits\n        else:\n            return logits",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:03:20.467284Z",
     "iopub.execute_input": "2024-05-03T11:03:20.468257Z",
     "iopub.status.idle": "2024-05-03T11:03:20.48298Z",
     "shell.execute_reply.started": "2024-05-03T11:03:20.468221Z",
     "shell.execute_reply": "2024-05-03T11:03:20.481692Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "class Custom_Model(PreTrainedModel):\n    def __init__(self, config, model):\n        super().__init__(config)\n        self.base_model = model\n          \n        self.pooler1 = MeanPooling() # Optional \n        self.pooler2 = MeanMaxPooling() # Optional\n        # self.LSTM = nn.LSTM(input_size=self.base_model.config.hidden_size, hidden_size=self.base_model.config.hidden_size // 2,\n        #                     num_layers=2, batch_first=True,dropout=self.base_model.config.hidden_dropout_prob, bidirectional=True)\n        self.fc1 = nn.Sequential(\n            nn.Linear(config.hidden_size, config.hidden_size),\n            nn.ReLU(),\n            nn.Linear(in_features = config.hidden_size, out_features = 1)\n        )\n        \n        self.fc2 = nn.Sequential(\n            nn.Linear(config.hidden_size*2, config.hidden_size*2),\n            nn.ReLU(),\n            nn.Linear(in_features = config.hidden_size*2, out_features = 1)\n        )\n    def forward(self, input_ids, attention_mask, labels=None):\n        output = self.base_model(input_ids=input_ids,\n                         attention_mask=attention_mask,\n                         labels = labels,\n                         output_hidden_states = True)\n        \n        #Mean Pooling\n        pooled_output1 = self.pooler1(output.hidden_states[-1], attention_mask)\n        logits = self.fc1(pooled_output1) \n        \n        # Mean-max Pooling\n        # pooled_output2 = self.pooler2(output.hidden_states[-1], attention_mask)\n        # logits = self.fc2(pooled_output2) \n    \n        # You can change MSE Loss -> RMSE Loss\n        if labels is not None:\n            loss_fct = nn.MSELoss()\n            mse_loss = loss_fct(logits.squeeze(), labels.squeeze())\n            rmse_loss = torch.sqrt(mse_loss)\n            return mse_loss, logits\n        else:\n            return logits",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T10:21:35.246078Z",
     "iopub.execute_input": "2024-05-02T10:21:35.246977Z",
     "iopub.status.idle": "2024-05-02T10:21:35.256693Z",
     "shell.execute_reply.started": "2024-05-02T10:21:35.246943Z",
     "shell.execute_reply": "2024-05-02T10:21:35.255694Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": "# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFA500\"><b><span style='color:#FFA500'></span></b> <b>5. Training Model</b></div>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "tokenizer = AutoTokenizer.from_pretrained(CFG.preset,  truncation=True, max_length=CFG.MAX_LEN, clean_up_tokenization_spaces=False)\ndef preprocess(sample):\n    return tokenizer(sample['full_text'],)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:03:21.84228Z",
     "iopub.execute_input": "2024-05-03T11:03:21.843095Z",
     "iopub.status.idle": "2024-05-03T11:03:22.191273Z",
     "shell.execute_reply.started": "2024-05-03T11:03:21.843063Z",
     "shell.execute_reply": "2024-05-03T11:03:22.190486Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "if CFG.INFERENCE is None:\n    for i in range(1):\n        train = df_train[df_train['fold'] != i]\n        valid = df_train[df_train['fold'] == i]\n\n        \n        dataset_v = Dataset.from_pandas(valid)\n        dataset_t = Dataset.from_pandas(train)\n        dataset = Dataset.from_pandas(df_train)\n        # Valid Dataset\n        tokenized_dataset_v = dataset_v.map(preprocess, num_proc=2, \n                         remove_columns=['essay_id', 'full_text','score'])\n        # Train Dataset\n        tokenized_dataset_t = dataset_t.map(preprocess, num_proc=2, \n                        remove_columns=['essay_id', 'full_text','score'])\n        \n        \n        trainer = Trainer(\n                 model = Custom_Model(base_model),\n                 args = training_args,\n                 tokenizer = tokenizer,\n                 train_dataset = tokenized_dataset_t,\n                 eval_dataset = tokenized_dataset_v,\n                 data_collator = DataCollatorWithPadding(tokenizer, padding='longest'),\n                 compute_metrics=compute_metrics\n                 )\n\n        trainer.train()\n        \n        y_true = valid['score'].values\n        predictions = trainer.predict(tokenized_dataset_v).predictions\n        predictions = predictions + 1\n        cm = confusion_matrix(y_true, predictions.clip(1,6).round(), labels=[x for x in range(1,7)])\n        draw_cm = ConfusionMatrixDisplay(confusion_matrix=cm,\n                                  display_labels=[x for x in range(1,7)])\n        draw_cm.plot()\n        plt.show()\n        \n        trainer.model.config = config\n        config.save_pretrained(f'DeBerta_Small_v{CFG.VER}_Fold{i}')\n        trainer.save_model(f'DeBerta_Small_v{CFG.VER}_Fold{i}')\n\n        del train, valid, tokenized_dataset_t, tokenized_dataset_v, trainer\n        clean_memory()\n        \nelse:\n    None",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:03:22.986512Z",
     "iopub.execute_input": "2024-05-03T11:03:22.986855Z",
     "iopub.status.idle": "2024-05-03T11:03:22.997941Z",
     "shell.execute_reply.started": "2024-05-03T11:03:22.98683Z",
     "shell.execute_reply": "2024-05-03T11:03:22.996857Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFA500\"><b><span style='color:#FFA500'></span></b> <b>6. Inference</b></div>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if CFG.INFERENCE:\n    dataset_test = Dataset.from_pandas(df_test)\n    tokenized_test = dataset_test.map(preprocess, num_proc=3, \n                         remove_columns=['essay_id', 'full_text'])\n    model = AutoModelForSequenceClassification.from_pretrained(CFG.preset)\n    \n    trainer = Trainer(\n                 model = model,\n                 args = training_args,\n                 tokenizer = tokenizer,\n                 data_collator = DataCollatorWithPadding(tokenizer, padding='longest'),\n                 compute_metrics=compute_metrics\n                 )\n    preds_test = trainer.predict(tokenized_test).predictions\n    preds_test = preds_test + 1\n    \n    sub = pd.DataFrame({'essay_id': df_test.essay_id.values})\n    sub['score'] = preds_test.clip(1,6).round()\n    sub.to_csv('submission.csv',index=False)\n    print('Submission shape', sub.shape)\n    print(sub.head())",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-03T11:03:33.631385Z",
     "iopub.execute_input": "2024-05-03T11:03:33.631761Z",
     "iopub.status.idle": "2024-05-03T11:03:37.153752Z",
     "shell.execute_reply.started": "2024-05-03T11:03:33.631732Z",
     "shell.execute_reply": "2024-05-03T11:03:37.15261Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
