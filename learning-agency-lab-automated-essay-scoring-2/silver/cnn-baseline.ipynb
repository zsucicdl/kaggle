{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 71485,
     "databundleVersionId": 8059942,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30673,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Based\n- https://www.kaggle.com/code/umar47/detect-ai-eda-tensorflow-0-91?scriptVersionId=159346087",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import polars as pl\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, LSTM, MultiHeadAttention, LayerNormalization\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import KFold\nimport numpy as np\nfrom tensorflow.keras.callbacks import EarlyStopping",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-07T15:16:17.150553Z",
     "iopub.execute_input": "2024-04-07T15:16:17.151239Z",
     "iopub.status.idle": "2024-04-07T15:16:29.832899Z",
     "shell.execute_reply.started": "2024-04-07T15:16:17.151206Z",
     "shell.execute_reply": "2024-04-07T15:16:29.830972Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train = pl.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv')\ntest = pl.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv')\n\nmax_features = 30000\nembedding_dim = 64\nsequence_length = 512\nbatch_size = 32\nn_splits = 5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-07T15:16:29.835262Z",
     "iopub.execute_input": "2024-04-07T15:16:29.835959Z",
     "iopub.status.idle": "2024-04-07T15:16:30.388373Z",
     "shell.execute_reply.started": "2024-04-07T15:16:29.835914Z",
     "shell.execute_reply": "2024-04-07T15:16:30.387425Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def tf_lower_and_split_punct(text):\n    text = tf.strings.lower(text)\n    text = tf.strings.regex_replace(text, '[^a-z.?!,¿]', '')\n    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n    text = tf.strings.strip(text)\n    return text\n\nvectorize_layer = tf.keras.layers.TextVectorization(\n    standardize=tf_lower_and_split_punct,\n    max_tokens=max_features,\n    ngrams=(3, 5),\n    output_mode=\"int\",\n    output_sequence_length=sequence_length,\n    pad_to_max_tokens=True\n)\n\ntext_ds = tf.data.Dataset.from_tensor_slices(train['full_text'].to_numpy()).batch(batch_size)\nvectorize_layer.adapt(text_ds)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-07T15:16:30.389928Z",
     "iopub.execute_input": "2024-04-07T15:16:30.390548Z",
     "iopub.status.idle": "2024-04-07T15:16:47.868014Z",
     "shell.execute_reply.started": "2024-04-07T15:16:30.39052Z",
     "shell.execute_reply": "2024-04-07T15:16:47.867174Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def vectorize_text(text, label):\n    text = tf.expand_dims(text, -1)\n    return vectorize_layer(text), label\n\ndef create_model():\n    inputs = Input(shape=(sequence_length,))\n    x = Embedding(max_features, embedding_dim, embeddings_regularizer=tf.keras.regularizers.l2(0.01))(inputs)\n    x = Dropout(0.5)(x)\n    x = Conv1D(64, 5, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n    x = LSTM(64, return_sequences=True)(x)\n    x = MultiHeadAttention(num_heads=8, key_dim=64)(x, x)\n    x = LayerNormalization(epsilon=1e-6)(x)\n    x = GlobalMaxPooling1D()(x)\n    x = Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n    x = Dropout(0.5)(x)\n    outputs = Dense(1, activation='linear')(x)\n    \n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n    return model",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-07T15:18:06.34618Z",
     "iopub.execute_input": "2024-04-07T15:18:06.346905Z",
     "iopub.status.idle": "2024-04-07T15:18:06.355541Z",
     "shell.execute_reply.started": "2024-04-07T15:18:06.346873Z",
     "shell.execute_reply": "2024-04-07T15:18:06.354527Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=222)\n\npredictions_list = []\n\nfor train_index, val_index in kfold.split(train):\n    train_df = train[train_index]\n    val_df = train[val_index]\n    \n    raw_train_ds = tf.data.Dataset.from_tensor_slices(\n        (train_df['full_text'].to_numpy(), train_df['score'].to_numpy())\n    ).batch(batch_size)\n    \n    raw_val_ds = tf.data.Dataset.from_tensor_slices(\n        (val_df['full_text'].to_numpy(), val_df['score'].to_numpy())\n    ).batch(batch_size)\n    \n    train_ds = raw_train_ds.map(vectorize_text)\n    val_ds = raw_val_ds.map(vectorize_text)\n    \n    model = create_model()\n    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n    model.fit(train_ds, validation_data=val_ds, epochs=9, callbacks=[early_stopping])\n    \n    test_texts = test['full_text'].to_numpy()\n    test_texts = tf.expand_dims(test_texts, -1)\n    test_texts = vectorize_layer(test_texts)\n    \n    predictions = model.predict(test_texts)\n    predictions_list.append(predictions)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-07T15:18:15.659795Z",
     "iopub.execute_input": "2024-04-07T15:18:15.66022Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "final_predictions = np.mean(predictions_list, axis=0)\nfinal_predictions = np.round(final_predictions).astype(int)\nfinal_predictions = np.clip(final_predictions, 1, 6)\n\nsubmission = test.select('essay_id').with_columns(score=final_predictions.flatten())\nsubmission.write_csv('submission.csv')\n\nsubmission.head()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Please upvote if you find this useful.",
   "metadata": {}
  }
 ]
}
