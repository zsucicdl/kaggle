{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 71485,
     "databundleVersionId": 8059942,
     "sourceType": "competition"
    },
    {
     "sourceId": 8259859,
     "sourceType": "datasetVersion",
     "datasetId": 4902293
    }
   ],
   "dockerImageVersionId": 30699,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "### TL;DR\nMany have demonstrated that regression approach works a lot better than classification approach in this comptetion. However, I found classification approach using Focal Loss ([Lin *et al.*, (2017)](https://arxiv.org/abs/1708.02002)) works as good as regression approach.<br>\nI used a focal loss with Œ≥=2 to train deberta-v3-small and got LB=0.797 (cv=0.808 please refer [version 4 ](https://www.kaggle.com/code/emiz6413/lb-0-797-deberta-v3-small-focal-loss?scriptVersionId=174316940) of this notebook for the training), which is very close to the LB=0.800 obtained in [the notebook](https://www.kaggle.com/code/cdeotte/deberta-v3-small-starter-cv-0-820-lb-0-800) by @cdeotte. <br>\n\n### üóíÔ∏è Note\nI haven't adjusted Œ≥ at all so far. I'm planning to tune it and will update the notebook once I find a better value. If you find a better Œ≥ and willing to share, please let me know in the commentüôá\n\n### üëÄ How focal loss works and motivation to use this\nThe formulation of focal loss (FL) is actually quite simple, it is cross entropy (CE) multiplied by a coefficient.\n\n$$\n\\textrm{FL}(p) = - (1 - p)^{\\gamma} \\log{p} = (1 - p)^{\\gamma} \\textrm{CE}(p)\n$$\n\n<img src=\"https://storage.googleapis.com/aes2-0/focal_loss_diagram.png\" width=50%>\n\nWe can think that the coefficient $(1 - p)^{\\gamma}$ controlls the amount of cross entropy loss taken into account. When $\\gamma = 0$, it matches with the definition of the cross entorpy. As $\\gamma$ increases, cross entropy is tweaked in such a way that it becomes increasingly more important to better classify hard (low `p`) examples rather than predicting higher probability on easy (high `p`) examples.\n\nWhile currently it achieves slightly lower cv/LB than the regression approach under current setting, one advantage of using this over the regression model is that we can compute the softmax probability of each class, which can be used to predict rare classes better with a threshold biased towards the rare classes (e.g. p(score=6) > 0.1).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import os\nimport copy\nfrom pathlib import Path\nfrom dataclasses import dataclass\n\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets.arrow_dataset import Dataset\nfrom transformers.trainer import Trainer\nfrom transformers.modeling_utils import PreTrainedModel\nfrom transformers.trainer_utils import EvalPrediction\nfrom transformers.training_args import TrainingArguments\nfrom transformers.models.deberta_v2 import DebertaV2ForSequenceClassification, DebertaV2TokenizerFast\nfrom tokenizers import AddedToken\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score, matthews_corrcoef, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-04-29T06:52:02.258781Z",
     "iopub.execute_input": "2024-04-29T06:52:02.259743Z",
     "iopub.status.idle": "2024-04-29T06:52:20.895803Z",
     "shell.execute_reply.started": "2024-04-29T06:52:02.259697Z",
     "shell.execute_reply": "2024-04-29T06:52:20.894573Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Config",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "@dataclass\nclass Config:\n    checkpoint: str = \"microsoft/deberta-v3-small\"\n    per_device_train_batch_size: int = 4\n    per_device_eval_batch_size: int = 8\n    gradient_accumulation_steps: int = 8 // torch.cuda.device_count() / per_device_train_batch_size\n    num_train_epochs: float = 4\n    train_max_length: int = 1024\n    eval_max_length: int = 2048\n    lr: float = 1e-5\n    scheduler: str = \"linear\"\n    warmup_ratio: float = 0.0\n    weight_decay = 0.01\n    amp: bool = True\n    n_splits: int = 5\n    gamma: float = 2.\n    optim: str = \"adamw_torch\"\n    inference: bool = True \n    inference_checkpoints_dir: str = \"/kaggle/input/aes-2-0-deberta-v3-small-focal-gamma2/output\"\n    \nconfig = Config()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-29T07:02:35.649761Z",
     "iopub.execute_input": "2024-04-29T07:02:35.650707Z",
     "iopub.status.idle": "2024-04-29T07:02:35.661229Z",
     "shell.execute_reply.started": "2024-04-29T07:02:35.650663Z",
     "shell.execute_reply": "2024-04-29T07:02:35.660051Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "args = TrainingArguments(\n    output_dir=\"output\",\n    report_to=\"none\",\n    per_device_train_batch_size=config.per_device_train_batch_size,\n    per_device_eval_batch_size=config.per_device_eval_batch_size,\n    gradient_accumulation_steps=config.gradient_accumulation_steps,\n    num_train_epochs=config.num_train_epochs,\n    weight_decay=config.weight_decay,\n    evaluation_strategy='epoch',\n    save_strategy=\"epoch\",\n    logging_steps=10,\n    save_total_limit=1,\n    metric_for_best_model=\"qwk\",\n    greater_is_better=True,\n    load_best_model_at_end=True,\n    fp16=config.amp,\n    learning_rate=config.lr,\n    lr_scheduler_type=config.scheduler,\n    warmup_ratio=config.warmup_ratio,\n    optim=config.optim\n)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-29T06:54:00.072434Z",
     "iopub.execute_input": "2024-04-29T06:54:00.072742Z",
     "iopub.status.idle": "2024-04-29T06:54:00.106291Z",
     "shell.execute_reply.started": "2024-04-29T06:54:00.072717Z",
     "shell.execute_reply": "2024-04-29T06:54:00.105461Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Instantiate the model & tokenizer",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class ModelInit:\n    model_class = DebertaV2ForSequenceClassification\n    \n    def __init__(self, checkpoint: str, num_labels: int = 6) -> None:\n        self.model = self.model_class.from_pretrained(checkpoint, num_labels=num_labels)\n        self.state_dict = copy.deepcopy(self.model.state_dict())\n        \n    def __call__(self) -> model_class:\n        self.model.load_state_dict(self.state_dict)\n        return self.model",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-29T06:54:04.361411Z",
     "iopub.execute_input": "2024-04-29T06:54:04.361745Z",
     "iopub.status.idle": "2024-04-29T06:54:04.367442Z",
     "shell.execute_reply.started": "2024-04-29T06:54:04.361719Z",
     "shell.execute_reply": "2024-04-29T06:54:04.366539Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Instantiate the dataset",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if config.inference:\n    df = pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\")\nelse:\n    df = pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\")\nds = Dataset.from_pandas(df)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-29T06:54:07.462478Z",
     "iopub.execute_input": "2024-04-29T06:54:07.462815Z",
     "iopub.status.idle": "2024-04-29T06:54:07.50282Z",
     "shell.execute_reply.started": "2024-04-29T06:54:07.462789Z",
     "shell.execute_reply": "2024-04-29T06:54:07.502139Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class Encoder:\n    def __init__(self, tokenizer, **encode_kwargs):\n        self.tokenizer = tokenizer\n        self.kwargs = encode_kwargs\n        \n    def __call__(self, batch: dict) -> dict:\n        encoded = self.tokenizer(batch[\"full_text\"], **self.kwargs)\n        encoded[\"labels\"] = [s-1 for s in batch[\"score\"]]  # score is 1~6\n        return encoded",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-29T06:54:07.66476Z",
     "iopub.execute_input": "2024-04-29T06:54:07.665064Z",
     "iopub.status.idle": "2024-04-29T06:54:07.672571Z",
     "shell.execute_reply.started": "2024-04-29T06:54:07.665041Z",
     "shell.execute_reply": "2024-04-29T06:54:07.671659Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Compute Metrics",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def compute_metrics(eval_pred: EvalPrediction) -> dict:\n    predictions = eval_pred.predictions\n    y_true = eval_pred.label_ids\n    y_pred = predictions.argmax(-1)\n    kappa = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n    corr = matthews_corrcoef(y_true, y_pred)\n    acc = accuracy_score(y_true, y_pred)\n    return {\"qwk\": kappa, \"corr\": corr, \"acc\": acc}",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-29T06:54:10.278672Z",
     "iopub.execute_input": "2024-04-29T06:54:10.27903Z",
     "iopub.status.idle": "2024-04-29T06:54:10.284502Z",
     "shell.execute_reply.started": "2024-04-29T06:54:10.279002Z",
     "shell.execute_reply": "2024-04-29T06:54:10.283565Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Custom Trainer with Focal Loss",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class FocalLoss(torch.nn.Module):\n    def __init__(self, weight: torch.Tensor | None = None, gamma: float = 2,) -> None:\n        super().__init__()\n        self.ce = torch.nn.CrossEntropyLoss(weight=weight)\n        self.gamma = gamma\n\n    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n        ce_loss: torch.Tensor = self.ce(input, target)\n        pt = torch.exp(-ce_loss)\n        f_loss = (1 - pt) ** self.gamma * ce_loss\n        f_loss = torch.mean(f_loss)\n        return f_loss\n    \n    \nclass FocalLossTrainer(Trainer):\n    def compute_loss(self, model: PreTrainedModel, inputs: dict, return_outputs: bool = False) -> tuple:\n        ce_loss, outputs = super().compute_loss(model, inputs, True)\n        labels = inputs[\"labels\"]\n        logits = outputs[\"logits\"]\n        loss_fn = FocalLoss(gamma=config.gamma)\n        loss = loss_fn(input=logits, target=labels)\n        outputs[\"loss\"] = loss\n        return (loss, outputs) if return_outputs else loss",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-29T06:54:12.844378Z",
     "iopub.execute_input": "2024-04-29T06:54:12.845157Z",
     "iopub.status.idle": "2024-04-29T06:54:12.853797Z",
     "shell.execute_reply.started": "2024-04-29T06:54:12.845125Z",
     "shell.execute_reply": "2024-04-29T06:54:12.85293Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Train",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-26T09:44:29.178919Z",
     "iopub.execute_input": "2024-04-26T09:44:29.179293Z",
     "iopub.status.idle": "2024-04-26T09:44:29.210433Z",
     "shell.execute_reply.started": "2024-04-26T09:44:29.17926Z",
     "shell.execute_reply": "2024-04-26T09:44:29.209755Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": "if not config.inference:\n    model_init = ModelInit(config.checkpoint)\n    tokenizer = DebertaV2TokenizerFast.from_pretrained(config.checkpoint)\n    tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\n    tokenizer.add_tokens([AddedToken(\" \"*2, normalized=False)])\n    \n    train_encoder = Encoder(tokenizer, max_length=config.train_max_length, truncation=True)\n    eval_encoder = Encoder(tokenizer, max_length=config.eval_max_length, truncation=True)\n    \n    # 5-fold stratified cv\n    cv = StratifiedKFold(n_splits=config.n_splits, shuffle=True, random_state=42)\n    folds = list(cv.split(np.zeros(len(df)), y=df[\"score\"].values))\n    idx2fold = {idx: fold for fold, (_, val_idx) in enumerate(folds) for idx in val_idx}\n    df[\"fold\"] = [idx2fold[i] for i in df.index]\n    df.to_csv(\"train_split.csv\", index=False)\n    \n    cv_res = []\n\n    for fold_idx in sorted(df[\"fold\"].unique()):\n        args.output_dir = os.path.join(\"output\", f\"fold_{fold_idx}\")\n        args.run_name = f\"{config.checkpoint}_fold-{fold_idx}\"\n        train_ds = ds.select([i for i, d in enumerate(ds) if d[\"fold\"] != fold_idx])\n        eval_ds = ds.select([i for i, d in enumerate(ds) if d[\"fold\"] == fold_idx])\n        train_ds = train_ds.map(train_encoder, batched=True)\n        eval_ds = eval_ds.map(eval_encoder, batched=True)\n        trainer = FocalLossTrainer(\n            args=args, \n            train_dataset=train_ds, \n            eval_dataset=eval_ds,\n            tokenizer=tokenizer,\n            model_init=model_init,\n            compute_metrics=compute_metrics,\n        )\n        trainer.train()\n        preds = trainer.predict(eval_ds).predictions\n        qwk = cohen_kappa_score(y1=np.array(eval_ds[\"labels\"]), y2=preds.argmax(-1), weights=\"quadratic\")\n        fig, ax = plt.subplots()\n        ConfusionMatrixDisplay.from_predictions(\n            y_true=np.array(eval_ds[\"labels\"]), \n            y_pred=preds.argmax(-1),\n            ax=ax\n        )\n        ax.set_title(f\"fold-{fold_idx} qwk: {qwk:.3f}\")\n        fig.show()\n        cv_res.append(qwk)\n\n        res_df = pd.DataFrame(\n            {\n                \"fold\": list(sorted(df[\"fold\"].unique())) + [\"mean\"],\n                \"qwk\": cv_res + [np.mean(cv_res)]\n            }\n        )\n        display(res_df)",
   "metadata": {
    "scrolled": true,
    "execution": {
     "iopub.status.busy": "2024-04-29T06:54:14.519818Z",
     "iopub.execute_input": "2024-04-29T06:54:14.5206Z",
     "iopub.status.idle": "2024-04-29T06:54:14.536093Z",
     "shell.execute_reply.started": "2024-04-29T06:54:14.52057Z",
     "shell.execute_reply": "2024-04-29T06:54:14.535161Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Inference",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if config.inference:\n    predictions = 0\n    checkpoints = list(Path(config.inference_checkpoints_dir).glob(\"fold*/checkpoint*\"))\n    print(checkpoints)\n\n    for checkpoint in checkpoints:\n        tokenizer = DebertaV2TokenizerFast.from_pretrained(checkpoint)\n        model = DebertaV2ForSequenceClassification.from_pretrained(checkpoint)\n        _ds = ds.map(\n            lambda i: tokenizer(i[\"full_text\"], max_length=config.eval_max_length, truncation=True), \n            batched=True,\n        )\n        args = TrainingArguments(\n            output_dir=\".\",\n            per_device_eval_batch_size=config.per_device_eval_batch_size,\n            fp16=config.amp,\n        )\n        trainer = Trainer(args=args, model=model, tokenizer=tokenizer)\n        preds = trainer.predict(_ds)\n        predictions += preds.predictions / len(checkpoints)\n\n    predicted_scores = predictions.argmax(-1) + 1  # [0,5] -> [1,6]\n    \n    df[\"score\"] = predicted_scores\n    df = df[[\"essay_id\", \"score\"]]\n    display(df)\n    df.to_csv(\"submission.csv\", index=False)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-29T07:03:33.761799Z",
     "iopub.execute_input": "2024-04-29T07:03:33.762145Z",
     "iopub.status.idle": "2024-04-29T07:03:57.986299Z",
     "shell.execute_reply.started": "2024-04-29T07:03:33.762119Z",
     "shell.execute_reply": "2024-04-29T07:03:57.985581Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
