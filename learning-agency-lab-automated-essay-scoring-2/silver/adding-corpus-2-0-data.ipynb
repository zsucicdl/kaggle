{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 71485,
     "databundleVersionId": 8059942,
     "sourceType": "competition"
    },
    {
     "sourceId": 173446080,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "Training Notebook: https://www.kaggle.com/code/hodinhtrieu/training-fold0-aes-deberta-model-starter",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd \nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\nfrom datasets import Dataset\n\nTEST_DATA_PATH = \"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\"\nMAX_LENGTH = 1024\nMODEL_FOLD0 = '/kaggle/input/training-fold0-aes-deberta-model-starter/deberta-small-fold0/checkpoint-3000/'\nMODEL_FOLD1 = '/kaggle/input/training-fold0-aes-deberta-model-starter/deberta-small-fold1/checkpoint-2500/'\nMODEL_FOLD2 = '/kaggle/input/training-fold0-aes-deberta-model-starter/deberta-small-fold2/checkpoint-2500/'\nMODEL_FOLD3 = '/kaggle/input/training-fold0-aes-deberta-model-starter/deberta-small-fold3/checkpoint-4000/'\nmodels = [MODEL_FOLD0,MODEL_FOLD1,MODEL_FOLD2,MODEL_FOLD3]\nEVAL_BATCH_SIZE = 1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-23T05:53:56.295107Z",
     "iopub.execute_input": "2024-04-23T05:53:56.296049Z",
     "iopub.status.idle": "2024-04-23T05:53:56.302039Z",
     "shell.execute_reply.started": "2024-04-23T05:53:56.296014Z",
     "shell.execute_reply": "2024-04-23T05:53:56.301009Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "tokenizer = AutoTokenizer.from_pretrained(MODEL_FOLD0)\n\ndef tokenize(sample):\n    return tokenizer(sample['full_text'], max_length=MAX_LENGTH, truncation=True)\n\ndf_test = pd.read_csv(TEST_DATA_PATH)\nds = Dataset.from_pandas(df_test).map(tokenize).remove_columns(['essay_id', 'full_text'])\n\nargs = TrainingArguments(\n    \".\", \n    per_device_eval_batch_size=EVAL_BATCH_SIZE, \n    report_to=\"none\"\n)\n\npredictions = []\nfor model in models:\n    model = AutoModelForSequenceClassification.from_pretrained(model)\n    trainer = Trainer(\n        model=model, \n        args=args, \n        data_collator=DataCollatorWithPadding(tokenizer), \n        tokenizer=tokenizer\n    )\n    \n    preds = trainer.predict(ds).predictions\n    predictions.append(softmax(preds, axis=-1))  \n    del model, trainer\n    torch.cuda.empty_cache()\n    gc.collect()\n    \npredicted_score = 0.\n\nfor p in predictions:\n    predicted_score += p\n    \npredicted_score /= len(predictions)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-23T05:54:20.924251Z",
     "iopub.execute_input": "2024-04-23T05:54:20.925116Z",
     "iopub.status.idle": "2024-04-23T05:54:40.784952Z",
     "shell.execute_reply.started": "2024-04-23T05:54:20.925083Z",
     "shell.execute_reply": "2024-04-23T05:54:40.784054Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df_test['score'] = predicted_score.argmax(-1) + 1\ndf_test.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-23T05:55:46.302689Z",
     "iopub.execute_input": "2024-04-23T05:55:46.303515Z",
     "iopub.status.idle": "2024-04-23T05:55:46.318451Z",
     "shell.execute_reply.started": "2024-04-23T05:55:46.303481Z",
     "shell.execute_reply": "2024-04-23T05:55:46.317468Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df_test[['essay_id', 'score']].to_csv('submission.csv', index=False)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
