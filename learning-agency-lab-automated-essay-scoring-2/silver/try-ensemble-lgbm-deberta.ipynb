{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"},{"sourceId":8046222,"sourceType":"datasetVersion","datasetId":4744550},{"sourceId":8029842,"sourceType":"datasetVersion","datasetId":4732809},{"sourceId":8070853,"sourceType":"datasetVersion","datasetId":4762179}],"dockerImageVersionId":30674,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:steelBlue;text-align:center;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\">Submission 1 (Deberta baseline)</div>\n\n- Ref: https://www.kaggle.com/code/idv2005/deberta-baseline-inference","metadata":{}},{"cell_type":"code","source":"  import numpy as np \nimport pandas as pd \nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import Dataset\nimport gc\nimport torch\nimport re\nimport copy\nimport polars as pl\nimport lightgbm as lgb\nfrom tqdm.auto import tqdm, trange\nfrom lightgbm import log_evaluation, early_stopping\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_DATA_PATH = \"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\"\nMAX_LENGTH = 1024\nMODEL_PATH = '/kaggle/input/es-deberta-large-fold0'\nEVAL_BATCH_SIZE = 1\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n\ndef tokenize(sample):\n    return tokenizer(sample['full_text'], max_length=MAX_LENGTH, truncation=True)\n\ndf_test = pd.read_csv(TEST_DATA_PATH)\nds = Dataset.from_pandas(df_test)\nds = ds.map(tokenize).remove_columns(['essay_id', 'full_text'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataCollator:\n    def __call__(self, features):\n        model_inputs = [{\n            'input_ids': feature['input_ids'],\n            'attention_mask': feature['attention_mask']\n        } for feature in features]\n        \n        batch = tokenizer.pad(\n            model_inputs,\n            padding=True,\n            max_length=MAX_LENGTH,\n            return_tensors='pt',\n            pad_to_multiple_of = 16\n        )\n        return batch","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\ncollator = DataCollator()\nargs = TrainingArguments(\".\", per_device_eval_batch_size=EVAL_BATCH_SIZE, report_to=\"none\")\ntrainer = Trainer(model=model, args=args, data_collator=collator, tokenizer=tokenizer)\npredictions = trainer.predict(ds).predictions\n\ndel model, trainer\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = predictions.argmax(-1) + 1\ndf_test['score'] = preds\ndf_test[['essay_id', 'score']].to_csv('submission_1.csv', index=False)\ndf_test.head(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:steelBlue;text-align:center;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\">Submission 2 (Tfidf + LGBM baseline)</div>\n- Ref: https://www.kaggle.com/code/ye11725/tfidf-lgbm-baseline","metadata":{}},{"cell_type":"code","source":"columns = [  \n    # paragraph\n    (pl.col(\"full_text\").str.split(by=\"\\n\\n\").alias(\"paragraph\")),\n]\nPATH = \"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/\"\ntrain = pl.read_csv(PATH + \"train.csv\").with_columns(columns)\ntest = pl.read_csv(PATH + \"test.csv\").with_columns(columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def removeHTML(x):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',x)\n\ndef dataPreprocessing(x):\n    x = x.lower()\n    x = removeHTML(x)\n    x = re.sub(\"@\\w+\", '',x)\n    x = re.sub(\"'\\d+\", '',x)\n    x = re.sub(\"\\d+\", '',x)\n    x = re.sub(\"http\\w+\", '',x)\n    x = re.sub(r\"\\s+\", \" \", x)\n    x = re.sub(r\"\\.+\", \".\", x)\n    x = re.sub(r\"\\,+\", \",\", x)\n    x = x.strip()\n    return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# paragraph feature\ndef Paragraph_Preprocess(tmp):\n    \n    tmp = tmp.explode('paragraph')\n    # preprocess\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(dataPreprocessing))\n    # paragraph_len\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x)).alias(\"paragraph_len\"))\n    # paragraph_sentence_cnt/paragraph_word_cnt\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x.split('.'))).alias(\"paragraph_sentence_cnt\"),\n                    pl.col('paragraph').map_elements(lambda x: len(x.split(' '))).alias(\"paragraph_word_cnt\"),)\n    return tmp\n# feature_eng\nparagraph_fea = ['paragraph_len','paragraph_sentence_cnt','paragraph_word_cnt']\ndef Paragraph_Eng(train_tmp):\n    aggs = [\n        # paragraph_len_cnt\n        *[pl.col('paragraph').filter(pl.col('paragraph_len') >= i).count().alias(f\"paragraph_{i}_cnt\") for i in [50,75,100,125,150,175,200,250,300,350,400,500,600,700] ], \n        *[pl.col('paragraph').filter(pl.col('paragraph_len') <= i).count().alias(f\"paragraph_{i}_cnt\") for i in [25,49]], \n        # other\n        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in paragraph_fea],\n        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in paragraph_fea],\n        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in paragraph_fea],\n        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in paragraph_fea],\n        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in paragraph_fea],\n        ]\n    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n    df = df.to_pandas()\n    return df\ntmp = Paragraph_Preprocess(train)\ntrain_feats = Paragraph_Eng(tmp)\ntrain_feats['score'] = train['score']\nprint('feature_num: ',len(train_feats.columns)-2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sentence feature\ndef Sentence_Preprocess(tmp):\n    \n    tmp = tmp.with_columns(pl.col('full_text').map_elements(dataPreprocessing).str.split(by=\".\").alias(\"sentence\"))\n    tmp = tmp.explode('sentence')\n    # sentence_len\n    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x)).alias(\"sentence_len\"))\n    # filter\n    tmp = tmp.filter(pl.col('sentence_len')>=15)\n    # sentence_word_cnt\n    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x.split(' '))).alias(\"sentence_word_cnt\"))\n    \n    return tmp\n# feature_eng\nsentence_fea = ['sentence_len','sentence_word_cnt']\ndef Sentence_Eng(train_tmp):\n    aggs = [\n        # sentence_cnt\n        *[pl.col('sentence').filter(pl.col('sentence_len') >= i).count().alias(f\"sentence_{i}_cnt\") for i in [15,50,100,150,200,250,300] ], \n        # other\n        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in sentence_fea],\n        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in sentence_fea],\n        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in sentence_fea],\n        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in sentence_fea],\n        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in sentence_fea],\n        ]\n    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n    df = df.to_pandas()\n    return df\n# merge\ntmp = Sentence_Preprocess(train)\ntrain_feats = train_feats.merge(Sentence_Eng(tmp), on='essay_id', how='left')\nprint('feature_num: ',len(train_feats.columns)-2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# word feature\ndef Word_Preprocess(tmp):\n\n    tmp = tmp.with_columns(pl.col('full_text').map_elements(dataPreprocessing).str.split(by=\" \").alias(\"word\"))\n    tmp = tmp.explode('word')\n    # word_len\n    tmp = tmp.with_columns(pl.col('word').map_elements(lambda x: len(x)).alias(\"word_len\"))\n    # filter\n    tmp = tmp.filter(pl.col('word_len')!=0)\n    \n    return tmp\n# feature_eng\ndef Word_Eng(train_tmp):\n    aggs = [\n        # word_cnt\n        *[pl.col('word').filter(pl.col('word_len') >= i+1).count().alias(f\"word_{i+1}_cnt\") for i in range(15) ], \n        # other\n        pl.col('word_len').max().alias(f\"word_len_max\"),\n        pl.col('word_len').mean().alias(f\"word_len_mean\"),\n        pl.col('word_len').std().alias(f\"word_len_std\"),\n        pl.col('word_len').quantile(0.25).alias(f\"word_len_q1\"),\n        pl.col('word_len').quantile(0.50).alias(f\"word_len_q2\"),\n        pl.col('word_len').quantile(0.75).alias(f\"word_len_q3\"),\n        ]\n    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n    df = df.to_pandas()\n    return df\n# merge\ntmp = Word_Preprocess(train)\ntrain_feats = train_feats.merge(Word_Eng(tmp), on='essay_id', how='left')\nprint('feature_num: ',len(train_feats.columns)-2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tfidf feature\nvectorizer = TfidfVectorizer(\n            tokenizer=lambda x: x,\n            preprocessor=lambda x: x,\n            token_pattern=None,\n            strip_accents='unicode',\n            analyzer = 'word',\n            ngram_range=(1,3),\n            min_df=0.05,\n            max_df=0.95,\n            sublinear_tf=True,\n)\n\ntrain_tfid = vectorizer.fit_transform([i for i in train['full_text']])\ndense_matrix = train_tfid.toarray()\ndf = pd.DataFrame(dense_matrix)\ntfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\ndf.columns = tfid_columns\ndf['essay_id'] = train_feats['essay_id']\n# merge\ntrain_feats = train_feats.merge(df, on='essay_id', how='left')\nfeature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\nprint('Features number: ',len(feature_names))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# idea from https://www.kaggle.com/code/rsakata/optimize-qwk-by-lgb/notebook#QWK-objective\na = 2.95\nb = 1.1\n\nnum_fold = 5\nmodels = []\nfor i in range(num_fold):\n    models.append(lgb.Booster(model_file=f'../input/lal-lgb-baseline-4/fold_{i}.txt'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = Paragraph_Preprocess(test)\ntest_feats = Paragraph_Eng(tmp)\ntmp = Sentence_Preprocess(test)\ntest_feats = test_feats.merge(Sentence_Eng(tmp), on='essay_id', how='left')\ntmp = Word_Preprocess(test)\ntest_feats = test_feats.merge(Word_Eng(tmp), on='essay_id', how='left')\ntest_tfid = vectorizer.transform([i for i in test['full_text']])\ndense_matrix = test_tfid.toarray()\ndf = pd.DataFrame(dense_matrix)\ntfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\ndf.columns = tfid_columns\ndf['essay_id'] = test_feats['essay_id']\ntest_feats = test_feats.merge(df, on='essay_id', how='left')\nfeature_names = list(filter(lambda x: x not in ['essay_id','score'], test_feats.columns))\nprint('Features number: ',len(feature_names))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = test_feats[['essay_id']].copy()\nprediction['score'] = 0\npred_test = models[0].predict(test_feats[feature_names]) + a\nfor i in range(num_fold-1):\n    pred_now = models[i+1].predict(test_feats[feature_names]) + a\n    pred_test = np.add(pred_test,pred_now)\npred_test = pred_test/num_fold\n\npred_test = pred_test.clip(1, 6).round()\nprediction['score'] = pred_test\nprediction.to_csv('submission_2.csv', index=False)\nprediction.head(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:steelBlue;text-align:center;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\">Ensemble</div>","metadata":{}},{"cell_type":"code","source":"# Load the data\ndf1 = pd.read_csv('/kaggle/working/submission_1.csv')\ndf2 = pd.read_csv('/kaggle/working/submission_2.csv')\n\n# Merging the dataframes on 'essay_id'\ndf = pd.merge(left=df1, right=df2, on='essay_id', suffixes=('_1', '_2'))\n\n# Calculating the average score directly without apply()\ndf['score'] = ((df['score_1'] + df['score_2']) / 2).round().astype(int)\n\n# Saving the desired columns to a new csv file\ndf[['essay_id', 'score']].to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}