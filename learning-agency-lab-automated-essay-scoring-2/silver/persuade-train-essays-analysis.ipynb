{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":61542,"databundleVersionId":7516023,"sourceType":"competition"},{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"},{"sourceId":7017419,"sourceType":"datasetVersion","datasetId":3937250},{"sourceId":8126394,"sourceType":"datasetVersion","datasetId":4802627}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PERSUADE -> train essays analysis\n\nPERSUADE corpus is available on kaggle [here](https://www.kaggle.com/datasets/nbroad/persaude-corpus-2/)","metadata":{}},{"cell_type":"code","source":"!pip install polyleven -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-19T18:21:50.997984Z","iopub.execute_input":"2024-04-19T18:21:50.998642Z","iopub.status.idle":"2024-04-19T18:22:04.387132Z","shell.execute_reply.started":"2024-04-19T18:21:50.998607Z","shell.execute_reply":"2024-04-19T18:22:04.385704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\n\npersuade_df = pd.read_csv(\"/kaggle/input/persaude-corpus-2/persuade_2.0_human_scores_demo_id_github.csv\")\ntrain_df = pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\").rename(columns={'full_text': 'text', 'essay_id': 'id'})\n\n# ignore other persuade essays with other prompts\n# persuade_filtered = persuade_df\n# train_filtered = train_df\n\n\ntrain_text2id = {t: i for t, i in train_df[[\"text\", \"id\"]].values}\ntrain_id2text = {v: k for k, v in train_text2id.items()}\npersuade_text2id = {\n    t: i for t, i in persuade_df[[\"full_text\", \"essay_id_comp\"]].values\n}\npersuade_id2text = {v: k for k, v in persuade_text2id.items()}\n\npersuade_df.shape, train_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:22:40.135788Z","iopub.execute_input":"2024-04-19T18:22:40.136153Z","iopub.status.idle":"2024-04-19T18:22:41.369949Z","shell.execute_reply.started":"2024-04-19T18:22:40.136127Z","shell.execute_reply":"2024-04-19T18:22:41.36886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking for exact matches\n\ntrain_df.text.str.strip().isin(persuade_df.full_text.str.strip()).sum()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:22:41.371922Z","iopub.execute_input":"2024-04-19T18:22:41.37233Z","iopub.status.idle":"2024-04-19T18:22:41.47472Z","shell.execute_reply.started":"2024-04-19T18:22:41.372292Z","shell.execute_reply":"2024-04-19T18:22:41.47367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# and the scores\n\ncommon_essays = train_df.merge(persuade_df, left_on='text', right_on='full_text', how='inner')\nall(common_essays.score == common_essays.holistic_essay_score)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:26:19.004062Z","iopub.execute_input":"2024-04-19T18:26:19.005012Z","iopub.status.idle":"2024-04-19T18:26:19.042021Z","shell.execute_reply.started":"2024-04-19T18:26:19.004975Z","shell.execute_reply":"2024-04-19T18:26:19.041133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop rows with exact matches\npersuade_filtered = persuade_df[~persuade_df.full_text.str.strip().isin(train_df.text.str.strip())]\ntrain_filtered = train_df[~train_df.text.str.strip().isin(persuade_df.full_text.str.strip())]\n\npersuade_filtered.to_csv(\"persuade.csv\", index=False)\ntrain_filtered.to_csv(\"train.csv\", index=False)\n\nlen(persuade_filtered), len(train_filtered)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:22:41.516871Z","iopub.execute_input":"2024-04-19T18:22:41.517249Z","iopub.status.idle":"2024-04-19T18:22:43.859886Z","shell.execute_reply.started":"2024-04-19T18:22:41.517214Z","shell.execute_reply":"2024-04-19T18:22:43.858952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create embeddings","metadata":{}},{"cell_type":"code","source":"%%writefile get_embeddings.py\n\nfrom argparse import ArgumentParser\nfrom transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments\nfrom datasets import Dataset\nimport pandas as pd\nimport torch\n\n\ndef parse_args():\n    parser = ArgumentParser()\n\n    parser.add_argument(\"--model_name\", type=str, default=\"BAAI/bge-base-en-v1.5\")\n    parser.add_argument(\"--csv_path\", type=str)\n    parser.add_argument(\"--text_col\", type=str)\n    parser.add_argument(\"--max_length\", type=int, default=512)\n    parser.add_argument(\"--batch_size\", type=int, default=128)\n    parser.add_argument(\"--num_proc\", type=int, default=2)\n    parser.add_argument(\"--output_path\", type=str)\n\n    return parser.parse_args()\n\n\ndef main():\n    args = parse_args()\n\n    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n    model = AutoModel.from_pretrained(args.model_name)\n    model.eval()\n\n    targs = TrainingArguments(\n        \".\",\n        report_to=\"none\",\n        per_device_eval_batch_size=args.batch_size,\n        dataloader_num_workers=1,\n    )\n\n    ds = Dataset.from_pandas(pd.read_csv(args.csv_path))\n\n    # strip whitespace from end\n    ds = ds.map(\n        lambda x: {args.text_col: x[args.text_col].strip()}, num_proc=args.num_proc\n    )\n\n    def tokenize(batch):\n        return tokenizer(\n            batch[args.text_col],\n            padding=False,\n            truncation=True,\n            max_length=args.max_length,\n        )\n\n    with targs.main_process_first(desc=\"dataset map pre-processing\"):\n        ds = ds.map(tokenize, batched=True, num_proc=args.num_proc)\n\n    trainer = Trainer(model=model, args=targs, tokenizer=tokenizer)\n\n    embeddings = trainer.predict(ds).predictions[0][:, 0]\n\n    embeddings = torch.nn.functional.normalize(\n        torch.tensor(embeddings), p=2, dim=1\n    ).cpu()\n\n    torch.save(embeddings, args.output_path)\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:22:43.861471Z","iopub.execute_input":"2024-04-19T18:22:43.861939Z","iopub.status.idle":"2024-04-19T18:22:43.870201Z","shell.execute_reply.started":"2024-04-19T18:22:43.861911Z","shell.execute_reply":"2024-04-19T18:22:43.869243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# run locally due to kaggle memory constraints\n\n\n# # Use both GPUs for faster inference\n\n# !torchrun --nproc_per_node 2 get_embeddings.py \\\n#   --model_name \"BAAI/bge-small-en-v1.5\" \\\n#   --csv_path \"./persuade.csv\" \\\n#   --text_col \"full_text\" \\\n#   --output_path \"persuade_embeddings.pt\" \n\n# !torchrun --nproc_per_node 2 get_embeddings.py \\\n#   --model_name \"BAAI/bge-small-en-v1.5\" \\\n#   --csv_path \"./train.csv\" \\\n#   --text_col \"text\" \\\n#   --output_path \"train_embeddings.pt\" ","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:22:43.871251Z","iopub.execute_input":"2024-04-19T18:22:43.871544Z","iopub.status.idle":"2024-04-19T18:22:43.88507Z","shell.execute_reply.started":"2024-04-19T18:22:43.871512Z","shell.execute_reply":"2024-04-19T18:22:43.88413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Take cosine similarity between train and PERSUADE embeddings","metadata":{}},{"cell_type":"code","source":"import torch\n\ndevice = 0 if torch.cuda.is_available() else torch.device(\"cpu\")\n\n# move to gpu to make dot product faster\ntrain_embeds = torch.load(\"/kaggle/input/aes-x-persuade/train_embeddings.pt\").to(device)\npersuade_embeds = torch.load(\"/kaggle/input/aes-x-persuade/persuade_embeddings.pt\").to(device)\n\n# dot product of normalized vectors is the same as cosine similarity\ncos_sim_matrix = torch.mm(train_embeds, persuade_embeds.transpose(0, 1))\n\ntopk_results = torch.topk(cos_sim_matrix, k=300)\n\ntopk_results","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:22:43.886662Z","iopub.execute_input":"2024-04-19T18:22:43.886956Z","iopub.status.idle":"2024-04-19T18:22:44.863385Z","shell.execute_reply.started":"2024-04-19T18:22:43.886922Z","shell.execute_reply":"2024-04-19T18:22:44.86248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Levenshtein distance for top cosine similarity scores","metadata":{}},{"cell_type":"code","source":"from polyleven import levenshtein\nfrom tqdm.auto import tqdm\n\ntrain_texts = train_filtered.text.values\npersuade_texts = persuade_filtered.full_text.values\ntopk_idxs = topk_results.indices.cpu().numpy()\n\nall_lev_scores = []\nfor topk, t_txt in zip(topk_idxs, train_texts):\n    \n    lev_scores = []\n    \n    for idx in topk:\n        p_txt = persuade_texts[idx]\n        lev = levenshtein(t_txt.strip(), p_txt.strip())\n        lev_scores.append(lev/max(len(t_txt.strip()), len(p_txt.strip())))\n    \n    all_lev_scores.append(lev_scores)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:22:44.864541Z","iopub.execute_input":"2024-04-19T18:22:44.864816Z","iopub.status.idle":"2024-04-19T18:22:47.621011Z","shell.execute_reply.started":"2024-04-19T18:22:44.864792Z","shell.execute_reply":"2024-04-19T18:22:47.62023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### It is clear to see that when the levenshtein distance is <0.3, the texts are the same","metadata":{}},{"cell_type":"code","source":"import difflib\nimport html\n\n\n# Created using gpt4\ndef compare_texts(text1, text2):\n\n    # Create a Differ object\n    differ = difflib.Differ()\n\n    # Compare the texts character by character\n    diff = differ.compare(text1, text2)\n\n    # Process the differences to generate HTML\n    html_output = []\n    for char in diff:\n        if char.startswith(\"+\"):\n            # Characters in text2 but not in text1, highlighted in blue\n            html_output.append(\n                f'<mark style=\"background-color: #AFEEEE;\">{html.escape(char[2:])}</mark>'\n            )\n        elif char.startswith(\"-\"):\n            # Characters in text1 but not in text2, highlighted in red\n            html_output.append(\n                f'<mark style=\"background-color: #DDA0DD;\">{html.escape(char[2:])}</mark>'\n            )\n        else:\n            # Characters that are the same in both texts\n            html_output.append(html.escape(char[2:]))\n\n    html_content = \"\".join(html_output)\n\n    # Join the processed characters to form the complete HTML\n    return f\"<pre style='font-size: 14px !important;'>{html_content}</pre>\"","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:22:47.622079Z","iopub.execute_input":"2024-04-19T18:22:47.622357Z","iopub.status.idle":"2024-04-19T18:22:47.629484Z","shell.execute_reply.started":"2024-04-19T18:22:47.622333Z","shell.execute_reply":"2024-04-19T18:22:47.628491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.core.display import HTML\n\nts, ps = [], []\n\nfor t, idxs, scores in zip(train_texts, topk_idxs, all_lev_scores):\n\n    if min(scores) > 0.3: continue\n\n    ts.append(t)\n    ps.append(persuade_texts[idxs[np.argmin(scores)]])\n    \n    # print(\" SCORES \".center(100, \"*\"), \"\\n\")\n    # print(scores[:5], \"\\n\")\n    # print(\" TRAIN TEXT BELOW \".center(100, \"*\"), \"\\n\")\n    # print(t, \"\\n\")\n    # print(\" PERSUADE CORPUS TEXT BELOW \".center(100, \"*\"), \"\\n\")\n    # print(persuade_texts[idxs[np.argmin(scores)]])\n    \n    # print(\"\\n\")\n    # print(\"-\"*100)\n    # print(\"\\n\")\n\nlen(ts), len(ps)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:22:47.633113Z","iopub.execute_input":"2024-04-19T18:22:47.633513Z","iopub.status.idle":"2024-04-19T18:22:47.685206Z","shell.execute_reply.started":"2024-04-19T18:22:47.633477Z","shell.execute_reply":"2024-04-19T18:22:47.684349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing differences\n\n#### <mark style=\"background-color: #AFEEEE;\">LIGHT BLUE</mark>: PERSUADE text has it, train text does NOT  \n#### <mark style=\"background-color: #DDA0DD;\">LIGHT PINK</mark>: train text has it, PERSUADE text does NOT\n\nNo highlight means both have it","metadata":{}},{"cell_type":"code","source":"i = 0\nHTML(compare_texts(ts[i], ps[i]))","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:22:47.686381Z","iopub.execute_input":"2024-04-19T18:22:47.686714Z","iopub.status.idle":"2024-04-19T18:22:47.739278Z","shell.execute_reply.started":"2024-04-19T18:22:47.686675Z","shell.execute_reply":"2024-04-19T18:22:47.738474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 1\nHTML(compare_texts(ts[i], ps[i]))","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:22:47.740436Z","iopub.execute_input":"2024-04-19T18:22:47.740709Z","iopub.status.idle":"2024-04-19T18:22:47.752575Z","shell.execute_reply.started":"2024-04-19T18:22:47.740686Z","shell.execute_reply":"2024-04-19T18:22:47.751659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_matches = []\np_matches = [] \nmatching_scores = []\nno_matches_t = []\n\nfor t_txt, idxs, l_scores in zip(train_texts, topk_idxs, all_lev_scores):\n    min_score = min(l_scores)\n    min_idx = l_scores.index(min_score)\n    if min_score < 0.3:\n        \n        t_matches.append(t_txt)\n        p_matches.append(persuade_texts[idxs[min_idx]])\n        matching_scores.append(min_score)\n    else:\n        no_matches_t.append(t_txt)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:22:47.75382Z","iopub.execute_input":"2024-04-19T18:22:47.754101Z","iopub.status.idle":"2024-04-19T18:22:47.801749Z","shell.execute_reply.started":"2024-04-19T18:22:47.754079Z","shell.execute_reply":"2024-04-19T18:22:47.801047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(t_matches), len(train_texts), len(no_matches_t)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:22:47.80279Z","iopub.execute_input":"2024-04-19T18:22:47.803393Z","iopub.status.idle":"2024-04-19T18:22:47.809477Z","shell.execute_reply.started":"2024-04-19T18:22:47.80336Z","shell.execute_reply":"2024-04-19T18:22:47.808607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l_scores = pd.Series([min(s) for s in all_lev_scores if min(s) > 0.3]).sort_values().reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:22:47.81063Z","iopub.execute_input":"2024-04-19T18:22:47.8109Z","iopub.status.idle":"2024-04-19T18:22:47.873039Z","shell.execute_reply.started":"2024-04-19T18:22:47.810865Z","shell.execute_reply":"2024-04-19T18:22:47.872223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l_scores","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:22:47.873945Z","iopub.execute_input":"2024-04-19T18:22:47.874211Z","iopub.status.idle":"2024-04-19T18:22:47.883342Z","shell.execute_reply.started":"2024-04-19T18:22:47.87417Z","shell.execute_reply":"2024-04-19T18:22:47.882234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = l_scores.plot.line()\nax.set_ylabel('levenshtein distance')\nax.set_xlabel('essays sorted by levenshtein distance')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T18:25:00.644429Z","iopub.execute_input":"2024-04-19T18:25:00.64482Z","iopub.status.idle":"2024-04-19T18:25:00.836246Z","shell.execute_reply.started":"2024-04-19T18:25:00.64479Z","shell.execute_reply":"2024-04-19T18:25:00.835232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}