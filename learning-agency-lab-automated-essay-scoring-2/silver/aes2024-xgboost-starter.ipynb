{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 71485,
     "databundleVersionId": 8059942,
     "sourceType": "competition"
    },
    {
     "sourceId": 8141507,
     "sourceType": "datasetVersion",
     "datasetId": 4813598
    },
    {
     "sourceId": 8267429,
     "sourceType": "datasetVersion",
     "datasetId": 4908030
    }
   ],
   "dockerImageVersionId": 30699,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "#### <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:white; font-size:180%; text-align:left;padding:3.0px; background: maroon; border-bottom: 8px solid black\" > TABLE OF CONTENTS<br><div>  \n* [INTRODUCTION](#2)   \n    * [UTILITIES](#2.1)  \n    * [FOREWORD](#2.2)\n    * [VERSION DETAILS](#2.3)\n* [PREPROCESSING](#3)  \n* [MODEL TRAINING](#4)\n      ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%time\n\n# Installing select libraries:-\nfrom gc import collect;\nfrom warnings import filterwarnings;\nfilterwarnings('ignore');\nfrom IPython.display import display_html, clear_output;\nimport logging\nimport sys\n\nfrom copy import deepcopy;\nimport pandas as pd, polars as pl, numpy as np;\nimport polars.selectors as cs;\nimport spacy, string, random\n\nfrom os import path, walk, getpid\nfrom psutil import Process\nimport re\nfrom collections import Counter\nfrom itertools import product\n\nfrom colorama import Fore, Style, init;\nfrom warnings import filterwarnings;\nfilterwarnings('ignore');\nimport joblib;\nimport os;\n\nfrom tqdm.notebook import tqdm;\nimport seaborn as sns;\nimport matplotlib.pyplot as plt;\nfrom matplotlib.colors import ListedColormap as LCM;\n%matplotlib inline\n\nfrom pprint import pprint;\nfrom functools import partial;\n\nimport ctypes\nlibc = ctypes.CDLL(\"libc.so.6\")\n\nprint();\ncollect();\nclear_output();",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-30T01:14:45.044094Z",
     "iopub.execute_input": "2024-04-30T01:14:45.04442Z",
     "iopub.status.idle": "2024-04-30T01:14:53.958558Z",
     "shell.execute_reply.started": "2024-04-30T01:14:45.044393Z",
     "shell.execute_reply": "2024-04-30T01:14:53.95737Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%time\n\n# Importing model and pipeline specifics:-\nfrom category_encoders import OrdinalEncoder, OneHotEncoder;\n\n# Pipeline specifics:-\nfrom sklearn.preprocessing import (RobustScaler,\n                                   MinMaxScaler,\n                                   StandardScaler,\n                                   FunctionTransformer as FT,\n                                   PowerTransformer,\n                                  );\nfrom sklearn.impute import SimpleImputer as SI;\nfrom sklearn.model_selection import (RepeatedStratifiedKFold as RSKF,\n                                     StratifiedKFold as SKF,\n                                     StratifiedGroupKFold as SGKF,\n                                     KFold,\n                                     RepeatedKFold as RKF,\n                                     cross_val_score,\n                                     cross_val_predict\n                                    );\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.pipeline import Pipeline, make_pipeline;\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin;\nfrom sklearn.compose import ColumnTransformer;\n\n# ML Model training:-\nfrom sklearn.metrics import (cohen_kappa_score,\n                             accuracy_score,\n                             roc_auc_score,\n                             confusion_matrix,\n                             ConfusionMatrixDisplay,\n                             f1_score)\nfrom xgboost import DMatrix, XGBRegressor as XGBR;\nimport xgboost as xgb\n\nclear_output();\nprint();\ncollect();",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-30T01:14:53.960739Z",
     "iopub.execute_input": "2024-04-30T01:14:53.961429Z",
     "iopub.status.idle": "2024-04-30T01:14:54.904204Z",
     "shell.execute_reply.started": "2024-04-30T01:14:53.961395Z",
     "shell.execute_reply": "2024-04-30T01:14:54.903317Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%time\n\n# Setting rc parameters in seaborn for plots and graphs-\n# Reference - https://matplotlib.org/stable/tutorials/introductory/customizing.html:-\n# To alter this, refer to matplotlib.rcParams.keys()\n\nsns.set({\"axes.facecolor\"       : \"#ffffff\",\n         \"figure.facecolor\"     : \"#ffffff\",\n         \"axes.edgecolor\"       : \"#000000\",\n         \"grid.color\"           : \"#ffffff\",\n         \"font.family\"          : ['Cambria'],\n         \"axes.labelcolor\"      : \"#000000\",\n         \"xtick.color\"          : \"#000000\",\n         \"ytick.color\"          : \"#000000\",\n         \"grid.linewidth\"       : 0.75,\n         \"grid.linestyle\"       : \"--\",\n         \"axes.titlecolor\"      : '#0099e6',\n         'axes.titlesize'       : 8.5,\n         'axes.labelweight'     : \"bold\",\n         'legend.fontsize'      : 7.0,\n         'legend.title_fontsize': 7.0,\n         'font.size'            : 7.5,\n         'xtick.labelsize'      : 7.5,\n         'ytick.labelsize'      : 7.5,\n        });\n\n# Setting global configuration for polars\npl.Config.activate_decimals(True).set_tbl_hide_column_data_types(True)\npl.Config(**dict(tbl_formatting = 'ASCII_FULL_CONDENSED',\n                 tbl_hide_column_data_types = True,\n                 tbl_hide_dataframe_shape = True,\n                 fmt_float = \"mixed\",\n                 tbl_cell_alignment = 'CENTER',\n                 tbl_hide_dtype_separator = True,\n                 tbl_cols = 100,\n                 tbl_rows = 50,\n                 fmt_str_lengths = 100,\n                )\n         )\n\n# Making sklearn pipeline outputs as dataframe:-\nfrom sklearn import set_config;\nset_config(transform_output = \"pandas\");\npd.set_option('display.max_columns', 50);\npd.set_option('display.max_rows', 50);\n\nprint();\ncollect();\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-30T01:14:54.905404Z",
     "iopub.execute_input": "2024-04-30T01:14:54.905906Z",
     "iopub.status.idle": "2024-04-30T01:14:55.084721Z",
     "shell.execute_reply.started": "2024-04-30T01:14:54.905879Z",
     "shell.execute_reply": "2024-04-30T01:14:55.083516Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"2\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color: white; font-size:120%; text-align:left;padding:3.0px; background: maroon; border-bottom: 8px solid black\" > INTRODUCTION<br><div>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"2.1\"></a>\n## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color: black; font-size:120%; text-align:left;padding:3.0px; background: #c2d6d6; border-bottom: 8px solid black\" > UTILITIES<br><div>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%time\n\nclass Utility:\n    \"\"\"\n    This class serves to do the below-\n    1. Define method to print in color\n    2. Define the garbage cleaning process\n    \"\"\";\n\n    def PrintColor(self,text:str, color = Fore.BLUE, style = Style.BRIGHT):\n        \"Prints color outputs using colorama using a text F-string\";\n        print(style + color + text + Style.RESET_ALL)\n\n    def ScoreMetric(self, ytrue, ypred)-> float:\n        \"\"\"\n        This method calculates the custom metric from the imported script\n        Inputs- ytrue, ypred:- input truth and predictions\n        Output- float:- competition metric\n        \"\"\";\n\n        y_pred = np.uint8(np.around(np.clip(ypred, a_min = 1, a_max = 6)))\n        return cohen_kappa_score(np.uint8(ytrue), y_pred, weights = \"quadratic\")\n\n    def ClsfMetric(self, ytrue, ypred)-> float:\n        \"\"\"\n        This method calculates the classifier model metric\n        Inputs- ytrue, ypred:- input truth and predictions\n        Output- float:- classifier metric\n        \"\"\";\n\n        return roc_auc_score(np.uint8(ytrue), ypred, multi_class = \"ovr\")\n\n    def CleanMemory(self):\n        \"This method cleans the memory off unused objects and displays the cleaned state RAM usage\";\n\n        collect();\n        libc.malloc_trim(0)\n        pid        = getpid()\n        py         = Process(pid)\n        memory_use = py.memory_info()[0] / 2. ** 30\n        return f\"\\nRAM usage = {memory_use :.4} GB\"\n\nUtils = Utility()\nprint();",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-30T01:14:55.086913Z",
     "iopub.execute_input": "2024-04-30T01:14:55.087195Z",
     "iopub.status.idle": "2024-04-30T01:14:55.110416Z",
     "shell.execute_reply.started": "2024-04-30T01:14:55.087171Z",
     "shell.execute_reply": "2024-04-30T01:14:55.109455Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"2.2\"></a>\n## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color: black; font-size:120%; text-align:left;padding:3.0px; background: #c2d6d6; border-bottom: 8px solid black\" > CONFIGURATION<br><div>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%time\n\nclass CFG:\n    \"\"\"\n    Configuration class for parameters and CV strategy for tuning and training\n    Some parameters may be unused here as this is a general configuration class\n    \n    for syntax check - use test_req = Y\n    for actual run, turn on the gpu_switch = ON and test_req = N\n    \"\"\";\n\n    # Data preparation:-\n    exp_nb             = 1;\n    version_nb         = 1;\n    test_req           = \"N\";\n    nb_cols_test       = 100;\n    gpu_switch         = \"ON\";\n\n    load_train_data    = True\n\n    cv_state           = 0;\n    state              = 42;\n\n    target             = \"score\";\n    path               = f\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2\";\n    op_path            = f\"/kaggle/working\"\n    vocab_path         = f'/kaggle/input/english-word-hx/words.txt'\n    mydatapath         = f\"/kaggle/input/aes2024startertraintest/Datasets\"\n\n    # Model Training:-\n    ML                 = \"Y\";\n    n_splits           = 3 if test_req == \"Y\" else 15;\n    n_repeats          = 1 ;\n    nbrnd_erly_stp     = 75;\n    mdlcv_mthd         = 'RSKF';\n\n    a                  = 2.998\n    b                  = 1.042\n\n    # Ensemble:-\n    ensemble_req       = \"N\";\n    metric_obj         = 'maximize';\n    ntrials            = 10 if test_req == \"Y\" else 250;\n\n    # Global variables for plotting:-\n    grid_specs = {'visible': True, 'which': 'both', 'linestyle': '--',\n                           'color': 'lightgrey', 'linewidth': 0.75};\n    title_specs = {'fontsize': 9, 'fontweight': 'bold', 'color': '#992600'};\n\nprint();\nUtils.PrintColor(f\"--> Configuration done!\\n\");\ncollect();",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-30T01:14:55.11142Z",
     "iopub.execute_input": "2024-04-30T01:14:55.111728Z",
     "iopub.status.idle": "2024-04-30T01:14:55.298527Z",
     "shell.execute_reply.started": "2024-04-30T01:14:55.111704Z",
     "shell.execute_reply": "2024-04-30T01:14:55.297492Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"2.3\"></a>\n## <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color: black; font-size:120%; text-align:left;padding:3.0px; background: #c2d6d6; border-bottom: 8px solid black\" > FOREWORD<br><div>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "This competition aims to grade essays into 6 grades from 1-6 using a training corpus data. We are asked to use **Quadratic Kappa Score** as the metric. <br>\nScoring rubric is explained in detail [here](https://storage.googleapis.com/kaggle-forum-message-attachments/2733927/20538/Rubric_%20Holistic%20Essay%20Scoring.pdf) as part of the competition overview and evaluation guidelines <br>\n\n### **KERNEL OBJECTIVE** <br>\nI delve into the data a bit here, use the public notebook to generate features and use them effectively to train ML models. <br>\nThis is not a tuned process. I aim to showcase the usage of XGboost training with custom loss function herewith. Feel free to use this in your pipeline and let me know in the comments regarding your thoughts! <br>\n\n### **USING THE NATIVE XGBOOST SYNTAX** <br>\nI like to use the xgboost **native syntax** for both classification and regression problems. I feel it is much easier to set up an objective, including custom objectives and evaluation metrics and provide labels to evaluation sets hereby. Also, the scikit-learn syntax for XGboost has changed over recent versions, deprecating traditional booster parameters like eval_metric and  callbacks from the fit() method. The native XGboost syntax is not affected with this problem though. A downside of this syntax is that one may not be able to use it in a pipeline as-is and will need to create a custom transformer to be able to use the predict/ fit methods. <br>\n\n### **BUILDING AND IMPROVING SINGLE MODELS** <br>\nI recommend one and all **not to overtly rely on blends and stacks** now and rather focus on single models. Such a pipeline will help you fathom the power of a single model. Hope this is useful!\n\n### **KERNEL SOURCES** <br>\nhttps://www.kaggle.com/code/ye11725/tfidf-lgbm-baseline-with-code-comments <br>\nhttps://www.kaggle.com/datasets/hideyukizushi/aes2-400-20240419134941 <br>\nhttps://www.kaggle.com/code/hideyukizushi/aes2-deberta-lgbm-countvectorizer-lb-814 <br>\nhttps://www.kaggle.com/code/yongsukprasertsuk/0-818-deberta-v3-large-lgbm-baseline <br>\n\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"3\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color: white; font-size:120%; text-align:left;padding:3.0px; background: maroon; border-bottom: 8px solid black\" > PREPROCESSING<br><div>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%time\n\nnlp = spacy.load(\"en_core_web_sm\")\nwith open(CFG.vocab_path, 'r') as file:\n    english_vocab = set(word.strip().lower() for word in file)\n\ndef count_spelling_errors(text):\n    doc = nlp(text)\n    lemmatized_tokens = [token.lemma_.lower() for token in doc]\n    spelling_errors = sum(1 for token in lemmatized_tokens if token not in english_vocab)\n    return spelling_errors\n\ndef removeHTML(x):\n    html = re.compile(r'<.*?>')\n    return html.sub(r'', x)\n\ndef dataPreprocessing(x):\n    x = x.lower()\n    x = removeHTML(x)\n    x = re.sub(\"@\\w+\", '',x)\n    x = re.sub(\"'\\d+\", '',x)\n    x = re.sub(\"\\d+\", '',x)\n    x = re.sub(\"http\\w+\", '',x)\n    x = re.sub(r\"\\s+\", \" \", x)\n    x = re.sub(r\"\\.+\", \".\", x)\n    x = re.sub(r\"\\,+\", \",\", x)\n    x = x.strip()\n    return x\n\ndef remove_punctuation(text):\n    \"\"\"\n    Remove all punctuation from the input text.\n\n    Args:\n    - text (str): The input text.\n\n    Returns:\n    - str: The text with punctuation removed.\n    \"\"\"\n    translator = str.maketrans('', '', string.punctuation)\n    return text.translate(translator)\n\ndef Paragraph_Preprocess(tmp):\n    tmp = tmp.explode('paragraph')\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(dataPreprocessing))\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(remove_punctuation).alias('paragraph_no_punctuation'))\n    tmp = tmp.with_columns(pl.col('paragraph_no_punctuation').map_elements(count_spelling_errors).alias(\"paragraph_error_num\"))\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x)).alias(\"paragraph_len\"))\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x.split('.'))).alias(\"paragraph_sentence_cnt\"),\n                           pl.col('paragraph').map_elements(lambda x: len(x.split(' '))).alias(\"paragraph_word_cnt\"),\n                           )\n    return tmp\n\nparagraph_fea  = ['paragraph_len','paragraph_sentence_cnt','paragraph_word_cnt']\nparagraph_fea2 = ['paragraph_error_num'] + paragraph_fea\n\ndef Paragraph_Eng(train_tmp):\n    num_list  = [0, 50,75,100,125,150,175,200,250,300,350,400,500,600]\n    num_list2 = [0, 50,75,100,125,150,175,200,250,300,350,400,500,600,700]\n\n    aggs = [\n        *[pl.col('paragraph').filter(pl.col('paragraph_len') >= i).\\\n          count().\\\n          alias(f\"paragraph_{i}_cnt\")\n          for i in [0, 50,75,100,125,150,175,200,250,300,350,400,500,600,700]\n          ],\n        *[pl.col('paragraph').filter(pl.col('paragraph_len') <= i).\\\n          count().\\\n          alias(f\"paragraph_{i}_cnt\") for i in [25,49]\n          ],\n        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in paragraph_fea2],\n        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in paragraph_fea2],\n        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in paragraph_fea2],\n        *[pl.col(fea).sum().alias(f\"{fea}_sum\") for fea in paragraph_fea2],\n        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in paragraph_fea2],\n        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in paragraph_fea2],\n        *[pl.col(fea).kurtosis().alias(f\"{fea}_kurtosis\") for fea in paragraph_fea2],\n        *[pl.col(fea).quantile(0.25).alias(f\"{fea}_q1\") for fea in paragraph_fea2],\n        *[pl.col(fea).quantile(0.75).alias(f\"{fea}_q3\") for fea in paragraph_fea2],\n        ]\n\n    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n    df = df.to_pandas()\n\n    return df\n\ndef Sentence_Preprocess(tmp):\n    tmp = tmp.with_columns(pl.col('full_text').map_elements(dataPreprocessing).str.split(by=\".\").alias(\"sentence\"))\n    tmp = tmp.explode('sentence')\n    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x)).alias(\"sentence_len\"))\n    tmp = tmp.filter(pl.col('sentence_len')>=15)\n    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x.split(' '))).alias(\"sentence_word_cnt\"))\n    return tmp\n\nsentence_fea = ['sentence_len','sentence_word_cnt']\n\ndef Sentence_Eng(train_tmp):\n    aggs = [\n        *[pl.col('sentence').filter(pl.col('sentence_len') >= i).\\\n          count().\\\n          alias(f\"sentence_{i}_cnt\")\n          for i in [0,15,50,100,150,200,250,300]\n          ],\n        *[pl.col('sentence').filter(pl.col('sentence_len') <= i).count().alias(f\"sentence_lt{i}_cnt\") for i in [15,50] ],\n        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in sentence_fea],\n        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in sentence_fea],\n        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in sentence_fea],\n        *[pl.col(fea).sum().alias(f\"{fea}_sum\") for fea in sentence_fea],\n        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in sentence_fea],\n        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in sentence_fea],\n        *[pl.col(fea).kurtosis().alias(f\"{fea}_kurtosis\") for fea in sentence_fea],\n        *[pl.col(fea).quantile(0.25).alias(f\"{fea}_q1\") for fea in sentence_fea],\n        *[pl.col(fea).quantile(0.75).alias(f\"{fea}_q3\") for fea in sentence_fea],\n        ]\n\n    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n    df = df.to_pandas()\n    return df\n\ndef Word_Preprocess(tmp):\n    tmp = tmp.with_columns(pl.col('full_text').map_elements(dataPreprocessing).str.split(by=\" \").alias(\"word\"))\n    tmp = tmp.explode('word')\n    tmp = tmp.with_columns(pl.col('word').map_elements(lambda x: len(x)).alias(\"word_len\"))\n    tmp = tmp.filter(pl.col('word_len')!=0)\n    return tmp\n\ndef Word_Eng(train_tmp):\n    aggs = [\n        *[pl.col('word').filter(pl.col('word_len') >= i+1).count().alias(f\"word_{i+1}_cnt\")\n        for i in range(15)\n        ],\n        pl.col('word_len').max().alias(f\"word_len_max\"),\n        pl.col('word_len').mean().alias(f\"word_len_mean\"),\n        pl.col('word_len').std().alias(f\"word_len_std\"),\n        pl.col('word_len').quantile(0.25).alias(f\"word_len_q1\"),\n        pl.col('word_len').quantile(0.50).alias(f\"word_len_q2\"),\n        pl.col('word_len').quantile(0.75).alias(f\"word_len_q3\"),\n        ]\n\n    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n    df = df.to_pandas()\n    return df\n\ndef Make_Feature(train, test):\n    \"\"\"\n    This function uses all other functions to make the associated features\n    \"\"\"\n\n    Utils.PrintColor(f\"Preprocessing\")\n    tmp         = Paragraph_Preprocess(train)\n    train_feats = Paragraph_Eng(tmp)\n\n    tmp         = Paragraph_Preprocess(test)\n    test_feats  = Paragraph_Eng(tmp)\n    Utils.PrintColor(f\"1. Paragraph Preprocessing train-test = {train_feats.shape} | {test_feats.shape}\",\n                     color = Fore.CYAN)\n\n    tmp         = Sentence_Preprocess(train)\n    train_feats = train_feats.merge(Sentence_Eng(tmp), on='essay_id', how='left')\n\n    tmp         = Sentence_Preprocess(test)\n    test_feats  = test_feats.merge(Sentence_Eng(tmp), on='essay_id', how='left')\n    Utils.PrintColor(f\"2. Sentence Preprocessing train-test = {train_feats.shape} | {test_feats.shape}\",\n                     color = Fore.CYAN)\n\n    tmp         = Word_Preprocess(train)\n    train_feats = train_feats.merge(Word_Eng(tmp), on='essay_id', how='left')\n\n    tmp         = Word_Preprocess(test)\n    test_feats  = test_feats.merge(Word_Eng(tmp), on='essay_id', how='left')\n    Utils.PrintColor(f\"3. Word Preprocessing train-test = {train_feats.shape} | {test_feats.shape}\",\n                     color = Fore.CYAN)\n\n    vectorizer = \\\n    TfidfVectorizer(tokenizer=lambda x: x,\n                    preprocessor=lambda x: x,\n                    token_pattern=None,\n                    strip_accents='unicode',\n                    analyzer = 'word',\n                    ngram_range=(3,6),\n                    min_df=0.05,\n                    max_df=0.95,\n                    sublinear_tf=True,\n                    )\n\n    train_tfid     = vectorizer.fit_transform([i for i in train['full_text']])\n    df             = pd.DataFrame(train_tfid.toarray())\n    tfid_columns   = [ f'tfid_{i}' for i in range(len(df.columns))]\n    df.columns     = tfid_columns\n    df['essay_id'] = train_feats['essay_id']\n    train_feats    = train_feats.merge(df, on='essay_id', how='left')\n\n    test_tfid      = vectorizer.transform([i for i in test['full_text']])\n    df             = pd.DataFrame(test_tfid.toarray())\n    tfid_columns   = [ f'tfid_{i}' for i in range(len(df.columns))]\n    df.columns     = tfid_columns\n    df['essay_id'] = test_feats['essay_id']\n    test_feats     = test_feats.merge(df, on='essay_id', how='left')\n    Utils.PrintColor(f\"4. TFIDF = {train_feats.shape} | {test_feats.shape}\", color = Fore.CYAN)\n\n    vectorizer_cnt = \\\n    CountVectorizer(tokenizer=lambda x: x,\n                    preprocessor=lambda x: x,\n                    token_pattern=None,\n                    strip_accents='unicode',\n                    analyzer = 'word',\n                    ngram_range=(2,3),\n                    min_df=0.10,\n                    max_df=0.85,\n                    )\n\n    train_tfid     = vectorizer_cnt.fit_transform([i for i in train['full_text']])\n    dense_matrix   = train_tfid.toarray()\n    df             = pd.DataFrame(dense_matrix)\n    tfid_columns   = [ f'tfid_cnt_{i}' for i in range(len(df.columns))]\n    df.columns     = tfid_columns\n    df['essay_id'] = train_feats['essay_id']\n    train_feats    = train_feats.merge(df, on='essay_id', how='left')\n\n    test_tfid      = vectorizer_cnt.transform([i for i in test['full_text']])\n    df             = pd.DataFrame(test_tfid.toarray())\n    tfid_columns   = [ f'tfid_{i}' for i in range(len(df.columns))]\n    df.columns     = tfid_columns\n    df['essay_id'] = test_feats['essay_id']\n    test_feats     = test_feats.merge(df, on='essay_id', how='left')\n    Utils.PrintColor(f\"5. Count vectorizer = {train_feats.shape} | {test_feats.shape}\", color = Fore.CYAN)\n\n    return train_feats, test_feats",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2024-04-30T01:14:55.300031Z",
     "iopub.execute_input": "2024-04-30T01:14:55.300352Z",
     "iopub.status.idle": "2024-04-30T01:14:56.814775Z",
     "shell.execute_reply.started": "2024-04-30T01:14:55.300316Z",
     "shell.execute_reply": "2024-04-30T01:14:56.813827Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%time\n\nif CFG.load_train_data == False:\n    train = pl.read_csv(os.path.join(CFG.path, \"train.csv\")).\\\n    with_columns([( pl.col(\"full_text\").str.split(by=\"\\n\\n\").alias(\"paragraph\"))])\n\n    test = pl.read_csv(os.path.join(CFG.path, \"test.csv\")).\\\n    with_columns([( pl.col(\"full_text\").str.split(by=\"\\n\\n\").alias(\"paragraph\"))])\n    Utils.PrintColor(f\"Train test shape = {train.shape} | {test.shape}\")\n\n    Xtrain, Xtest  = MakeFeature(train, test)\n    Utils.PrintColor(f\"\\nTest data preprocessing\")\n    print(\"\\n\")\n\n    Utils.PrintColor(f\"Train test shape = {Xtrain.shape} | {Xtest.shape}\")\n\n    Xtrain.to_parquet(os.path.join(CFG.op_path, f\"Xtrain_E{CFG.exp_nb}.parquet\"))\n    Xtest.to_parquet(os.path.join(CFG.op_path, f\"Xtest_E{CFG.exp_nb}.parquet\"))\n    \n    ytrain = train[CFG.target].to_pandas().astype(np.float32) - CFG.a\n    ygrp   = train[CFG.target].to_pandas().astype(np.uint8)\n\nelif CFG.load_train_data == True:\n    ytrain = pd.read_csv(os.path.join(CFG.path, \"train.csv\"),\n                         usecols = [\"essay_id\", CFG.target]\n                        )\n    \n    Xtrain = joblib.load(os.path.join(CFG.mydatapath, f\"Xtrain.pickle\"))\n    Xtest  = joblib.load(os.path.join(CFG.mydatapath, f\"Xtest.pickle\"))\n    Xtrain = Xtrain.merge(ytrain, how = \"left\", on  = \"essay_id\")\n    Xtrain.index = range(len(Xtrain))\n\n    ytrain = Xtrain[CFG.target].astype(np.float32) - CFG.a\n    ygrp   = Xtrain[CFG.target].astype(np.uint8)\n    Xtrain = Xtrain.drop(columns = [CFG.target])\n\nXtrain.columns = Xtrain.columns.str.replace(r\"<\", \"le\").str.replace(r\">\", \"ge\").str.replace(r\"?\", \"Q\")\nXtest.columns  = Xtrain.columns\nUtils.PrintColor(f\"Train test shape = {Xtrain.shape} | {Xtest.shape} | {ytrain.shape} | {ygrp.shape}\")\n\nif CFG.test_req == \"Y\":\n    Utils.PrintColor(f\"\\nSelecting a small set of columns for the syntax check\")\n    Xtrain = Xtrain.iloc[:, 0: CFG.nb_cols_test]\n    Xtest  = Xtest[Xtrain.columns]\n    \n    Utils.PrintColor(f\"Train test shape after syntax check = {Xtrain.shape} | {Xtest.shape}\")\n    \nelse:\n    pass\n\n_ = Utils.CleanMemory()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-30T01:14:56.816292Z",
     "iopub.execute_input": "2024-04-30T01:14:56.816619Z",
     "iopub.status.idle": "2024-04-30T01:15:19.684186Z",
     "shell.execute_reply.started": "2024-04-30T01:14:56.816587Z",
     "shell.execute_reply": "2024-04-30T01:15:19.683347Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"4\"></a>\n# <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color: white; font-size:120%; text-align:left;padding:3.0px; background: maroon; border-bottom: 8px solid black\" > MODEL TRAINING<br><div>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%time\n\nclass XGBSupport:\n    \"\"\"\n    This class designs helpers for the subseqent XGBoost using custom loss and evaluations\n    \"\"\"\n    \n    def __init__(self, a, b):\n        self.a = a\n        self.b = b\n    \n    def MakeMetricXGB(self, y_pred, dm):\n        \"\"\"\n        This method prepares the custom eval metric for XGboost\n        \"\"\"\n        \n        y_true = dm.get_label() + self.a\n        y_pred = np.round(np.clip(y_pred + self.a, a_min = 1, a_max = 6))\n\n        score = cohen_kappa_score(y_true, y_pred, weights = \"quadratic\")\n        return 'QWK', score\n\n    def MakeObjXGB(self, y_pred, dm):\n        \"\"\"\n        This method designs the custom objective for XGBoost\n        \"\"\"\n        \n        y_true = dm.get_label()\n        labels = y_true + self.a\n        preds  = y_pred + self.a\n        preds  = np.clip(preds, a_min = 1, a_max = 6)\n        \n        f      = 1/2*np.sum((preds- labels) ** 2)\n        g      = 1/2*np.sum((preds- self.a) **2 + self.b)\n        \n        df   = preds - labels\n        dg   = preds - self.a\n        grad = (df / g - f*dg / g**2) * len(labels)\n        hess = np.ones(len(labels))\n        \n        return grad, hess\n\n# Customizing logging for XGBoost\nfor handler in logging.root.handlers[:]:\n    logging.root.removeHandler(handler)\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.ERROR)\nformatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n\nstdout_handler = logging.StreamHandler(sys.stdout)\nstdout_handler.setLevel(logging.INFO)\nstdout_handler.setFormatter(formatter)\n\nfile_handler = logging.FileHandler(f'xgb_optimize.log')\nfile_handler.setLevel(logging.ERROR)\nfile_handler.setFormatter(formatter)\n\nlogger.addHandler(file_handler)\nlogger.addHandler(stdout_handler)\n\nclass XGBLogging(xgb.callback.TrainingCallback):\n    \"\"\"\n    This class designs the custom logging for XGboost \n    This is to be used inside the XGboost callback\n    \"\"\"\n\n    def __init__(self, epoch_log_interval=100):\n        self.epoch_log_interval = epoch_log_interval\n\n    def after_iteration(self, model, epoch:int, evals_log:xgb.callback.TrainingCallback.EvalsLog):\n        if self.epoch_log_interval <= 0:\n            pass\n        \n        elif (epoch %  self.epoch_log_interval == 0):\n            for data, metric in evals_log.items():\n                for metric_name, log in metric.items():\n                    score = log[-1][0] if isinstance(log[-1], tuple) else log[-1]\n                    logger.info(f\"XGBLogging epoch {epoch} dataset {data} {metric_name} {score}\")\n\n        return False\n\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-30T01:15:19.685229Z",
     "iopub.execute_input": "2024-04-30T01:15:19.685525Z",
     "iopub.status.idle": "2024-04-30T01:15:19.700285Z",
     "shell.execute_reply.started": "2024-04-30T01:15:19.685495Z",
     "shell.execute_reply": "2024-04-30T01:15:19.699429Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%time\n\ncv     = SKF(n_splits= CFG.n_splits, shuffle= True, random_state= CFG.cv_state)\nmodels = []\nScores = pd.DataFrame(index = range(CFG.n_splits), \n                      columns = [\"Fscore\", \"QWK\"]\n                     )\nOOF_Preds = pd.DataFrame(columns = [\"essay_id\", CFG.target, \"Preds\"])\nFtreImp   = pd.DataFrame(columns = [\"Imp\", \"Fold_Nb\"])\nFtreImp.index.name = \"Feature\"\n\nparams = \\\ndict(   learning_rate      = 0.05,\n        max_depth          = 5,\n        num_leaves         = 10,\n        colsample_bytree   = 0.3,\n        colsample_bylevel  = 0.35,\n        subsample          = 0.55,\n        reg_alpha          = 0.7,\n        reg_lambda         = 0.1,\n        random_state       = 42,\n        min_child_weight   = 25,\n        verbose            = 0,\n        device             = \"cuda\" if CFG.test_req != \"Y\" else \"cpu\",\n        enable_categorical = True,\n        disable_default_eval_metric = 1\n        )\n\nxgbhelper = XGBSupport(a = CFG.a, b = CFG.b)\nessay_id  = Xtrain[\"essay_id\"]\n\nfor i, (train_index, test_index) in enumerate(cv.split(Xtrain, ygrp)):\n\n    Xtr  = Xtrain.drop(columns = ['essay_id']).iloc[train_index]\n    Xdev = Xtrain.drop(columns = ['essay_id']).iloc[test_index]\n    ytr  = ytrain.iloc[train_index]\n    ydev = ytrain.iloc[test_index]\n\n    dmtrain = DMatrix(Xtr, label = ytr)\n    dmdev   = DMatrix(Xdev,  label = ydev)\n    dmtest  = DMatrix(Xtest.drop(columns = [\"essay_id\"]))\n\n    predictor = xgb.train(params = params,\n                          dtrain = dmtrain,\n                          num_boost_round = 3500,\n                          evals = [(dmdev, \"Dev\")],\n                          verbose_eval = 0,\n                          obj = xgbhelper.MakeObjXGB,\n                          custom_metric = xgbhelper.MakeMetricXGB,\n                          callbacks = [XGBLogging(epoch_log_interval= 0)],\n                          maximize = True,\n                          early_stopping_rounds = CFG.nbrnd_erly_stp,\n                          )\n    \n    predictor.save_model(os.path.join(CFG.op_path, \n                                      f\"XGB1R_E{CFG.exp_nb}V{CFG.version_nb}_Fold{i}.txt\")\n                        )\n    models.append(predictor)\n    \n    ftreimp = \\\n    pd.DataFrame.from_dict(predictor.get_score(), \n                           orient = \"index\", \n                           columns = [\"Imp\"]\n                          )\n    ftreimp[\"Fold_Nb\"] = i\n    ftreimp.columns = [\"Imp\", \"Fold_Nb\"]\n    FtreImp = pd.concat([FtreImp, ftreimp], axis=0)\n    \n    dev_preds = predictor.predict(dmdev)\n    dev_preds = dev_preds + CFG.a\n    OOF_Preds = pd.concat([OOF_Preds, \n                           pd.DataFrame({\"essay_id\": essay_id.iloc[test_index].values,\n                                         CFG.target: ygrp.iloc[test_index].values,\n                                         \"Preds\"   : dev_preds\n                                        }\n                                       )\n                          ],\n                          axis = 0,\n                          ignore_index = True\n                         )  \n    \n    dev_preds = np.round(np.clip(dev_preds, a_min = 1, a_max = 6), 0)\n    \n    f_dev      = f1_score(ygrp.iloc[test_index], dev_preds, average='weighted')\n    kappa_dev  = cohen_kappa_score(ygrp.iloc[test_index], dev_preds, weights = 'quadratic')\n       \n    Scores.loc[i] = [f_dev, kappa_dev]\n    Utils.PrintColor(f\"Fscore = {f_dev:.5f} | QWK = {kappa_dev:.5f} | Fold {i}\")\n\njoblib.dump(models, os.path.join(CFG.op_path, f\"XGB1R_E{CFG.exp_nb}V{CFG.version_nb}\"))\nOOF_Preds.to_csv(os.path.join(CFG.op_path, f\"OOF_Preds_E{CFG.exp_nb}V{CFG.version_nb}\"))\n_ = Utils.CleanMemory()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-30T01:15:19.701587Z",
     "iopub.execute_input": "2024-04-30T01:15:19.701883Z",
     "iopub.status.idle": "2024-04-30T01:15:36.488942Z",
     "shell.execute_reply.started": "2024-04-30T01:15:19.701849Z",
     "shell.execute_reply": "2024-04-30T01:15:36.487993Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%time \n\nfig, axes = plt.subplots(CFG.n_splits, 1, \n                         figsize = (20, CFG.n_splits * 9),\n                         gridspec_kw = {\"wspace\": 1.8, \"hspace\" : 0.4}\n                        )\n\nfor i in range(CFG.n_splits):\n    ax = axes[i]\n    FtreImp.loc[FtreImp.Fold_Nb == i, \"Imp\"].\\\n    sort_values(ascending = False).\\\n    head(50).plot.bar(ax = ax, color = \"tab:blue\")\n    ax.set_title(f\"Fold{i} feature importances\", **CFG.title_specs)\n    \nplt.tight_layout()\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-30T01:15:36.49112Z",
     "iopub.execute_input": "2024-04-30T01:15:36.491406Z",
     "iopub.status.idle": "2024-04-30T01:15:39.180221Z",
     "shell.execute_reply.started": "2024-04-30T01:15:36.491381Z",
     "shell.execute_reply": "2024-04-30T01:15:39.179306Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
