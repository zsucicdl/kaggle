{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 71485,
     "databundleVersionId": 8059942,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30674,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# AES 2.0 | TF-IDF & XGB Baseline",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# 1. Libraries",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import os\nimport re\nimport nltk\nimport string\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nwarnings.filterwarnings('ignore')",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-04-07T19:09:35.648628Z",
     "iopub.execute_input": "2024-04-07T19:09:35.648926Z",
     "iopub.status.idle": "2024-04-07T19:09:38.797656Z",
     "shell.execute_reply.started": "2024-04-07T19:09:35.6489Z",
     "shell.execute_reply": "2024-04-07T19:09:38.796715Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# 2. Configuration",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class config:\n    root = \"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/\"\n    train_path = os.path.join(root, \"train.csv\")\n    test_path = os.path.join(root, \"test.csv\")\n    sample_submission_path = os.path.join(root, \"sample_submission.csv\")\n    \n    seed = 45\n    n_folds = 10\n    num_rounds = 5000\n    early_stopping_rounds = 500\n    verbose = 500",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-07T19:09:38.799296Z",
     "iopub.execute_input": "2024-04-07T19:09:38.799678Z",
     "iopub.status.idle": "2024-04-07T19:09:38.80519Z",
     "shell.execute_reply.started": "2024-04-07T19:09:38.799652Z",
     "shell.execute_reply": "2024-04-07T19:09:38.804157Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# 3. Loading Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train = pd.read_csv(config.train_path)\ntest = pd.read_csv(config.test_path)\nsample_submission = pd.read_csv(config.sample_submission_path)\n\nprint(f\"train shape: {train.shape}\")\nprint(f\"test shape: {test.shape}\")\nprint(\"-\"*90)\nprint(f\"train missing values: {train.isnull().sum().sum()}\")\nprint(f\"test missing values: {test.isnull().sum().sum()}\")\nprint(\"-\"*90)\ntrain.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-07T19:09:38.80959Z",
     "iopub.execute_input": "2024-04-07T19:09:38.809879Z",
     "iopub.status.idle": "2024-04-07T19:09:39.588639Z",
     "shell.execute_reply.started": "2024-04-07T19:09:38.809856Z",
     "shell.execute_reply": "2024-04-07T19:09:39.587725Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# 4. Target Distribution",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "sns.set_style(\"whitegrid\")\n\nplt.figure(figsize = (10, 5))\n\nsns.histplot(data=train, x='score')\n\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-07T19:09:39.589943Z",
     "iopub.execute_input": "2024-04-07T19:09:39.590348Z",
     "iopub.status.idle": "2024-04-07T19:09:39.938197Z",
     "shell.execute_reply.started": "2024-04-07T19:09:39.590314Z",
     "shell.execute_reply": "2024-04-07T19:09:39.937051Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# 5. Feature Engineering",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def count_stopwords(text: str) -> int:\n    stopword_list = set(stopwords.words('english'))\n    words = text.split()\n    stopwords_count = sum(1 for word in words if word.lower() in stopword_list)\n    return stopwords_count\n\ndef count_punctuation(text: str) -> int:\n    punctuation_set = set(string.punctuation)\n    punctuation_count = sum(1 for char in text if char in punctuation_set)\n    return punctuation_count\n\ndef count_numbers(text: str) -> int:\n    numbers = re.findall(r'\\d+', text)\n    numbers_count = len(numbers)\n    return numbers_count\n\ndef feature_engineer(dataframe: pd.DataFrame) -> pd.DataFrame:\n    \n    words = dataframe[\"full_text\"].apply(lambda x: [len(w) for w in x.split()])\n    \n    dataframe[\"total_words\"] = words.apply(lambda x: len(x))\n    dataframe[\"word_len_max\"] = words.apply(lambda x: np.max(x))\n    dataframe[\"word_len_mean\"] = words.apply(lambda x: np.mean(x))\n    dataframe[\"word_len_min\"] = words.apply(lambda x: np.min(x))\n    dataframe[\"word_len_std\"] = words.apply(lambda x: np.std(x))\n    dataframe[\"word_len_var\"] = words.apply(lambda x: np.var(x))\n    \n    dataframe[\"word_len_q25\"] = words.apply(lambda x: np.quantile(x, 0.25))\n    dataframe[\"word_len_q50\"] = words.apply(lambda x: np.quantile(x, 0.50))\n    dataframe[\"word_len_q75\"] = words.apply(lambda x: np.quantile(x, 0.75))\n    dataframe[\"word_len_q90\"] = words.apply(lambda x: np.quantile(x, 0.90))\n    \n    dataframe[\"sentence_len\"] = dataframe[\"full_text\"].apply(lambda x: len(x))\n    dataframe[\"stopword_cnt\"] = dataframe[\"full_text\"].apply(lambda x: count_stopwords(x))\n    dataframe[\"punct_cnt\"] = dataframe[\"full_text\"].apply(lambda x: count_punctuation(x))\n    dataframe[\"number_cnt\"] = dataframe[\"full_text\"].apply(lambda x: count_numbers(x))\n    dataframe[\"sentence_word_ratio\"] = dataframe[\"sentence_len\"] / dataframe[\"total_words\"]\n    dataframe[\"stopwords_ratio\"] = dataframe[\"total_words\"] / dataframe[\"stopword_cnt\"] \n    \n    return dataframe",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-07T19:14:31.806244Z",
     "iopub.execute_input": "2024-04-07T19:14:31.806603Z",
     "iopub.status.idle": "2024-04-07T19:14:31.820719Z",
     "shell.execute_reply.started": "2024-04-07T19:14:31.806574Z",
     "shell.execute_reply": "2024-04-07T19:14:31.819839Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_fe = feature_engineer(train)\ntest_fe = feature_engineer(test)\n\ntrain_fe.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-07T19:14:31.940626Z",
     "iopub.execute_input": "2024-04-07T19:14:31.941178Z",
     "iopub.status.idle": "2024-04-07T19:14:54.844948Z",
     "shell.execute_reply.started": "2024-04-07T19:14:31.941147Z",
     "shell.execute_reply": "2024-04-07T19:14:54.843908Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "vectorizer = TfidfVectorizer(\n    encoding='utf-8',\n    ngram_range=(1, 3),\n    strip_accents='unicode',\n    analyzer='word',\n    min_df=0.05,\n    max_df=0.95,\n    sublinear_tf=True\n)\n\ntrain_vectorized = pd.DataFrame(\n    vectorizer.fit_transform(train['full_text']).toarray(),\n    columns=[f\"tfidf_{str(f)}\" for f in vectorizer.get_feature_names_out()],\n)\n\ntest_vectorized = pd.DataFrame(\n    vectorizer.transform(test['full_text']).toarray(),\n    columns=[f\"tfidf_{str(f)}\" for f in vectorizer.get_feature_names_out()],\n)\n\ntrain_vectorized.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-06T22:31:57.100162Z",
     "iopub.execute_input": "2024-04-06T22:31:57.100467Z",
     "iopub.status.idle": "2024-04-06T22:32:58.819173Z",
     "shell.execute_reply.started": "2024-04-06T22:31:57.100439Z",
     "shell.execute_reply": "2024-04-06T22:32:58.818215Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# 6. Modeling",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "params = {\n    'booster': 'gbtree',\n    'objective': 'reg:squarederror',\n    'eval_metric': 'rmse',\n    'sampling_method': 'uniform',\n    'tree_method': 'gpu_hist',\n    'learning_rate': 0.025,\n    'max_depth': 7,\n    'subsample': 0.78,\n    'min_child_weight': 5\n}\n\nX = pd.concat([train_fe, train_vectorized], axis=1).drop(columns=[\"essay_id\", \"full_text\", \"score\"], axis=1)\nX_test = pd.concat([test_fe, test_vectorized], axis=1).drop(columns=[\"essay_id\", \"full_text\"], axis=1)\ny = train[\"score\"]\ny_test = np.zeros(shape=test.shape[0], dtype=float)\ndtest = xgb.DMatrix(data=X_test)\n\ncv = StratifiedKFold(n_splits=config.n_folds, shuffle=True, random_state=config.seed)\n\nfor idx, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n    print(f\"| Fold {idx+1} |\".center(80, \"-\"))\n    X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n    X_val, y_val = X.loc[val_idx], y.loc[val_idx]\n\n    print(f'train: {X_train.shape}')\n    print(f'val: {X_val.shape}')\n    \n    dtrain = xgb.DMatrix(data=X_train, label=y_train)\n    dval = xgb.DMatrix(data=X_val, label=y_val)\n\n    model = xgb.train(\n        params=params,\n        dtrain=dtrain,\n        evals=[(dtrain, 'train'), (dval, 'validation')],\n        num_boost_round=config.num_rounds,\n        early_stopping_rounds=config.early_stopping_rounds,\n        verbose_eval=config.verbose\n    )\n\n    y_test += model.predict(dtest) / config.n_folds\n    \nsample_submission[\"score\"] = [round(i) for i in y_test]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-06T22:32:58.820187Z",
     "iopub.execute_input": "2024-04-06T22:32:58.820442Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# 7. Saving Submission",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "sample_submission.head()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "sample_submission.to_csv('submission.csv', index=False)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
