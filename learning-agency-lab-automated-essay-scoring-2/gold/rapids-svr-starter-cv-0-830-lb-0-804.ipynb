{
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 71485,
     "databundleVersionId": 8059942,
     "sourceType": "competition"
    },
    {
     "sourceId": 8403792,
     "sourceType": "datasetVersion",
     "datasetId": 5000565
    },
    {
     "sourceId": 177473688,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 177475777,
     "sourceType": "kernelVersion"
    }
   ],
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 258.371239,
   "end_time": "2024-05-13T19:21:02.799575",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-13T19:16:44.428336",
   "version": "2.3.4"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# RAPIDS SVR - CV 0.830\nThis notebook is a RAPIDS SVR starter notebook which achieves CV 0.830 and LB ???. (Let's submit to LB and see what score it achieves).\n\nIn this notebook, we extract text embeddings from 6 Hugging Face models. We **do not** finetune any LLM. The 6 LLM that we use here are models directly downloaded from Hugging Face (in notebook [here][1]) as is. Each of these model can accept token lengths of at least 1024 as discussed [here][3]. Therefore we can input the full essay instead of breaking into 512 chunks.\n\nWe extract 6 sets of embeddings and concatenate them into 5376 features! Afterward we use RAPIDS SVR to quickly train a 15-Fold support vector regression model on Kaggle's 2xT4 GPUs.\n\nThen we apply threshold post process to convert the regression outputs into the 6 possible target labels of 1, 2, 3, 4, 5, 6 as discussed by MPWare [here][2]\n\n[1]: https://www.kaggle.com/code/cdeotte/download-huggingface-models\n[2]: https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/discussion/502279\n[3]: https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/discussion/498571",
   "metadata": {
    "papermill": {
     "duration": 0.008083,
     "end_time": "2024-05-13T19:16:47.363019",
     "exception": false,
     "start_time": "2024-05-13T19:16:47.354936",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Fix RAPIDS Installation\nTo make RAPIDS work in a Kaggle notebook we need to do one of the following:\n* Downgrade Pandas to 1.X\n* Pip install the latest RAPIDS\n\nI will do the first option since it is faster and RAPIDS v23.08.00 is recent enough for our SVR in this notebook. An example of pip install recent RAPIDS v24.02.00 is [here][1]\n\n[1]: https://www.kaggle.com/code/premsagar/rapids-cudf-pandas-on-kaggle",
   "metadata": {
    "papermill": {
     "duration": 0.007393,
     "end_time": "2024-05-13T19:16:47.378261",
     "exception": false,
     "start_time": "2024-05-13T19:16:47.370868",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "!pip install --find-links /kaggle/input/downgrade-pandas /kaggle/input/downgrade-pandas/pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-05-13T19:16:47.395485Z",
     "iopub.status.busy": "2024-05-13T19:16:47.394763Z",
     "iopub.status.idle": "2024-05-13T19:17:32.292915Z",
     "shell.execute_reply": "2024-05-13T19:17:32.291764Z"
    },
    "papermill": {
     "duration": 44.909529,
     "end_time": "2024-05-13T19:17:32.295355",
     "exception": false,
     "start_time": "2024-05-13T19:16:47.385826",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Load Libraries and Data",
   "metadata": {
    "papermill": {
     "duration": 0.012248,
     "end_time": "2024-05-13T19:17:32.316881",
     "exception": false,
     "start_time": "2024-05-13T19:17:32.304633",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n\nimport numpy as np, gc, re \nimport pandas as pd \n\ntrain = pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\")\nprint(\"Train shape\",train.shape)\ndisplay(train.head())\nprint()\n\ntest = pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\")\nprint(\"Test shape\",test.shape)\ndisplay(test.head())",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:17:32.334977Z",
     "iopub.status.busy": "2024-05-13T19:17:32.334656Z",
     "iopub.status.idle": "2024-05-13T19:17:33.590753Z",
     "shell.execute_reply": "2024-05-13T19:17:33.589782Z"
    },
    "papermill": {
     "duration": 1.267719,
     "end_time": "2024-05-13T19:17:33.592756",
     "exception": false,
     "start_time": "2024-05-13T19:17:32.325037",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Stratified 15 K Fold",
   "metadata": {
    "papermill": {
     "duration": 0.008383,
     "end_time": "2024-05-13T19:17:33.610024",
     "exception": false,
     "start_time": "2024-05-13T19:17:33.601641",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "from sklearn.model_selection import StratifiedKFold\n\nFOLDS = 15\ntrain[\"fold\"] = -1\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\nfor fold,(train_index, val_index) in enumerate(skf.split(train,train[\"score\"])):\n    train.loc[val_index,\"fold\"] = fold\nprint('Train samples per fold:')\ntrain.fold.value_counts().sort_index()",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:17:33.629869Z",
     "iopub.status.busy": "2024-05-13T19:17:33.629071Z",
     "iopub.status.idle": "2024-05-13T19:17:34.834928Z",
     "shell.execute_reply": "2024-05-13T19:17:34.834029Z"
    },
    "papermill": {
     "duration": 1.218633,
     "end_time": "2024-05-13T19:17:34.837061",
     "exception": false,
     "start_time": "2024-05-13T19:17:33.618428",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Generate Embeddings",
   "metadata": {
    "papermill": {
     "duration": 0.008867,
     "end_time": "2024-05-13T19:17:34.854859",
     "exception": false,
     "start_time": "2024-05-13T19:17:34.845992",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "from transformers import AutoModel,AutoTokenizer\nimport torch, torch.nn.functional as F\nfrom tqdm import tqdm",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:17:34.874546Z",
     "iopub.status.busy": "2024-05-13T19:17:34.873639Z",
     "iopub.status.idle": "2024-05-13T19:17:41.584345Z",
     "shell.execute_reply": "2024-05-13T19:17:41.583543Z"
    },
    "papermill": {
     "duration": 6.722973,
     "end_time": "2024-05-13T19:17:41.586735",
     "exception": false,
     "start_time": "2024-05-13T19:17:34.863762",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output.last_hidden_state.detach().cpu()\n    input_mask_expanded = (\n        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    )\n    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n        input_mask_expanded.sum(1), min=1e-9\n    )",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:17:41.606261Z",
     "iopub.status.busy": "2024-05-13T19:17:41.60581Z",
     "iopub.status.idle": "2024-05-13T19:17:41.611374Z",
     "shell.execute_reply": "2024-05-13T19:17:41.610552Z"
    },
    "papermill": {
     "duration": 0.017389,
     "end_time": "2024-05-13T19:17:41.613232",
     "exception": false,
     "start_time": "2024-05-13T19:17:41.595843",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class EmbedDataset(torch.utils.data.Dataset):\n    def __init__(self,df,tokenizer,max_length):\n        self.df = df.reset_index(drop=True)\n        self.tokenizer = tokenizer\n        self.max = max_length\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self,idx):\n        text = self.df.loc[idx,\"full_text\"]\n        tokens = self.tokenizer(\n                text,\n                None,\n                add_special_tokens=True,\n                padding='max_length',\n                truncation=True,\n                max_length=self.max,\n                return_tensors=\"pt\")\n        tokens = {k:v.squeeze(0) for k,v in tokens.items()}\n        return tokens",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:17:41.631385Z",
     "iopub.status.busy": "2024-05-13T19:17:41.63111Z",
     "iopub.status.idle": "2024-05-13T19:17:41.637907Z",
     "shell.execute_reply": "2024-05-13T19:17:41.637039Z"
    },
    "papermill": {
     "duration": 0.017943,
     "end_time": "2024-05-13T19:17:41.6398",
     "exception": false,
     "start_time": "2024-05-13T19:17:41.621857",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Extract Embeddings",
   "metadata": {
    "papermill": {
     "duration": 0.008495,
     "end_time": "2024-05-13T19:17:41.656901",
     "exception": false,
     "start_time": "2024-05-13T19:17:41.648406",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "def get_embeddings(model_name='', max_length=1024, batch_size=32, compute_train=True, compute_test=True):\n\n    global train, test\n\n    DEVICE = \"cuda:1\" # EXTRACT EMBEDDINGS WITH GPU #2\n    path = \"/kaggle/input/download-huggingface-models/\"\n    disk_name = path + model_name.replace(\"/\",\"_\")\n    model = AutoModel.from_pretrained( disk_name , trust_remote_code=True)\n    tokenizer = AutoTokenizer.from_pretrained( disk_name , trust_remote_code=True)\n\n    ds_tr = EmbedDataset(train, tokenizer, max_length)\n    embed_dataloader_tr = torch.utils.data.DataLoader(ds_tr,\n                            batch_size=batch_size,\n                            shuffle=False)\n    ds_te = EmbedDataset(test, tokenizer, max_length)\n    embed_dataloader_te = torch.utils.data.DataLoader(ds_te,\n                            batch_size=batch_size,\n                            shuffle=False)\n    \n    model = model.to(DEVICE)\n    model.eval()\n\n    # COMPUTE TRAIN EMBEDDINGS\n    all_train_text_feats = []\n    if compute_train:\n        for batch in tqdm(embed_dataloader_tr,total=len(embed_dataloader_tr)):\n            input_ids = batch[\"input_ids\"].to(DEVICE)\n            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n            with torch.no_grad():\n                with torch.cuda.amp.autocast(enabled=True):\n                    model_output = model(input_ids=input_ids,attention_mask=attention_mask)\n            sentence_embeddings = mean_pooling(model_output, attention_mask.detach().cpu())\n            # Normalize the embeddings\n            sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n            sentence_embeddings =  sentence_embeddings.squeeze(0).detach().cpu().numpy()\n            all_train_text_feats.extend(sentence_embeddings)\n    all_train_text_feats = np.array(all_train_text_feats)\n\n    # COMPUTE TEST EMBEDDINGS\n    all_test_text_feats = []\n    if compute_test:\n        for batch in embed_dataloader_te:\n            input_ids = batch[\"input_ids\"].to(DEVICE)\n            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n            with torch.no_grad():\n                with torch.cuda.amp.autocast(enabled=True):\n                    model_output = model(input_ids=input_ids,attention_mask=attention_mask)\n            sentence_embeddings = mean_pooling(model_output, attention_mask.detach().cpu())\n            # Normalize the embeddings\n            sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n            sentence_embeddings =  sentence_embeddings.squeeze(0).detach().cpu().numpy()\n            all_test_text_feats.extend(sentence_embeddings)\n        all_test_text_feats = np.array(all_test_text_feats)\n    all_test_text_feats = np.array(all_test_text_feats)\n\n    # CLEAR MEMORY\n    del ds_tr, ds_te\n    del embed_dataloader_tr, embed_dataloader_te\n    del model, tokenizer\n    del model_output, sentence_embeddings, input_ids, attention_mask\n    gc.collect()\n    torch.cuda.empty_cache()\n\n    # RETURN EMBEDDINGS\n    return all_train_text_feats, all_test_text_feats",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:17:41.675807Z",
     "iopub.status.busy": "2024-05-13T19:17:41.675474Z",
     "iopub.status.idle": "2024-05-13T19:17:41.690029Z",
     "shell.execute_reply": "2024-05-13T19:17:41.68911Z"
    },
    "papermill": {
     "duration": 0.026311,
     "end_time": "2024-05-13T19:17:41.691963",
     "exception": false,
     "start_time": "2024-05-13T19:17:41.665652",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# EMBEDDINGS TO LOAD/COMPUTE\n# PARAMETERS = (MODEL_NAME, MAX_LENGTH, BATCH_SIZE)\n# CHOOSE LARGEST BATCH SIZE WITHOUT MEMORY ERROR\n\nmodels = [\n    ('microsoft/deberta-base', 1024, 32),\n    ('microsoft/deberta-large', 1024, 8),\n    ('microsoft/deberta-v3-large', 1024, 8),\n    ('allenai/longformer-base-4096', 1024, 32),\n    ('google/bigbird-roberta-base', 1024, 32),\n    ('google/bigbird-roberta-large', 1024, 8),\n]",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:17:41.711285Z",
     "iopub.status.busy": "2024-05-13T19:17:41.710938Z",
     "iopub.status.idle": "2024-05-13T19:17:41.715989Z",
     "shell.execute_reply": "2024-05-13T19:17:41.715098Z"
    },
    "papermill": {
     "duration": 0.016991,
     "end_time": "2024-05-13T19:17:41.717967",
     "exception": false,
     "start_time": "2024-05-13T19:17:41.700976",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "path = \"/kaggle/input/essay-embeddings-v1/\"\nall_train_embeds = []\nall_test_embeds = []\n\nfor (model, max_length, batch_size) in models:\n    name = path + model.replace(\"/\",\"_\") + \".npy\"\n    if os.path.exists(name):\n        _, test_embed = get_embeddings(model_name=model, max_length=max_length, batch_size=batch_size, compute_train=False)\n        train_embed = np.load(name)\n        print(f\"Loading train embeddings for {name}\")\n    else:\n        print(f\"Computing train embeddings for {name}\")\n        train_embed, test_embed = get_embeddings(model_name=model, max_length=max_length, batch_size=batch_size, compute_train=True)\n        np.save(name, train_embed)\n    all_train_embeds.append(train_embed)\n    all_test_embeds.append(test_embed)\n\ndel train_embed, test_embed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:17:41.737122Z",
     "iopub.status.busy": "2024-05-13T19:17:41.736844Z",
     "iopub.status.idle": "2024-05-13T19:18:33.11327Z",
     "shell.execute_reply": "2024-05-13T19:18:33.112296Z"
    },
    "papermill": {
     "duration": 51.388457,
     "end_time": "2024-05-13T19:18:33.115494",
     "exception": false,
     "start_time": "2024-05-13T19:17:41.727037",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Combine Feature Embeddings",
   "metadata": {
    "papermill": {
     "duration": 0.008934,
     "end_time": "2024-05-13T19:18:33.13384",
     "exception": false,
     "start_time": "2024-05-13T19:18:33.124906",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "all_train_embeds = np.concatenate(all_train_embeds,axis=1)\nall_test_embeds = np.concatenate(all_test_embeds,axis=1)\n\ngc.collect()\nprint('Our concatenated train embeddings have shape', all_train_embeds.shape )",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:18:33.153616Z",
     "iopub.status.busy": "2024-05-13T19:18:33.153139Z",
     "iopub.status.idle": "2024-05-13T19:18:33.397856Z",
     "shell.execute_reply": "2024-05-13T19:18:33.396895Z"
    },
    "papermill": {
     "duration": 0.257046,
     "end_time": "2024-05-13T19:18:33.40012",
     "exception": false,
     "start_time": "2024-05-13T19:18:33.143074",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Train RAPIDS cuML SVR\nDocumentation for RAPIDS SVR is [here][1]. Using RAPIDS support vector regression (SVR) is a great model when we have 1000s of features because it is quick and it naturally will perform feature selection and remove features to prevent overfitting.\n\nNote that SVR model likes the inputs to be standardized so that each feature is rougly mean 0 and std 1. We approximate this by performing L2 norm on the extracted embeddings.\n\n[1]: https://docs.rapids.ai/api/cuml/stable/api.html#support-vector-machines",
   "metadata": {
    "papermill": {
     "duration": 0.010034,
     "end_time": "2024-05-13T19:18:33.419647",
     "exception": false,
     "start_time": "2024-05-13T19:18:33.409613",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "from cuml.svm import SVR\nimport cuml\nprint('RAPIDS version',cuml.__version__)",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:18:33.439426Z",
     "iopub.status.busy": "2024-05-13T19:18:33.439158Z",
     "iopub.status.idle": "2024-05-13T19:18:39.286857Z",
     "shell.execute_reply": "2024-05-13T19:18:39.285803Z"
    },
    "papermill": {
     "duration": 5.860218,
     "end_time": "2024-05-13T19:18:39.289139",
     "exception": false,
     "start_time": "2024-05-13T19:18:33.428921",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from sklearn.metrics import cohen_kappa_score\n\noof = np.zeros(len(train), dtype='float32')\ntest_preds = np.zeros((len(test),FOLDS), dtype='float32')\n\ndef comp_score(y_true,y_pred):\n    p = y_pred.clip(1,6).round(0)\n    m = cohen_kappa_score(y_true, p, weights='quadratic')\n    return m\n\nfor fold in range(FOLDS):\n    print('#'*25)\n    print('### Fold',fold+1)\n    print('#'*25)\n    \n    train_index = train[\"fold\"] != fold\n    valid_index = train[\"fold\"] == fold\n    \n    X_train = all_train_embeds[train_index,]\n    y_train = train.loc[train_index,'score'].values\n    X_valid = all_train_embeds[valid_index,]\n    y_valid = train.loc[valid_index,'score'].values\n    X_test = all_test_embeds\n    \n    model = SVR(C=10)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    test_preds[:,fold] = model.predict(X_test)\n    oof[valid_index] = preds\n\n    score = comp_score(y_valid, preds)    \n    print(f\"=> QWK score: {score}\")\n    print()\n    \nprint('#'*25)\nscore = comp_score(train.score.values, oof)\nprint('Overall CV QWK score =',score)",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:18:39.310531Z",
     "iopub.status.busy": "2024-05-13T19:18:39.310001Z",
     "iopub.status.idle": "2024-05-13T19:19:07.772972Z",
     "shell.execute_reply": "2024-05-13T19:19:07.771712Z"
    },
    "papermill": {
     "duration": 28.475824,
     "end_time": "2024-05-13T19:19:07.77502",
     "exception": false,
     "start_time": "2024-05-13T19:18:39.299196",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Find QWK Thresholds\nThe target labels are 1,2,3,4,5,6. So there are 5 thresholds. There is a threshold to decide between prediction 1 versus 2. For example if we have regression prediction 1.3, should it become final target 1 or 2? Where should the cutoff be?\n\nThe algorithm below determines that 1.749 is the optimal cutoff for our SVR in this notebook. A different model may have different optimal threshold. This threshold says when regression prediction is between 0 and 1.749 then we predict 1. And when regression prediction is between 1.749 and the next threshold of 2.533 then we predict 2. The other thresholds decide when to predict 3,4,5,6.",
   "metadata": {
    "papermill": {
     "duration": 0.011076,
     "end_time": "2024-05-13T19:19:07.797436",
     "exception": false,
     "start_time": "2024-05-13T19:19:07.78636",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "def find_thresholds(true, pred, steps=50):\n\n    # SAVE TRIALS FOR PLOTTING\n    xs = [[],[],[],[],[]]\n    ys = [[],[],[],[],[]]\n\n    # COMPUTE BASELINE METRIC\n    threshold = [1.5, 2.5, 3.5, 4.5, 5.5]\n    pred2 = pd.cut(pred, [-np.inf] + threshold + [np.inf], \n                    labels=[1,2,3,4,5,6]).astype('int32')\n    best = cohen_kappa_score(true, pred2, weights=\"quadratic\")\n\n    # FIND FIVE OPTIMAL THRESHOLDS\n    for k in range(5):\n        for sign in [1,-1]:\n            v = threshold[k]\n            threshold2 = threshold.copy()\n            stop = 0\n            while stop<steps:\n\n                # TRY NEW THRESHOLD\n                v += sign * 0.001\n                threshold2[k] = v\n                pred2 = pd.cut(pred, [-np.inf] + threshold2 + [np.inf], \n                                labels=[1,2,3,4,5,6]).astype('int32')\n                metric = cohen_kappa_score(true, pred2, weights=\"quadratic\")\n\n                # SAVE TRIALS FOR PLOTTING\n                xs[k].append(v)\n                ys[k].append(metric)\n\n                # EARLY STOPPING\n                if metric<=best:\n                    stop += 1\n                else:\n                    stop = 0\n                    best = metric\n                    threshold = threshold2.copy()\n\n    # COMPUTE FINAL METRIC\n    pred2 = pd.cut(pred, [-np.inf] + threshold + [np.inf], \n                    labels=[1,2,3,4,5,6]).astype('int32')\n    best = cohen_kappa_score(true, pred2, weights=\"quadratic\")   \n\n    # RETURN RESULTS\n    threshold = [np.round(t,3) for t in threshold]\n    return best, threshold, xs, ys",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:19:07.820551Z",
     "iopub.status.busy": "2024-05-13T19:19:07.820215Z",
     "iopub.status.idle": "2024-05-13T19:19:07.847325Z",
     "shell.execute_reply": "2024-05-13T19:19:07.846569Z"
    },
    "papermill": {
     "duration": 0.041129,
     "end_time": "2024-05-13T19:19:07.849209",
     "exception": false,
     "start_time": "2024-05-13T19:19:07.80808",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "best, thresholds, xs, ys = find_thresholds(train.score.values, oof, steps=500)\nprint('Best thresholds are:', thresholds )\nprint('=> achieve Overall CV QWK score =', best )",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:19:07.872024Z",
     "iopub.status.busy": "2024-05-13T19:19:07.87171Z",
     "iopub.status.idle": "2024-05-13T19:20:58.540933Z",
     "shell.execute_reply": "2024-05-13T19:20:58.53988Z"
    },
    "papermill": {
     "duration": 110.693874,
     "end_time": "2024-05-13T19:20:58.553785",
     "exception": false,
     "start_time": "2024-05-13T19:19:07.859911",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Display Threshold Trials\nBelow we observe the result of different thresholds and resultant CV QWK score. We note that the curves are pretty smooth which is good. If it is too bumpy, then the bumps are most likely random and will not generalize to unseen test data.",
   "metadata": {
    "papermill": {
     "duration": 0.010983,
     "end_time": "2024-05-13T19:20:58.575958",
     "exception": false,
     "start_time": "2024-05-13T19:20:58.564975",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\n\ndiff = 0.5\nfor k in range(5):\n    plt.figure(figsize=(10,3))\n    plt.scatter(xs[k],ys[k],s=3)\n    m = k+1.5\n    plt.xlim((m-diff,m+diff))\n    i = np.where( (np.array(xs[k])>m-diff)&(np.array(xs[k])<m+diff) )[0]\n    mn = np.min(np.array(ys[k])[i])\n    mx = np.max(np.array(ys[k])[i])\n    plt.ylim((mn,mx))\n    \n    plt.plot([thresholds[k],thresholds[k]],[mn,mx],'--',\n             color='black', label='optimal threshold')\n    \n    plt.title(f\"Threshold between {k+1} and {k+2}\",size=16)\n    plt.xlabel('Threshold value',size=10)\n    plt.ylabel('QWK CV score',size=10)\n    plt.legend()\n    plt.show()",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:20:58.598624Z",
     "iopub.status.busy": "2024-05-13T19:20:58.598288Z",
     "iopub.status.idle": "2024-05-13T19:21:00.106553Z",
     "shell.execute_reply": "2024-05-13T19:21:00.105666Z"
    },
    "papermill": {
     "duration": 1.522249,
     "end_time": "2024-05-13T19:21:00.108914",
     "exception": false,
     "start_time": "2024-05-13T19:20:58.586665",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Create Submission CSV\nWe average our 15 fold predictions and apply optimal thresholds above to convert the 15 sets of regression predictions into 1 set of final target predictions.",
   "metadata": {
    "papermill": {
     "duration": 0.013187,
     "end_time": "2024-05-13T19:21:00.135815",
     "exception": false,
     "start_time": "2024-05-13T19:21:00.122628",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "test_preds = np.mean(test_preds,axis=1)\nprint('Test preds shape:', test_preds.shape )\nprint('First 3 test preds:',test_preds[:3] )",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:21:00.163381Z",
     "iopub.status.busy": "2024-05-13T19:21:00.163088Z",
     "iopub.status.idle": "2024-05-13T19:21:00.168421Z",
     "shell.execute_reply": "2024-05-13T19:21:00.167541Z"
    },
    "papermill": {
     "duration": 0.021494,
     "end_time": "2024-05-13T19:21:00.170466",
     "exception": false,
     "start_time": "2024-05-13T19:21:00.148972",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "test_preds_pp = pd.cut(test_preds, [-np.inf] + thresholds + [np.inf], \n                       labels=[1,2,3,4,5,6]).astype('int32')\nprint('First 3 test preds after PP:',test_preds_pp[:3] )",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:21:00.198184Z",
     "iopub.status.busy": "2024-05-13T19:21:00.197872Z",
     "iopub.status.idle": "2024-05-13T19:21:00.205168Z",
     "shell.execute_reply": "2024-05-13T19:21:00.204207Z"
    },
    "papermill": {
     "duration": 0.023285,
     "end_time": "2024-05-13T19:21:00.207086",
     "exception": false,
     "start_time": "2024-05-13T19:21:00.183801",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "sub = pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\")\nsub[\"score\"] = test_preds_pp\nsub.score = sub.score.astype('int32')\nsub.to_csv(\"submission.csv\",index=False)\nprint(\"Submission shape\", sub.shape )\nsub.head()",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T19:21:00.23704Z",
     "iopub.status.busy": "2024-05-13T19:21:00.236706Z",
     "iopub.status.idle": "2024-05-13T19:21:00.255327Z",
     "shell.execute_reply": "2024-05-13T19:21:00.254466Z"
    },
    "papermill": {
     "duration": 0.035365,
     "end_time": "2024-05-13T19:21:00.257232",
     "exception": false,
     "start_time": "2024-05-13T19:21:00.221867",
     "status": "completed"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
