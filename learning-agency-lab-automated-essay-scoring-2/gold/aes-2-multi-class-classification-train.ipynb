{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"V100"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8300d88d0af44ae4bc6c3239f6b6a93d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_37b23a08174a43dca8ad75689c30c4da","IPY_MODEL_e6706c4f670b425c9c0063fa68af91c9","IPY_MODEL_63e7a551b730494d83ce866c3226e638"],"layout":"IPY_MODEL_585f999635c04d73947110b7a203dc07"}},"37b23a08174a43dca8ad75689c30c4da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ce960afff3740bea5267a63014506f4","placeholder":"‚Äã","style":"IPY_MODEL_af9c246a538247b291c2e80d6620b31b","value":"100%"}},"e6706c4f670b425c9c0063fa68af91c9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61e5b1d6a37b425c98a6c89830a453f0","max":17307,"min":0,"orientation":"horizontal","style":"IPY_MODEL_702cb3875a0e4ad0a6b685d66421a00e","value":17307}},"63e7a551b730494d83ce866c3226e638":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67ab9492f5f44b20b1ec05f04ffa970c","placeholder":"‚Äã","style":"IPY_MODEL_ff9722f1ef22400285bc87ba8f0ab902","value":"‚Äá17307/17307‚Äá[00:39&lt;00:00,‚Äá803.76it/s]"}},"585f999635c04d73947110b7a203dc07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ce960afff3740bea5267a63014506f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af9c246a538247b291c2e80d6620b31b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61e5b1d6a37b425c98a6c89830a453f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"702cb3875a0e4ad0a6b685d66421a00e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67ab9492f5f44b20b1ec05f04ffa970c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff9722f1ef22400285bc87ba8f0ab902":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a613bf026ef441eb07d30ea0bd799d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_005bd4ffccbd4fccad83eb51301980bb","IPY_MODEL_1507ad7c4d104ea4a93c96226d47e525","IPY_MODEL_5e60c22f7af340f3b668689b75b73d63"],"layout":"IPY_MODEL_50670eb3ad1a4bdbae800fbefe74d048"}},"005bd4ffccbd4fccad83eb51301980bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33d73c67becb48839e828a83039c4955","placeholder":"‚Äã","style":"IPY_MODEL_9c3b0f775cb64608a55a28d5fec7c295","value":"Train:‚Äá100%"}},"1507ad7c4d104ea4a93c96226d47e525":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_741e5b8593504c8593b2bea2374b849b","max":865,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86ef73726e5c479ab22c807f98a56cf9","value":865}},"5e60c22f7af340f3b668689b75b73d63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b805eb5f75e84595aa666099882a0072","placeholder":"‚Äã","style":"IPY_MODEL_05a3d969e6d54bb39f808e356f23b63e","value":"‚Äá865/865‚Äá[05:38&lt;00:00,‚Äá‚Äá2.57train_batch/s]"}},"50670eb3ad1a4bdbae800fbefe74d048":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33d73c67becb48839e828a83039c4955":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c3b0f775cb64608a55a28d5fec7c295":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"741e5b8593504c8593b2bea2374b849b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86ef73726e5c479ab22c807f98a56cf9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b805eb5f75e84595aa666099882a0072":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05a3d969e6d54bb39f808e356f23b63e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d38ae743df4249c29b27559e75628646":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e35f94ee71414e178047bf99549bb22d","IPY_MODEL_5ebb627de96f43a9a277bed808a83de7","IPY_MODEL_88cd0786451f42f69e1436d44570379e"],"layout":"IPY_MODEL_bb64af7ba07c4bbbad81252de40dc6e2"}},"e35f94ee71414e178047bf99549bb22d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e52d1eebe2b413b8a5bde428f4b0529","placeholder":"‚Äã","style":"IPY_MODEL_e3bc4494d48f43b3bf6c10e43267c9d9","value":"Validation:‚Äá100%"}},"5ebb627de96f43a9a277bed808a83de7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5fcd4740e4e4b1fb052aa65c5909b85","max":433,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c4b86d21e8b4e08bbd041fc9e8cacc7","value":433}},"88cd0786451f42f69e1436d44570379e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f20627dc47f341a8b056e2aea1d918f8","placeholder":"‚Äã","style":"IPY_MODEL_490211620a1849e3bfe5928e9d4444d7","value":"‚Äá433/433‚Äá[00:57&lt;00:00,‚Äá‚Äá7.78valid_batch/s]"}},"bb64af7ba07c4bbbad81252de40dc6e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e52d1eebe2b413b8a5bde428f4b0529":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3bc4494d48f43b3bf6c10e43267c9d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5fcd4740e4e4b1fb052aa65c5909b85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c4b86d21e8b4e08bbd041fc9e8cacc7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f20627dc47f341a8b056e2aea1d918f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"490211620a1849e3bfe5928e9d4444d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7991a37445b846cf94ad30ab2cdb77bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb7d694e24c44b86a75e87f8bce0be8f","IPY_MODEL_1f3541d1817d48a291127dadcaa67a45","IPY_MODEL_2aa49f7f8a484c139dfe6e5b55653ea3"],"layout":"IPY_MODEL_c3bacd2abc3b4589ae96f5636c90696d"}},"fb7d694e24c44b86a75e87f8bce0be8f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84f2f412f6314be795d179061a86e1e8","placeholder":"‚Äã","style":"IPY_MODEL_faf75bb7b3d6444ca114beca2ab38688","value":"Train:‚Äá‚Äá27%"}},"1f3541d1817d48a291127dadcaa67a45":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5088e8c482a44a92896adaf91cbe0b2f","max":865,"min":0,"orientation":"horizontal","style":"IPY_MODEL_36ec6064332f4276bf2193d61aeb8daa","value":237}},"2aa49f7f8a484c139dfe6e5b55653ea3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_673e4ee26f0c419bb35146c0313f33d0","placeholder":"‚Äã","style":"IPY_MODEL_384208f3251e474484132b009f6b1ae7","value":"‚Äá237/865‚Äá[01:32&lt;04:07,‚Äá‚Äá2.53train_batch/s]"}},"c3bacd2abc3b4589ae96f5636c90696d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84f2f412f6314be795d179061a86e1e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"faf75bb7b3d6444ca114beca2ab38688":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5088e8c482a44a92896adaf91cbe0b2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36ec6064332f4276bf2193d61aeb8daa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"673e4ee26f0c419bb35146c0313f33d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"384208f3251e474484132b009f6b1ae7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> AES-2: <span style='color:#F1A424'>Multi-class Classification </span><span style='color:#ABABAB'> [Train]</span></b>\n\n***\n\n- [Trained Model Weights](https://www.kaggle.com/datasets/alejopaullier/aes2-trained-models): in case you do not wish to run the whole train notebook you can find the weights here.\n- [Inference code](https://www.kaggle.com/code/alejopaullier/aes-2-multi-class-classification-inference) üëàüèº\n\nThe goal of this competition is to train a model to score student essays. Your efforts are needed to reduce the high expense and time required to hand grade these essays. Reliable automated techniques could allow essays to be introduced in testing, a key indicator of student learning that is currently commonly avoided due to the challenges in grading.\n\nIn this baseline you will learn how to train a PyTorch multi-class text classification model to predict essays scores. \n\n### <b><span style='color:#F1A424'>Table of Contents</span></b> <a class='anchor' id='top'></a>\n<div style=\" background-color:#3b3745; padding: 13px 13px; border-radius: 8px; color: white\">\n<li> <a href=\"#introduction\">Introduction</a></li>\n<li> <a href=\"#install_libraries\">Install libraries</a></li>\n<li><a href=\"#import_libraries\">Import Libraries</a></li>\n<li><a href=\"#configuration\">Configuration</a></li>\n<li><a href=\"#utils\">Utils</a></li>\n<li><a href=\"#load_data\">Load Data</a></li>\n<li><a href=\"#validation\">Validation</a></li>\n<li><a href=\"#dataset\">Dataset</a></li>\n<li><a href=\"#model\">Model</a></li>\n<li><a href=\"#loss\">Loss Function</a></li>\n<li><a href=\"#functions\">Train and Validation Functions</a></li>\n<li><a href=\"#train_loop\">Train Loop</a></li>\n<li><a href=\"#train\">Train</a></li>\n<li><a href=\"#evaluate\">Evaluate</a></li>\n</div>\n\n\n# <b><span style='color:#F1A424'>|</span> Introduction</b><a class='anchor' id='introduction'></a> [‚Üë](#top)\n\n***\n\n### <b><span style='color:#F1A424'>Useful References</span></b>\n\n- [Deberta v3 Hugging Face](https://huggingface.co/microsoft/deberta-v3-base)\n- [Deberta paper](https://arxiv.org/abs/2006.03654)","metadata":{"papermill":{"duration":0.012455,"end_time":"2022-08-31T07:01:57.321119","exception":false,"start_time":"2022-08-31T07:01:57.308664","status":"completed"},"tags":[],"id":"7cNgG2_x5sZQ"}},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Import Libraries</b><a class='anchor' id='import_libraries'></a> [‚Üë](#top)\n\n***\n\nImport all the required libraries for this notebook.","metadata":{"id":"9yb96wRP5sZU"}},{"cell_type":"code","source":"import ast\nimport copy\nimport gc\nimport itertools\nimport joblib\nimport json\nimport math\nimport matplotlib.pyplot as plt\nimport multiprocessing\nimport numpy as np\nimport os\nimport pandas as pd\nimport pickle\nimport random\nimport re\nimport scipy as sp\nimport string\nimport sys\nimport time\nimport warnings\nimport wandb\n\n\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm.auto import tqdm\n\n# ======= OPTIONS =========\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Current device is: {device}\")\nwarnings.filterwarnings(\"ignore\")\n!mkdir output","metadata":{"_kg_hide-input":true,"id":"RIxlDWxG5sZU","outputId":"be30d358-4e02-49e4-b2c4-3fdca620b29d","execution":{"iopub.status.busy":"2024-04-04T11:56:39.232195Z","iopub.execute_input":"2024-04-04T11:56:39.233022Z","iopub.status.idle":"2024-04-04T11:56:47.32731Z","shell.execute_reply.started":"2024-04-04T11:56:39.232981Z","shell.execute_reply":"2024-04-04T11:56:47.326248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b><span style='color:#F1A424'>Tokenizers and transformers</span></b>","metadata":{"id":"V_cygU8u5sZY"}},{"cell_type":"code","source":"import tokenizers\nimport transformers\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")","metadata":{"_kg_hide-input":true,"scrolled":true,"_kg_hide-output":true,"id":"vpz8cycz5sZZ","outputId":"ceab9da4-d872-4f90-8708-6ce1161f7a62","execution":{"iopub.status.busy":"2024-04-04T11:56:47.329555Z","iopub.execute_input":"2024-04-04T11:56:47.330386Z","iopub.status.idle":"2024-04-04T11:56:49.562678Z","shell.execute_reply.started":"2024-04-04T11:56:47.330354Z","shell.execute_reply":"2024-04-04T11:56:49.561734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Configuration</b><a class='anchor' id='configuration'></a> [‚Üë](#top)\n\n***\n\nCentral repository for this notebook's hyperparameters.","metadata":{"papermill":{"duration":0.006569,"end_time":"2022-08-31T07:01:57.395826","exception":false,"start_time":"2022-08-31T07:01:57.389257","status":"completed"},"tags":[],"id":"Q7Rc6VWy5sZa"}},{"cell_type":"code","source":"class config:\n    APEX = True # Automatic Precision Enabled\n    BATCH_SCHEDULER = True\n    BATCH_SIZE_TRAIN = 16\n    BATCH_SIZE_VALID = 8\n    BETAS = (0.9, 0.999)\n    DEBUG = False\n    DECODER_LR = 2e-5\n    ENCODER_LR = 2e-5\n    EPOCHS = 2\n    EPS = 1e-6\n    FOLDS = 5\n    GRADIENT_ACCUMULATION_STEPS = 1\n    GRADIENT_CHECKPOINTING = True\n    MAX_GRAD_NORM=1000\n    MAX_LEN = 512\n    MIN_LR = 1e-6\n    MODEL = \"microsoft/deberta-v3-base\"\n    NUM_CYCLES = 0.5\n    NUM_CLASSES = 6\n    NUM_WARMUP_STEPS = 0\n    NUM_WORKERS = 0 #multiprocessing.cpu_count()\n    PRINT_FREQ = 20\n    SCHEDULER = 'cosine' # ['linear', 'cosine']\n    SEED = 20\n    TRAIN = True\n    TRAIN_FOLDS = [0, 1, 2, 3, 4]\n    WEIGHT_DECAY = 0.01\n\n\nclass paths:\n    OUTPUT_DIR = \"/kaggle/working/output\"\n    TEST_CSV = \"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\"\n    TRAIN_CSV = \"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\"\n\n\nif config.DEBUG:\n    config.EPOCHS = 2\n    config.TRAIN_FOLDS = [0]","metadata":{"papermill":{"duration":0.015868,"end_time":"2022-08-31T07:01:57.417077","exception":false,"start_time":"2022-08-31T07:01:57.401209","status":"completed"},"tags":[],"id":"SjChKCdG5sZa","execution":{"iopub.status.busy":"2024-04-04T11:56:49.563998Z","iopub.execute_input":"2024-04-04T11:56:49.564554Z","iopub.status.idle":"2024-04-04T11:56:49.573004Z","shell.execute_reply.started":"2024-04-04T11:56:49.56452Z","shell.execute_reply":"2024-04-04T11:56:49.571853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Utils</b><a class='anchor' id='utils'></a> [‚Üë](#top)\n\n***\n\nUtility functions used throughout the notebook.","metadata":{"papermill":{"duration":0.007998,"end_time":"2022-08-31T07:03:04.079768","exception":false,"start_time":"2022-08-31T07:03:04.07177","status":"completed"},"tags":[],"id":"2ULiUvMV5sZb"}},{"cell_type":"code","source":"def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    optimizer_parameters = [\n        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n         'lr': encoder_lr, 'weight_decay': weight_decay},\n        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n         'lr': encoder_lr, 'weight_decay': 0.0},\n        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n         'lr': decoder_lr, 'weight_decay': 0.0}\n    ]\n    return optimizer_parameters\n\n\ndef get_logger(filename=paths.OUTPUT_DIR):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\n\ndef get_scheduler(cfg, optimizer, num_train_steps):\n    if cfg.SCHEDULER == 'linear':\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer, num_warmup_steps=cfg.NUM_WARMUP_STEPS,\n            num_training_steps=num_train_steps\n        )\n    elif cfg.SCHEDULER == 'cosine':\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer, num_warmup_steps=cfg.NUM_WARMUP_STEPS,\n            num_training_steps=num_train_steps, num_cycles=cfg.NUM_CYCLES\n        )\n    return scheduler\n\n\ndef get_score(y_true, y_pred):\n    score = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n    return score\n\n\ndef seed_everything(seed=20):\n    \"\"\"Seed everything to ensure reproducibility\"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n\ndef sep():\n    print(\"-\"*100)\n\n\nLOGGER = get_logger()\nseed_everything(seed=config.SEED)","metadata":{"papermill":{"duration":0.024132,"end_time":"2022-08-31T07:03:04.111108","exception":false,"start_time":"2022-08-31T07:03:04.086976","status":"completed"},"tags":[],"id":"ceIPtRIS5sZb","execution":{"iopub.status.busy":"2024-04-04T11:56:49.575659Z","iopub.execute_input":"2024-04-04T11:56:49.576019Z","iopub.status.idle":"2024-04-04T11:56:49.593537Z","shell.execute_reply.started":"2024-04-04T11:56:49.575987Z","shell.execute_reply":"2024-04-04T11:56:49.592604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Load Data</b><a class='anchor' id='load_data'></a> [‚Üë](#top)\n\n***\n\nLoad data.","metadata":{"papermill":{"duration":0.012589,"end_time":"2022-08-31T07:03:04.13341","exception":false,"start_time":"2022-08-31T07:03:04.120821","status":"completed"},"tags":[],"id":"or6YUwoO5sZc"}},{"cell_type":"code","source":"train_df = pd.read_csv(paths.TRAIN_CSV, sep=',')\ntrain_df[\"score\"] = train_df[\"score\"] - 1\ntest_df = pd.read_csv(paths.TEST_CSV, sep=',')\nprint(f\"Train dataframe has shape: {train_df.shape}\"), sep()\nprint(f\"Test dataframe has shape: {test_df.shape}\"), sep()\ndisplay(train_df.head())\ndisplay(test_df.head())","metadata":{"papermill":{"duration":0.242687,"end_time":"2022-08-31T07:03:04.383434","exception":false,"start_time":"2022-08-31T07:03:04.140747","status":"completed"},"tags":[],"id":"upABGcsW5sZd","outputId":"dcf4b289-27fd-4954-d764-b1188986bc55","execution":{"iopub.status.busy":"2024-04-04T11:56:49.594789Z","iopub.execute_input":"2024-04-04T11:56:49.595124Z","iopub.status.idle":"2024-04-04T11:56:50.393097Z","shell.execute_reply.started":"2024-04-04T11:56:49.595101Z","shell.execute_reply":"2024-04-04T11:56:50.392172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Validation</b><a class='anchor' id='validation'></a> [‚Üë](#top)\n\n***\n\nSince we lack any metadata to do the split we will split using `StratifiedKFold`. A better split would be to use a `StratifiedGroupKFold`, grouping by `prompt_id` which indicates the original text in which the essay was based.","metadata":{"papermill":{"duration":0.008293,"end_time":"2022-08-31T07:03:04.40102","exception":false,"start_time":"2022-08-31T07:03:04.392727","status":"completed"},"tags":[],"id":"4ZPp2vMs5sZd"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import StratifiedKFold\n\ntrain_df[\"fold\"] = -1\nX = train_df[\"full_text\"]\ny = train_df[\"score\"]\nskf = StratifiedKFold(n_splits=config.FOLDS)\n\nfor i, (train_index, val_index) in enumerate(skf.split(X, y)):\n    train_df.loc[val_index, \"fold\"] = i\n\nprint(train_df[\"fold\"].value_counts())","metadata":{"id":"suMHAdqk5sZe","outputId":"5e57d775-494b-4f84-b512-7475e4b8928e","execution":{"iopub.status.busy":"2024-04-04T11:56:50.394458Z","iopub.execute_input":"2024-04-04T11:56:50.395233Z","iopub.status.idle":"2024-04-04T11:56:50.419053Z","shell.execute_reply.started":"2024-04-04T11:56:50.395199Z","shell.execute_reply":"2024-04-04T11:56:50.418181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Tokenizer</b><a class='anchor' id='tokenizer'></a> [‚Üë](#top)\n\n***","metadata":{"papermill":{"duration":0.007561,"end_time":"2022-08-31T07:03:04.604916","exception":false,"start_time":"2022-08-31T07:03:04.597355","status":"completed"},"tags":[],"id":"TYAcl6lt5sZe"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.MODEL)\ntokenizer.save_pretrained(paths.OUTPUT_DIR + '/tokenizer/')\nprint(tokenizer)","metadata":{"papermill":{"duration":7.351568,"end_time":"2022-08-31T07:03:11.964298","exception":false,"start_time":"2022-08-31T07:03:04.61273","status":"completed"},"tags":[],"id":"oVlpqW5I5sZf","outputId":"7119baed-38d0-49d7-b83f-0d6aa1b2297a","execution":{"iopub.status.busy":"2024-04-04T11:56:50.420135Z","iopub.execute_input":"2024-04-04T11:56:50.420401Z","iopub.status.idle":"2024-04-04T11:56:52.785698Z","shell.execute_reply.started":"2024-04-04T11:56:50.420378Z","shell.execute_reply":"2024-04-04T11:56:52.784754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Dataset</b><a class='anchor' id='dataset'></a> [‚Üë](#top)\n\n***\n\n    \nWe need to get the `max_len` from our `tokenizer`. We create a `tqdm` iterator and for each text we extract the tokenized length. Then we get the maximum value and we add 3 for the special tokens `CLS`, `SEP`, `SEP`.\n\n- [Hugging Face Padding and Truncation](https://huggingface.co/docs/transformers/pad_truncation): check truncation to `max_length` or `True` (batch max length).","metadata":{"papermill":{"duration":0.008127,"end_time":"2022-08-31T07:03:11.985369","exception":false,"start_time":"2022-08-31T07:03:11.977242","status":"completed"},"tags":[],"id":"vL63RCn75sZf"}},{"cell_type":"code","source":"lengths = []\ntqdm_loader = tqdm(train_df['full_text'].fillna(\"\").values, total=len(train_df))\nfor text in tqdm_loader:\n    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n    lengths.append(length)\n\n# config.MAX_LEN = max(lengths) + 3 # cls & sep & sep\nLOGGER.info(f\"max_len: {config.MAX_LEN}\")\n_ = plt.hist(lengths, bins=25)","metadata":{"papermill":{"duration":5.893032,"end_time":"2022-08-31T07:03:17.886504","exception":false,"start_time":"2022-08-31T07:03:11.993472","status":"completed"},"tags":[],"id":"U9kMZLCD5sZf","outputId":"0197095f-b833-46dd-dde1-067c52842692","execution":{"iopub.status.busy":"2024-04-04T11:56:52.786878Z","iopub.execute_input":"2024-04-04T11:56:52.787171Z","iopub.status.idle":"2024-04-04T11:57:13.292081Z","shell.execute_reply.started":"2024-04-04T11:56:52.787147Z","shell.execute_reply":"2024-04-04T11:57:13.29107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_input(cfg, text, tokenizer):\n    \"\"\"\n    This function tokenizes the input text with the configured padding and truncation. Then,\n    returns the input dictionary, which contains the following keys: \"input_ids\",\n    \"token_type_ids\" and \"attention_mask\". Each value is a torch.tensor.\n    :param cfg: configuration class with a TOKENIZER attribute.\n    :param text: a numpy array where each value is a text as string.\n    :return inputs: python dictionary where values are torch tensors.\n    \"\"\"\n    inputs = tokenizer.encode_plus(\n        text,\n        return_tensors=None,\n        add_special_tokens=True,\n        max_length=cfg.MAX_LEN,\n        padding='max_length', # TODO: check padding to max sequence in batch\n        truncation=True\n    )\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long) # TODO: check dtypes\n    return inputs\n\n\ndef collate(inputs):\n    \"\"\"\n    It truncates the inputs to the maximum sequence length in the batch.\n    \"\"\"\n    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max()) # Get batch's max sequence length\n    for k, v in inputs.items():\n        inputs[k] = inputs[k][:,:mask_len]\n    return inputs\n\n\nclass CustomDataset(Dataset):\n    def __init__(self, cfg, df, tokenizer):\n        self.cfg = cfg\n        self.texts = df['full_text'].values\n        self.labels = df['score'].values\n        self.tokenizer = tokenizer\n        self.essay_ids = df['essay_id'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        output = {}\n        output[\"inputs\"] = prepare_input(self.cfg, self.texts[item], self.tokenizer)\n        output[\"labels\"] = torch.tensor(self.labels[item], dtype=torch.long) # TODO: check dtypes\n        output[\"essay_ids\"] = self.essay_ids[item]\n        return output","metadata":{"papermill":{"duration":0.020447,"end_time":"2022-08-31T07:03:17.916566","exception":false,"start_time":"2022-08-31T07:03:17.896119","status":"completed"},"tags":[],"id":"awnMw3Np5sZf","execution":{"iopub.status.busy":"2024-04-04T11:57:13.293335Z","iopub.execute_input":"2024-04-04T11:57:13.293641Z","iopub.status.idle":"2024-04-04T11:57:13.304458Z","shell.execute_reply.started":"2024-04-04T11:57:13.293616Z","shell.execute_reply":"2024-04-04T11:57:13.303564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One sample from the dataset should look as following:\n```python\n{\n\t'inputs': {\n\t\t'input_ids': tensor([1, 279, 883, ..., 0, 0]),\n\t\t'token_type_ids': tensor([0, 0, 0, ..., 0, 0]),\n\t\t'attention_mask': tensor([1, 1, 1, ..., 0, 0])\n\t},\n\t'label': tensor([5]),\n\t'essay_': '30ff0f0'\n}\n```\nYou can check it by running the cell below.","metadata":{"id":"ybyuQWfZ5sZg"}},{"cell_type":"code","source":"if config.DEBUG:\n    # ======== SPLIT ==========\n    fold = 0\n    train_folds = train_df[train_df['fold'] != fold].reset_index(drop=True)\n    valid_folds = train_df[train_df['fold'] == fold].reset_index(drop=True)\n    valid_labels = valid_folds[\"score\"].values\n\n    # ======== DATASETS ==========\n    train_dataset = CustomDataset(config, train_folds, tokenizer)\n    valid_dataset = CustomDataset(config, valid_folds, tokenizer)\n\n    # ======== DATALOADERS ==========\n    train_loader = DataLoader(train_dataset,\n                              batch_size=config.BATCH_SIZE_TRAIN, # TODO: split into train and valid\n                              shuffle=True,\n                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset,\n                              batch_size=config.BATCH_SIZE_VALID,\n                              shuffle=False,\n                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False)\n\n    # === Let's check one sample ===\n    sample = train_dataset[0]\n    print(f\"Encoding keys: {sample.keys()} \\n\")\n    print(sample)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"id":"rNdhW6-p5sZg","execution":{"iopub.status.busy":"2024-04-04T11:57:13.307998Z","iopub.execute_input":"2024-04-04T11:57:13.308286Z","iopub.status.idle":"2024-04-04T11:57:13.324922Z","shell.execute_reply.started":"2024-04-04T11:57:13.308262Z","shell.execute_reply":"2024-04-04T11:57:13.323992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Model</b><a class='anchor' id='model'></a> [‚Üë](#top)\n\n***","metadata":{"papermill":{"duration":0.008073,"end_time":"2022-08-31T07:03:17.933189","exception":false,"start_time":"2022-08-31T07:03:17.925116","status":"completed"},"tags":[],"id":"9GREa9n35sZg"}},{"cell_type":"code","source":"class MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n\n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n\n\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        # Load config by inferencing it from the model name.\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.MODEL, output_hidden_states=True)\n            self.config.hidden_dropout = 0.\n            self.config.hidden_dropout_prob = 0.\n            self.config.attention_dropout = 0.\n            self.config.attention_probs_dropout_prob = 0.\n        # Load config from a file.\n        else:\n            self.config = torch.load(config_path)\n\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.MODEL, config=self.config)\n        else:\n            self.model = AutoModel(self.config)\n\n        if self.cfg.GRADIENT_CHECKPOINTING:\n            self.model.gradient_checkpointing_enable()\n\n        # Add MeanPooling and Linear head at the end to transform the Model into a RegressionModel\n        self.pool = MeanPooling()\n        self.fc = nn.Linear(self.config.hidden_size, config.NUM_CLASSES)\n        self._init_weights(self.fc)\n\n    def _init_weights(self, module):\n        \"\"\"\n        This method initializes weights for different types of layers. The type of layers\n        supported are nn.Linear, nn.Embedding and nn.LayerNorm.\n        \"\"\"\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n\n    def feature(self, inputs):\n        \"\"\"\n        This method makes a forward pass through the model, get the last hidden state (embedding)\n        and pass it through the MeanPooling layer.\n        \"\"\"\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n        return feature\n\n    def forward(self, inputs):\n        \"\"\"\n        This method makes a forward pass through the model, the MeanPooling layer and finally\n        then through the Linear layer to get a regression value.\n        \"\"\"\n        feature = self.feature(inputs)\n        output = self.fc(feature)\n        return output","metadata":{"papermill":{"duration":0.033105,"end_time":"2022-08-31T07:03:17.97447","exception":false,"start_time":"2022-08-31T07:03:17.941365","status":"completed"},"tags":[],"id":"h1s7jOpD5sZg","execution":{"iopub.status.busy":"2024-04-04T11:57:13.326184Z","iopub.execute_input":"2024-04-04T11:57:13.326776Z","iopub.status.idle":"2024-04-04T11:57:13.344494Z","shell.execute_reply.started":"2024-04-04T11:57:13.326743Z","shell.execute_reply":"2024-04-04T11:57:13.343595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Loss Function</b><a class='anchor' id='loss'></a> [‚Üë](#top)\n\n***","metadata":{"papermill":{"duration":0.008106,"end_time":"2022-08-31T07:03:17.993861","exception":false,"start_time":"2022-08-31T07:03:17.985755","status":"completed"},"tags":[],"id":"fm7uYYs95sZh"}},{"cell_type":"code","source":"class RMSELoss(nn.Module):\n    def __init__(self, reduction='mean', eps=1e-9):\n        super().__init__()\n        self.mse = nn.MSELoss(reduction='none')\n        self.reduction = reduction\n        self.eps = eps\n\n    def forward(self, y_pred, y_true):\n        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n        if self.reduction == 'none':\n            loss = loss\n        elif self.reduction == 'sum':\n            loss = loss.sum()\n        elif self.reduction == 'mean':\n            loss = loss.mean()\n        return loss","metadata":{"papermill":{"duration":0.021697,"end_time":"2022-08-31T07:03:18.02376","exception":false,"start_time":"2022-08-31T07:03:18.002063","status":"completed"},"tags":[],"id":"JBBEeNt45sZh","execution":{"iopub.status.busy":"2024-04-04T11:57:13.345574Z","iopub.execute_input":"2024-04-04T11:57:13.345872Z","iopub.status.idle":"2024-04-04T11:57:13.358341Z","shell.execute_reply.started":"2024-04-04T11:57:13.345848Z","shell.execute_reply":"2024-04-04T11:57:13.357443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Train and Validation Functions</b><a class='anchor' id='functions'></a> [‚Üë](#top)\n\n***","metadata":{"papermill":{"duration":0.008452,"end_time":"2022-08-31T07:03:18.041557","exception":false,"start_time":"2022-08-31T07:03:18.033105","status":"completed"},"tags":[],"id":"Mpwq4sfw5sZh"}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_epoch(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    \"\"\"One epoch training pass.\"\"\"\n    model.train() # set model in train mode\n    scaler = torch.cuda.amp.GradScaler(enabled=config.APEX) # Automatic Mixed Precision tries to match each op to its appropriate datatype.\n    losses = AverageMeter() # initiate AverageMeter to track the loss.\n    start = end = time.time() # track the execution time.\n    global_step = 0\n\n    # ========== ITERATE OVER TRAIN BATCHES ============\n    with tqdm(train_loader, unit=\"train_batch\", desc='Train') as tqdm_train_loader:\n        for step, batch in enumerate(tqdm_train_loader):\n            inputs = batch.pop(\"inputs\")\n            labels = batch.pop(\"labels\")\n            inputs = collate(inputs) # collate inputs\n            for k, v in inputs.items(): # send each tensor value to `device`\n                inputs[k] = v.to(device)\n            labels = labels.to(device) # send labels to `device`\n            batch_size = labels.size(0)\n            with torch.cuda.amp.autocast(enabled=config.APEX):\n                y_preds = model(inputs) # forward propagation pass\n                loss = criterion(y_preds, labels) # get loss\n            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n            losses.update(loss.item(), batch_size) # update loss function tracking\n            scaler.scale(loss).backward() # backward propagation pass\n            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n\n            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n                scaler.step(optimizer) # update optimizer parameters\n                scaler.update()\n                optimizer.zero_grad() # zero out the gradients\n                global_step += 1\n                if config.BATCH_SCHEDULER:\n                    scheduler.step() # update learning rate\n            end = time.time() # get finish time\n\n            # ========== LOG INFO ==========\n            if step % config.PRINT_FREQ == 0 or step == (len(train_loader)-1):\n                print('Epoch: [{0}][{1}/{2}] '\n                      'Elapsed {remain:s} '\n                      'Loss: {loss.avg:.4f} '\n                      'Grad: {grad_norm:.4f}  '\n                      'LR: {lr:.8f}  '\n                      .format(epoch+1, step, len(train_loader),\n                              remain=timeSince(start, float(step+1)/len(train_loader)),\n                              loss=losses,\n                              grad_norm=grad_norm,\n                              lr=scheduler.get_lr()[0]))\n\n    return losses.avg\n\n\ndef valid_epoch(valid_loader, model, criterion, device):\n    model.eval() # set model in evaluation mode\n    losses = AverageMeter() # initiate AverageMeter for tracking the loss.\n    prediction_dict = {}\n    preds = []\n    start = end = time.time() # track the execution time.\n    with tqdm(valid_loader, unit=\"valid_batch\", desc='Validation') as tqdm_valid_loader:\n        for step, batch in enumerate(tqdm_valid_loader):\n            inputs = batch.pop(\"inputs\")\n            labels = batch.pop(\"labels\")\n            student_ids = batch.pop(\"essay_ids\")\n            inputs = collate(inputs) # collate inputs\n            for k, v in inputs.items():\n                inputs[k] = v.to(device) # send inputs to device\n            labels = labels.to(device)\n            batch_size = labels.size(0)\n            with torch.no_grad():\n                y_preds = model(inputs) # forward propagation pass\n                loss = criterion(y_preds, labels) # get loss\n            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n            losses.update(loss.item(), batch_size) # update loss function tracking\n            preds.append(y_preds.to('cpu').numpy()) # save predictions\n            end = time.time() # get finish time\n\n            # ========== LOG INFO ==========\n            if step % config.PRINT_FREQ == 0 or step == (len(valid_loader)-1):\n                print('EVAL: [{0}/{1}] '\n                      'Elapsed {remain:s} '\n                      'Loss: {loss.avg:.4f} '\n                      .format(step, len(valid_loader),\n                              loss=losses,\n                              remain=timeSince(start, float(step+1)/len(valid_loader))))\n\n    prediction_dict[\"predictions\"] = np.concatenate(preds) # np.array() of shape (fold_size, target_cols)\n    prediction_dict[\"essay_ids\"] = student_ids\n    return losses.avg, prediction_dict","metadata":{"papermill":{"duration":0.030759,"end_time":"2022-08-31T07:03:18.08056","exception":false,"start_time":"2022-08-31T07:03:18.049801","status":"completed"},"tags":[],"id":"f5KRc7Lh5sZh","execution":{"iopub.status.busy":"2024-04-04T11:57:13.359659Z","iopub.execute_input":"2024-04-04T11:57:13.360082Z","iopub.status.idle":"2024-04-04T11:57:13.384527Z","shell.execute_reply.started":"2024-04-04T11:57:13.36005Z","shell.execute_reply":"2024-04-04T11:57:13.383614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Train Loop</b><a class='anchor' id='train_loop'></a> [‚Üë](#top)\n\n***","metadata":{"papermill":{"duration":0.0081,"end_time":"2022-08-31T07:03:18.100232","exception":false,"start_time":"2022-08-31T07:03:18.092132","status":"completed"},"tags":[],"id":"Foj4Zac95sZi"}},{"cell_type":"code","source":"def train_loop(folds, fold):\n\n    LOGGER.info(f\"========== Fold: {fold} training ==========\")\n\n    # ======== SPLIT ==========\n    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n    valid_labels = valid_folds[\"score\"].values\n\n    # ======== DATASETS ==========\n    train_dataset = CustomDataset(config, train_folds, tokenizer)\n    valid_dataset = CustomDataset(config, valid_folds, tokenizer)\n\n    # ======== DATALOADERS ==========\n    train_loader = DataLoader(train_dataset,\n                              batch_size=config.BATCH_SIZE_TRAIN, # TODO: split into train and valid\n                              shuffle=True,\n                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset,\n                              batch_size=config.BATCH_SIZE_VALID,\n                              shuffle=False,\n                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False)\n\n    # ======== MODEL ==========\n    model = CustomModel(config, config_path=None, pretrained=True)\n    torch.save(model.config, paths.OUTPUT_DIR + '/config.pth')\n    model.to(device)\n\n    optimizer_parameters = get_optimizer_params(model,\n                                                encoder_lr=config.ENCODER_LR,\n                                                decoder_lr=config.DECODER_LR,\n                                                weight_decay=config.WEIGHT_DECAY)\n    optimizer = AdamW(\n        optimizer_parameters,\n        lr=config.ENCODER_LR,\n        eps=config.EPS,\n        betas=config.BETAS\n    )\n\n\n    num_train_steps = int(len(train_folds) / config.BATCH_SIZE_TRAIN * config.EPOCHS)\n    scheduler = get_scheduler(config, optimizer, num_train_steps)\n\n    # ======= LOSS ==========\n    # criterion = RMSELoss(reduction=\"mean\") # nn.SmoothL1Loss(reduction='mean')\n    criterion = nn.CrossEntropyLoss()\n    softmax = nn.Softmax(dim=1)\n\n    best_score = -np.inf\n    # ====== ITERATE EPOCHS ========\n    for epoch in range(config.EPOCHS):\n\n        start_time = time.time()\n\n        # ======= TRAIN ==========\n        avg_loss = train_epoch(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n\n        # ======= EVALUATION ==========\n        avg_val_loss, prediction_dict = valid_epoch(valid_loader, model, criterion, device)\n        predictions = prediction_dict[\"predictions\"]\n        _, predictions = torch.max(softmax(torch.tensor(predictions)), dim=1)\n\n        # ======= SCORING ==========\n        score = get_score(valid_labels, predictions)\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n\n        if score > best_score:\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(),\n                        'predictions': predictions},\n                        paths.OUTPUT_DIR + f\"/{config.MODEL.replace('/', '_')}_fold_{fold}_best.pth\")\n\n    predictions = torch.load(paths.OUTPUT_DIR + f\"/{config.MODEL.replace('/', '_')}_fold_{fold}_best.pth\",\n                             map_location=torch.device('cpu'))['predictions']\n    valid_folds[\"pred_score\"] = predictions\n\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    return valid_folds","metadata":{"papermill":{"duration":0.033332,"end_time":"2022-08-31T07:03:18.141812","exception":false,"start_time":"2022-08-31T07:03:18.10848","status":"completed"},"tags":[],"id":"1pWR94BH5sZi","execution":{"iopub.status.busy":"2024-04-04T11:57:13.38575Z","iopub.execute_input":"2024-04-04T11:57:13.386081Z","iopub.status.idle":"2024-04-04T11:57:13.401023Z","shell.execute_reply.started":"2024-04-04T11:57:13.386058Z","shell.execute_reply":"2024-04-04T11:57:13.400186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Train</b><a class='anchor' id='train'></a> [‚Üë](#top)\n\n***","metadata":{"id":"Bs2mSN4R5sZi"}},{"cell_type":"code","source":"if __name__ == '__main__':\n\n    def get_result(oof_df):\n        labels = oof_df[\"score\"].values\n        preds = oof_df[\"pred_score\"].values\n        score = get_score(labels, preds)\n        LOGGER.info(f'Score: {score:<.4f}')\n\n    if config.TRAIN:\n        oof_df = pd.DataFrame()\n        for fold in range(config.FOLDS):\n            if fold in config.TRAIN_FOLDS:\n                _oof_df = train_loop(train_df, fold)\n                oof_df = pd.concat([oof_df, _oof_df])\n                LOGGER.info(f\"========== Fold: {fold} result ==========\")\n                get_result(_oof_df)\n        oof_df = oof_df.reset_index(drop=True)\n        LOGGER.info(f\"========== CV ==========\")\n        get_result(oof_df)\n        oof_df.to_csv(paths.OUTPUT_DIR + '/oof_df.csv', index=False)","metadata":{"papermill":{"duration":11935.46951,"end_time":"2022-08-31T10:22:13.621316","exception":false,"start_time":"2022-08-31T07:03:18.151806","status":"completed"},"tags":[],"id":"UBRZ72Pl5sZi","outputId":"0931bbb2-42b6-490a-9866-f87791f58565","execution":{"iopub.status.busy":"2024-04-04T11:57:13.401982Z","iopub.execute_input":"2024-04-04T11:57:13.402235Z","iopub.status.idle":"2024-04-04T12:52:37.893208Z","shell.execute_reply.started":"2024-04-04T11:57:13.402214Z","shell.execute_reply":"2024-04-04T12:52:37.891872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Uqza6dRXFqXE"},"execution_count":null,"outputs":[]}]}