{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"},{"sourceId":7017419,"sourceType":"datasetVersion","datasetId":3937250},{"sourceId":173399938,"sourceType":"kernelVersion"}],"dockerImageVersionId":30699,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LB Probe if Test Data in Persuade Corpus\nIs this notebook, we probe the LB test data to see if any test essays are duplicate matches from the Persuade 2.0 corpus. We do not expect them to be, but we will check. There is a discussion [here][1] and previous notebook to analyze train data [here][2]\n\nAs a baseline, we will use the simple notebook [here][3] (which submits essay length mean targets) and achieves `LB=0.703`. If using targets from Persuade corpus whenever we find a match improves our LB score, then we have evidence that some test data (and their LB targets) are duplicates of Persuade 2.0 corpus.\n\n[1]: https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/discussion/493962#2760994\n[2]: https://www.kaggle.com/code/abdullahmeda/persuade-train-essays-analysis/\n[3]: https://www.kaggle.com/code/ianchute/no-model-baseline","metadata":{}},{"cell_type":"markdown","source":"# Load Persuade and Train Data\nHere is Persuade 2.0 corpus and competition train data.","metadata":{}},{"cell_type":"code","source":"import pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nimport cupy as cp\n\npersuade = pd.read_csv('/kaggle/input/persaude-corpus-2/persuade_2.0_human_scores_demo_id_github.csv')\nprint('Persuade corpus 2.0 shape:', persuade.shape )\npersuade.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:01:22.658268Z","iopub.execute_input":"2024-04-22T20:01:22.658667Z","iopub.status.idle":"2024-04-22T20:01:23.523283Z","shell.execute_reply.started":"2024-04-22T20:01:22.658637Z","shell.execute_reply":"2024-04-22T20:01:23.522392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv')\nprint('Train data shape:', train.shape )\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:01:23.525309Z","iopub.execute_input":"2024-04-22T20:01:23.525961Z","iopub.status.idle":"2024-04-22T20:01:23.932579Z","shell.execute_reply.started":"2024-04-22T20:01:23.525925Z","shell.execute_reply":"2024-04-22T20:01:23.931509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create CountVectorizer Embeddings\nWe will use normalized CountVectorizer with English stop words and with max vocab 1024 to create embeddings","metadata":{}},{"cell_type":"code","source":"%%time\nfrom sklearn.feature_extraction.text import CountVectorizer\nmodel = CountVectorizer(stop_words='english',max_features=1024)\np_embed = model.fit_transform(persuade.full_text.values)\np_embed = cp.array(p_embed.toarray())\nnorm = cp.sqrt( cp.sum(p_embed*p_embed,axis=1, keepdims=True) )\np_embed = p_embed / norm","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:01:23.933949Z","iopub.execute_input":"2024-04-22T20:01:23.934271Z","iopub.status.idle":"2024-04-22T20:01:33.142263Z","shell.execute_reply.started":"2024-04-22T20:01:23.934245Z","shell.execute_reply":"2024-04-22T20:01:33.141133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_embed = model.transform(train.full_text.values)\ntrain_embed = cp.array(train_embed.toarray())\nnorm = cp.sqrt( cp.sum(train_embed*train_embed,axis=1, keepdims=True) )\ntrain_embed = train_embed / norm","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:01:33.144515Z","iopub.execute_input":"2024-04-22T20:01:33.144799Z","iopub.status.idle":"2024-04-22T20:01:38.862764Z","shell.execute_reply.started":"2024-04-22T20:01:33.144775Z","shell.execute_reply":"2024-04-22T20:01:38.861779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cosine Similarity Search\nWe use GPU CuPy to quickly multiply the normalized embedding matrices of Persuade and Train to compute cosine similarity and find the TopK matches. We will only use Top1 match.","metadata":{}},{"cell_type":"code","source":"%%time\ntop1 = cp.dot(p_embed, train_embed.T)\ntop1 = cp.argmax(top1,axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:01:38.864148Z","iopub.execute_input":"2024-04-22T20:01:38.864542Z","iopub.status.idle":"2024-04-22T20:01:38.871615Z","shell.execute_reply.started":"2024-04-22T20:01:38.864509Z","shell.execute_reply":"2024-04-22T20:01:38.870586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['full_text_p'] = ''\ntrain['score_p'] = -1\nfor k in range(len(train)):\n    if k%500==0: print(k,', ',end='')\n    train.loc[k,'full_text_p'] = persuade.loc[top1[k].item(),'full_text']\n    train.loc[k,'score_p'] = persuade.loc[top1[k].item(),'holistic_essay_score']","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:01:38.872838Z","iopub.execute_input":"2024-04-22T20:01:38.873125Z","iopub.status.idle":"2024-04-22T20:01:52.092256Z","shell.execute_reply.started":"2024-04-22T20:01:38.873101Z","shell.execute_reply":"2024-04-22T20:01:52.091225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute Levenstein Distance\nWe will assume a match if `normalized levenstein distance < 0.1`. We use 90% character match in case Kaggle changed the essays slightly.","metadata":{}},{"cell_type":"code","source":"!pip install /kaggle/input/polyleven-whl-files/polyleven-0.8-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-22T20:01:52.093611Z","iopub.execute_input":"2024-04-22T20:01:52.09398Z","iopub.status.idle":"2024-04-22T20:02:04.841141Z","shell.execute_reply.started":"2024-04-22T20:01:52.093946Z","shell.execute_reply":"2024-04-22T20:02:04.840057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from polyleven import levenshtein\nMATCH_THRESHOLD = 0.1\n\ndef levenshtein_distance(row):\n    s1 = row.full_text\n    s2 = row.full_text_p\n    lev = levenshtein(s1.strip(), s2.strip())\n    lev = lev/max(len(s1.strip()), len(s2.strip()))\n    row['lev'] = lev\n    return row    ","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:02:04.842624Z","iopub.execute_input":"2024-04-22T20:02:04.842926Z","iopub.status.idle":"2024-04-22T20:02:04.849503Z","shell.execute_reply.started":"2024-04-22T20:02:04.842898Z","shell.execute_reply":"2024-04-22T20:02:04.848621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain = train.apply(levenshtein_distance,axis=1)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:02:04.850738Z","iopub.execute_input":"2024-04-22T20:02:04.850988Z","iopub.status.idle":"2024-04-22T20:02:30.647167Z","shell.execute_reply.started":"2024-04-22T20:02:04.850967Z","shell.execute_reply":"2024-04-22T20:02:30.646225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = (train.lev<MATCH_THRESHOLD).sum()\nprint(f'There are {c} out of {len(train)} train essays that match Persuade Corpus 2.0 with threshold {MATCH_THRESHOLD}')","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:02:30.650937Z","iopub.execute_input":"2024-04-22T20:02:30.65137Z","iopub.status.idle":"2024-04-22T20:02:30.657514Z","shell.execute_reply.started":"2024-04-22T20:02:30.651319Z","shell.execute_reply":"2024-04-22T20:02:30.65651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist( train.lev.values, bins=100)\nplt.plot([MATCH_THRESHOLD,MATCH_THRESHOLD],[0,100],'--',color='black',\n         label=f'We use\\nthreshold\\nfor match\\n= {MATCH_THRESHOLD}')\nplt.ylim((0,100))\nplt.legend()\nplt.title('Histrogram of Normalized Levenstein\\nbetween Persuade data and Train data',size=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:04:02.769712Z","iopub.execute_input":"2024-04-22T20:04:02.77039Z","iopub.status.idle":"2024-04-22T20:04:03.201958Z","shell.execute_reply.started":"2024-04-22T20:04:02.77036Z","shell.execute_reply":"2024-04-22T20:04:03.200928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA Matches\nBelow we show 1 match for sanity check. We could explore more here.","metadata":{}},{"cell_type":"code","source":"tmp = train.loc[train.lev<MATCH_THRESHOLD]\np = (tmp.score != tmp.score_p).sum()\nprint(f'Among {c} matches, all targets match except {p}')","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:02:31.169957Z","iopub.execute_input":"2024-04-22T20:02:31.170297Z","iopub.status.idle":"2024-04-22T20:02:31.201474Z","shell.execute_reply.started":"2024-04-22T20:02:31.170265Z","shell.execute_reply":"2024-04-22T20:02:31.200373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row = tmp.sample(1,random_state=42).iloc[0]\nprint(f\"Example essay from train data with score = {row['score']}:\\n\")\nprint( row.full_text )","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:02:31.202499Z","iopub.execute_input":"2024-04-22T20:02:31.20277Z","iopub.status.idle":"2024-04-22T20:02:31.21256Z","shell.execute_reply.started":"2024-04-22T20:02:31.202746Z","shell.execute_reply":"2024-04-22T20:02:31.21165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Example matched essay from Persuade Corpus with Persuade score = {row['score_p']}:\\n\")\nprint( row.full_text_p )","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:02:31.213786Z","iopub.execute_input":"2024-04-22T20:02:31.214095Z","iopub.status.idle":"2024-04-22T20:02:31.223447Z","shell.execute_reply.started":"2024-04-22T20:02:31.214069Z","shell.execute_reply":"2024-04-22T20:02:31.222294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Submission CSV Baseline\nThis baseline solution comes from [here][1] and achieves `LB=0.703`. By having a baseline with known LB score, we will know whether our modifications based on matches with Persuade corpus (in next section) improve or hurt our LB score.\n\n[1]: https://www.kaggle.com/code/ianchute/no-model-baseline","metadata":{}},{"cell_type":"code","source":"train2 = pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\",\n                     index_col=\"essay_id\")\ntest2 = pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\",\n                    index_col=\"essay_id\")\n\ntrain2[\"length\"] = train2.full_text.str.replace(\"[Ee\\s]\", \"\", regex=True).str.len() // 50\ntest2[\"length\"] = test2.full_text.str.replace(\"[Ee\\s]\", \"\", regex=True).str.len() // 50\n\nmodes = (train2\n    .groupby(\"length\")\n    .score\n    .agg(lambda s: s.value_counts().keys()[0])\n    .sort_index()\n    .reindex(range(0, 200))\n    .fillna(0)\n    .clip(lower=1)\n    .cummax()\n    .astype(int))\n\nfrom sklearn.metrics import cohen_kappa_score\nqwk = cohen_kappa_score(train2.score, train2.length.map(modes), weights=\"quadratic\")\nmodes.plot.line(title=f\"Baseline Prediction versus Essay Character Length / 50\\n(with spaces and letter E's removed)\\nBaseline CV QWK Score = {qwk}\")\nplt.ylabel('Prediction')\nplt.xlabel(\"Essay character length / 50 (with E's and spaces removed)\")\nplt.show()\n\nprint('\\nBaseline predictions:')\nbaseline = test2.length.map(modes).rename(\"score\").reset_index()\nbaseline.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-22T20:02:31.224756Z","iopub.execute_input":"2024-04-22T20:02:31.225043Z","iopub.status.idle":"2024-04-22T20:02:36.304968Z","shell.execute_reply.started":"2024-04-22T20:02:31.225018Z","shell.execute_reply":"2024-04-22T20:02:36.303928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modify Submission CSV using Persuade Matches\nWe will search test data for matches with Persuade 2.0 corpus. Whenever we find a match with `normalized levenstein distance < 0.1`, we will use the target label from Persuade corpus as our prediction. Otherwise we will use the baseline solution from the previous section (which comes from [here][1] and achieves `LB=0.703`)\n\n[1]: https://www.kaggle.com/code/ianchute/no-model-baseline","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv')\nprint('Test data shape:', train.shape )\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:02:36.30643Z","iopub.execute_input":"2024-04-22T20:02:36.30681Z","iopub.status.idle":"2024-04-22T20:02:36.320438Z","shell.execute_reply.started":"2024-04-22T20:02:36.306776Z","shell.execute_reply":"2024-04-22T20:02:36.319528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_embed = model.transform(test.full_text.values)\ntest_embed = cp.array(test_embed.toarray())\nnorm = cp.sqrt( cp.sum(test_embed*test_embed,axis=1, keepdims=True) )\ntest_embed = test_embed / norm","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:02:36.321725Z","iopub.execute_input":"2024-04-22T20:02:36.322301Z","iopub.status.idle":"2024-04-22T20:02:36.332762Z","shell.execute_reply.started":"2024-04-22T20:02:36.322268Z","shell.execute_reply":"2024-04-22T20:02:36.331891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top1 = cp.dot(p_embed, test_embed.T)\ntop1 = cp.argmax(top1,axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:02:36.334028Z","iopub.execute_input":"2024-04-22T20:02:36.334312Z","iopub.status.idle":"2024-04-22T20:02:36.34455Z","shell.execute_reply.started":"2024-04-22T20:02:36.334287Z","shell.execute_reply":"2024-04-22T20:02:36.343765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['full_text_p'] = ''\ntest['score_p'] = -1\ntest = test.merge(baseline, on='essay_id', how='left').fillna(3)\nfor k in range(len(test)):\n    test.loc[k,'full_text_p'] = persuade.loc[top1[k].item(),'full_text']\n    test.loc[k,'score_p'] = persuade.loc[top1[k].item(),'holistic_essay_score']","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:02:36.345626Z","iopub.execute_input":"2024-04-22T20:02:36.345975Z","iopub.status.idle":"2024-04-22T20:02:36.386115Z","shell.execute_reply.started":"2024-04-22T20:02:36.345948Z","shell.execute_reply":"2024-04-22T20:02:36.385318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.apply(levenshtein_distance,axis=1)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:02:36.387508Z","iopub.execute_input":"2024-04-22T20:02:36.387866Z","iopub.status.idle":"2024-04-22T20:02:36.404724Z","shell.execute_reply.started":"2024-04-22T20:02:36.387837Z","shell.execute_reply":"2024-04-22T20:02:36.403775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.loc[test.lev<MATCH_THRESHOLD,'score'] = test.loc[test.lev<MATCH_THRESHOLD,'score_p']\nsub = test[['essay_id','score']].copy()\nsub.score = sub.score.astype('int32') # to be safe\nsub.to_csv('submission.csv',index=False)\nprint('Submission shape:',sub.shape)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:02:36.405645Z","iopub.execute_input":"2024-04-22T20:02:36.405887Z","iopub.status.idle":"2024-04-22T20:02:36.428194Z","shell.execute_reply.started":"2024-04-22T20:02:36.405867Z","shell.execute_reply":"2024-04-22T20:02:36.427251Z"},"trusted":true},"execution_count":null,"outputs":[]}]}