{
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 71485,
     "databundleVersionId": 8059942,
     "sourceType": "competition"
    },
    {
     "sourceId": 8126207,
     "sourceType": "datasetVersion",
     "datasetId": 4791897
    },
    {
     "sourceId": 8141507,
     "sourceType": "datasetVersion",
     "datasetId": 4813598
    },
    {
     "sourceId": 8166166,
     "sourceType": "datasetVersion",
     "datasetId": 4832208
    },
    {
     "sourceId": 8231106,
     "sourceType": "datasetVersion",
     "datasetId": 4775761
    }
   ],
   "dockerImageVersionId": 30684,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 154.350718,
   "end_time": "2024-04-25T15:21:02.327797",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-25T15:18:27.977079",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d9a49e38af744cb8cd74a9a31ab3530": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9b2d82c51f34462eb2def3c0fcde71a0",
       "placeholder": "​",
       "style": "IPY_MODEL_cb3c9e1ae6b74ad7987df36715cf30f7",
       "value": "Map: 100%"
      }
     },
     "33f6a104d89e4a2faeacc26b44ff2976": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "47a3fadf5f7d4cf982d07418e2dfa05d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_88fff92673304c669cd5583421fbfd80",
       "placeholder": "​",
       "style": "IPY_MODEL_92ae19e0887d406d955ffaa50267d76b",
       "value": " 3/3 [00:00&lt;00:00, 60.84 examples/s]"
      }
     },
     "5708ef2cc92843c994a7cc3483cf5ef7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2d9a49e38af744cb8cd74a9a31ab3530",
        "IPY_MODEL_8f88c87c92154a65a3f427ddbc2df157",
        "IPY_MODEL_47a3fadf5f7d4cf982d07418e2dfa05d"
       ],
       "layout": "IPY_MODEL_d2ca337441f7410987e905abb127b3e9"
      }
     },
     "7e5aa851f6eb4da4962cec65594059da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "88fff92673304c669cd5583421fbfd80": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f88c87c92154a65a3f427ddbc2df157": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7e5aa851f6eb4da4962cec65594059da",
       "max": 3,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_33f6a104d89e4a2faeacc26b44ff2976",
       "value": 3
      }
     },
     "92ae19e0887d406d955ffaa50267d76b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9b2d82c51f34462eb2def3c0fcde71a0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb3c9e1ae6b74ad7987df36715cf30f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d2ca337441f7410987e905abb127b3e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "#### <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:white; font-size:180%; text-align:left;padding:3.0px; background: maroon; border-bottom: 8px solid black\" > TABLE OF CONTENTS<br><div>  \n* [INTRODUCTION](#2)   \n    * [UTILITIES](#2.1)  \n    * [FOREWORD](#2.2)\n    * [VERSION DETAILS](#2.3)\n* [MODEL PREDICTIONS](#3) \n    * [PREPROCESSING](#3.1)\n    * [PUBLIC DEBERTA V3 LARGE](#3.2)\n    * [LGBM MODEL](#3.3)        ",
   "metadata": {
    "papermill": {
     "duration": 0.007296,
     "end_time": "2024-04-25T15:18:31.055959",
     "exception": false,
     "start_time": "2024-04-25T15:18:31.048663",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "%%time\n\n# Installing select libraries:-\nfrom gc import collect;\nfrom warnings import filterwarnings;\nfilterwarnings('ignore');\nfrom IPython.display import display_html, clear_output;\nimport logging;\nfrom shutil import copyfile\n\nfrom copy import deepcopy;\nimport pandas as pd, polars as pl, numpy as np;\nimport polars.selectors as cs;\n\nfrom os import path, walk, getpid\nfrom psutil import Process\nimport re\nfrom collections import Counter\nfrom itertools import product\nimport spacy, string, random\n\nfrom colorama import Fore, Style, init;\nfrom warnings import filterwarnings;\nfilterwarnings('ignore');\nimport joblib;\nimport os;\n\nfrom tqdm.notebook import tqdm;\nimport seaborn as sns;\nimport matplotlib.pyplot as plt;\nfrom matplotlib.colors import ListedColormap as LCM;\n%matplotlib inline\n\nfrom pprint import pprint;\nfrom functools import partial;\n\nimport ctypes\nlibc = ctypes.CDLL(\"libc.so.6\")\n\nprint();\ncollect();\nclear_output();",
   "metadata": {
    "papermill": {
     "duration": 10.318639,
     "end_time": "2024-04-25T15:18:41.381318",
     "exception": false,
     "start_time": "2024-04-25T15:18:31.062679",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-04-25T22:17:43.613066Z",
     "iopub.execute_input": "2024-04-25T22:17:43.613434Z",
     "iopub.status.idle": "2024-04-25T22:17:52.430705Z",
     "shell.execute_reply.started": "2024-04-25T22:17:43.613406Z",
     "shell.execute_reply": "2024-04-25T22:17:52.429704Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%time\n\n# Importing model and pipeline specifics:-\nfrom category_encoders import OrdinalEncoder, OneHotEncoder;\n\n# Pipeline specifics:-\nfrom sklearn.preprocessing import (RobustScaler,\n                                   MinMaxScaler,\n                                   StandardScaler,\n                                   FunctionTransformer as FT,\n                                   PowerTransformer,\n                                  );\nfrom sklearn.impute import SimpleImputer as SI;\nfrom sklearn.model_selection import (RepeatedStratifiedKFold as RSKF,\n                                     StratifiedKFold as SKF,\n                                     StratifiedGroupKFold as SGKF,\n                                     KFold,\n                                     RepeatedKFold as RKF,\n                                     cross_val_score,\n                                     cross_val_predict\n                                    );\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline, make_pipeline;\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin;\nfrom sklearn.compose import ColumnTransformer;\n\n# ML Model training:-\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score;\nfrom xgboost import DMatrix, XGBRegressor as XGBR;\nimport lightgbm as lgb\nfrom lightgbm import log_evaluation, early_stopping, LGBMRegressor as LGBMR;\nfrom catboost import CatBoostRegressor as CBR, Pool;\n\n# Ensemble and tuning:-\nimport optuna;\nfrom optuna import Trial, trial, create_study;\nfrom optuna.pruners import HyperbandPruner;\nfrom optuna.samplers import TPESampler, CmaEsSampler;\noptuna.logging.set_verbosity = optuna.logging.ERROR;\noptuna.logging.disable_default_handler()\n\nclear_output();\nprint();\ncollect();",
   "metadata": {
    "papermill": {
     "duration": 2.669375,
     "end_time": "2024-04-25T15:18:44.057547",
     "exception": false,
     "start_time": "2024-04-25T15:18:41.388172",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-04-25T22:17:52.432615Z",
     "iopub.execute_input": "2024-04-25T22:17:52.433191Z",
     "iopub.status.idle": "2024-04-25T22:17:54.690634Z",
     "shell.execute_reply.started": "2024-04-25T22:17:52.433134Z",
     "shell.execute_reply": "2024-04-25T22:17:54.689738Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%time\n\n# Setting rc parameters in seaborn for plots and graphs-\n# Reference - https://matplotlib.org/stable/tutorials/introductory/customizing.html:-\n# To alter this, refer to matplotlib.rcParams.keys()\n\nsns.set({\"axes.facecolor\"       : \"#ffffff\",\n         \"figure.facecolor\"     : \"#ffffff\",\n         \"axes.edgecolor\"       : \"#000000\",\n         \"grid.color\"           : \"#ffffff\",\n         \"font.family\"          : ['Cambria'],\n         \"axes.labelcolor\"      : \"#000000\",\n         \"xtick.color\"          : \"#000000\",\n         \"ytick.color\"          : \"#000000\",\n         \"grid.linewidth\"       : 0.75,\n         \"grid.linestyle\"       : \"--\",\n         \"axes.titlecolor\"      : '#0099e6',\n         'axes.titlesize'       : 8.5,\n         'axes.labelweight'     : \"bold\",\n         'legend.fontsize'      : 7.0,\n         'legend.title_fontsize': 7.0,\n         'font.size'            : 7.5,\n         'xtick.labelsize'      : 7.5,\n         'ytick.labelsize'      : 7.5,\n        });\n\n# Setting global configuration for polars\npl.Config.activate_decimals(True).set_tbl_hide_column_data_types(True)\npl.Config(**dict(tbl_formatting = 'ASCII_FULL_CONDENSED',\n                 tbl_hide_column_data_types = True,\n                 tbl_hide_dataframe_shape = True,\n                 fmt_float = \"mixed\",\n                 tbl_cell_alignment = 'CENTER',\n                 tbl_hide_dtype_separator = True,\n                 tbl_cols = 100,\n                 tbl_rows = 50,\n                 fmt_str_lengths = 100,\n                )\n         )\n\n# Making sklearn pipeline outputs as dataframe:-\nfrom sklearn import set_config;\nset_config(transform_output = \"pandas\");\npd.set_option('display.max_columns', 50);\npd.set_option('display.max_rows', 50);\n\nprint();\ncollect();\n",
   "metadata": {
    "papermill": {
     "duration": 0.225479,
     "end_time": "2024-04-25T15:18:44.289637",
     "exception": false,
     "start_time": "2024-04-25T15:18:44.064158",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-04-25T22:17:54.691756Z",
     "iopub.execute_input": "2024-04-25T22:17:54.692027Z",
     "iopub.status.idle": "2024-04-25T22:17:54.870034Z",
     "shell.execute_reply.started": "2024-04-25T22:17:54.692003Z",
     "shell.execute_reply": "2024-04-25T22:17:54.869107Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"2\"></a>\n#### <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:white; font-size:180%; text-align:left;padding:3.0px; background: maroon; border-bottom: 8px solid black\" > INTRODUCTION<br><div>",
   "metadata": {
    "papermill": {
     "duration": 0.006531,
     "end_time": "2024-04-25T15:18:44.303059",
     "exception": false,
     "start_time": "2024-04-25T15:18:44.296528",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"2.1\"></a>\n#### <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:160%; text-align:left;padding:3.0px; background: lightgrey; border-bottom: 8px solid maroon\" > UTILITIES<br><div>",
   "metadata": {
    "papermill": {
     "duration": 0.006187,
     "end_time": "2024-04-25T15:18:44.315864",
     "exception": false,
     "start_time": "2024-04-25T15:18:44.309677",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "%%time\n\nclass Utility:\n    \"\"\"\n    This class serves to do the below-\n    1. Define method to print in color\n    2. Define the garbage cleaning process\n    \"\"\";\n\n    def PrintColor(self,text:str, color = Fore.BLUE, style = Style.BRIGHT):\n        \"Prints color outputs using colorama using a text F-string\";\n        print(style + color + text + Style.RESET_ALL)\n\n    def ScoreMetric(self, ytrue, ypred)-> float:\n        \"\"\"\n        This method calculates the custom metric from the imported script\n        Inputs- ytrue, ypred:- input truth and predictions\n        Output- float:- competition metric\n        \"\"\";\n\n        y_pred = np.uint8(np.around(np.clip(ypred, a_min = 1, a_max = 6)))\n        return cohen_kappa_score(np.uint8(ytrue), y_pred, weights = \"quadratic\")\n\n    def CleanMemory(self):\n        \"This method cleans the memory off unused objects and displays the cleaned state RAM usage\";\n\n        collect();\n        libc.malloc_trim(0)\n        pid        = getpid()\n        py         = Process(pid)\n        memory_use = py.memory_info()[0] / 2. ** 30\n        return f\"\\nRAM usage = {memory_use :.4} GB\"\n\nUtils = Utility()\nprint();",
   "metadata": {
    "papermill": {
     "duration": 0.019903,
     "end_time": "2024-04-25T15:18:44.342352",
     "exception": false,
     "start_time": "2024-04-25T15:18:44.322449",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-04-25T22:17:54.872641Z",
     "iopub.execute_input": "2024-04-25T22:17:54.873011Z",
     "iopub.status.idle": "2024-04-25T22:17:54.890376Z",
     "shell.execute_reply.started": "2024-04-25T22:17:54.872978Z",
     "shell.execute_reply": "2024-04-25T22:17:54.889582Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%time\n\nclass CFG:\n    \"\"\"\n    Configuration class for parameters and CV strategy for tuning and training\n    Some parameters may be unused here as this is a general configuration class\n    \"\"\";\n\n    # Data preparation:-\n    exp_nb             = 1;\n    version_nb         = 18;\n    test_req           = \"N\";\n    test_sample_frac   = 0.025;\n    gpu_switch         = \"ON\";\n    state              = 42;\n    target             = \"score\";\n    path               = f\"/kaggle/input/aes2024ancillary\";\n    op_path            = f\"/kaggle/working\"\n    vocab_path         = f'/kaggle/input/english-word-hx/words.txt'\n    llm_path           = f'/kaggle/input/aes2-400-20240419134941'\n\n    dtl_preproc_req    = \"Y\";\n    ftre_plots_req     = 'Y';\n    ftre_imp_req       = \"Y\";\n\n    # Model Training:-\n    ML                 = \"Y\";\n    nb_models          = 10;\n    n_splits           = 3 if test_req == \"Y\" else 15;\n    n_repeats          = 1 ;\n    nbrnd_erly_stp     = 75;\n    mdlcv_mthd         = 'RSKF';\n\n    a                  = 2.998\n    b                  = 1.042\n\n    # Ensemble:-\n    ensemble_req       = \"N\";\n    metric_obj         = 'maximize';\n    ntrials            = 10 if test_req == \"Y\" else 250;\n\n    # Global variables for plotting:-\n    grid_specs = {'visible': True, 'which': 'both', 'linestyle': '--',\n                           'color': 'lightgrey', 'linewidth': 0.75};\n    title_specs = {'fontsize': 9, 'fontweight': 'bold', 'color': '#992600'};\n\nprint();\nUtils.PrintColor(f\"--> Configuration done!\\n\");\ncollect();",
   "metadata": {
    "papermill": {
     "duration": 0.216596,
     "end_time": "2024-04-25T15:18:44.565661",
     "exception": false,
     "start_time": "2024-04-25T15:18:44.349065",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-04-25T22:17:54.891547Z",
     "iopub.execute_input": "2024-04-25T22:17:54.891827Z",
     "iopub.status.idle": "2024-04-25T22:17:55.077256Z",
     "shell.execute_reply.started": "2024-04-25T22:17:54.891804Z",
     "shell.execute_reply": "2024-04-25T22:17:55.076335Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "| Parameter         | Description                                             | Possible value choices|\n| ---               | ---                                                     | :-:                   |\n|  exp_nb           | Experiment Number                                       | integer               |\n|  version_nb       | Version Number                                          | integer               |\n|  test_req         | Are we testing syntax here?                             | Y/N                   |  \n|  test_sample_frac | Sample size for syntax test                             | float(0-1)/ int       |     \n|  gpu_switch       | GPU switch                                              | ON/OFF                |\n|  state            | Random state for most purposes                          | integer               |\n|  target           | Target column names                                     | string                |   \n|  path             | Path for input data files                               |                       |\n|  op_path          | Path for output data files                              |                       |\n|  llm_path         | Path for LLM OOF data files                             |                       |\n|  vocab_path       | Path for English vocab files                            |                       |\n|  dtl_preproc_req  | Proprocessing required                                  | Y/N                   |   \n|  ftre_plots_req   | Feature plots required                                  | Y/N                   |\n|  ftre_imp_req     | Feature importance required                             | Y/N                   |   \n|  ML               | Machine Learning Models                                 | Y/N                   |\n|  n_splits         | Number of CV splits                                     | integer               |\n|  n_repeats        | Number of CV repeats                                    | integer               |\n|  nbrnd_erly_stp   | Number of early stopping rounds                         | integer               |\n|  mdl_cv_mthd      | Model CV method name                                    | RKF/ RSKF/ SKF/ KFold |\n|  ensemble_req     | Ensemble required                                       | Y/N                   |\n|  metric_obj       | Metric objective                                        | maximize/ minimize    |  \n|  ntrials          | Number of trials                                        | int                   |  ",
   "metadata": {
    "papermill": {
     "duration": 0.006692,
     "end_time": "2024-04-25T15:18:44.579137",
     "exception": false,
     "start_time": "2024-04-25T15:18:44.572445",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"2.2\"></a>\n#### <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:160%; text-align:left;padding:3.0px; background: lightgrey; border-bottom: 8px solid maroon\" > FOREWORD<br><div>",
   "metadata": {
    "papermill": {
     "duration": 0.006321,
     "end_time": "2024-04-25T15:18:44.592146",
     "exception": false,
     "start_time": "2024-04-25T15:18:44.585825",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": "This competition aims to grade essays into 6 grades from 1-6 using a training corpus data. We are asked to use **Quadratic Kappa Score** as the metric. <br>\nScoring rubric is explained in detail [here](https://storage.googleapis.com/kaggle-forum-message-attachments/2733927/20538/Rubric_%20Holistic%20Essay%20Scoring.pdf) as part of the competition overview and evaluation guidelines <br>\n\n### **KERNEL SOURCES** <br>\n1. https://www.kaggle.com/code/ye11725/tfidf-lgbm-baseline-with-code-comments <br>\n2. https://www.kaggle.com/code/hideyukizushi/aes2-5folddeberta-lgbm-countvectorizer-lb-810 <br>\n3. https://www.kaggle.com/datasets/hideyukizushi/aes2-400-20240419134941 <br>\n4. https://www.kaggle.com/code/yongsukprasertsuk/0-818-deberta-v3-large-lgbm-baseline <br>\n\n### **MY CONTRIBUTION** <br>\n1. I created a script to collate all preprocessing functions and use them in the train and inference kernels separately <br>\n2. I have created a class for the vectorizer instead of the function and lambda expression <br>\n3. I added a few more models and created an Optuna ensemble, CV score is better this way <br>\n\n### **TRAINING KERNEL** <br>\nOne could build this pipeline using the kernel [here](https://www.kaggle.com/code/ravi20076/aes2024-baseline-ml-training) <br>\nTraining kernel is separated from the inference kernel, significantly reducing the inference time. We save the OOF predictions and the train set (excluding the DeBERTa features) for easy reuse as well <br>",
   "metadata": {
    "papermill": {
     "duration": 0.006438,
     "end_time": "2024-04-25T15:18:44.605398",
     "exception": false,
     "start_time": "2024-04-25T15:18:44.59896",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"2.3\"></a>\n#### <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:160%; text-align:left;padding:3.0px; background: lightgrey; border-bottom: 8px solid maroon\" > VERSION DETAILS<br><div>",
   "metadata": {
    "papermill": {
     "duration": 0.00666,
     "end_time": "2024-04-25T15:18:44.618959",
     "exception": false,
     "start_time": "2024-04-25T15:18:44.612299",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": "|Experiment <br> Number|Version <br> Number|Details|CV score|LB score|\n|-----|-------|----------| :-: | :-:|\n|E1   | V1 | * All features from public notebook- 3361 features <br> * 4 LGBM regressors <br> * Optuna ensemble | 0.80812 |0.796 | \n|E1   | V2 | * All features from public notebook- 3237 features <br> * 4 LGBM regressors <br> * Optuna ensemble | 0.80631 |0.796 | \n|E1   | V3 | * All features from public notebook- 3237 features <br> * 4 LGBM regressors <br> * Optuna ensemble <br> * Repeated k fold CV 10x1 | 0.80683 |0.799 | \n|E1   | V4 | * All features from public notebook- 3237 features <br> * 4 LGBM regressors <br> * Optuna ensemble <br> * Repeated k fold CV 5x1 <br> * Slightly altered parameters| 0.80453 | 0.796| \n|E1   | V5 | * All features from public notebook- 3361 features <br> * 10 LGBM regressors with simgle model and varying states <br> * Optuna ensemble <br> * Repeated k fold CV 5x1| 0.80738 |0.796 | \n|E1 | V6 |* Public notebook features - 8742 features <br> * Retained infinity values <br> * ML model training, 4 models <br> * Optuna ensemble <br> * 5x1 RSKF |0.80684|0.796|\n|E1 | V7 |* Mode blending - Versions 1, 5, 6 ||0.796|\n|E1 | V8 |Mean blending <br> * E1V6, E1V5, E1V1 <br> * DeBERTa V3 Large <br> * Best public LGBM |0.80684||\n|E1 | V9 |* Stacking DeBERTa V3 Large and LGBM <br> * 13781 features <br> * 15x1 RSKF  |0.83627|0.806|\n|E1 | V10 |* Stacking DeBERTa V3 Large and LGBM classifier <br> * 21867 + 12 features <br> * 12x1 RSKF |0.83319|0.808|\n|E1 | V11 |* Stacking DeBERTa V3 Large (new public version) and LGBM classifier <br> * 21867 + 12 features <br> * 12x1 RSKF |0.83948|0.796|\n|E1 | V12 |* Stacking DeBERTa V3 Large (old + new public version) and LGBM classifier <br> * 21867 + 18 features <br> * 12x1 RSKF |0.84148|0.806|\n|E1 | V13 |* Stacking DeBERTa V3 Large (old + new public version) <br> * 21867 + 12 features <br> * 12x1 RSKF |0.84118|0.813|\n|E1 | V14 |* Stacking DeBERTa V3 Large (old + new public version) <br> * 27056 + 12 features <br> * 12x1 RSKF |0.84082|0.806|\n|E1 | V15 |* Stacking DeBERTa V3 Large (new public version) <br> * 27056 + 6 features <br> * 15x1 RSKF |0.83909|0.811|\n|E1 | V16 |* Stacking DeBERTa V3 Large (new public version) <br> * 24434 + 6 features <br> * 15x1 RSKF |0.83909|0.811|\n|E1 | V18 |* Stacking DeBERTa V3 Large (new public version) <br> * 24434 + 6 features <br> * 15x1 RSKF |0.83846||\n|E1 | V19 |* Stacking DeBERTa V3 Large (new public version) <br> * 24468 + 6 features <br> * 15x1 RSKF <br> * Fold level feature selection to 13000 features|0.83798|0.607 <br> Bug |\n|E1 | V20 |* Stacking DeBERTa V3 Large (new public version) <br> * 21990 + 6 features <br> * 15x1 RSKF <br> * Fold level feature selection to 13000 features|0.83795| |",
   "metadata": {
    "papermill": {
     "duration": 0.006575,
     "end_time": "2024-04-25T15:18:44.632896",
     "exception": false,
     "start_time": "2024-04-25T15:18:44.626321",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"3\"></a>\n#### <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:white; font-size:180%; text-align:left;padding:3.0px; background: maroon; border-bottom: 8px solid black\" > MODEL INFERENCING<br><div>",
   "metadata": {
    "papermill": {
     "duration": 0.006432,
     "end_time": "2024-04-25T15:18:44.646125",
     "exception": false,
     "start_time": "2024-04-25T15:18:44.639693",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"3.1\"></a>\n#### <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:160%; text-align:left;padding:3.0px; background: lightgrey; border-bottom: 8px solid maroon\" > PREPROCESSING<br><div>",
   "metadata": {
    "papermill": {
     "duration": 0.006601,
     "end_time": "2024-04-25T15:18:44.65944",
     "exception": false,
     "start_time": "2024-04-25T15:18:44.652839",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "%%time \n\n# Storing the output predictions:-\nsub_fl    = pd.read_csv(f\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\")\n\ntest = \\\npl.read_csv(os.path.join(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\")).\\\nwith_columns([( pl.col(\"full_text\").str.split(by=\"\\n\\n\").alias(\"paragraph\"))])\n\nUtils.PrintColor(f\"\\nTest data sample\\n\")\ndisplay(test.head(1))\nprint();\n\ncopyfile(src = os.path.join(CFG.path, \"fe.py\"), dst = \"fe.py\");\n\nimport fe\nfrom fe import *\n\nXtest = Make_Features(df     = test,\n                      lbl    = \"test\",\n                      target = CFG.target,\n                      path   = CFG.path, \n                      vocab_path = CFG.vocab_path\n                     )\n\nXtest = ReduceMem(Xtest)\n\nprint()\n_ = Utils.CleanMemory()",
   "metadata": {
    "papermill": {
     "duration": 45.613404,
     "end_time": "2024-04-25T15:19:30.279598",
     "exception": false,
     "start_time": "2024-04-25T15:18:44.666194",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-04-25T22:17:55.078588Z",
     "iopub.execute_input": "2024-04-25T22:17:55.079001Z",
     "iopub.status.idle": "2024-04-25T22:18:35.68041Z",
     "shell.execute_reply.started": "2024-04-25T22:17:55.07897Z",
     "shell.execute_reply": "2024-04-25T22:18:35.679449Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"3.2\"></a>\n#### <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:160%; text-align:left;padding:3.0px; background: lightgrey; border-bottom: 8px solid maroon\" > PUBLIC DEBERTA V3 LARGE<br><div>",
   "metadata": {
    "papermill": {
     "duration": 0.007887,
     "end_time": "2024-04-25T15:19:30.296327",
     "exception": false,
     "start_time": "2024-04-25T15:19:30.28844",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "%%time \n\nfrom transformers import (AutoTokenizer, \n                          AutoModelForSequenceClassification, \n                          Trainer, \n                          TrainingArguments, \n                          DataCollatorWithPadding\n                         )\nfrom datasets import Dataset\nfrom glob import glob\nfrom scipy.special import softmax\nimport torch\n\nMAX_LENGTH      = 1024\nTEST_DATA_PATH  = \"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\"\n\nmodel_paths = {\"debertav5_\": f'//kaggle/input/aes2-400-20240419134941/*/*',}\nEVAL_BATCH_SIZE = 1\n\ndef tokenize(sample):\n    return tokenizer(sample['full_text'], max_length=MAX_LENGTH, truncation=True)\n\nclear_output();\n\nUtils.PrintColor(f\"\\nData size and shape before DeBERTa predictions = {Xtest.shape}\")\nfor prefix_lbl, MODEL_PATH in model_paths.items():\n\n    models      = glob(MODEL_PATH)\n    tokenizer   = AutoTokenizer.from_pretrained(models[0])\n    df_test     = pd.read_csv(TEST_DATA_PATH)\n    ds          = Dataset.from_pandas(df_test).map(tokenize).remove_columns(['essay_id', 'full_text'])\n    args        = TrainingArguments(\".\", per_device_eval_batch_size=EVAL_BATCH_SIZE, report_to=\"none\")\n    predictions = []\n\n    for model in models:\n        model   = AutoModelForSequenceClassification.from_pretrained(model)\n        trainer = Trainer(model=model, args=args, data_collator=DataCollatorWithPadding(tokenizer), tokenizer=tokenizer)    \n        preds   = trainer.predict(ds).predictions\n        predictions.append(softmax(preds, axis=-1))\n        del model, trainer\n        torch.cuda.empty_cache()\n        _ = Utils.CleanMemory();\n\n    predicted_score = 0.0\n    for p in predictions:\n        predicted_score += p\n    predicted_score /= len(predictions)\n\n    df    = pd.DataFrame(predicted_score, index = df_test[\"essay_id\"]).add_prefix(prefix_lbl)\n    Xtest = Xtest.merge(df, how = \"left\", left_on = \"essay_id\", right_index = True)\n    \n    Utils.PrintColor(f\"Data size and shape after merge {prefix_lbl} = {Xtest.shape}\")\n    print()\n    display(df.head(5).style.format(precision = 5).set_caption(f\"DeBERTA predictions\"))\n    print()\n    _  = Utils.CleanMemory()\n       \n_  = Utils.CleanMemory()",
   "metadata": {
    "papermill": {
     "duration": 86.322432,
     "end_time": "2024-04-25T15:20:56.626792",
     "exception": false,
     "start_time": "2024-04-25T15:19:30.30436",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-04-25T22:18:35.681819Z",
     "iopub.execute_input": "2024-04-25T22:18:35.682436Z",
     "iopub.status.idle": "2024-04-25T22:20:03.790423Z",
     "shell.execute_reply.started": "2024-04-25T22:18:35.682401Z",
     "shell.execute_reply": "2024-04-25T22:20:03.789475Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a id=\"3.2\"></a>\n#### <div style= \"font-family: Cambria; font-weight:bold; letter-spacing: 0px; color:black; font-size:160%; text-align:left;padding:3.0px; background: lightgrey; border-bottom: 8px solid maroon\" > ML REGRESSOR<br><div>",
   "metadata": {
    "papermill": {
     "duration": 0.008427,
     "end_time": "2024-04-25T15:20:56.644104",
     "exception": false,
     "start_time": "2024-04-25T15:20:56.635677",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": "%%time\n\nclass LGBMSupport:\n    \"\"\"\n    This class supports the LGBM training with a custom metric and objective function\n    \"\"\"\n\n    def __init__(self, a, b):\n        \"\"\"\n        Initializing class level parameters\n        \"\"\"\n        self.a = a\n        self.b = b\n\n    def _LGBMetric(self, y_true, y_pred):\n        \"\"\"\n        This is the custom metric used in evaluation and early stopping\n        \"\"\";\n\n        y_true = y_true + self.a\n        y_pred = (y_pred + self.a).clip(1, 6).round()\n        qwk = cohen_kappa_score(np.around(y_true,0), y_pred, weights=\"quadratic\")\n        return 'QWK', qwk, True\n\n    def _LGBObj(self, y_true, y_pred):\n        \"This is the custom objective function for the LGBM\"\n\n        labels = y_true  + self.a\n        preds  = y_pred  + self.a\n        preds = preds.clip(1, 6)\n\n        f = 1/2 * np.sum((preds-labels)**2)\n        g = 1/2 * np.sum((preds- self.a)**2  + self.b)\n\n        df = preds - labels\n        dg = preds - self.a\n\n        grad = (df/g - f*dg/g**2)*len(labels)\n        hess = np.ones(len(labels))\n        return grad, hess\n\nclass MyLogger:\n    \"\"\"\n    This class helps to suppress logs in lightgbm and Optuna\n    Source - https://github.com/microsoft/LightGBM/issues/6014\n    \"\"\"\n\n    def init(self, logging_lbl: str):\n        self.logger = logging.getLogger(logging_lbl)\n        self.logger.setLevel(logging.ERROR)\n\n    def info(self, message):\n        pass\n\n    def warning(self, message):\n        pass\n\n    def error(self, message):\n        self.logger.error(message)\n\nclass VotingModelMaker(BaseEstimator, RegressorMixin):\n    def __init__(self, estimators: list, weights: list, a = CFG.a, b = CFG.b):\n        super().__init__()\n        self.estimators = estimators\n        self.weights    = weights\n        self.a = a\n        self.b = b\n\n    def fit(self, X, y=None):\n        return self\n\n    def mdlpredict(self, X):\n        y_preds = \\\n        pd.DataFrame(columns = [f\"Est{i}\" for i in range(len((self.estimators)))],\n                     index = range(len(X))\n                    )\n\n        for i, estm in enumerate(self.estimators):\n            y_preds[f\"Est{i}\"] = estm.predict(X) + self.a\n\n        if self.weights != []:\n            return np.average(y_preds, axis=1, weights = self.weights)\n        else:\n            return np.mean(y_preds, axis=1,)\n\n    def mdlpredictproba(self, X):\n        y_preds = \\\n        pd.DataFrame(columns = [f\"Est{i}\" for i in range(len(range(self.estimators)))],\n                     index = range(len(X))\n                    )\n\n        for i, estm in enumerate(self.estimators):\n            y_preds[f\"Est{i}\"] = estm.predict_proba(X)\n\n        if self.weights != []:\n            return np.average(y_preds, axis=1, weights = self.weights)\n        else:\n            return np.mean(y_preds, axis=1,)",
   "metadata": {
    "papermill": {
     "duration": 0.029067,
     "end_time": "2024-04-25T15:20:56.681547",
     "exception": false,
     "start_time": "2024-04-25T15:20:56.65248",
     "status": "completed"
    },
    "tags": [],
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2024-04-25T22:20:03.791812Z",
     "iopub.execute_input": "2024-04-25T22:20:03.792079Z",
     "iopub.status.idle": "2024-04-25T22:20:03.810046Z",
     "shell.execute_reply.started": "2024-04-25T22:20:03.792055Z",
     "shell.execute_reply": "2024-04-25T22:20:03.809082Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%time \n\nmodels    = joblib.load(os.path.join(CFG.path, f\"VR_E{CFG.exp_nb}V{CFG.version_nb}\"))\ndrop_cols = [\"essay_id\", \"id\", \"Source\"]\n\nMdl_Preds = pd.DataFrame(index = Xtest[\"essay_id\"])\nfor i, mdl in enumerate(models):\n    Utils.PrintColor(f\"---> Model {i}\");\n    Mdl_Preds[f\"Model{i}\"] = \\\n    mdl.mdlpredict(Xtest.drop(drop_cols, axis=1, errors = \"ignore\")).values\n    \nprint()\ndisplay(Mdl_Preds.head(10).style.format(precision = 2).set_caption(\"Model predictions file\"));\n\nif len(models) > 1:\n    sub_fl[CFG.target] = np.round(np.clip(np.mean(Mdl_Preds, axis=1), a_min = 1, a_max = 6),0)\nelse:\n    sub_fl[CFG.target] = np.round(np.clip(Mdl_Preds[\"Model0\"].values, a_min = 1, a_max = 6),0)\n\ndel Mdl_Preds, Xtest, models, drop_cols;\n_  = Utils.CleanMemory()\n\nprint(\"\\n\\n\")\ndisplay(sub_fl.head(10).style.format(precision = 2).set_caption(\"Submission file\"));\n\nsub_fl.to_csv(\"submission.csv\", index = None);\nprint();\n_  = Utils.CleanMemory()\n\n!ls",
   "metadata": {
    "papermill": {
     "duration": 2.520798,
     "end_time": "2024-04-25T15:20:59.211268",
     "exception": false,
     "start_time": "2024-04-25T15:20:56.69047",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2024-04-25T22:20:03.811257Z",
     "iopub.execute_input": "2024-04-25T22:20:03.811522Z",
     "iopub.status.idle": "2024-04-25T22:20:06.656796Z",
     "shell.execute_reply.started": "2024-04-25T22:20:03.8115Z",
     "shell.execute_reply": "2024-04-25T22:20:06.655492Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
