{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 71485,
     "databundleVersionId": 8059942,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30674,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# <center><span style=\"color: #00bfff; font-family: Arial, sans-serif;\">Welcome to my sanctuary</span></center>\n<div style=\"background-color: #f0e68c; padding: 20px; border-radius: 15px;\">\n<h2 style=\"color: #00008b; font-family: Arial, sans-serif;\">Thank you for exploring my notebook. Feel free to customize or fork it according to your requirements. Your feedback and support are highly valued.Stay Tunned for Next kernels</h2>\n</div>\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# [Learning Agency Lab Automated Essay Scoring 2.0 Competition](https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2)\n![Automatic Essay Checking with Machine Learning](https://th.bing.com/th/id/OIG1.hauKIGeSwYx8ZtIiz1Fo?pid=ImgGn)\n\n\n### Introduction\nThe Automated Essay Scoring (AES) competition aims to develop advanced algorithms for scoring student essays automatically. By automating this process, we can alleviate the burden on teachers and provide timely feedback to students, especially in underserved communities.\n\n### Background\nThe first AES competition took place twelve years ago, marking a significant milestone in the field. Since then, there have been notable advancements in technology and methodologies. However, challenges such as dataset limitations and algorithmic bias persist.\n\n### Objectives\n1. **Dataset Enhancement**: Prior competitions faced limitations due to small, non-diverse datasets. The current competition addresses this by providing a large, diverse dataset aligned with modern educational standards.\n  \n2. **Algorithm Improvement**: The goal is to surpass the performance of previous competitions, such as the Automated Student Assessment Prize (ASAP) competition held in 2012. This entails developing open-source scoring algorithms that are more accurate and efficient.\n\n### Competition Structure\n- **Host**: Vanderbilt University in collaboration with The Learning Agency Lab.\n  \n- **Timeline**: The competition runs from April 2, 2024, to July 2, 2024.\n  \n- **Evaluation Metric**: Submissions are scored based on the quadratic weighted kappa, which measures agreement between predicted and actual scores. The higher the kappa, the better the agreement.\n\n### Submission Requirements\n- **Code Competition**: Submissions must be made through Notebooks. \n- **Submission Format**: Each submission file must contain essay IDs and their corresponding predicted scores.\n- **Prizes**: Leaderboard prizes are awarded based on performance, while efficiency prizes focus on both runtime and predictive performance.\n  \n### Impact and Acknowledgments\n- **Impact**: Automated essay scoring can lead to more accessible educational tools and support for both students and educators.\n  \n- **Acknowledgments**: The competition organizers thank supporters like the Bill & Melinda Gates Foundation, Schmidt Futures, and Chan Zuckerberg Initiative for their contributions.\n\n> ### Notebook Objective:\nThis notebook focuses on utilizing simple ML libraries, FLAML for automated machine learning, and TF-IDF for text feature extraction. The goal is to efficiently conduct Exploratory Data Analysis (EDA) and build predictive models.\n\n### Methodology:\nWe'll start by exploring the dataset using pandas and matplotlib for EDA. Then, FLAML will be employed for automated model selection and hyperparameter tuning. Finally, TF-IDF will be utilized to extract features from text data.\n\n### Conclusion:\nBy integrating these techniques, we aim to streamline the data analysis process and develop accurate predictive models effectively.",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-06T01:37:49.657895Z",
     "iopub.execute_input": "2024-04-06T01:37:49.658579Z",
     "iopub.status.idle": "2024-04-06T01:37:49.671927Z",
     "shell.execute_reply.started": "2024-04-06T01:37:49.658547Z",
     "shell.execute_reply": "2024-04-06T01:37:49.670658Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": "---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "> # 1. Libraries",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import subprocess module to run shell commands\nimport subprocess\n\n# Define the pip install command for FLAML\ninstall_command = 'pip install flaml'\n\ntry:\n    # Use subprocess to run the pip install command\n    subprocess.run(install_command, shell=True, check=True)\n    print(\"FLAML installed successfully!\")\nexcept subprocess.CalledProcessError as e:\n    # If an error occurs, print the error message\n    print(f\"Error installing FLAML: {e}\")\n",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2024-04-06T20:01:36.834037Z",
     "iopub.execute_input": "2024-04-06T20:01:36.834739Z",
     "iopub.status.idle": "2024-04-06T20:01:49.069521Z",
     "shell.execute_reply.started": "2024-04-06T20:01:36.834707Z",
     "shell.execute_reply": "2024-04-06T20:01:49.068368Z"
    },
    "_kg_hide-input": true,
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#!pip install flaml\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time,os\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\nimport lightgbm as lgb\nfrom flaml import AutoML\nimport polars as pl\nimport nltk\nfrom nltk.corpus import stopwords\nimport warnings\nwarnings.filterwarnings('ignore')\n",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2024-04-06T19:43:54.121509Z",
     "iopub.execute_input": "2024-04-06T19:43:54.121898Z",
     "iopub.status.idle": "2024-04-06T19:44:02.606106Z",
     "shell.execute_reply.started": "2024-04-06T19:43:54.121866Z",
     "shell.execute_reply": "2024-04-06T19:44:02.605198Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "> # 2. Importing Datset",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Read train and test datasets\ntrain = pl.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv')\ntest = pl.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv')\nsubmission=pl.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv')\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-06T19:44:02.607669Z",
     "iopub.execute_input": "2024-04-06T19:44:02.607974Z",
     "iopub.status.idle": "2024-04-06T19:44:03.184314Z",
     "shell.execute_reply.started": "2024-04-06T19:44:02.607945Z",
     "shell.execute_reply": "2024-04-06T19:44:03.183513Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## `head & tail of dataset`",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Display the first few rows of each dataset\nprint(\"train:\")\nprint(train.head())\nprint(\"\\ntest :\")\nprint(test.head())\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-06T19:44:04.579229Z",
     "iopub.execute_input": "2024-04-06T19:44:04.580184Z",
     "iopub.status.idle": "2024-04-06T19:44:04.602939Z",
     "shell.execute_reply.started": "2024-04-06T19:44:04.580148Z",
     "shell.execute_reply": "2024-04-06T19:44:04.601813Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## `Length`",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print(len(train))\nprint(len(test))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-06T19:44:07.263879Z",
     "iopub.execute_input": "2024-04-06T19:44:07.264254Z",
     "iopub.status.idle": "2024-04-06T19:44:07.270008Z",
     "shell.execute_reply.started": "2024-04-06T19:44:07.264224Z",
     "shell.execute_reply": "2024-04-06T19:44:07.268823Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## `Summary`",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Summary statistics for numerical columns\nprint(\"\\nSummary statistics for train dataset:\")\nprint(train.describe())\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-06T19:44:09.230427Z",
     "iopub.execute_input": "2024-04-06T19:44:09.231227Z",
     "iopub.status.idle": "2024-04-06T19:44:09.289535Z",
     "shell.execute_reply.started": "2024-04-06T19:44:09.231192Z",
     "shell.execute_reply": "2024-04-06T19:44:09.288295Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(\"Summary statistics for test dataset :\")\nprint(test.describe())",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-06T19:44:13.792663Z",
     "iopub.execute_input": "2024-04-06T19:44:13.793101Z",
     "iopub.status.idle": "2024-04-06T19:44:13.800345Z",
     "shell.execute_reply.started": "2024-04-06T19:44:13.793066Z",
     "shell.execute_reply": "2024-04-06T19:44:13.799245Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "> # 4.Vectorization and LGBM\n- In this  uses TF-IDF vectorization to convert text data into numerical features. It then employs AutoML to find the best hyperparameters for LightGBM, a gradient boosting algorithm, and trains a model for text classification.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%time\n#This code hrlp from that notebook-->[https://www.kaggle.com/code/davidjlochner/base-tfidf-lgbm/notebook]\n# TF-IDF Vectorization\nvectorizer = TfidfVectorizer(min_df=.05)\ntrain_tfid = vectorizer.fit_transform(train['full_text'])\ntest_tfid = vectorizer.transform(test['full_text'])\n\ntrain_y = np.array(train['score'])\n\n# Initialize AutoML for hyperparameter optimization\naml = AutoML()\n\n# Fit AutoML to find the best hyperparameters\naml.fit(train_tfid, train_y, estimator_list=['lgbm'], task='classification', metric='macro_f1', time_budget=600)\n\n# Retrieve the best hyperparameters found by AutoML\nbest_config = aml.best_config\n\n# Initialize LGBMClassifier with the best hyperparameters found\nmodel = lgb.LGBMClassifier(**best_config)\n\n# Train the model\nmodel.fit(train_tfid, train_y)",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2024-04-06T19:44:18.185631Z",
     "iopub.execute_input": "2024-04-06T19:44:18.186035Z",
     "iopub.status.idle": "2024-04-06T19:54:49.058209Z",
     "shell.execute_reply.started": "2024-04-06T19:44:18.186003Z",
     "shell.execute_reply": "2024-04-06T19:54:49.057196Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "> # 5.Submission",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Predict scores for test data using the model\nsubmission = test.select('essay_id').with_columns(score=model.predict(test_tfid))\n\n# Display the submission data\ndisplay(submission)\n\n# Write the submission to a CSV file\nsubmission.write_csv('submission.csv')\n\n# Add insights\nprint(\"Submission generated successfully.\")\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-06T19:55:29.955054Z",
     "iopub.execute_input": "2024-04-06T19:55:29.955887Z",
     "iopub.status.idle": "2024-04-06T19:55:29.972733Z",
     "shell.execute_reply.started": "2024-04-06T19:55:29.95584Z",
     "shell.execute_reply": "2024-04-06T19:55:29.971704Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## ``In summary, continuous refinement of model parameters and exploration of advanced algorithms are pivotal for enhancing accuracy. Collaboration and knowledge-sharing within the community offer valuable insights for achieving breakthroughs. With each iteration, we propel forward, contributing to the evolution of machine learning capabilities.``",
   "metadata": {}
  }
 ]
}
