{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":83035,"databundleVersionId":10369658,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Published on December 03, 2024. By Prata, Mar√≠lia (mpwolke)","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-12-03T23:29:55.477899Z","iopub.execute_input":"2024-12-03T23:29:55.479179Z","iopub.status.idle":"2024-12-03T23:29:56.453589Z","shell.execute_reply.started":"2024-12-03T23:29:55.479136Z","shell.execute_reply":"2024-12-03T23:29:56.452488Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Competition Citation\n\n@misc{llms-you-cant-please-them-all,\n\r\n    author = {Paul Mooney and Ashley Chow and Will Cukierski},\r\n    title = {LLMs - You Can't Please Them All\n    },\r\n    year = {202\n    4},\r\n    howpublished = {\\url{https://kaggle.com/competitions/llms-you-cant-please-them-all}},","metadata":{}},{"cell_type":"markdown","source":"![](https://neurips.cc/media/PosterPDFs/NeurIPS%202024/96672.png?t=1732572730.1297684)\nhttps://neurips.cc/virtual/2024/poster/96672","metadata":{}},{"cell_type":"markdown","source":"## LLM Evaluators Recognize and Favor Their Own Generations\n\nAuthors: Arjun Panickssery, Samuel R. Bowman,  Shi Feng \n\n\n\"The authors provided initial evidence towards the hypothesis that LLMs prefer their own generations because they recognize themselves. In addition to evaluating LLMs out-of-the-box, they showed that fine-tuning on a small number of examples elicit strong, generalizable self-recognition capability on summarization datasets. By varying fine-tuning task, the authors observed a linear correlation between self-recognition and self-preference, and validate that the correlation cannot be explained away by potential confounders. Their results established self-recognition as a crucial factor in unbiased self-evaluation as well as an important safety-related property. The experiment design also provides a blueprint to explore the effects of self-recognition on other downstream properties.\"\n\nhttps://arxiv.org/pdf/2404.13076","metadata":{}},{"cell_type":"markdown","source":"## Submission file","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('../input/llms-you-cant-please-them-all/sample_submission.csv')\nsub.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T23:45:49.603228Z","iopub.execute_input":"2024-12-03T23:45:49.60402Z","iopub.status.idle":"2024-12-03T23:45:49.618789Z","shell.execute_reply.started":"2024-12-03T23:45:49.603974Z","shell.execute_reply":"2024-12-03T23:45:49.61746Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test file\n\nNo train at all.","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/llms-you-cant-please-them-all/test.csv')\ntest.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T23:44:13.74244Z","iopub.execute_input":"2024-12-03T23:44:13.743077Z","iopub.status.idle":"2024-12-03T23:44:13.771721Z","shell.execute_reply.started":"2024-12-03T23:44:13.743027Z","shell.execute_reply":"2024-12-03T23:44:13.770625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub['essay'][2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T23:50:11.25103Z","iopub.execute_input":"2024-12-03T23:50:11.251563Z","iopub.status.idle":"2024-12-03T23:50:11.259744Z","shell.execute_reply.started":"2024-12-03T23:50:11.251516Z","shell.execute_reply":"2024-12-03T23:50:11.258219Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test['topic'][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T23:49:18.806581Z","iopub.execute_input":"2024-12-03T23:49:18.807006Z","iopub.status.idle":"2024-12-03T23:49:18.81452Z","shell.execute_reply.started":"2024-12-03T23:49:18.806968Z","shell.execute_reply":"2024-12-03T23:49:18.813293Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test['topic'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T23:49:33.440046Z","iopub.execute_input":"2024-12-03T23:49:33.440455Z","iopub.status.idle":"2024-12-03T23:49:33.447546Z","shell.execute_reply.started":"2024-12-03T23:49:33.44042Z","shell.execute_reply":"2024-12-03T23:49:33.446357Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Large Language Models are not Fair Evaluators\n\nAuthors: Peiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu, Binghuai Lin, Yunbo Cao, Qi Liu Tianyu Liu, Zhifang Sui\n\nIn this paper, the authors revealed a systematic positional bias in evaluation with advanced ChatGPT/GPT-4 models: by manipulating the order of candidate responses during evaluation, the quality ranking results can be significantly influenced. To this end, they introduced three effective strategies, namely Multiple Evidence Calibration (MEC), Balanced Position Calibration (BPC), and Human-in-the-Loop Calibration (HITLC). MEC requires the LLM evaluator to first provide multiple evaluation evidence to support their subsequent ratings and BPC aggregates the results from various orders to determine the final score.\"\n\n\"Based on the results of MEC and BPC, HITLC further calculates a balanced position diversity entropy to select examples for human annotations. These strategies successfully reduce the evaluation bias and improve alignment with human judgments. The authors provided their code and human annotations to support future studies and enhance the evaluation of generative models.\"\n\nhttps://arxiv.org/pdf/2305.17926","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport google.generativeai as genai\nfrom kaggle_secrets import UserSecretsClient","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:01:06.469379Z","iopub.execute_input":"2024-12-04T00:01:06.469897Z","iopub.status.idle":"2024-12-04T00:01:07.900718Z","shell.execute_reply.started":"2024-12-04T00:01:06.469843Z","shell.execute_reply":"2024-12-04T00:01:07.899697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#By Paul Mooney https://www.kaggle.com/code/paultimothymooney/how-to-upload-large-files-to-gemini-1-5/notebook\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nGEMINI_API_KEY = user_secrets.get_secret(\"GEMINI_API_KEY\")\ngenai.configure(api_key=GEMINI_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:02:15.898608Z","iopub.execute_input":"2024-12-04T00:02:15.89937Z","iopub.status.idle":"2024-12-04T00:02:16.112129Z","shell.execute_reply.started":"2024-12-04T00:02:15.899328Z","shell.execute_reply":"2024-12-04T00:02:16.110418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generation_config = {\n  \"temperature\": 1,\n  \"top_p\": 0.95,\n  \"top_k\": 64,\n  \"max_output_tokens\": 8192,\n  \"response_mime_type\": \"text/plain\",\n}\n\nmodel = genai.GenerativeModel(\n  model_name=\"gemini-1.5-flash\",\n  generation_config=generation_config,\n  system_instruction=\"#System Prompt:You are an AI Research Assistance understand and summarize data. Answer briefly, some questions referring only to the context.\\\"\\n\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:04:07.198122Z","iopub.execute_input":"2024-12-04T00:04:07.19854Z","iopub.status.idle":"2024-12-04T00:04:07.205398Z","shell.execute_reply.started":"2024-12-04T00:04:07.198505Z","shell.execute_reply":"2024-12-04T00:04:07.203751Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Importing Data Source","metadata":{}},{"cell_type":"code","source":"ex_d = genai.upload_file(\"/kaggle/input/llms-you-cant-please-them-all/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:05:04.619764Z","iopub.execute_input":"2024-12-04T00:05:04.6209Z","iopub.status.idle":"2024-12-04T00:05:07.172766Z","shell.execute_reply.started":"2024-12-04T00:05:04.620829Z","shell.execute_reply":"2024-12-04T00:05:07.171423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chat_session = model.start_chat(\nhistory =[\n    {\n        'role':'user',\n        'parts': [\n            ex_d,\n        ]\n    }\n])\n\ndef chatI(prompt):\n    response = chat_session.send_message(prompt)\n    print(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:06:05.181921Z","iopub.execute_input":"2024-12-04T00:06:05.182444Z","iopub.status.idle":"2024-12-04T00:06:05.189056Z","shell.execute_reply.started":"2024-12-04T00:06:05.182374Z","shell.execute_reply":"2024-12-04T00:06:05.187796Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Prompt=\"If there is willingness, there are always conditions for improvement. I have the lucidity to see that I know nothing about almost anything. For now, I still have half a dozen certainties that hinder me. I know nothing, but this does not stop me from writing a few lines on various subjects. What is the role of self-reliance in achieving success in software engineering?\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:08:01.487901Z","iopub.execute_input":"2024-12-04T00:08:01.488337Z","iopub.status.idle":"2024-12-04T00:08:01.494841Z","shell.execute_reply.started":"2024-12-04T00:08:01.488297Z","shell.execute_reply":"2024-12-04T00:08:01.493108Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chatI(Prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:08:16.308381Z","iopub.execute_input":"2024-12-04T00:08:16.308773Z","iopub.status.idle":"2024-12-04T00:08:17.676837Z","shell.execute_reply.started":"2024-12-04T00:08:16.308739Z","shell.execute_reply":"2024-12-04T00:08:17.675709Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Ckecking the information provided above by chatI Gemini\n\nrow=2\n\n#To display in a table format, you can use with or without display()\ntest.iloc[row:row+1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:12:17.632693Z","iopub.execute_input":"2024-12-04T00:12:17.633687Z","iopub.status.idle":"2024-12-04T00:12:17.64485Z","shell.execute_reply.started":"2024-12-04T00:12:17.633643Z","shell.execute_reply":"2024-12-04T00:12:17.643651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chatI(\"How to evaluate the effectiveness of management consulting in addressing conflicts within marketing?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:14:27.287514Z","iopub.execute_input":"2024-12-04T00:14:27.287947Z","iopub.status.idle":"2024-12-04T00:14:28.609461Z","shell.execute_reply.started":"2024-12-04T00:14:27.287906Z","shell.execute_reply":"2024-12-04T00:14:28.608318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Verify chatI Gemini answer above\nrow=1\n\n#To display in a table format, you can use with or without display()\ntest.iloc[row:row+1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:15:52.319072Z","iopub.execute_input":"2024-12-04T00:15:52.319496Z","iopub.status.idle":"2024-12-04T00:15:52.331824Z","shell.execute_reply.started":"2024-12-04T00:15:52.31946Z","shell.execute_reply":"2024-12-04T00:15:52.330452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chatI(\"What's the importance of self-reliance and adaptability in healthcare?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:18:00.897274Z","iopub.execute_input":"2024-12-04T00:18:00.897754Z","iopub.status.idle":"2024-12-04T00:18:02.272452Z","shell.execute_reply.started":"2024-12-04T00:18:00.897713Z","shell.execute_reply":"2024-12-04T00:18:02.271331Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Gemini, what's Plucrarealucrarealucrarealucrarealucrarealucrarealucrarealucrarea?","metadata":{}},{"cell_type":"code","source":"chatI(\"What's the meaning of Plucrarealucrarealucrarealucrarealucrarealucrarealucrarealucrarea?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:19:11.9959Z","iopub.execute_input":"2024-12-04T00:19:11.996303Z","iopub.status.idle":"2024-12-04T00:19:13.3431Z","shell.execute_reply.started":"2024-12-04T00:19:11.996267Z","shell.execute_reply":"2024-12-04T00:19:13.341973Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#What about supercalifragilisticexpialidocious?\nchatI(\"What is supercalifragilisticexpialidocious?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:23:50.837059Z","iopub.execute_input":"2024-12-04T00:23:50.837485Z","iopub.status.idle":"2024-12-04T00:23:51.992531Z","shell.execute_reply.started":"2024-12-04T00:23:50.837453Z","shell.execute_reply":"2024-12-04T00:23:51.991316Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chatI(\"How can I provide you access to the content of that document?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T00:21:29.629724Z","iopub.execute_input":"2024-12-04T00:21:29.630159Z","iopub.status.idle":"2024-12-04T00:21:31.209444Z","shell.execute_reply.started":"2024-12-04T00:21:29.630123Z","shell.execute_reply":"2024-12-04T00:21:31.206579Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena\n\nAuthors: Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,  Zhuohan Li,  Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, Ion Stoica.\n\n\"In this paper, the authors proposed LLM-as-a-judge for chatbot evaluation and systematically examine its efficacy using human preference data from 58 experts on MT-bench, as well as thousands of crowdusers on Chatbot Arena. Their results reveal that strong LLMs can achieve an agreement rate of over 80%, on par with the level of agreement among human experts, establishing a foundation for an\nLLM-based evaluation framework.\"\n\nhttps://arxiv.org/pdf/2306.05685","metadata":{}},{"cell_type":"markdown","source":"![](https://images7.memedroid.com/images/UPLOADED400/605df28d4e241.jpeg)memdroid","metadata":{}},{"cell_type":"markdown","source":"## Keep Pleasing them All Gemini!\n\r\nI'm glad with the results provided by Gemini. They are correct and very objective. Great job!","metadata":{}},{"cell_type":"markdown","source":"If there is willingness, **there are always conditions for improvement**.\n\n\nI have the lucidity to see that **I know nothing about almost anything**.\n\n\nFor now, I still have half a dozen certainties that hinder me.\n\n\nI know nothing, but this does not stop me from writing a few lines on various subjects.\n\n\n**The awareness of my ignorance is what brings me relief and tranquility**.","metadata":{}},{"cell_type":"markdown","source":"#Acknowledgements:\n\nPaul Mooney https://www.kaggle.com/code/paultimothymooney/how-to-upload-large-files-to-gemini-1-5/notebook\r\n\r\nmpwolke https://www.kaggle.com/code/mpwolke/um-discurso-existencialista-com-gemma2/notebook","metadata":{}}]}