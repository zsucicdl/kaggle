{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":83035,"databundleVersionId":10369658,"sourceType":"competition"},{"sourceId":203811899,"sourceType":"kernelVersion"},{"sourceId":28808,"sourceType":"modelInstanceVersion","modelInstanceId":8332,"modelId":3301},{"sourceId":118192,"sourceType":"modelInstanceVersion","modelInstanceId":99392,"modelId":123481},{"sourceId":120005,"sourceType":"modelInstanceVersion","modelInstanceId":100936,"modelId":121027}],"dockerImageVersionId":30805,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Credits-\n### - @richolson for vLLM 0.6.3 utility script\n### - @takanashihumbert for Qwen2.5-32B-awq model","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\n### change MODEL PATH here\nos.environ['llm_path'] = '/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1'\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nIS_SUBMISSION = bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T06:39:16.183086Z","iopub.execute_input":"2024-12-04T06:39:16.183502Z","iopub.status.idle":"2024-12-04T06:39:17.891711Z","shell.execute_reply.started":"2024-12-04T06:39:16.183472Z","shell.execute_reply":"2024-12-04T06:39:17.890753Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/llms-you-cant-please-them-all/test.csv')\ndf.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T06:39:17.893034Z","iopub.execute_input":"2024-12-04T06:39:17.893878Z","iopub.status.idle":"2024-12-04T06:39:17.917477Z","shell.execute_reply.started":"2024-12-04T06:39:17.893846Z","shell.execute_reply":"2024-12-04T06:39:17.916528Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile run_vllm.py\n\nimport sys\nimport re\nimport gc\nimport vllm\nprint('vllm version=',vllm.__version__)\nimport pandas as pd\nimport os\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n\ndf = pd.read_csv('/kaggle/input/llms-you-cant-please-them-all/test.csv')\n\nllm = vllm.LLM(model=os.getenv(\"llm_path\"),\n          dtype='half',\n          enforce_eager=True,\n          gpu_memory_utilization=0.98,\n          max_model_len=1024,\n          tensor_parallel_size=2,\n          trust_remote_code=True)\ntokenizer = llm.get_tokenizer()\n\ndef apply_template(topic, tokenizer):\n    messages = [\n        {\"role\": \"system\", \n         \"content\": '''You are an expert essay writer. Write a comprehensive essay on the given topic.\nIMPORTANT: Limit the essay to approximately 100-150 words.'''\n        },\n        {\n            \"role\": \"user\", \n            \"content\": topic\n        }\n    ]\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    return text\n\ndf[\"topic\"] = df['topic'].apply(lambda x: apply_template(x, tokenizer))\nprint('Example input-\\n',df[\"topic\"][0])\n\nresponses = llm.generate(\n    df[\"topic\"].values,\n    vllm.SamplingParams(\n        n=1,  # Number of output sequences to return for each prompt.\n        top_p=0.9,  # Float that controls the cumulative probability of the top tokens to consider.\n        temperature=0.7,  # randomness of the sampling\n        seed=777, # Seed for reprodicibility\n        skip_special_tokens=False,  # Whether to skip special tokens in the output.\n        max_tokens=199,  # Maximum number of tokens to generate per output sequence.\n    ),\n    use_tqdm = True\n)\n\ndf[\"essay\"] = [x.outputs[0].text for x in responses]\ndf.to_csv(\"submission.csv\", columns=[\"id\", \"essay\"], index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T06:39:17.918662Z","iopub.execute_input":"2024-12-04T06:39:17.919051Z","iopub.status.idle":"2024-12-04T06:39:17.926551Z","shell.execute_reply.started":"2024-12-04T06:39:17.91901Z","shell.execute_reply":"2024-12-04T06:39:17.925548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python run_vllm.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T06:39:17.927797Z","iopub.execute_input":"2024-12-04T06:39:17.928149Z","iopub.status.idle":"2024-12-04T06:41:39.511269Z","shell.execute_reply.started":"2024-12-04T06:39:17.928107Z","shell.execute_reply":"2024-12-04T06:41:39.51013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('submission.csv')\ndf.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T06:41:39.512866Z","iopub.execute_input":"2024-12-04T06:41:39.513309Z","iopub.status.idle":"2024-12-04T06:41:39.522721Z","shell.execute_reply.started":"2024-12-04T06:41:39.513263Z","shell.execute_reply":"2024-12-04T06:41:39.521865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}