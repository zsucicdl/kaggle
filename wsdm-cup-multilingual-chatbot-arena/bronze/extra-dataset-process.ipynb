{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"},{"sourceId":86946,"databundleVersionId":10131489,"sourceType":"competition"},{"sourceId":8297557,"sourceType":"datasetVersion","datasetId":4927617},{"sourceId":8377405,"sourceType":"datasetVersion","datasetId":4959805}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-17T06:36:39.992167Z","iopub.execute_input":"2024-12-17T06:36:39.992684Z","iopub.status.idle":"2024-12-17T06:36:41.506679Z","shell.execute_reply.started":"2024-12-17T06:36:39.992641Z","shell.execute_reply":"2024-12-17T06:36:41.505508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_wsdm = pd.read_parquet(\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet\")\nprint(df_wsdm.shape)\ndf_wsdm.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T06:36:41.50893Z","iopub.execute_input":"2024-12-17T06:36:41.509484Z","iopub.status.idle":"2024-12-17T06:36:45.107737Z","shell.execute_reply.started":"2024-12-17T06:36:41.509448Z","shell.execute_reply":"2024-12-17T06:36:45.106338Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### LMSYS 57k","metadata":{}},{"cell_type":"code","source":"df_lmsys = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\nprint(df_lmsys.shape)\nimport pandas as pd\nimport json\n\ndef process_lmsys_df(df_lmsys):\n    for col in [\"prompt\", \"response_a\", \"response_b\"]:\n        df_lmsys[col] = df_lmsys[col].apply(lambda x: json.loads(x))\n    df_lmsys[\"winner\"] = df_lmsys[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values.argmax(axis=1)\n    df_lmsys[\"turn\"] = df_lmsys[\"prompt\"].apply(lambda x: len(x))\n    df_lmsys.drop(columns=[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"], inplace=True)\n    for col in [\"prompt\", \"response_a\", \"response_b\"]:\n        df_lmsys[col] = df_lmsys[col].apply(lambda x: \" \".join([i for i in x if i is not None]))\n    df_lmsys = df_lmsys[df_lmsys[\"winner\"] != 2].copy()\n    df_lmsys[\"winner\"] = df_lmsys[\"winner\"].apply(lambda x: \"model_a\" if x == 0 else \"model_b\")\n    return df_lmsys\ndf_lmsys = process_lmsys_df(df_lmsys)\nprint(df_lmsys.shape)\ndf_lmsys.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T06:43:20.161599Z","iopub.execute_input":"2024-12-17T06:43:20.161981Z","iopub.status.idle":"2024-12-17T06:43:26.312751Z","shell.execute_reply.started":"2024-12-17T06:43:20.161953Z","shell.execute_reply":"2024-12-17T06:43:26.311618Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### UT 157k","metadata":{}},{"cell_type":"code","source":"df_ut = pd.read_parquet(\"/kaggle/input/llm-human-preference-data-ultrafeedback/ultrafeedback.parquet\")\nprint(df_ut.shape)\ndf_ut.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:12:29.952762Z","iopub.execute_input":"2024-12-17T07:12:29.953164Z","iopub.status.idle":"2024-12-17T07:12:32.360637Z","shell.execute_reply.started":"2024-12-17T07:12:29.953136Z","shell.execute_reply":"2024-12-17T07:12:32.359251Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Chosen-rating distribution:\")\nprint(df_ut[\"chosen-rating\"].value_counts())\nprint(\"\\nRejected-rating distribution:\")\nprint(df_ut[\"rejected-rating\"].value_counts())\ndf_ut[\"chosen-rating-rejected-rating\"] = df_ut[\"chosen-rating\"]-df_ut[\"rejected-rating\"]\nprint(df_ut[\"chosen-rating-rejected-rating\"].value_counts())\nprint(df_ut[\"chosen-rating-rejected-rating\"].mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:12:32.362105Z","iopub.execute_input":"2024-12-17T07:12:32.362416Z","iopub.status.idle":"2024-12-17T07:12:32.384551Z","shell.execute_reply.started":"2024-12-17T07:12:32.362392Z","shell.execute_reply":"2024-12-17T07:12:32.38328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_ut = pd.read_parquet(\"/kaggle/input/llm-human-preference-data-ultrafeedback/ultrafeedback.parquet\")\nprint(df_ut.shape)\n\nrandom.seed(0)\ndef process_ut_df(df_ut):\n    labels, texts = [], []\n    for _, row in tqdm(df_ut.iterrows() ,total=len(df_ut)):\n\n        if not (\n            (row[\"chosen-rating\"] - row[\"rejected-rating\"] >= 1.50)\n        ):\n            continue  \n        chosen = row[\"chosen\"]\n        rejected = row[\"rejected\"]\n        assert len(chosen) == 2\n        assert len(rejected) == 2\n        assert rejected[0] == chosen[0]\n        \n        prompt = chosen[0]['content']\n        response_a = chosen[1][\"content\"]\n        response_b = rejected[1][\"content\"]\n        model_a = row[\"chosen-model\"]\n        model_b = row[\"rejected-model\"]\n        \n        if random.random() > 0.5:\n            winner=\"model_a\"\n        else:\n            winner=\"model_b\"\n            response_a, response_b = response_b, response_a\n            model_a, model_b = model_b, model_a\n\n        labels.append(winner)\n        texts.append((model_a, model_b, prompt, response_a, response_b))\n    labels_df = pd.DataFrame(labels, columns=[\"winner\"])\n    texts_df = pd.DataFrame(texts, columns=[\"model_a\", \"model_b\", \"prompt\", \"response_a\", \"response_b\"]).astype(str)\n    merge_df = pd.concat([texts_df, labels_df], axis=1)\n    merge_df[\"id\"] = [f\"ultrachat_{i:05}\" for i in range(len(merge_df))]\n    merge_df[\"turn\"]=1\n    return merge_df\n    \ndf_ut = process_ut_df(df_ut)\nprint(df_ut.shape)\ndf_ut.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:12:32.542756Z","iopub.execute_input":"2024-12-17T07:12:32.543132Z","iopub.status.idle":"2024-12-17T07:12:44.991255Z","shell.execute_reply.started":"2024-12-17T07:12:32.543105Z","shell.execute_reply":"2024-12-17T07:12:44.990106Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### additional-33k-labelled-conversations","metadata":{}},{"cell_type":"code","source":"df_add = pd.read_csv(\"/kaggle/input/lmsys-additional-33k-labelled-conversations/lmsys-33k.csv\")\nprint(df_add.shape)\ndf_add = process_lmsys_df(df_add)\nprint(df_add.shape)\ndf_add.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:12:47.633636Z","iopub.execute_input":"2024-12-17T07:12:47.634054Z","iopub.status.idle":"2024-12-17T07:12:49.273299Z","shell.execute_reply.started":"2024-12-17T07:12:47.634017Z","shell.execute_reply":"2024-12-17T07:12:49.271997Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### orpo-dpo-mix-40k","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset('mlabonne/orpo-dpo-mix-40k', split='train')\ndf_dpo = dataset.to_pandas()\nprint(df_dpo.shape)\ndf_dpo.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:12:57.410634Z","iopub.execute_input":"2024-12-17T07:12:57.411241Z","iopub.status.idle":"2024-12-17T07:13:06.695598Z","shell.execute_reply.started":"2024-12-17T07:12:57.411158Z","shell.execute_reply":"2024-12-17T07:13:06.694119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_dpo_df(df_ut):\n    labels, texts = [], []\n    for _, row in tqdm(df_ut.iterrows() ,total=len(df_ut)):\n        chosen = row[\"chosen\"]\n        rejected = row[\"rejected\"]\n        \n        assert len(chosen) == len(rejected)\n    \n        prompt = [i['content'] for i in chosen if i[\"role\"]==\"user\"]\n        response_a = [i['content'] for i in chosen if i[\"role\"]==\"assistant\"]\n        response_b = [i['content'] for i in rejected if i[\"role\"]==\"assistant\"]\n        model_a = \"unknown\"\n        model_b = \"unknown\"\n        \n        if random.random() > 0.5:\n            winner=\"model_a\"\n        else:\n            winner=\"model_b\"\n            response_a, response_b = response_b, response_a\n            model_a, model_b = model_b, model_a\n\n        labels.append(winner)\n        texts.append((model_a, model_b, prompt, response_a, response_b))\n    labels_df = pd.DataFrame(labels, columns=[\"winner\"])\n    texts_df = pd.DataFrame(texts, columns=[\"model_a\", \"model_b\", \"prompt\", \"response_a\", \"response_b\"])\n    merge_df = pd.concat([texts_df, labels_df], axis=1)\n    merge_df[\"id\"] = [f\"orpo-dpo-mix_{i:05}\" for i in range(len(merge_df))]\n    merge_df[\"turn\"] = merge_df[\"prompt\"].apply(lambda x: len(x))\n    for col in [\"prompt\", \"response_a\", \"response_b\"]:\n        merge_df[col] = merge_df[col].apply(lambda x: \" \".join([i for i in x if i is not None]))\n    return merge_df\n    \ndf_dpo = process_dpo_df(df_dpo)\nprint(df_dpo)\ndf_dpo.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:13:09.571448Z","iopub.execute_input":"2024-12-17T07:13:09.572043Z","iopub.status.idle":"2024-12-17T07:13:13.123607Z","shell.execute_reply.started":"2024-12-17T07:13:09.572011Z","shell.execute_reply":"2024-12-17T07:13:13.122193Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Filtering Data","metadata":{}},{"cell_type":"code","source":"# df_ut.to_parquet(\"ut_157k.parquet\", index=False)\n# df_add.to_parquet(\"lmsys_39k.parquet\", index=False)\n# df_add.to_parquet(\"add_23k.parquet\", index=False)\n# df_dpo.to_parquet(\"dpo_44k.parquet\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:37:12.667522Z","iopub.execute_input":"2024-12-11T15:37:12.667879Z","iopub.status.idle":"2024-12-11T15:37:18.037188Z","shell.execute_reply.started":"2024-12-11T15:37:12.667824Z","shell.execute_reply":"2024-12-11T15:37:18.035976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_lmsys = df_lmsys.copy()\ndf_add = df_add.copy()\ndf_ut = df_ut.copy()\ndf_dpo = df_dpo.copy()\ndf_lmsys['id'] = ['lmsys_' + str(i) for i in range(1, len(df_lmsys) + 1)]\ndf_add['id'] = ['add_' + str(i) for i in range(1, len(df_add) + 1)]\ndf_ut['id'] = ['ut_' + str(i) for i in range(1, len(df_ut) + 1)]\ndf_dpo['id'] = ['dpo_' + str(i) for i in range(1, len(df_dpo) + 1)]\n\nsuperset = pd.concat([df_lmsys, df_add, df_ut, df_dpo]).reset_index(drop=True)\nprint(len(superset))\nsuperset = superset.drop_duplicates(subset=['prompt', 'response_a', 'response_b',], keep='last').reset_index(drop=True)\nprint(len(superset))\nsuperset.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T08:15:34.631826Z","iopub.execute_input":"2024-12-17T08:15:34.632252Z","iopub.status.idle":"2024-12-17T08:15:36.373854Z","shell.execute_reply.started":"2024-12-17T08:15:34.632224Z","shell.execute_reply":"2024-12-17T08:15:36.372384Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# 1. 计算每行的长度（prompt, response_a, response_b 总长度）\nsuperset['total_length'] = superset['prompt'].apply(len) + superset['response_a'].apply(len) + superset['response_b'].apply(len)\n\n# 2. 随机打乱数据\nsuperset = superset.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# 3. 分配 batch，确保无数据丢失\nbatch_size = 32  # 设置 batch 大小\n\n# 按 total_length 对数据排序\nsuperset = superset.sort_values(by='total_length').reset_index(drop=True)\n\n# 4. 创建批次\nbatches = []\nnum_batches = len(superset) // batch_size\n\nfor i in range(num_batches):\n    batch = superset.iloc[i * batch_size: (i + 1) * batch_size]\n    batches.append(batch)\n\n# 处理剩余数据（直接追加）\nremaining_data = superset.iloc[num_batches * batch_size:]\nif not remaining_data.empty:\n    print(f\"Adding {len(remaining_data)} remaining rows to the final dataset.\")\n    batches.append(remaining_data)\n\n# 5. 合并所有批次并打乱\nbalanced_superset = pd.concat(batches, ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n\n# 6. 打印结果\nprint(f\"Original length: {len(superset)}\")\nprint(f\"Balanced length: {len(balanced_superset)}\")\nbalanced_superset.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T08:15:36.737238Z","iopub.execute_input":"2024-12-17T08:15:36.73769Z","iopub.status.idle":"2024-12-17T08:15:37.834831Z","shell.execute_reply.started":"2024-12-17T08:15:36.737657Z","shell.execute_reply":"2024-12-17T08:15:37.833698Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# 1. 画出 total_length 的趋势图\nplt.figure(figsize=(12, 6))\nplt.plot(balanced_superset.index, balanced_superset['total_length'], color='blue', linewidth=1)\n\n# 2. 添加标题和标签\nplt.title(\"Trend of Total Length in Balanced Superset\", fontsize=14)\nplt.xlabel(\"Index\", fontsize=12)\nplt.ylabel(\"Total Length\", fontsize=12)\n\n# 3. 显示网格\nplt.grid(True)\n\n# 4. 显示图表\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T08:15:50.03564Z","iopub.execute_input":"2024-12-17T08:15:50.036042Z","iopub.status.idle":"2024-12-17T08:15:50.576407Z","shell.execute_reply.started":"2024-12-17T08:15:50.036013Z","shell.execute_reply":"2024-12-17T08:15:50.575105Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"balanced_superset['id'] = balanced_superset['id'].astype(str)\nbalanced_superset = balanced_superset.drop(columns=['total_length'])\nbalanced_superset.to_parquet(\"all_extra_161k.parquet\", index=None)\nbalanced_superset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T08:17:17.716605Z","iopub.execute_input":"2024-12-17T08:17:17.717876Z","iopub.status.idle":"2024-12-17T08:17:22.557776Z","shell.execute_reply.started":"2024-12-17T08:17:17.717836Z","shell.execute_reply":"2024-12-17T08:17:22.556442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print((superset['winner'] == 'model_a').sum())\nprint((superset['winner'] == 'model_b').sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T08:17:29.757181Z","iopub.execute_input":"2024-12-17T08:17:29.75761Z","iopub.status.idle":"2024-12-17T08:17:29.794972Z","shell.execute_reply.started":"2024-12-17T08:17:29.757577Z","shell.execute_reply":"2024-12-17T08:17:29.793593Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T15:37:23.747868Z","iopub.status.idle":"2024-12-11T15:37:23.748321Z","shell.execute_reply.started":"2024-12-11T15:37:23.74811Z","shell.execute_reply":"2024-12-11T15:37:23.748133Z"}},"outputs":[],"execution_count":null}]}