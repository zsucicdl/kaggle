{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86946,"databundleVersionId":10131489,"sourceType":"competition"},{"sourceId":8218776,"sourceType":"datasetVersion","datasetId":4871830},{"sourceId":9948011,"sourceType":"datasetVersion","datasetId":6117312},{"sourceId":210357319,"sourceType":"kernelVersion"},{"sourceId":120005,"sourceType":"modelInstanceVersion","modelInstanceId":100936,"modelId":121027},{"sourceId":154590,"sourceType":"modelInstanceVersion","modelInstanceId":131339,"modelId":154149},{"sourceId":188115,"sourceType":"modelInstanceVersion","modelInstanceId":160376,"modelId":182744},{"sourceId":188158,"sourceType":"modelInstanceVersion","modelInstanceId":160415,"modelId":182769},{"sourceId":191689,"sourceType":"modelInstanceVersion","modelInstanceId":163393,"modelId":185749}],"dockerImageVersionId":30805,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%writefile install_packages.py\n\ndef install_packages():\n  import os\n  os.system('pip uninstall -y torch')\n  os.system('pip uninstall -y torchvision')\n  os.system('pip install -q --no-index --find-links=/kaggle/input/0-6-3-post1-wheels-vllm vllm')\n  os.system('pip install -q --no-index -U --upgrade /kaggle/input/vllm-t4-fix/grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl')\n  os.system('pip install -q --no-index -U --upgrade /kaggle/input/vllm-t4-fix/ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl')\n  os.system('pip uninstall -y pynvml')\n  os.system('pip install --no-deps --no-index /kaggle/input/0-6-3-post1-wheels-vllm/nvidia_ml_py-12.560.30-py3-none-any.whl')\n  os.system('pip install --no-deps --no-index /kaggle/input/logits-processor-zoo/logits_processor_zoo-0.1.0-py3-none-any.whl')\n\ninstall_packages()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:27:28.087417Z","iopub.execute_input":"2024-12-16T20:27:28.087915Z","iopub.status.idle":"2024-12-16T20:27:28.127336Z","shell.execute_reply.started":"2024-12-16T20:27:28.087843Z","shell.execute_reply":"2024-12-16T20:27:28.126285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n    import vllm\n    print('vllm version=',vllm.__version__)\nexcept ImportError:\n    print('Installing packages')\n    !python install_packages.py\n    import vllm\n    print('----'*10,'\\nvllm version=',vllm.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:27:28.128879Z","iopub.execute_input":"2024-12-16T20:27:28.129266Z","iopub.status.idle":"2024-12-16T20:30:17.953526Z","shell.execute_reply.started":"2024-12-16T20:27:28.12918Z","shell.execute_reply":"2024-12-16T20:30:17.95261Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"model_path\"] = \"/kaggle/input/qwen2.5-14b-instruct-gptq-int8/transformers/default/1\"\n\nIS_SUBMISSION = bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\n\nrun_eval = True ## To check score on train data- 100 samples","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:30:17.954786Z","iopub.execute_input":"2024-12-16T20:30:17.955409Z","iopub.status.idle":"2024-12-16T20:30:17.960276Z","shell.execute_reply.started":"2024-12-16T20:30:17.955369Z","shell.execute_reply":"2024-12-16T20:30:17.959273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile run_vllm.py\n\nimport sys\nimport re\nimport gc\nimport vllm\nimport pandas as pd\nimport os\nfrom transformers import AutoTokenizer, AutoModel\nfrom logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n\n\nIS_SUBMISSION = bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n\nif IS_SUBMISSION:\n    df = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet')\nelse:\n    df = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet')\n    df = df.sample(100, random_state=42).reset_index(drop=True).copy()\n    df['winner_GT'] = df['winner']\n    print('Length of df=',len(df))\n\ndef apply_template(row, tokenizer):\n    messages = [\n        {\"role\": \"system\", \n         \"content\": '''You are a highly skilled judge tasked with selecting the best response to a given query.\n\nInput Format:\n<Query>\n[The question that needs to be answered.]\n</Query>\n\n<Response_A> \n[The response from the first candidate.]\n</Response_A>\n\n<Response_B>\n[The response from the second candidate.]\n</Response_B>\n\nYour Task:\nCarefully analyze both <Response_A> and <Response_B> in relation to the Query.\nDetermine which response provides a better answer based on:\n- Helpfulness\n- Accuracy\n- Relevance\n\nOutput:\nRespond with only a single letter:\n- A if <Response_A> is better.\n- B if <Response_B> is better.\n\nImportant Notes:\n- Provide only the letter A or B as your response.\n- No explanations are needed.'''\n        },\n        {\n            \"role\": \"user\", \n            \"content\": f'''Here is your input to process now-\n\n<Query>\n{row['prompt']}\n</Query>\n{'---'*10}\n<Response_A>\n{row['response_a']}\n</Response_A>\n{'---'*10}\n<Response_B>\n{row['response_b']}\n</Response_B>\n'''\n        }\n    ]\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    return text+' Choice: '\n\ndef winner(x):\n    return f'model_{x.lower()}'\n\n\nmodel_path = os.getenv('model_path')\nif model_path in ['/kaggle/input/meta-llama-3.3-70b/transformers/ibnzterrell-instruct-awq-int4/1',\n                  '/kaggle/input/qwen-72b-gptq-int4/transformers/qwen2.5-72b-instruct-gptq-int4/1']:\n    print(\"Offload needed\")\n    offload = 8.5\n    swap = 1\n    max_len = 4000\n    num_seqs = 35\nelse:\n    offload = 0\n    swap = 5\n    max_len = 10000\n    num_seqs = 256\n\n\nllm = vllm.LLM(model=model_path,\n    tensor_parallel_size= 2,\n    gpu_memory_utilization= 0.99, \n    trust_remote_code= True,\n    dtype= \"half\",\n    enforce_eager= True,\n    max_model_len= max_len,\n    disable_log_stats= True,\n    cpu_offload_gb= offload,\n    swap_space= swap,\n    device= 'cuda',\n    max_num_seqs= num_seqs,\n    enable_prefix_caching= True,\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\ndf[\"text\"] = df.apply(lambda row: apply_template(row, tokenizer),axis=1)\n\ndef tok_len(txt):\n    return len(tokenizer.encode(txt))\n\ndf['token_length'] = df['text'].apply(tok_len)\n\nprint(\"Stats of df\",df['token_length'].describe())\nprint('Example input-\\n',df[\"text\"][0])\n\nresponses = llm.generate(\n        df[\"text\"].values,\n        vllm.SamplingParams(\n            n=1,  \n            top_k=1,  \n            temperature=0,  \n            seed=777, \n            skip_special_tokens=False, \n            max_tokens=1, \n            logits_processors=[MultipleChoiceLogitsProcessor(tokenizer, choices=[\"A\",\"B\"])]\n        ),\n        use_tqdm=True\n    )\nprint('Raw responses: ',[x.outputs[0].text for x in responses])\ndf[\"winner\"] = [winner(x.outputs[0].text) for x in responses]\n\nif IS_SUBMISSION:\n    df.to_csv(\"submission.csv\", columns=[\"id\", \"winner\"], index=False)\nelse:\n    df.to_csv(\"submission.csv\", columns=[\"id\", \"winner\", \"winner_GT\"], index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:30:17.962586Z","iopub.execute_input":"2024-12-16T20:30:17.962957Z","iopub.status.idle":"2024-12-16T20:30:18.021388Z","shell.execute_reply.started":"2024-12-16T20:30:17.962912Z","shell.execute_reply":"2024-12-16T20:30:18.020443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if IS_SUBMISSION or run_eval:\n    !python run_vllm.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:30:18.022386Z","iopub.execute_input":"2024-12-16T20:30:18.022626Z","iopub.status.idle":"2024-12-16T20:35:40.261423Z","shell.execute_reply.started":"2024-12-16T20:30:18.022602Z","shell.execute_reply":"2024-12-16T20:35:40.26028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if not IS_SUBMISSION and run_eval:\n    df = pd.read_csv('submission.csv')\n    correct_preds = (df['winner'] == df['winner_GT']).sum()\n    total_preds = len(df)\n    acc = correct_preds / total_preds\n    \n    print(f\"Accuracy: {acc}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:35:40.26307Z","iopub.execute_input":"2024-12-16T20:35:40.263506Z","iopub.status.idle":"2024-12-16T20:35:40.27898Z","shell.execute_reply.started":"2024-12-16T20:35:40.263463Z","shell.execute_reply":"2024-12-16T20:35:40.278259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}