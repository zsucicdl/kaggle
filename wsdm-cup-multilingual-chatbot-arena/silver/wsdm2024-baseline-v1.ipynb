{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86946,"databundleVersionId":10131489,"sourceType":"competition"},{"sourceId":208401434,"sourceType":"kernelVersion"}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **FOREWORD**","metadata":{}},{"cell_type":"markdown","source":"This kernel is a second part to my [ML baseline public materials](https://www.kaggle.com/code/ravi20076/playgrounds4e11-imports-v1). My older kernel for Baseline models became a bit clunky and needed revision. <br>\nThis kernel is divided into 2 parts with scripts- <br>\n1. Utility script with relevant imports, package installations and model training script for all types of Playground assignments <br>\n2. Model kernel using the previous step as imported script and execution of the model <br>\n\nI wish to extend sincere thanks to the Kaggle community for the long standing support over the years! Thanks for all the feedback on my kernels and many thanks for your collective generosity!\n\n### **WHAT IS DIFFERENT HERE** <br>\n1. Usage of a utility script for imports and a general training class for all types of Playground datasets with(out) the original data <br>\n2. Common training class for regression, multiclass and binary problems <br>\n3. Ability to train single models one at a time <br>\n4. Ability to enter a pipeline object instead of a model object for training <br>\n5. Separate ensemble with facility for Optuna blending with normalised weights as output. User has full choice to implement his/ her ensemble method <br>\n6. Ability to skip early stopping if needed in the pipeline <br> \n7. Compatible with any scikit-learn model/ classical ML model <br>\n8. Ability to perform online full fit <br>\n9. Can be used for code competitions as well, returns fitted models as one of the outputs <br>\n10. Ability to load the dataset as per the choice of original dataset included/ excluded in the CV scheme <br>\n","metadata":{}},{"cell_type":"markdown","source":"### **COMPETITION AND DATASET DETAILS** <br>\n\nThis is a binary classifier for the [WSDM Cup - Multilingual Chatbot Arena](https://www.kaggle.com/competitions/wsdm-cup-multilingual-chatbot-arena) competition. <br> **Binary accuracy score** is the evaluation metric and needs to be maximized <br>\n\nIn this baseline kernel, I start off with simple feature engneering and ML models to initiate the process. Let's delve deeper into the challenge as we move along and improve the process! <br>\n\n### **REFERENCE**\n1. https://www.kaggle.com/code/pietromaldini1/multilingual-chatbot-arena-challenge-baseline\n2. https://www.kaggle.com/code/jiaoyouzhang/wsdm-tfidfvectorizer-lightgbm\n\nAll the best!","metadata":{}},{"cell_type":"markdown","source":"# **IMPORTS**","metadata":{}},{"cell_type":"code","source":"%%time\n\n!pip install -q lightgbm==4.5.0     --no-index --find-links=/kaggle/input/wsdm2024-public-imports-v1/packages\n!pip install -q scikit-learn==1.5.2 --no-index --find-links=/kaggle/input/wsdm2024-public-imports-v1/packages\n!pip install -q xgboost==2.1.2      --no-index --find-links=/kaggle/input/wsdm2024-public-imports-v1/packages\n!pip install -q polars==1.14.0      --no-index --find-links=/kaggle/input/wsdm2024-public-imports-v1/packages\n\nexec(open('/kaggle/input/wsdm2024-public-imports-v1/myimports.py','r').read())\nexec(open('/kaggle/input/wsdm2024-public-imports-v1/training.py','r').read())\n\n%matplotlib inline\nprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T19:12:02.931608Z","iopub.execute_input":"2024-11-19T19:12:02.931969Z","iopub.status.idle":"2024-11-19T19:13:33.414903Z","shell.execute_reply.started":"2024-11-19T19:12:02.931913Z","shell.execute_reply":"2024-11-19T19:13:33.413534Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **CONFIGURATION**","metadata":{}},{"cell_type":"code","source":"%%time \n\nclass CFG:\n    \"\"\"\n    Configuration class for parameters and CV strategy for tuning and training\n    Some parameters may be unused here as this is a general configuration class\n    \"\"\";\n\n    # Data preparation:-\n    version_nb  = 1\n    model_id    = \"V1_2\"\n    model_label = \"ML\"\n\n    test_req           = False\n    test_sample_frac   = 0.05\n\n    gpu_switch         = \"OFF\"\n    state              = 42\n    target             = f\"winner\"\n    grouper            = f\"\"\n    tgt_mapper         = {\"model_a\" : 0, \"model_b\" : 1}\n\n    ip_path            = f\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena\"\n    op_path            = f\"/kaggle/working\"\n    ftre_plots_req     = True\n    ftre_imp_req       = True\n    nb_orig            = 0\n    orig_all_folds     = False\n\n    # Model Training:-\n    pstprcs_oof        = False\n    pstprcs_train      = False\n    pstprcs_test       = False\n    ML                 = True\n    test_preds_req     = False\n\n    pseudo_lbl_req     = \"N\"\n    pseudolbl_up       = 0.975\n    pseudolbl_low      = 0.00\n\n    n_splits           = 3 if test_req == True else 5\n    n_repeats          = 1\n    nbrnd_erly_stp     = 100\n    mdlcv_mthd         = 'SKF'\n\n    # Ensemble:-\n    ensemble_req       = True\n    optuna_req         = False\n    metric_obj         = 'maximize'\n    ntrials            = 10 if test_req == True else 300\n\n    # Global variables for plotting:-\n    grid_specs = {'visible'  : True,\n                  'which'    : 'both',\n                  'linestyle': '--',\n                  'color'    : 'lightgrey',\n                  'linewidth': 0.75\n                 }\n\n    title_specs = {'fontsize'   : 9,\n                   'fontweight' : 'bold',\n                   'color'      : '#992600',\n                  }\n\nPrintColor(f\"\\n---> Configuration done!\\n\")\n\ncv_selector = \\\n{\n \"RKF\"   : RKF(n_splits = CFG.n_splits, n_repeats= CFG.n_repeats, random_state= CFG.state),\n \"RSKF\"  : RSKF(n_splits = CFG.n_splits, n_repeats= CFG.n_repeats, random_state= CFG.state),\n \"SKF\"   : SKF(n_splits = CFG.n_splits, shuffle = True, random_state= CFG.state),\n \"KF\"    : KFold(n_splits = CFG.n_splits, shuffle = True, random_state= CFG.state),\n \"GKF\"   : GKF(n_splits = CFG.n_splits)\n}\n\ncollect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T19:13:33.416349Z","iopub.execute_input":"2024-11-19T19:13:33.417105Z","iopub.status.idle":"2024-11-19T19:13:33.740359Z","shell.execute_reply.started":"2024-11-19T19:13:33.417065Z","shell.execute_reply":"2024-11-19T19:13:33.739005Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"|Configuration parameter| Explanation| Data type| Sample values |  \n| ---------------------- | ------------------------------- | --------------------- | --------------- |\n| version_nb    | Version Number | int | 1 | \n| model_id      | Model ID    | string | V1_1 | \n| model_label   | Model Label | string | ML | \n| test_req      | Test Required| bool | True / False | \n| test_sample_frac| Test sampled fraction | int | 1000 |\n| gpu_switch      | Do we need GPU support | bool | True / False |\n| state           | Random state | int | 42 |\n| target          | Target column | str |  |\n| grouper         | CV grouper column | str |  |\n| ip_path, op_path | Data paths  | str | |\n| pstprcs_* | Do we need post-processing  | bool |True / False |\n| ML| Do we need machine learning models  | bool |True / False |\n| test_preds_req| Do we need test set predictions (training in inference kernel)  | bool |True / False |\n| pseudo_lbl_req| Pseudo label required?  | bool |True / False |\n| pseudo_lbl_* | Pseudo label cutoff | float | |\n| n_splits/ n_repeats | N-splits and repeats for CV scheme | int | 3/5/10|\n| nbrnd_erly_stp | Early stopping rounds | int | 40|\n| mdlcv_mthd | Model CV method | str | RSKF|\n| ensemble_req | Do we need ensemble | bool | True / False |\n| optuna_req   | Do we need optuna | bool | True / False |\n| metric_obj   | Metric direction | str | minimize/ maximize |\n| ntrials      | Trials | int | 300 |","metadata":{}},{"cell_type":"markdown","source":"# **PREPROCESSING**","metadata":{}},{"cell_type":"code","source":"%%time \n\ntrain  = pd.read_parquet(f\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet\")\ntest   = pd.read_parquet(f\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet\")\nsub_fl = pd.read_csv(f\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/sample_submission.csv\")\n\ntrain_inv = train.copy()\ntrain_inv[\"response_a\"], train_inv[\"response_b\"] = train_inv[\"response_b\"], train_inv[\"response_a\"]\ntrain_inv[\"winner\"] = train_inv[\"winner\"].apply(lambda x: \"model_a\" if \"b\" in x else \"model_b\")\n\ntrain = pd.concat([train, train_inv], axis=0, ignore_index = True)\n\ndel train_inv\n\n# Fixating CV folds\ncv = cv_selector[CFG.mdlcv_mthd]\nygrp = np.zeros(len(train))\nfor fold_nb, (train_idx, dev_idx) in enumerate(cv.split(train, train[CFG.target])):\n    ygrp[dev_idx] = fold_nb\n\nygrp = pd.Series(ygrp, dtype = np.uint8, name = \"fold_nb\")\n\n_ = utils.CleanMemory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T19:13:33.741795Z","iopub.execute_input":"2024-11-19T19:13:33.742746Z","iopub.status.idle":"2024-11-19T19:13:37.738341Z","shell.execute_reply.started":"2024-11-19T19:13:33.74271Z","shell.execute_reply":"2024-11-19T19:13:37.736559Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **FEATURE CREATION**","metadata":{}},{"cell_type":"code","source":"%%time \n\ndef make_ftre(df : pd.DataFrame):\n    \"This method makes static features on the dataset provided\"\n\n    for col in [\"response_a\", \"response_b\", \"prompt\"]:\n        df[f\"{col}_len\"]              = df[f\"{col}\"].str.len()\n        df[f\"{col}_spaces\"]           = df[f\"{col}\"].str.count(\"\\s\")\n        df[f\"{col}_punct\"]            = df[f\"{col}\"].str.count(\",|\\.|!\")\n        df[f\"{col}_question_mark\"]    = df[f\"{col}\"].str.count(\"\\?\")\n        df[f\"{col}_quot\"]             = df[f\"{col}\"].str.count(\"'|\\\"\")\n        df[f\"{col}_formatting_chars\"] = df[f\"{col}\"].str.count(\"\\*|\\_\")\n        df[f\"{col}_math_chars\"]       = df[f\"{col}\"].str.count(\"\\-|\\+|\\=\")\n        df[f\"{col}_curly_open\"]       = df[f\"{col}\"].str.count(\"\\{\")\n        df[f\"{col}_curly_close\"]      = df[f\"{col}\"].str.count(\"}\")\n        df[f\"{col}_round_open\"]       = df[f\"{col}\"].str.count(\"\\(\")\n        df[f\"{col}_round_close\"]      = df[f\"{col}\"].str.count(\"\\)\")\n        df[f\"{col}_special_chars\"]    = df[f\"{col}\"].str.count(\"\\W\")\n        df[f\"{col}_digits\"]           = df[f\"{col}\"].str.count(\"\\d\") > 0\n        df[f\"{col}_letters\"]          = df[f\"{col}\"].str.count(\"[a-zA-Z]\") > 0.1 * df[f\"{col}_len\"]\n        df[f\"{col}_chinese\"]          = df[f\"{col}\"].str.count(r'[\\u4e00-\\u9fff]+') > 0.1 * df[f\"{col}_len\"]\n\n    df[f\"{col}_round_balance\"] = df[f\"{col}_round_open\"] - df[f\"{col}_round_close\"]\n    df[f\"{col}_curly_balance\"] = df[f\"{col}_curly_open\"] - df[f\"{col}_curly_close\"]\n    df[f\"{col}_json\"]          = df[f\"{col}\"].str.lower().str.count(\"json\")\n\n    print(f\"---> Shape = {df.shape}\")\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T19:13:37.741519Z","iopub.execute_input":"2024-11-19T19:13:37.742048Z","iopub.status.idle":"2024-11-19T19:13:37.753782Z","shell.execute_reply.started":"2024-11-19T19:13:37.741994Z","shell.execute_reply":"2024-11-19T19:13:37.752393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time \n\ntrain  = make_ftre(train)\nXtest  = make_ftre(test).drop(\"scored\", axis=1)\n\nXtrain = train.drop([CFG.target], axis=1)\nytrain = train[CFG.target].map(CFG.tgt_mapper).astype(np.uint8)\n\nXtrain[\"Source\"], Xtest[\"Source\"] = (\"Competition\", \"Competition\")\n\nPrintColor(f\"\\n\\n---> Shapes  = {Xtrain.shape} {ytrain.shape} {Xtest.shape}\")\n_ = utils.CleanMemory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T19:13:37.755507Z","iopub.execute_input":"2024-11-19T19:13:37.756048Z","iopub.status.idle":"2024-11-19T19:15:50.661162Z","shell.execute_reply.started":"2024-11-19T19:13:37.755992Z","shell.execute_reply":"2024-11-19T19:15:50.659895Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **MODEL TRAINING**","metadata":{}},{"cell_type":"markdown","source":"We use a smoother metric like auc score / logloss for early stopping - accuracy does not do well with such endeavors","metadata":{}},{"cell_type":"code","source":"%%time \n\ntry:\n    l = MyLogger()\n    l.init(logging_lbl = \"lightgbm_custom\")\n    lgb.register_logger(l)\nexcept:\n    pass\n\n# Initializing model parameters\nMdl_Master = \\\n{    \n f'CB1C' : CBC(**{'task_type'           : \"CPU\",\n                  'loss_function'       : 'Logloss',\n                  'eval_metric'         : \"Logloss\",\n                  'bagging_temperature' : 0.25,\n                  'colsample_bylevel'   : 0.70,\n                  'iterations'          : 5_000,\n                  'learning_rate'       : 0.035,\n                  'max_depth'           : 7,\n                  'l2_leaf_reg'         : 0.80,\n                  'min_data_in_leaf'    : 35,\n                  'random_strength'     : 0.25,\n                  'verbose'             : 0,\n                 }\n              ),\n\n f'CB2C' : CBC(**{'task_type'           : \"CPU\",\n                  'loss_function'       : 'Logloss',\n                  'eval_metric'         : \"AUC\",\n                  'bagging_temperature' : 0.25,\n                  'colsample_bylevel'   : 0.60,\n                  'iterations'          : 5_000,\n                  'learning_rate'       : 0.05,\n                  'max_depth'           : 7,\n                  'l2_leaf_reg'         : 0.50,\n                  'min_data_in_leaf'    : 18,\n                  'random_strength'     : 0.10,\n                  'verbose'             : 0,\n                 }\n              ),\n\n f\"LGBM1C\"  : LGBMC(**{ 'objective'        : 'binary',\n                        'eval_metric'      : 'logloss',\n                        'n_estimators'     : 5_000,\n                        'learning_rate'    : 0.03,\n                        'max_depth'        : 7,\n                        'num_leaves'       : 35,\n                        'min_data_in_leaf' : 13,\n                        'feature_fraction' : 0.80,\n                        'bagging_fraction' : 0.60,\n                        'lambda_l1'        : 0.001,\n                        'lambda_l2'        : 0.85,\n                        'device'           : 'cpu' if CFG.gpu_switch == \"OFF\" else \"gpu\",\n                        'verbosity'        : -1,\n                     }\n                  ),\n\n f\"LGBM2C\"  : LGBMC(**{ 'objective'        : 'binary',\n                        'eval_metric'      : 'auc',\n                        'data_sample_strategy' : 'goss', \n                        'n_estimators'     : 5_000,\n                        'learning_rate'    : 0.035,\n                        'max_depth'        : 7,\n                        'num_leaves'       : 22,\n                        'min_data_in_leaf' : 17,\n                        'feature_fraction' : 0.90,\n                        'bagging_fraction' : 0.70,\n                        'lambda_l1'        : 0.001,\n                        'lambda_l2'        : 0.60,\n                        'device'           : 'cpu' if CFG.gpu_switch == \"OFF\" else \"gpu\",\n                        'verbosity'        : -1,\n                     }\n                  ),\n\n f\"XGB1C\"  :   XGBC(**{  'objective'          : \"binary:logistic\",\n                         'eval_metric'        : \"auc\",\n                         'n_estimators'       : 5_000,\n                         'learning_rate'      : 0.035,\n                         'max_depth'          : 7,\n                         'colsample_bytree'   : 0.45,\n                         'subsample'          : 0.80,\n                         'lambda_l1'          : 0.001,\n                         'lambda_l2'          : 0.001,\n                         'device'             : 'cpu' if CFG.gpu_switch == \"OFF\" else \"cuda\",\n                         'verbosity'          : 0,\n                         'enable_categorical' : True,\n                         'early_stopping_rounds' : CFG.nbrnd_erly_stp,\n                     }\n                  ),\n\n}\n\n# Initializing model outputs\nOOF_Preds    = {}\nMdl_Preds    = {}\nFittedModels = {}\nFtreImp      = {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T19:15:50.662697Z","iopub.execute_input":"2024-11-19T19:15:50.663096Z","iopub.status.idle":"2024-11-19T19:15:50.681356Z","shell.execute_reply.started":"2024-11-19T19:15:50.663061Z","shell.execute_reply":"2024-11-19T19:15:50.680041Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **SINGLE MODELS**","metadata":{}},{"cell_type":"code","source":"%%time\n\n# Model training:-\ndrop_cols = [\"Source\", \"id\", \"Id\", \"Label\", CFG.target, \"fold_nb\",\n             'prompt', 'response_a', 'response_b', 'winner', 'model_a',\n             'model_b', 'language', 'scored',\n            ]\n\nfor method, mymodel in tqdm(Mdl_Master.items()):\n\n    PrintColor(f\"\\n{'=' * 20} {method.upper()} MODEL TRAINING {'=' * 20}\\n\")\n\n    md = \\\n    ModelTrainer(\n        problem_type   = \"binary\",\n        es             = CFG.nbrnd_erly_stp,\n        target         = CFG.target,\n        orig_req       = False,\n        orig_all_folds = False,\n        metric_lbl     = \"accuracy\",\n        drop_cols      = drop_cols,\n        )\n\n    sel_mdl_cols = list(Xtest.columns)\n    \n    PrintColor(f\"Selected columns = {len(sel_mdl_cols) :,.0f}\", color = Fore.RED)\n    \n    fitted_models, oof_preds, test_preds, ftreimp, mdl_best_iter =  \\\n    md.MakeOfflineModel(\n        Xtrain[sel_mdl_cols].copy(),\n        deepcopy(ytrain),\n        ygrp,\n        Xtest[sel_mdl_cols].copy(),\n        clone(mymodel),\n        method,\n        test_preds_req   = True,\n        ftreimp_plot_req = CFG.ftre_imp_req,\n        ntop = 50,\n    )\n\n    OOF_Preds[method]    = oof_preds\n    Mdl_Preds[method]    = test_preds\n    FittedModels[method] = fitted_models\n    FtreImp[method]      = ftreimp\n\n    del fitted_models, oof_preds, test_preds, ftreimp, sel_mdl_cols\n    print()\n    collect();\n\n_ = utils.CleanMemory();\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T19:15:50.683077Z","iopub.execute_input":"2024-11-19T19:15:50.683537Z","iopub.status.idle":"2024-11-19T19:21:00.967669Z","shell.execute_reply.started":"2024-11-19T19:15:50.68348Z","shell.execute_reply":"2024-11-19T19:21:00.965905Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **ENSEMBLE**","metadata":{}},{"cell_type":"code","source":"%%time \n\nEns_Master = {f\"LR1C\" : LRC(C = 2.5, random_state = CFG.state, max_iter = 5000)}\n\noof_preds = pd.DataFrame(OOF_Preds).assign(**{\"Source\" : \"Competition\"})\nmdl_preds = pd.DataFrame(Mdl_Preds).assign(**{\"Source\" : \"Competition\"})\n\nfor method, mymodel in tqdm(Ens_Master.items()):\n    md = \\\n    ModelTrainer(\n        problem_type   = \"binary\",\n        es             = CFG.nbrnd_erly_stp,\n        target         = CFG.target,\n        orig_req       = False,\n        orig_all_folds = False,\n        metric_lbl     = \"accuracy\",\n        drop_cols      = drop_cols,\n        )\n\n    sel_mdl_cols = list(mdl_preds.columns)\n\n    fitted_models, oof_ens_preds, test_preds, ftreimp, mdl_best_iter  =  \\\n    md.MakeOfflineModel(\n        oof_preds[sel_mdl_cols],\n        ytrain,\n        ygrp,\n        mdl_preds[sel_mdl_cols],\n        mymodel,\n        method,\n        test_preds_req   = True,\n        ftreimp_plot_req = False,\n        ntop = 50,\n    )\n\n    coefs_ = []\n    for model in tqdm(fitted_models) :\n        coefs_.append(model.coef_.flatten())\n\n    coefs_ = \\\n    pd.DataFrame(np.stack(coefs_, axis=1),\n                 index = list(set(sel_mdl_cols).difference(drop_cols))\n                )\n    \n    print(\"\\n\\n\")\n    coefs_ = coefs_.mean(axis=1)\n    md.PlotFtreImp(\n        coefs_, method = method, ntop = 50, title_specs = CFG.title_specs\n    )\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T19:21:00.969926Z","iopub.execute_input":"2024-11-19T19:21:00.970545Z","iopub.status.idle":"2024-11-19T19:21:02.719712Z","shell.execute_reply.started":"2024-11-19T19:21:00.970428Z","shell.execute_reply":"2024-11-19T19:21:02.71823Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **THRESHOLD ADJUSTMENT**\n\nWe will try and find an optimal cutoff using a very basic search to elicit perhaps better results from the past version. This can be done using [TunedThresholdClassifierCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TunedThresholdClassifierCV.html) for sklearn 1.5.0 and later. One can use scipy.minimize and Optuna too for this step. <br>","metadata":{}},{"cell_type":"code","source":"%%time \n\nbest_score = \\\npd.DataFrame(\n    columns = [\"BestCutoff\", \"BestScore\"], \n    index = range(CFG.n_splits)\n)\n\nfor fold_nb, (_, dev_idx) in enumerate(cv.split(oof_preds, ytrain)):\n    ypreds = oof_ens_preds[dev_idx]\n    ytrue  = ytrain.values[dev_idx]\n\n    tuned_scores = {}\n    \n    for i in np.arange(0.40, 0.70, 0.0005):\n        score = utils.ScoreMetric(ytrue, np.where(ypreds > i, 1, 0))\n        tuned_scores[i] = score\n\n    best_cutoff = max(tuned_scores, key= tuned_scores.get)\n    max_score   = tuned_scores[best_cutoff]\n\n    best_score.loc[fold_nb] = [best_cutoff, max_score]\n    \n    PrintColor(\n        f\"Fold{fold_nb} - Best cutoff = {best_cutoff :.4f} score = {max_score :.6f}\",\n        color = Fore.CYAN\n    )\n\nbest_score = best_score.mean(axis=0).values\ncutoff, score = best_score[0], best_score[1]\nPrintColor(\n    f\"\\nOverall - Best cutoff = {cutoff :.4f} score = {score :.6f}\",\n    color = Fore.BLUE\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T19:43:00.906204Z","iopub.execute_input":"2024-11-19T19:43:00.906644Z","iopub.status.idle":"2024-11-19T19:43:08.152391Z","shell.execute_reply.started":"2024-11-19T19:43:00.906609Z","shell.execute_reply":"2024-11-19T19:43:08.150617Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **SUBMISSION**","metadata":{}},{"cell_type":"code","source":"%%time \n\nsub_fl[CFG.target] = np.where(test_preds > cutoff, \"model_b\", \"model_a\")\nsub_fl.to_csv(\"submission.csv\", index = None)\n\n\njoblib.dump(FittedModels,  \"FittedModels.joblib\")\njoblib.dump(fitted_models, \"EnsembleModel.joblib\")\npd.DataFrame(FtreImp).to_csv(f\"FtreImp.csv\")\npd.DataFrame(OOF_Preds).to_csv(\"OOF_Preds.csv\")\n\n!ls\n\n!head submission.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T19:43:29.809447Z","iopub.execute_input":"2024-11-19T19:43:29.810473Z","iopub.status.idle":"2024-11-19T19:43:34.107441Z","shell.execute_reply.started":"2024-11-19T19:43:29.810436Z","shell.execute_reply":"2024-11-19T19:43:34.105784Z"}},"outputs":[],"execution_count":null}]}