{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86946,"databundleVersionId":10131489,"sourceType":"competition"},{"sourceId":8897601,"sourceType":"datasetVersion","datasetId":5297895},{"sourceId":8926343,"sourceType":"datasetVersion","datasetId":5369301},{"sourceId":8955574,"sourceType":"datasetVersion","datasetId":5379750},{"sourceId":8968923,"sourceType":"datasetVersion","datasetId":5399319},{"sourceId":8982029,"sourceType":"datasetVersion","datasetId":5408901},{"sourceId":8993713,"sourceType":"datasetVersion","datasetId":5417216},{"sourceId":8999278,"sourceType":"datasetVersion","datasetId":5420981},{"sourceId":9043787,"sourceType":"datasetVersion","datasetId":5441935},{"sourceId":9051926,"sourceType":"datasetVersion","datasetId":5457847},{"sourceId":75103,"sourceType":"modelInstanceVersion","modelInstanceId":63082,"modelId":86587}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":148.347272,"end_time":"2024-07-10T01:15:35.655682","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-07-10T01:13:07.30841","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0f59addf0d2f40309e025976c382cad8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_268e3946106b4e41849bf11c5a375dac","placeholder":"​","style":"IPY_MODEL_5bb130c471af4927a6644f932ae47523","value":" 2/2 [00:03&lt;00:00,  1.48s/it]"}},"19ef2d43bafa44a8b20dc5230aea5ae4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ca042ffa14e4dbebdc66435f7b1f07f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19ef2d43bafa44a8b20dc5230aea5ae4","placeholder":"​","style":"IPY_MODEL_d8a7714cd80d479e859b6ae31ebce7e5","value":"Loading checkpoint shards: 100%"}},"1d03719518b8423099b8b68a92e449d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64ef70cfa9c04764868fa52963323322","placeholder":"​","style":"IPY_MODEL_5e81b324ca1b46a2a96d02bb2acadc0a","value":"Loading checkpoint shards: 100%"}},"1d89705c74d34016bbc1e0601ead825c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d409334237014614bf9ae742597d98ea","placeholder":"​","style":"IPY_MODEL_875758123e4f41f0b5c3fa0cd4fb47c6","value":" 2/2 [01:18&lt;00:00, 34.68s/it]"}},"1ef6d64d40d8461d9e6adddd513089b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"268e3946106b4e41849bf11c5a375dac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"324c2396f44f45c89d9ec264007ef9ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5bb130c471af4927a6644f932ae47523":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d243712a1a545e99fa858b0cf19831d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e81b324ca1b46a2a96d02bb2acadc0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64ef70cfa9c04764868fa52963323322":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68ae4b02a13f4570ad729c437ebd28ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ca042ffa14e4dbebdc66435f7b1f07f","IPY_MODEL_81b4a9a7cde64b17856b89dbd238c0ef","IPY_MODEL_0f59addf0d2f40309e025976c382cad8"],"layout":"IPY_MODEL_9422a87b93ab4473913e601da3a18689"}},"81b4a9a7cde64b17856b89dbd238c0ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ef6d64d40d8461d9e6adddd513089b8","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_324c2396f44f45c89d9ec264007ef9ff","value":2}},"85d217d6b45847869cea506db59e8b42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d243712a1a545e99fa858b0cf19831d","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96385fd98f304649ab5c4ae81333fb63","value":2}},"875758123e4f41f0b5c3fa0cd4fb47c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9422a87b93ab4473913e601da3a18689":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96385fd98f304649ab5c4ae81333fb63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d409334237014614bf9ae742597d98ea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d576a283e6424206ab4c25d809241c21":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8a7714cd80d479e859b6ae31ebce7e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d98918fae8174629b4819a1114f21202":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d03719518b8423099b8b68a92e449d7","IPY_MODEL_85d217d6b45847869cea506db59e8b42","IPY_MODEL_1d89705c74d34016bbc1e0601ead825c"],"layout":"IPY_MODEL_d576a283e6424206ab4c25d809241c21"}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook is a direct adaptation of my solution to the previous LMSYS competition for this competition!\n\nThe format for submitting the prediction results is different, so I have aligned that, but other than that, I have kept my submission code Forked.\n\nFor more details on the solution, please refer to the Discussion [here](https://www.kaggle.com/competitions/lmsys-chatbot-arena/discussion/527938).\n\n\n#### Previous LMSYS result:\n\n|  | log loss |\n| - | - |\n| public LB | 0.89009 |\n| private LB | 1.00182 |","metadata":{}},{"cell_type":"code","source":"!pip install transformers peft accelerate bitsandbytes \\\n    -U --no-index --find-links /kaggle/input/lmsys-wheel-files","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"papermill":{"duration":31.479497,"end_time":"2024-07-10T01:13:41.690971","exception":false,"start_time":"2024-07-10T01:13:10.211474","status":"completed"},"scrolled":true,"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T20:12:42.372856Z","iopub.execute_input":"2024-11-19T20:12:42.373782Z","iopub.status.idle":"2024-11-19T20:12:50.509075Z","shell.execute_reply.started":"2024-11-19T20:12:42.373733Z","shell.execute_reply":"2024-11-19T20:12:50.508249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cp -r /kaggle/input/lmsys-gemma2-test/last_model ./merge_model\n!rm ./merge_model/adapter_model.safetensors ./merge_model/adapter_config.json\n!ls merge_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T20:12:50.511755Z","iopub.execute_input":"2024-11-19T20:12:50.51207Z","iopub.status.idle":"2024-11-19T20:12:53.569324Z","shell.execute_reply.started":"2024-11-19T20:12:50.51204Z","shell.execute_reply":"2024-11-19T20:12:53.568465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nfrom dataclasses import dataclass\nfrom concurrent.futures import ThreadPoolExecutor\n\nimport torch\nimport sklearn\nimport numpy as np\nimport pandas as pd\nfrom transformers import Gemma2ForSequenceClassification, GemmaTokenizerFast, BitsAndBytesConfig\nfrom transformers.data.data_collator import pad_without_fast_tokenizer_warning\nfrom peft import PeftModel","metadata":{"papermill":{"duration":19.200405,"end_time":"2024-07-10T01:14:00.90474","exception":false,"start_time":"2024-07-10T01:13:41.704335","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-19T20:12:53.57109Z","iopub.execute_input":"2024-11-19T20:12:53.571589Z","iopub.status.idle":"2024-11-19T20:13:10.732137Z","shell.execute_reply.started":"2024-11-19T20:12:53.571539Z","shell.execute_reply":"2024-11-19T20:13:10.731464Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"assert torch.cuda.device_count() == 2","metadata":{"papermill":{"duration":0.047799,"end_time":"2024-07-10T01:14:00.965921","exception":false,"start_time":"2024-07-10T01:14:00.918122","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-19T20:13:10.733143Z","iopub.execute_input":"2024-11-19T20:13:10.733619Z","iopub.status.idle":"2024-11-19T20:13:10.764774Z","shell.execute_reply.started":"2024-11-19T20:13:10.733592Z","shell.execute_reply":"2024-11-19T20:13:10.764208Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Configurations","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass Config:\n    gemma_dir = '/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit'\n    lora_dir = \"./merge_model\"\n    lora_dirs = [\n        \"/kaggle/input/lmsys-exp14-full-long-lr1e4/exp14_full_long_lr1e4/last_model\",\n        \"/kaggle/input/lmsys-exp15-cont-org-lr-3e5/last_model\",\n    ]\n    #lora_weights = [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125]\n    lora_weights = [0.7, 0.3]\n    max_length = 2048\n    prompt_max_l = 512\n    batch_size = 4\n    device = torch.device(\"cuda\")    \n    tta = True  # test time augmentation. <prompt>-<model-b's response>-<model-a's response>\n    spread_max_length = False  # whether to apply max_length//3 on each input or max_length on the concatenated input\n    \n    best_temp = 1\n    merge_method = \"avg\" # concatenation, svd, linear\n\ncfg = Config()","metadata":{"papermill":{"duration":0.021338,"end_time":"2024-07-10T01:14:01.000606","exception":false,"start_time":"2024-07-10T01:14:00.979268","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-19T20:13:10.765652Z","iopub.execute_input":"2024-11-19T20:13:10.765885Z","iopub.status.idle":"2024-11-19T20:13:10.770975Z","shell.execute_reply.started":"2024-11-19T20:13:10.76586Z","shell.execute_reply":"2024-11-19T20:13:10.770057Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom peft import LoraConfig\nfrom safetensors.torch import load_file, save_file\nimport json\n\ndef load_config(path):\n    with open(path, 'r') as f:\n        return json.load(f)\n    \ndef load_lora_weights(path):\n    return load_file(path)\n    \ndef weighted_merge_lora_weights(weight_files, weights):\n    if len(weight_files) != len(weights):\n        raise ValueError(\"Number of weight files and weights must match\")\n    \n    all_lora_weights = [load_lora_weights(f + \"/adapter_model.safetensors\") for f in weight_files]\n    merged_weights = {}\n    \n    for key in all_lora_weights[0].keys():\n        merged_weights[key] = sum(w * lora_weights[key] for w, lora_weights in zip(weights, all_lora_weights))\n    \n    return merged_weights\n\ndef save_merged_weights(weights, output_path):\n    save_file(weights, output_path)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:13:10.771987Z","iopub.execute_input":"2024-11-19T20:13:10.772276Z","iopub.status.idle":"2024-11-19T20:13:10.783441Z","shell.execute_reply.started":"2024-11-19T20:13:10.772249Z","shell.execute_reply":"2024-11-19T20:13:10.782745Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_config = load_config(cfg.lora_dirs[0] + \"/adapter_config.json\")\n\nif cfg.merge_method == \"avg\":\n    ensembled_weights = weighted_merge_lora_weights(cfg.lora_dirs, cfg.lora_weights)\nelif cfg.merge_method == \"cat\":\n    merged_config[\"lora_alpha\"] *= 2\n    merged_config[\"r\"] *= 2\n    weights = [load_file(d + \"/adapter_model.safetensors\") for d in cfg.lora_dirs]\n    \n    ensembled_weights = {}\n    for key in weights[0].keys():\n        if \"lora_A\" in key:\n            ensembled_weights[key] = torch.cat([w[key] for w in weights], dim=0)\n        elif \"lora_B\" in key:\n            ensembled_weights[key] = torch.cat([w[key] for w in weights], dim=1)\n        else:\n            ensembled_weights[key] = weights[0][key]  # 他の重みはそのまま保持\n\nsave_merged_weights(ensembled_weights, \"./merge_model/adapter_model.safetensors\")\nwith open(\"./merge_model/adapter_config.json\", 'w') as f:\n    json.dump(merged_config, f, indent=2)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:13:10.784545Z","iopub.execute_input":"2024-11-19T20:13:10.785158Z","iopub.status.idle":"2024-11-19T20:13:11.933758Z","shell.execute_reply.started":"2024-11-19T20:13:10.785098Z","shell.execute_reply":"2024-11-19T20:13:11.932848Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load & pre-process Data ","metadata":{"papermill":{"duration":0.012663,"end_time":"2024-07-10T01:14:01.026248","exception":false,"start_time":"2024-07-10T01:14:01.013585","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pyarrow\nimport pyarrow.parquet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T20:14:06.397859Z","iopub.execute_input":"2024-11-19T20:14:06.398249Z","iopub.status.idle":"2024-11-19T20:14:06.472446Z","shell.execute_reply.started":"2024-11-19T20:14:06.398217Z","shell.execute_reply":"2024-11-19T20:14:06.471601Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test =  pyarrow.parquet.read_table('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet')\ntest  = test.to_pandas()\ntest = test.fillna(\"\")\ntest","metadata":{"papermill":{"duration":0.02967,"end_time":"2024-07-10T01:14:01.06946","exception":false,"start_time":"2024-07-10T01:14:01.03979","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-19T20:14:11.832909Z","iopub.execute_input":"2024-11-19T20:14:11.833553Z","iopub.status.idle":"2024-11-19T20:14:11.947168Z","shell.execute_reply.started":"2024-11-19T20:14:11.833515Z","shell.execute_reply":"2024-11-19T20:14:11.946353Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Tokenize","metadata":{"papermill":{"duration":0.012864,"end_time":"2024-07-10T01:14:01.148412","exception":false,"start_time":"2024-07-10T01:14:01.135548","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def tokenize_shape(prompt, response_a, response_b):\n    p = tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n    a = tokenizer(response_a, add_special_tokens=False)[\"input_ids\"]\n    b = tokenizer(response_b, add_special_tokens=False)[\"input_ids\"]\n\n    tokenized = {\"input_ids\": [], \"attention_mask\": []}\n    for i, _p in enumerate(p):\n        if len(_p) > cfg.prompt_max_l:\n            _p = _p[-cfg.prompt_max_l:]\n        rl = (cfg.max_length - len(_p)) // 2\n        input_ids = [tokenizer.bos_token_id] + _p + a[i][-rl:] + b[i][-rl:] + [tokenizer.eos_token_id]\n        attention_mask = [1] * len(input_ids)\n        tokenized[\"input_ids\"].append(input_ids)\n        tokenized[\"attention_mask\"].append(attention_mask)\n    return tokenized\n\ndef tokenize(\n    tokenizer, prompt, response_a, response_b, max_length=cfg.max_length, spread_max_length=cfg.spread_max_length\n):\n    prompt = [\"<prompt>: \" + p for p in prompt]\n    response_a = [\"\\n\\n<response_a>: \" + r_a for r_a in response_a]\n    response_b = [\"\\n\\n<response_b>: \" + r_b for r_b in response_b]\n    tokenized = tokenize_shape(prompt, response_a, response_b)\n    input_ids = tokenized[\"input_ids\"]\n    attention_mask = tokenized[\"attention_mask\"]\n    return input_ids, attention_mask","metadata":{"papermill":{"duration":0.030237,"end_time":"2024-07-10T01:14:01.194318","exception":false,"start_time":"2024-07-10T01:14:01.164081","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-19T20:14:17.305184Z","iopub.execute_input":"2024-11-19T20:14:17.306056Z","iopub.status.idle":"2024-11-19T20:14:17.313427Z","shell.execute_reply.started":"2024-11-19T20:14:17.306019Z","shell.execute_reply":"2024-11-19T20:14:17.312354Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\ntokenizer = GemmaTokenizerFast.from_pretrained(cfg.gemma_dir)\ntokenizer.add_eos_token = True\ntokenizer.padding_side = \"right\"\n\ndata = pd.DataFrame()\ndata[\"id\"] = test[\"id\"]\ndata[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\ndata[\"length\"] = data[\"input_ids\"].apply(len)\n\naug_data = pd.DataFrame()\naug_data[\"id\"] = test[\"id\"]\n# swap response_a & response_b\naug_data['input_ids'], aug_data['attention_mask'] = tokenize(tokenizer, test[\"prompt\"], test[\"response_b\"], test[\"response_a\"])\naug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)","metadata":{"papermill":{"duration":1.169844,"end_time":"2024-07-10T01:14:02.377579","exception":false,"start_time":"2024-07-10T01:14:01.207735","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-19T20:14:31.655358Z","iopub.execute_input":"2024-11-19T20:14:31.656007Z","iopub.status.idle":"2024-11-19T20:14:32.971032Z","shell.execute_reply.started":"2024-11-19T20:14:31.655974Z","shell.execute_reply":"2024-11-19T20:14:32.970164Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(tokenizer.decode(aug_data[\"input_ids\"][0]))","metadata":{"papermill":{"duration":0.021982,"end_time":"2024-07-10T01:14:02.454045","exception":false,"start_time":"2024-07-10T01:14:02.432063","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-19T20:14:44.109872Z","iopub.execute_input":"2024-11-19T20:14:44.110587Z","iopub.status.idle":"2024-11-19T20:14:44.1261Z","shell.execute_reply.started":"2024-11-19T20:14:44.110552Z","shell.execute_reply":"2024-11-19T20:14:44.125171Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load model","metadata":{"papermill":{"duration":0.013054,"end_time":"2024-07-10T01:14:02.480304","exception":false,"start_time":"2024-07-10T01:14:02.46725","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Load base model on GPU 0\ndevice_0 = torch.device('cuda:0')\nmodel_0 = Gemma2ForSequenceClassification.from_pretrained(\n    cfg.gemma_dir,\n    device_map=device_0,\n    use_cache=False,\n)\n\n# Load base model on GPU 1\ndevice_1 = torch.device('cuda:1')\nmodel_1 = Gemma2ForSequenceClassification.from_pretrained(\n    cfg.gemma_dir,\n    device_map=device_1,\n    use_cache=False,\n)","metadata":{"papermill":{"duration":83.919146,"end_time":"2024-07-10T01:15:26.412583","exception":false,"start_time":"2024-07-10T01:14:02.493437","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-19T20:15:00.798464Z","iopub.execute_input":"2024-11-19T20:15:00.798834Z","iopub.status.idle":"2024-11-19T20:15:48.996462Z","shell.execute_reply.started":"2024-11-19T20:15:00.798806Z","shell.execute_reply":"2024-11-19T20:15:48.995766Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Load LoRA adapter","metadata":{"papermill":{"duration":0.013639,"end_time":"2024-07-10T01:15:26.440571","exception":false,"start_time":"2024-07-10T01:15:26.426932","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_0 = PeftModel.from_pretrained(model_0, cfg.lora_dir)\nmodel_1 = PeftModel.from_pretrained(model_1, cfg.lora_dir)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T20:15:49.022068Z","iopub.execute_input":"2024-11-19T20:15:49.02237Z","iopub.status.idle":"2024-11-19T20:15:49.532478Z","shell.execute_reply.started":"2024-11-19T20:15:49.022343Z","shell.execute_reply":"2024-11-19T20:15:49.531628Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference\n","metadata":{"papermill":{"duration":0.013989,"end_time":"2024-07-10T01:15:27.797512","exception":false,"start_time":"2024-07-10T01:15:27.783523","status":"completed"},"tags":[]}},{"cell_type":"code","source":"@torch.no_grad()\n@torch.cuda.amp.autocast()\ndef inference(df, model, device, batch_size=cfg.batch_size, max_length=cfg.max_length):\n    a_win, b_win, tie = [], [], []\n    \n    for start_idx in range(0, len(df), batch_size):\n        end_idx = min(start_idx + batch_size, len(df))\n        tmp = df.iloc[start_idx:end_idx]\n        input_ids = tmp[\"input_ids\"].to_list()\n        attention_mask = tmp[\"attention_mask\"].to_list()\n        inputs = pad_without_fast_tokenizer_warning(\n            tokenizer,\n            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n            padding=\"longest\",\n            pad_to_multiple_of=None,\n            return_tensors=\"pt\",\n        )\n        outputs = model(**inputs.to(device))\n        proba = (outputs.logits / cfg.best_temp).softmax(-1).cpu()\n        \n        a_win.extend(proba[:, 0].tolist())\n        b_win.extend(proba[:, 1].tolist())\n        tie.extend(proba[:, 2].tolist())\n    \n    df[\"winner_model_a\"] = a_win\n    df[\"winner_model_b\"] = b_win\n    df[\"winner_tie\"] = tie\n    \n    return df","metadata":{"papermill":{"duration":0.026726,"end_time":"2024-07-10T01:15:27.838497","exception":false,"start_time":"2024-07-10T01:15:27.811771","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-19T20:15:49.53474Z","iopub.execute_input":"2024-11-19T20:15:49.535265Z","iopub.status.idle":"2024-11-19T20:15:49.542576Z","shell.execute_reply.started":"2024-11-19T20:15:49.535215Z","shell.execute_reply":"2024-11-19T20:15:49.541701Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"st = time.time()\n\n# sort by input length to fully leverage dynaminc padding\ndata = data.sort_values(\"length\", ascending=False)\n# the total #tokens in sub_1 and sub_2 should be more or less the same\nsub_1 = data.iloc[0::2].copy()\nsub_2 = data.iloc[1::2].copy()\n\nwith ThreadPoolExecutor(max_workers=2) as executor:\n    results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n\nresult_df = pd.concat(list(results), axis=0)\nproba = result_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values\n\nprint(f\"elapsed time: {time.time() - st}\")","metadata":{"papermill":{"duration":4.598663,"end_time":"2024-07-10T01:15:32.45234","exception":false,"start_time":"2024-07-10T01:15:27.853677","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-19T20:16:16.625202Z","iopub.execute_input":"2024-11-19T20:16:16.62552Z","iopub.status.idle":"2024-11-19T20:16:21.727777Z","shell.execute_reply.started":"2024-11-19T20:16:16.625494Z","shell.execute_reply":"2024-11-19T20:16:21.726801Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"st = time.time()\n\nif cfg.tta:\n    data = aug_data.sort_values(\"length\", ascending=False)  # sort by input length to boost speed\n    sub_1 = data.iloc[0::2].copy()\n    sub_2 = data.iloc[1::2].copy()\n\n    with ThreadPoolExecutor(max_workers=2) as executor:\n        results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n\n    tta_result_df = pd.concat(list(results), axis=0)\n    # recall TTA's order is flipped\n    tta_proba = tta_result_df[[\"winner_model_b\", \"winner_model_a\", \"winner_tie\"]].values \n    # average original result and TTA result.\n    #proba = (proba + tta_proba) / 2\n    proba = proba * 0.45 + tta_proba * 0.55\n\nprint(f\"elapsed time: {time.time() - st}\")","metadata":{"papermill":{"duration":0.024559,"end_time":"2024-07-10T01:15:32.491283","exception":false,"start_time":"2024-07-10T01:15:32.466724","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-19T20:16:21.729136Z","iopub.execute_input":"2024-11-19T20:16:21.729495Z","iopub.status.idle":"2024-11-19T20:16:26.021374Z","shell.execute_reply.started":"2024-11-19T20:16:21.729455Z","shell.execute_reply":"2024-11-19T20:16:26.020458Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result_df.loc[:, \"winner_model_a\"] = proba[:, 0]\nresult_df.loc[:, \"winner_model_b\"] = proba[:, 1]\nresult_df.loc[:, \"winner_tie\"] = proba[:, 2]\nresult_df[\"winner\"] = [\"model_a\" if i else \"model_b\" for i in proba[:, 0] > proba[:, 1]]\nresult_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T20:18:29.037194Z","iopub.execute_input":"2024-11-19T20:18:29.037571Z","iopub.status.idle":"2024-11-19T20:18:29.054016Z","shell.execute_reply.started":"2024-11-19T20:18:29.037536Z","shell.execute_reply":"2024-11-19T20:18:29.05313Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result_df[[\"id\", \"winner\"]].to_csv('submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub_df = pd.read_csv(\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/sample_submission.csv\")\nsub_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T20:17:25.475986Z","iopub.execute_input":"2024-11-19T20:17:25.476354Z","iopub.status.idle":"2024-11-19T20:17:25.486454Z","shell.execute_reply.started":"2024-11-19T20:17:25.476322Z","shell.execute_reply":"2024-11-19T20:17:25.485462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.read_csv(\"submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T20:19:28.779805Z","iopub.execute_input":"2024-11-19T20:19:28.780531Z","iopub.status.idle":"2024-11-19T20:19:28.789866Z","shell.execute_reply.started":"2024-11-19T20:19:28.780496Z","shell.execute_reply":"2024-11-19T20:19:28.788791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}