{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86946,"databundleVersionId":10131489,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# WSDM Cup - Multilingual Chatbot Arena: All you need is a decision tree\n\nThe Multilingual Chatbot Arena competition \"challenges you to predict which responses users will prefer in a head-to-head battle between chatbots powered by large language models.\"\n\nThis notebook shows what score we can get with a decision tree which looks at a single feature, the difference of the lengths of the two responses.\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T20:18:59.894357Z","iopub.execute_input":"2024-11-19T20:18:59.894795Z","iopub.status.idle":"2024-11-19T20:19:00.97264Z","shell.execute_reply.started":"2024-11-19T20:18:59.894759Z","shell.execute_reply":"2024-11-19T20:19:00.971051Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet')\ntest = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T20:19:00.97469Z","iopub.execute_input":"2024-11-19T20:19:00.975183Z","iopub.status.idle":"2024-11-19T20:19:03.0698Z","shell.execute_reply.started":"2024-11-19T20:19:00.97515Z","shell.execute_reply":"2024-11-19T20:19:03.068465Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We compute the single feature `len_b-len_a` as the difference in length of the two response strings.","metadata":{}},{"cell_type":"code","source":"def add_features(df):\n    df['len_a'] = df.response_a.str.len()\n    df['len_b'] = df.response_b.str.len()\n    df['len_b-len_a'] = df['len_b'] - df['len_a']\n    \nadd_features(train)\nadd_features(test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T20:19:03.071266Z","iopub.execute_input":"2024-11-19T20:19:03.071786Z","iopub.status.idle":"2024-11-19T20:19:03.204907Z","shell.execute_reply.started":"2024-11-19T20:19:03.071734Z","shell.execute_reply":"2024-11-19T20:19:03.203161Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We cross-validate decision trees of depth 1 through 7. Depth 3 gives the best cv score, and we plot the tree.","metadata":{}},{"cell_type":"code","source":"# Cross-validate\nfor max_depth in range(1, 7):\n    model = DecisionTreeClassifier(max_depth=max_depth)\n    print(f\"CV Accuracy with {max_depth=}: \"\n          f\"{cross_val_score(model, train[['len_b-len_a']], train['winner'], scoring='accuracy').mean():.3f}\")\n\n# Refit and plot the tree\nmodel = DecisionTreeClassifier(max_depth=3)\nmodel.fit(train[['len_b-len_a']], train['winner'])\nplt.figure(figsize=(15, 6))\nplot_tree(model, ax=plt.gca(), filled=True, impurity=False, proportion=True,\n          class_names=model.classes_, feature_names=model.feature_names_in_)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T20:21:41.59501Z","iopub.execute_input":"2024-11-19T20:21:41.595481Z","iopub.status.idle":"2024-11-19T20:21:45.928071Z","shell.execute_reply.started":"2024-11-19T20:21:41.59544Z","shell.execute_reply":"2024-11-19T20:21:45.926823Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Interpretation\n\nThe decision tree model can be summarized in the following statements:\n\n- `len_b < len_a - 8430`: Model B wins because the response of A is too long\n- `len_a - 8430 ≤ len_b < len_a - 15`: Model A wins because its response is longer\n- `len_a - 15 ≤ len_b < len_a + 8644`: Model B wins because its response is the same length or longer\n- `len_a + 8644 ≤ len_b`: Model A wins because the response of B is too long\n  \nIn other words:\n> - The longer response wins — unless the difference is too high: If the difference is greater than 8500, the shorter response wins.\n> - If the response lengths are almost the same, response B wins.\n\nNotice that the extreme cases where one response is too long are rare: They make up only 0.5 % of the samples on either end of the scale.","metadata":{}},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({'id': test.id,\n                           'winner': model.predict(test[['len_b-len_a']])})\nsubmission.to_csv('submission.csv', index=False)\n!head submission.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T20:19:07.191183Z","iopub.execute_input":"2024-11-19T20:19:07.19168Z","iopub.status.idle":"2024-11-19T20:19:08.457008Z","shell.execute_reply.started":"2024-11-19T20:19:07.191631Z","shell.execute_reply":"2024-11-19T20:19:08.454185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}