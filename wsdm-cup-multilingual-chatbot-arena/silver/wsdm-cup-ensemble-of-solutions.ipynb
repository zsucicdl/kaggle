{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86946,"databundleVersionId":10131489,"sourceType":"competition"},{"sourceId":208314140,"sourceType":"kernelVersion"},{"sourceId":208537924,"sourceType":"kernelVersion"}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"One of the [outstanding members](https://www.kaggle.com/cdeotte) of the Kaggle community, grandmaster, gives a link to his [**work**](https://www.kaggle.com/code/cdeotte/top-solutions-ensemble-0-947), where he shows the refinement of the prediction using an experimental example. Also, for a more \"subtle\" clarification, 2 more mechanisms will be added, based on the [works](https://www.kaggle.com/carlmcbrideellis/code) and experimental examples of the Norwegian [master](https://www.kaggle.com/ravaghi), and the [excellent works](https://www.kaggle.com/carlmcbrideellis/code) of the Spanish [grandmaster](https://www.kaggle.com/carlmcbrideellis), writer and active specialist in the field of ML. In order to try to refine our predictions at the [WSDM Cup - Multilingual Chatbot Arena](https://www.kaggle.com/competitions/wsdm-cup-multilingual-chatbot-arena/code?competitionId=86946&sortBy=scoreDescending&excludeNonAccessedDatasources=true) competition.\n\nThis approach - direct weighing, showed the following results: [Ariel](https://www.kaggle.com/competitions/ariel-data-challenge-2024/leaderboard) - 149[/](https://www.kaggle.com/code/vyacheslavbolotin/stat-ensemble-of-solutions)1152, [PS-S4 E10](https://www.kaggle.com/competitions/playground-series-s4e10/leaderboard) - 166[/](https://www.kaggle.com/code/vyacheslavbolotin/stat-ensemble-of-solutions)3859, [RSNA](https://www.kaggle.com/competitions/rsna-2024-lumbar-spine-degenerative-classification/leaderboard) - 283[/](https://www.kaggle.com/code/vyacheslavbolotin/stat-ensemble-of-solutions)1875, [ISIC](https://www.kaggle.com/competitions/isic-2024-challenge/leaderboard) - 83[/](https://www.kaggle.com/code/vyacheslavbolotin/stat-ensemble-of-solutions)2740, [Connect X](https://www.kaggle.com/competitions/connectx/leaderboard?) - 20[/](https://www.kaggle.com/code/vyacheslavbolotin/stat-ensemble-of-solutions)221. On average, ten percent in our Leaderboard's. In [PS-S4 E11](https://www.kaggle.com/competitions/playground-series-s4e11/code?competitionId=84895&sortBy=scoreDescending&excludeNonAccessedDatasources=true), on the 15th day from the start of the competition, he showed \"insufficiently stable behavior\" of public solutions, which gave rise to the [following hypothesis](https://www.kaggle.com/code/francescoliveras/ps-s4-e11-eda-model-en-es/comments), work in this direction continues.\n\nSo far, there is only one, direct approach has proven itself in the following competitions: 1. [ISIC 2024 - Skin Cancer Detection with 3D-TBP](https://www.kaggle.com/competitions/isic-2024-challenge/code?competitionId=63056&sortBy=scoreDescending&excludeNonAccessedDatasources=true), 2. [RSNA 2024 Lumbar Spine Degenerative Classification](https://www.kaggle.com/competitions/rsna-2024-lumbar-spine-degenerative-classification/code?competitionId=71549&sortBy=scoreAscending&excludeNonAccessedDatasources=true), 3. [NeurIPS - Ariel Data Challenge 2024](https://www.kaggle.com/competitions/ariel-data-challenge-2024/code?competitionId=70367&sortBy=scoreDescending&excludeNonAccessedDatasources=true), 4. [Child Mind Institute â€” Problematic Internet Use](https://www.kaggle.com/competitions/child-mind-institute-problematic-internet-use/code?competitionId=81933&sortBy=scoreDescending&excludeNonAccessedDatasources=true), 5. [BrisT1D Blood Glucose Prediction Competition](https://www.kaggle.com/competitions/brist1d/code?competitionId=82611&sortBy=scoreAscending&excludeNonAccessedDatasources=true), 6. [Eedi - Mining Misconceptions in Mathematics](https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/code?competitionId=82695&sortBy=scoreDescending&excludeNonAccessedDatasources=true), 7. [Connect X](https://www.kaggle.com/competitions/connectx/leaderboard?), 8. [Loan Approval Prediction {PS-S4.E10}](https://www.kaggle.com/competitions/brist1d/code), 9. [Jane Street Real-Time Market Data Forecasting](https://www.kaggle.com/competitions/jane-street-real-time-market-data-forecasting/code?competitionId=84493&sortBy=scoreDescending&excludeNonAccessedDatasources=true), 10. [UM - Game-Playing Strength of MCTS Variants](https://www.kaggle.com/competitions/um-game-playing-strength-of-mcts-variants/code?competitionId=70089&sortBy=scoreAscending&excludeNonAccessedDatasources=true), 11. [Exploring Mental Health Data {PS-S4.E11}](https://www.kaggle.com/competitions/playground-series-s4e11/code?competitionId=84895&sortBy=scoreDescending&excludeNonAccessedDatasources=true), 12. [WSDM Cup - Multilingual Chatbot Arena](https://www.kaggle.com/competitions/wsdm-cup-multilingual-chatbot-arena/code?competitionId=86946&sortBy=scoreDescending&excludeNonAccessedDatasources=true), 14. [FIDE & Google Efficient Chess AI Challenge](https://www.kaggle.com/competitions/fide-google-efficiency-chess-ai-challenge/leaderboard)\n\nAnd accordingly in the following notebooks: 1. [ISIC | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/isic-2024-ensemble-of-solutions), 2. [RSNA | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/rsna-ensemble-of-solutions), 3. [Ariel | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/ariel-ensemble-of-solutions), 4. [CMI | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/cmi-ensemble-of-solutions), 5. [*BrisT1D* | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/brist1d-ensemble-of-solutions), 6. [Eedi | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/eedi-ensemble-of-solutions), 7. [agents Connect X](https://www.kaggle.com/code/vyacheslavbolotin/agents-connect-x), 8. [PS-S4.E10 | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/pss4e10-ensemble-of-solutions), 9. [Jane Street | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/jane-street-ensemble-of-solutions), 10. [MCTS | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/mcts-ensemble-of-solutions/), 11. [PS-S4.E11 | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/ps-s4-e11-ensemble-of-solutions), 12. [WSDM Cup | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions), 14. [Chess | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/chess-ensemble-of-solutions/)\n\n#### WSDM Cup - Multilingual Chatbot Arena | Ensemble of solutions:\n* &nbsp;&nbsp;**[1]()**. Lb=[0.63](https://www.kaggle.com/code/mbmmurad/gemma-2-9b-4-bit-qlora-lb-0-63), Bangladesh [Gemma-2 9b 4-bit QLoRA - LB 0.63](https://www.kaggle.com/code/mbmmurad/gemma-2-9b-4-bit-qlora-lb-0-63), by master [Md Boktiar Mahbub Murad](https://www.kaggle.com/mbmmurad)\n* &nbsp;&nbsp;**[2]()**. Lb=[0.61](https://www.kaggle.com/code/pietromaldini1/multilingual-chatbot-arena-challenge-baseline), Italy [Multilingual chatbot arena challenge baseline](https://www.kaggle.com/code/pietromaldini1/multilingual-chatbot-arena-challenge-baseline), by expert [Pietro Maldini](https://www.kaggle.com/pietromaldini1)\n* &nbsp;&nbsp;**[3]()**. Lb=[0.61](https://www.kaggle.com/code/yekenot/wsdm-ancient-baseline), Russia [WSDM: Ancient Baseline](https://www.kaggle.com/code/yekenot/wsdm-ancient-baseline), by master [Vladimir Demidov](https://www.kaggle.com/yekenot)\n* &nbsp;&nbsp;**[4]()**. Lb=[0.61](), China [WSDM Yunbase](https://www.kaggle.com/code/yunsuxiaozi/wsdm-yunbase), by master [yunsuxiaozi](https://www.kaggle.com/yunsuxiaozi)\n* &nbsp;&nbsp;**[5]()**. Lb=[0.61](), World [WSDM: Tfidf - LightGBM](https://www.kaggle.com/code/jiaoyouzhang/wsdm-tfidf-lightgbm), by contributor [JYZ](https://www.kaggle.com/jiaoyouzhang)\n* &nbsp;&nbsp;**[6]()**. Lb=[0.62](), Pakistan [WSDM || AbdBase || V2](https://www.kaggle.com/code/abdmental01/wsdm-abdbase-v2), by grandmaster [Sheikh Muhammad Abdullah](https://www.kaggle.com/abdmental01)\n\n\n#### options\n- Lb=[0.60](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=208509524) &nbsp;&nbsp;option.1, &nbsp;&nbsp;[v1](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=208509524) -> solutions.( [**2**](),[**3**]() ), &nbsp;[[0.61]()+[0.61]()]\n- Lb=[0.61](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=208520286) &nbsp;&nbsp;option.2, &nbsp;&nbsp;[v2](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=208520286) -> solutions.( [**2**](),[**4**]() ), &nbsp;[[0.61]()+[0.61]()]\n- Lb=[0.61](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=208528225) &nbsp;&nbsp;option.3, &nbsp;&nbsp;[v3](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=208528225) -> solutions.( [**3**](),[**4**]() ), &nbsp;[[0.61]()+[0.61]()]\n- \n- Lb=[0.62](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=208544699) &nbsp;&nbsp;option.4, &nbsp;&nbsp;[v4](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=208544699) -> solutions.( [**2**](),[**3**](),[**4**]() ), &nbsp;[[0.61]()+[0.61]()+[0.61]()] best.**2**\n- \n- Lb=[0.62](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=208605221) &nbsp;&nbsp;option.5, &nbsp;&nbsp;[v5](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=208605221) -> solutions.( [**2**](),[**3**](),[**4**](),[**5**]() ), &nbsp;[[0.61]()+[0.61]()+[0.61]()+[0.61]()]\n- \n- Lb=[0,62](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=209066709) &nbsp;&nbsp;option.6, &nbsp;&nbsp;[v6](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=209066709) -> solutions.( [**3**](),[**4**](),[**5**](),[**6**]() ), &nbsp;[[0.61]()+[0.61]()+[0.61]()+[0.62]()]\n- Lb=[0,62](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=209066839) &nbsp;&nbsp;option.7, &nbsp;&nbsp;[v7](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=209066839) -> solutions.( [**2**](),[**4**](),[**5**](),[**6**]() ), &nbsp;[[0.61]()+[0.61]()+[0.61]()+[0.62]()]\n- Lb=[0.61](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=209066921) &nbsp;&nbsp;option.8, &nbsp;&nbsp;[v8](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=209066921) -> solutions.( [**2**](),[**3**](),[**5**](),[**6**]() ), &nbsp;[[0.61]()+[0.61]()+[0.61]()+[0.62]()]\n- Lb=[0.62](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=209066992) &nbsp;&nbsp;option.9, &nbsp;&nbsp;[v9](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=209066992) -> solutions.( [**2**](),[**3**](),[**4**](),[**6**]() ), &nbsp;[[0.61]()+[0.61]()+[0.61]()+[0.62]()] best.**3**\n- \n- Lb=[0.62](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=209077361) &nbsp;&nbsp;option.10, &nbsp;&nbsp;[v10](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=209077361) -> solutions.( [**3**](),[**4**](),[**6**]() ), &nbsp;[[0.61]()+[0.61]()+[0.62]()] best.**1**\n\n#### some rezults\n- v3 < v2 < v5 < v9 < v4 < v10\n\n#### best option\n- Lb=[0.62](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=209077361) &nbsp;&nbsp;option.10, &nbsp;&nbsp;[v10](https://www.kaggle.com/code/vyacheslavbolotin/wsdm-cup-ensemble-of-solutions?scriptVersionId=209077361) -> solutions.( [**3**](),[**4**](),[**6**]() ), &nbsp;[[0.61]()+[0.61]()+[0.62]()]\n\n#### current options\n- Lb=**?** &nbsp;&nbsp;option.11, &nbsp;&nbsp;v11 -> solutions.( [**2**](),[**3**](),[**4**](),[**5**](),[**6**]() ), &nbsp;[[0.61]()+[0.61]()+[0.61]()+[0.61]()+[0.62]()]\n\n#### next options\n- Lb=**?** &nbsp;&nbsp;option.12, &nbsp;&nbsp;v12 -> solutions.( [**1**](),[**2**](),[**3**](),[**4**](),[**5**]() ), &nbsp;[[0.63]()+[0.61]()+[0.61]()+[0.61]()+[0.61]()]","metadata":{}},{"cell_type":"code","source":"OPTION             = 'option 11'\nFILES_SUBM         = ['subm_2.csv','subm_3.csv','subm_4.csv','subm_5.csv','subm_6.csv'] # Lb=?\nENSEMBLE_SOLUTIONS = ['SOLUTION_2','SOLUTION_3','SOLUTION_4','SOLUTION_5','SOLUTION_6']","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def ensemble_of_solutions(\n        option     = OPTION,\n        solutions  = ENSEMBLE_SOLUTIONS,\n        files_subm = FILES_SUBM):\n    \n    smA = pd.read_csv(files_subm[0])\n    smB = pd.read_csv(files_subm[1]).drop(['id'], axis=1)\n    smC = pd.read_csv(files_subm[2]).drop(['id'], axis=1)\n    smD = pd.read_csv(files_subm[3]).drop(['id'], axis=1)\n    smE = pd.read_csv(files_subm[4]).drop(['id'], axis=1)\n    \n    smA = smA.rename(columns={\"winner\": 'winner_A'})\n    smB = smB.rename(columns={'winner': 'winner_B'})\n    smC = smC.rename(columns={'winner': 'winner_C'})\n    smD = smD.rename(columns={'winner': 'winner_D'})\n    smE = smE.rename(columns={'winner': 'winner_E'})\n   \n    sms = pd.concat([smA,smB,smC,smD,smE],axis=1)\n    \n    display(sms)\n\n    sms['winner'] = sms[['winner_A','winner_B','winner_C','winner_D','winner_E']].mode(axis=1)[0]\n    \n    return sms, option,solutions","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. [Gemma-2 9b 4-bit QLoRA - LB 0.63](https://www.kaggle.com/code/mbmmurad/gemma-2-9b-4-bit-qlora-lb-0-63), Lb=0.63\n## [Md Boktiar Mahbub Murad](https://www.kaggle.com/mbmmurad)","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS: pass","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. [Multilingual chatbot arena challenge baseline](https://www.kaggle.com/code/pietromaldini1/multilingual-chatbot-arena-challenge-baseline), Lb=0.61\n### [Pietro Maldini](https://www.kaggle.com/pietromaldini1)","metadata":{}},{"cell_type":"markdown","source":"#### This notebook is a really simple idea of a possible baseline for the competition.\n\nThe solution highlights how some particular aspects of the prompt and the responses can help getting better result than the always choosing model_a/model_b strategy.\n\nThe notebook can be worked on and improved, as well as the model that could be tuned and optimized, and additional models could be tested.\n\nI want this notebook to be an easy starting point for those that want to use feature of the text for their modelling.\n\nFeel free to comment your opinions or to fork the notebook and try out additional features!","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"markdown","source":"### Imports","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    import numpy as np\n    import pandas as pd \n    from sklearn.model_selection import train_test_split\n    from lightgbm import early_stopping,log_evaluation,LGBMClassifier\n    from sklearn.pipeline import FeatureUnion\n    from sklearn.compose import ColumnTransformer\n    from sklearn.feature_extraction.text import TfidfVectorizer\n    from sklearn.linear_model import LogisticRegression","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Data Loading","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    path  = \"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/\"\n    train = pd.read_parquet(path+\"train.parquet\")\n    test  = pd.read_parquet(path+\"test.parquet\")\n    sub   = pd.read_csv    (path+\"sample_submission.csv\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    train.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Data split and feature calculation","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    # 10% as validation split, this percentage could be changed\n    train,valid=train_test_split(train,test_size=0.1,stratify=train[\"winner\"],random_state=161194)\n\n    # Train set can be inverted (and winner too) to get twice the data from the available training dataset\n    train_inv=train.copy()\n    train_inv[\"response_a\"],train_inv[\"response_b\"]=train_inv[\"response_b\"],train_inv[\"response_a\"]\n    train_inv[\"winner\"]=train_inv[\"winner\"].apply(lambda x: \"model_a\" if \"b\" in x else \"model_b\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    # Here I compute some features\n    def compute_feats(df):\n        for col in [\"response_a\",\"response_b\",\"prompt\"]:\n            # response lenght is a key factor when choosing between two responses\n            df[f\"{col}_len\"]=df[f\"{col}\"].str.len()\n\n            # Some characters counting features \n            df[f\"{col}_spaces\"]=df[f\"{col}\"].str.count(\"\\s\")\n            df[f\"{col}_punct\"]=df[f\"{col}\"].str.count(\",|\\.|!\")\n            df[f\"{col}_question_mark\"]=df[f\"{col}\"].str.count(\"\\?\")\n            df[f\"{col}_quot\"]=df[f\"{col}\"].str.count(\"'|\\\"\")\n            df[f\"{col}_formatting_chars\"]=df[f\"{col}\"].str.count(\"\\*|\\_\")\n            df[f\"{col}_math_chars\"]=df[f\"{col}\"].str.count(\"\\-|\\+|\\=\")\n            df[f\"{col}_curly_open\"]=df[f\"{col}\"].str.count(\"\\{\")\n            df[f\"{col}_curly_close\"]=df[f\"{col}\"].str.count(\"}\")\n            df[f\"{col}_round_open\"]=df[f\"{col}\"].str.count(\"\\(\")\n            df[f\"{col}_round_close\"]=df[f\"{col}\"].str.count(\"\\)\")\n            df[f\"{col}_special_chars\"]=df[f\"{col}\"].str.count(\"\\W\")\n            df[f\"{col}_digits\"]=df[f\"{col}\"].str.count(\"\\d\")>0\n            df[f\"{col}_lower\"]=df[f\"{col}\"].str.count(\"[a-z]\").astype(\"float32\")/df[f\"{col}_len\"]\n            df[f\"{col}_upper\"]=df[f\"{col}\"].str.count(\"[A-Z]\").astype(\"float32\")/df[f\"{col}_len\"]\n            df[f\"{col}_chinese\"]=df[f\"{col}\"].str.count(r'[\\u4e00-\\u9fff]+').astype(\"float32\")/df[f\"{col}_len\"]\n\n            # Feature that show how balanced are curly and round brackets\n            df[f\"{col}_round_balance\"]=df[f\"{col}_round_open\"]-df[f\"{col}_round_close\"]\n            df[f\"{col}_curly_balance\"]=df[f\"{col}_curly_open\"]-df[f\"{col}_curly_close\"]\n\n            # Feature that tells if the string json is present somewhere (e.g. asking a json response or similar)\n            # This for example could be expanded also to yaml, but analyses on train set are required to see if enough data is present for this to be really useful\n            df[f\"{col}_json\"]=df[f\"{col}\"].str.lower().str.count(\"json\")\n        return df\n    train=compute_feats(train)\n    train_inv=compute_feats(train_inv)\n\n    train=pd.concat([train,train_inv])\n    valid=compute_feats(valid)\n    test=compute_feats(test)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Ancient Baseline from notebook [WSDM: Ancient Baseline](https://www.kaggle.com/code/yekenot/wsdm-ancient-baseline) \nPlease go and like the notebook","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    vectorizer_char = TfidfVectorizer(sublinear_tf=True, analyzer='char', ngram_range=(1,2), max_features=100_000)\n    vectorizer_word = TfidfVectorizer(sublinear_tf=True, analyzer='word', min_df=3)\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('prompt_feats', FeatureUnion([\n                ('prompt_char', vectorizer_char),\n                ('prompt_word', vectorizer_word)\n            ]), 'prompt'),\n            ('response_a_feats', FeatureUnion([\n                ('response_a_char', vectorizer_char),\n                ('response_a_word', vectorizer_word)\n            ]), 'response_a'),\n            ('response_b_feats', FeatureUnion([\n                ('response_b_char', vectorizer_char),\n                ('response_b_word', vectorizer_word)\n            ]), 'response_b')\n        ]\n    )\n    train_feats = preprocessor.fit_transform(train[[\"response_a\",\"response_b\",\"prompt\"]])\n    test_feats = preprocessor.transform(test[[\"response_a\",\"response_b\",\"prompt\"]])\n    valid_feats = preprocessor.transform(valid[[\"response_a\",\"response_b\",\"prompt\"]])","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    model = LogisticRegression(C=0.1, solver='liblinear', dual=True, random_state=42)\n    model.fit(train_feats, train.winner)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:    \n    \n    model.predict_proba(test_feats)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Prepare Data for training","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    train.columns","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    feats=list(train.columns)[8:]\n    train[\"winner\"]=(train[\"winner\"]==\"model_a\").astype(\"int\")\n    valid[\"winner\"]=(valid[\"winner\"]==\"model_a\").astype(\"int\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    X=train[feats]\n    y=train[\"winner\"]\n\n    X_val=valid[feats]\n    y_val=valid[\"winner\"]","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model training","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    def get_callbacks():\n        return [early_stopping(100),log_evaluation(1)]\n\n    model=LGBMClassifier(n_estimators=1000,learning_rate=0.1)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    history=model.fit(X,y,eval_set=(X_val,y_val),eval_metric=\"binary_error\",callbacks=get_callbacks())","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Prediction","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    X_test=test[feats]","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test[\"winner\"]=model.predict(X_test)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test[\"winner\"]=test[\"winner\"].apply(lambda x: \"model_a\" if x==1 else \"model_b\")\n\n    sub=test[[\"id\",\"winner\"]]","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    sub.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Submission","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    sub.to_csv(\"subm_2.csv\",index=False)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. [WSDM: Ancient Baseline](https://www.kaggle.com/code/yekenot/wsdm-ancient-baseline), Lb=0.61\n### [Vladimir Demidov](https://www.kaggle.com/yekenot)","metadata":{}},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    import pandas as pd\n    from sklearn.pipeline import FeatureUnion\n    from sklearn.compose import ColumnTransformer\n    from sklearn.model_selection import cross_val_score\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    path = \"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/\"\n    train = pd.read_parquet(path+\"train.parquet\")\n    test = pd.read_parquet(path+\"test.parquet\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n    \nif 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    vectorizer_char = TfidfVectorizer(sublinear_tf=True, analyzer='char', ngram_range=(1,2), max_features=100_000)\n    vectorizer_word = TfidfVectorizer(sublinear_tf=True, analyzer='word', min_df=3)\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('prompt_feats', FeatureUnion([\n                ('prompt_char', vectorizer_char),\n                ('prompt_word', vectorizer_word)\n            ]), 'prompt'),\n            ('response_a_feats', FeatureUnion([\n                ('response_a_char', vectorizer_char),\n                ('response_a_word', vectorizer_word)\n            ]), 'response_a'),\n            ('response_b_feats', FeatureUnion([\n                ('response_b_char', vectorizer_char),\n                ('response_b_word', vectorizer_word)\n            ]), 'response_b')\n        ]\n    )\n    train_feats = preprocessor.fit_transform(train)\n    test_feats = preprocessor.transform(test)\n    print(train_feats.shape)\n    print(test_feats.shape)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\nif 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n\n    model = LogisticRegression(C=0.1, solver='liblinear', dual=True, random_state=42)\n    model.fit(train_feats, train.winner)\n    accuracy_scores = cross_val_score(model, train_feats, train.winner, cv=3, scoring='accuracy')\n    print(f'Accuracy scores for each fold: {accuracy_scores}')\n    print(f'Mean accuracy: {accuracy_scores.mean():.4f}')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    test['winner'] = model.predict(test_feats)\n    test[['id','winner']].to_csv('subm_3.csv', index=False)\n    test[['id','winner']]","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. [WSDM Yunbase](https://www.kaggle.com/code/yunsuxiaozi/wsdm-yunbase), Lb=0.61\n### [yunsuxiaozi](https://www.kaggle.com/yunsuxiaozi)","metadata":{}},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n\n    source_file_path = '/kaggle/input/yunbase/Yunbase/baseline.py'\n    target_file_path = '/kaggle/working/baseline.py'\n    with open(source_file_path, 'r', encoding='utf-8') as file:\n        content = file.read()\n    with open(target_file_path, 'w', encoding='utf-8') as file:\n        file.write(content)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n    \n    !pip install -q --requirement /kaggle/input/yunbase/Yunbase/requirements.txt  \\\n    --no-index --find-links file:/kaggle/input/yunbase/","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n    \n    from baseline import Yunbase\n\n    import polars as pl#similar to pandas, but with better performance when dealing with large datasets.\n    import pandas as pd#read csv,parquet\n    import numpy as np#for scientific computation of matrices\n    from  lightgbm import LGBMClassifier,log_evaluation,early_stopping\n    import warnings#avoid some negligible errors\n    #The filterwarnings () method is used to set warning filters, which can control the output method and level of warning information.\n    warnings.filterwarnings('ignore')\n\n    import random#provide some function to generate random_seed.\n    #set random seed,to make sure model can be recurrented.\n    def seed_everything(seed):\n        np.random.seed(seed)#numpy's random seed\n        random.seed(seed)#python built-in random seed\n    seed_everything(seed=2024)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n    \n    yunbase=Yunbase(num_folds=10,\n                      models=[(LGBMClassifier(n_estimators=1024),'lgb')],\n                      seed=2024,\n                      drop_cols=['model_a','model_b','language','scored'],\n                      objective='binary',\n                      metric='accuracy',\n                      nan_margin=0.95,\n                      num_classes=2,\n                      target_col='winner',\n                      infer_size=10000,\n                      save_oof_preds=True,\n                      save_test_preds=True,\n                      device='cpu',\n                      early_stop=100,\n                      text_cols=['prompt','response_a','response_b'],\n                      plot_feature_importance=True,\n                      use_reduce_memory=True,\n                      AGGREGATIONS=['nunique','count','min','max','first',\n                                           'last', 'mean','median','sum','std','skew']\n    )\n    train=pd.read_parquet(\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet\")\n    test=pd.read_parquet(\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet\")\n    yunbase.fit(train)\n    test_preds=yunbase.predict(test)\n    yunbase.submit(\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/sample_submission.csv\",\n                   save_name='subm_4',test_preds=test_preds)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. [WSDM: Tfidf - LightGBM](https://www.kaggle.com/code/jiaoyouzhang/wsdm-tfidf-lightgbm), Lb=0.61\n### [JYZ](https://www.kaggle.com/jiaoyouzhang)","metadata":{}},{"cell_type":"markdown","source":"#### The model parameters were obtained using Optuna.\n \nhttps://www.kaggle.com/code/jiaoyouzhang/wsdm-tf-idf-lightgbm-optuna?scriptVersionId=208417125","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    \n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.feature_extraction.text import TfidfVectorizer\n    from sklearn.compose import ColumnTransformer\n    from sklearn.metrics import accuracy_score\n    import lightgbm as lgb\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n    from sklearn.preprocessing import LabelEncoder","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    \n    train = pd.read_parquet(\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet\")\n    test = pd.read_parquet(\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    \n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('prompt_feats',     TfidfVectorizer(analyzer = 'char_wb',max_features=1000), 'prompt'),\n            ('response_a_feats', TfidfVectorizer(analyzer = 'char_wb',max_features=1000), 'response_a'),\n            ('response_b_feats', TfidfVectorizer(analyzer = 'char_wb',max_features=1000), 'response_b')\n        ]\n    )\n\n    train_tfidf = preprocessor.fit_transform(train)\n    test_tfidf = preprocessor.transform(test)\n    train['winner'] = train['winner'].map({\"model_a\": 0, \"model_b\": 1})","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    \n    ######################################################################\n    num_features = train_tfidf.shape[1]\n    new_columns = [f\"tfidf{i+1}\" for i in range(num_features)]\n\n    train_tfidf = pd.DataFrame(train_tfidf.toarray(), columns=new_columns)\n    train['response_a_len']=train['response_a'].apply(len)\n    train['response_b_len']=train['response_b'].apply(len)\n    train_tfidf = pd.concat([train[['response_a_len','response_b_len']],train_tfidf], axis=1)\n\n\n    test_tfidf = pd.DataFrame(test_tfidf.toarray(), columns=new_columns)\n    test['response_a_len']=test['response_a'].apply(len)\n    test['response_b_len']=test['response_b'].apply(len)\n    test_tfidf = pd.concat([test[['response_a_len','response_b_len']],test_tfidf], axis=1)\n    #print(train_tfidf.columns.value_counts())\n    #print(test_tfidf.columns.value_counts())\n    ######################################################################","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    \n    X=train_tfidf\n    y=train['winner']","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    \n    param = {\n        'num_leaves'   : 128, \n        'max_depth'    : 2, \n        'learning_rate': 0.03, \n        'n_estimators' : 2671, \n        'reg_alpha'    : 10.0, \n        'reg_lambda'   : 0.01,\n        'random_state' : 2024, \n        'verbose'      : -1\n    }\n\n    model = lgb.LGBMClassifier(**param)\n    model.fit(X,y)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    \n    y_pred = model.predict(test_tfidf)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    \n    y_pred_labels = ['model_a' if label == 0 else 'model_b' for label in y_pred]","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    \n    submission = pd.DataFrame({'id': test['id'], 'winner': y_pred_labels})\n    submission .to_csv('subm_5.csv', index=False)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. [WSDM || AbdBase || V2](https://www.kaggle.com/code/abdmental01/wsdm-abdbase-v2), Lb=0.62\n### [Sheikh Muhammad Abdullah](https://www.kaggle.com/abdmental01)","metadata":{}},{"cell_type":"code","source":"if 'SOLUTION_6' in ENSEMBLE_SOLUTIONS:\n\n    import numpy as np\n    import polars as pl\n    import pandas as pd\n\n    from sklearn.base import clone\n    import optuna\n    import os\n\n    from tqdm import tqdm\n    import category_encoders as ce\n    from IPython.display import clear_output\n    from scipy.sparse import hstack\n\n    from sklearn.decomposition import TruncatedSVD\n    from sklearn.feature_extraction.text import TfidfVectorizer\n    from nltk.corpus import stopwords\n    import nltk\n    import string\n\n    import warnings\n    warnings.filterwarnings('ignore')\n    pd.options.display.max_columns = None\n\n    import lightgbm as lgb\n    from lightgbm import early_stopping  \n    from catboost import CatBoostRegressor, CatBoostClassifier, Pool\n    from sklearn.model_selection import *\n    from sklearn.metrics import *\n\n    SEED = 42\n    n_splits = 5","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_6' in ENSEMBLE_SOLUTIONS:\n\n    sp = '/kaggle/input/abdbase/AbdML/main.py'\n    tp = '/kaggle/working/main.py'\n\n    with open(sp, 'r', encoding='utf-8') as file:\n        content = file.read()\n    with open(tp, 'w', encoding='utf-8') as file:\n        file.write(content)\n\n    from main import AbdBase\n\n    train = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet')\n    test = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet')\n    sample = pd.read_csv('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/sample_submission.csv')\n\n    train['winner'] = train['winner'].map({\"model_a\": 0, \"model_b\": 1})\n    drop_cols = ['model_a', 'model_b', 'language', 'scored']\n\n    train = train.drop(columns=drop_cols, errors='ignore')\n    test = test.drop(columns=drop_cols, errors='ignore')\n\n    train['id'] = train['id'].astype('category')\n    test['id'] = test['id'].astype('category')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_6' in ENSEMBLE_SOLUTIONS:\n\n    stop_words = set(stopwords.words('english'))\n\n    def text_stat(df, txt_col):\n        for col in tqdm(txt_col, desc=\"Processing text columns\"):\n            df[f'{col}_length'] = df[col].apply(len)\n            df[f'{col}_word_count'] = df[col].apply(lambda x: len(x.split()))\n            df[f'{col}_char_count'] = df[col].apply(lambda x: sum([len(word) for word in x.split()]))\n            df[f'{col}_avg_word_length'] = df[f'{col}_char_count'] / df[f'{col}_word_count']\n\n            df[f'{col}_punctuation_count'] = df[col].apply(lambda x: sum([1 for char in x if char in string.punctuation]))\n            df[f'{col}_capitalized_count'] = df[col].apply(lambda x: sum([1 for word in x.split() if word.isupper()]))\n            df[f'{col}_special_char_count'] = df[col].apply(lambda x: sum([1 for char in x if not char.isalnum() and not char.isspace()]))\n            df[f'{col}_stopwords_count'] = df[col].apply(lambda x: len([word for word in x.split() if word.lower() in stop_words]))\n            df[f'{col}_unique_word_count'] = df[col].apply(lambda x: len(set(x.split())))\n            df[f'{col}_lexical_diversity'] = df[f'{col}_unique_word_count'] / df[f'{col}_word_count']\n\n        return df\n\n    txt_col = ['prompt', 'response_a', 'response_b']\n\n    train = text_stat(train, txt_col)\n    test = text_stat(test, txt_col)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_6' in ENSEMBLE_SOLUTIONS:\n\n    def tf_fe(train, test, text_columns, max_features=3000, analyzer='char_wb'):\n\n        train_features = []\n        test_features = []\n\n        for col in tqdm(text_columns, desc=\"Processing text columns\", unit=\"col\"):\n            vectorizer = TfidfVectorizer(analyzer=analyzer, max_features=max_features)\n            train_tfidf_col = vectorizer.fit_transform(train[col])\n            test_tfidf_col = vectorizer.transform(test[col])\n            train_tfidf_col = pd.DataFrame(train_tfidf_col.toarray(), columns=[f\"tfidf_{col}_{i}\" for i in range(train_tfidf_col.shape[1])])\n            test_tfidf_col = pd.DataFrame(test_tfidf_col.toarray(), columns=[f\"tfidf_{col}_{i}\" for i in range(test_tfidf_col.shape[1])])\n            train_features.append(train_tfidf_col)\n            test_features.append(test_tfidf_col)\n\n        train_with_tfidf = pd.concat([train, *train_features], axis=1)\n        test_with_tfidf = pd.concat([test, *test_features], axis=1)\n\n        return train_with_tfidf, test_with_tfidf\n\n    txt_col = ['prompt', 'response_a', 'response_b']\n    train, test = tf_fe(train, test, txt_col)\n\n    train = train.drop(columns=txt_col, errors='ignore')\n    test = test.drop(columns=txt_col, errors='ignore')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_6' in ENSEMBLE_SOLUTIONS:\n\n    SEED = 42\n\n    base = AbdBase(train_data=train, test_data=test, target_column='winner',gpu=False,\n                     problem_type=\"classification\", metric=\"accuracy\", seed=SEED,\n                     n_splits=5,early_stop=True,num_classes=2,prob=False,\n                     fold_type='SKF',weights=None,tf_vec=False)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_6' in ENSEMBLE_SOLUTIONS:\n\n    Params = {'n_estimators': 3642, 'learning_rate': 0.01518747922672247, 'max_depth': 8, 'num_leaves': 31,'n_jobs':-1,\n              'min_child_samples': 56, 'subsample': 0.8570351922786027, 'colsample_bytree': 0.639934756431672,\n              'lambda_l1': 1.0677482709481354, 'lambda_l2': 1.5304852121831465, 'min_gain_to_split': 0.013935123815999317}\n\n    meanOFFL, meanTestL = base.Train_ML(Params,'LGBM',e_stop=40)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'SOLUTION_6' in ENSEMBLE_SOLUTIONS:\n\n    sample['winner'] = np.round(meanTestL).astype('int')\n    sample['winner'] = sample['winner'].map({0: 'model_a', 1: 'model_b'})\n\n    sample.to_csv('subm_6.csv', index = False)\n    sample.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ensemble & submit","metadata":{}},{"cell_type":"code","source":"sms, option,solutions = ensemble_of_solutions()\n\nprint(solutions)\n\nsub = sms[['id','winner']]\nsub.to_csv('submission.csv', index=False)\nsub","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Archive\n\n#OPTION             = 'option 6'\n#FILES_SUBM         = ['subm_3.csv','subm_4.csv','subm_5.csv','subm_6.csv'] # Lb=?\n#ENSEMBLE_SOLUTIONS = ['SOLUTION_3','SOLUTION_4','SOLUTION_5','SOLUTION_6']\n\n#OPTION             = 'option 7'\n#FILES_SUBM         = ['subm_2.csv','subm_4.csv','subm_5.csv','subm_6.csv'] # Lb=?\n#ENSEMBLE_SOLUTIONS = ['SOLUTION_2','SOLUTION_4','SOLUTION_5','SOLUTION_6']\n\n#OPTION             = 'option 8'\n#FILES_SUBM         = ['subm_2.csv','subm_3.csv','subm_5.csv','subm_6.csv'] # Lb=?\n#ENSEMBLE_SOLUTIONS = ['SOLUTION_2','SOLUTION_3','SOLUTION_5','SOLUTION_6']\n\n# OPTION             = 'option 9'\n# FILES_SUBM         = ['subm_2.csv','subm_3.csv','subm_4.csv','subm_6.csv'] # Lb=?\n# ENSEMBLE_SOLUTIONS = ['SOLUTION_2','SOLUTION_3','SOLUTION_4','SOLUTION_6']\n\n#OPTION             = 'option 10'\n#FILES_SUBM         = ['subm_2.csv','subm_3.csv','subm_4.csv','subm_5.csv','subm_6.csv'] # Lb=?\n#ENSEMBLE_SOLUTIONS = ['SOLUTION_2','SOLUTION_3','SOLUTION_4','SOLUTION_5','SOLUTION_6']\n\n#OPTION             = 'option 11'\n#FILES_SUBM         = ['subm_1.csv','subm_2.csv','subm_3.csv','subm_4.csv','subm_5.csv']\n#ENSEMBLE_SOLUTIONS = ['SOLUTION_1','SOLUTION_2','SOLUTION_3','SOLUTION_4','SOLUTION_5']\n\n\n\n#FILES_SUBM, OPTION = ['subm_2.csv','subm_3.csv'],'option 1'                           # Lb=0.60\n#ENSEMBLE_SOLUTIONS = ['SOLUTION_2','SOLUTION_3']\n\n#FILES_SUBM, OPTION = ['subm_2.csv','subm_4.csv'],'option 2'                           # Lb=0.61\n#ENSEMBLE_SOLUTIONS = ['SOLUTION_2','SOLUTION_4']\n\n#FILES_SUBM, OPTION = ['subm_3.csv','subm_4.csv'],'option 3'                           # Lb=0.61\n#ENSEMBLE_SOLUTIONS = ['SOLUTION_3','SOLUTION_4']\n\n#FILES_SUBM, OPTION = ['subm_2.csv','subm_3.csv','subm_4.csv'],'option 4'              # Lb=0.62\n#ENSEMBLE_SOLUTIONS = ['SOLUTION_2','SOLUTION_3','SOLUTION_4']\n\n#FILES_SUBM, OPTION = ['subm_2.csv','subm_3.csv','subm_4.csv','subm_5.csv'],'option 5' # Lb=0.62\n#ENSEMBLE_SOLUTIONS = ['SOLUTION_2','SOLUTION_3','SOLUTION_4','SOLUTION_5']\n\n#OPTION = 'option 6'\n#FILES_SUBM         = ['subm_1.csv','subm_2.csv','subm_3.csv','subm_4.csv','subm_5.csv']\n#ENSEMBLE_SOLUTIONS = ['SOLUTION_1','SOLUTION_2','SOLUTION_3','SOLUTION_4','SOLUTION_5']\n\n# def ensemble_of_solutions(\n#         option     = OPTION,\n#         solutions  = ENSEMBLE_SOLUTIONS,\n#         files_subm = FILES_SUBM):\n    \n#     smA = pd.read_csv(files_subm[0])\n#     smB = pd.read_csv(files_subm[1])\n    \n#     smA = smA.rename(columns={\"winner\": 'winner_A'})\n#     smB = smB.rename(columns={'winner': 'winner_B'})\n   \n#     sms = pd.merge(smA,smB, on=[\"id\"])\n    \n#     display(sms)\n\n#     sms['winner'] = sms[['winner_A','winner_B']].mode(axis=1)[0]\n    \n#     return sms, option,solutions\n\n# - - - - - - - - - - - - - - - - - - - - -\n\n# def ensemble_of_solutions(\n#         option     = OPTION,\n#         solutions  = ENSEMBLE_SOLUTIONS,\n#         files_subm = FILES_SUBM):\n    \n#     smA = pd.read_csv(files_subm[0])\n#     smB = pd.read_csv(files_subm[1]).drop(['id'], axis=1)\n#     smC = pd.read_csv(files_subm[2]).drop(['id'], axis=1)\n#     smD = pd.read_csv(files_subm[3]).drop(['id'], axis=1)\n    \n#     smA = smA.rename(columns={\"winner\": 'winner_A'})\n#     smB = smB.rename(columns={'winner': 'winner_B'})\n#     smC = smC.rename(columns={'winner': 'winner_C'})\n#     smD = smD.rename(columns={'winner': 'winner_D'})\n   \n#     sms = pd.concat([smA,smB,smC,smD],axis=1)\n    \n#     display(sms)\n\n#     sms['winner'] = sms[['winner_A','winner_B','winner_C','winner_D']].mode(axis=1)[0]\n    \n#     return sms, option,solutions","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"outputs":[],"execution_count":null}]}