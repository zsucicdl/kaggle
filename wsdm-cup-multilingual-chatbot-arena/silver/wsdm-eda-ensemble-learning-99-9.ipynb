{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86946,"databundleVersionId":10131489,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background: linear-gradient(45deg, #fa0cbb, #fa0519); padding: 20px; border-radius: 10px; box-shadow: 0 0 10px rgba(0, 0, 0, 0.5); text-align: center; background-color: green; color: white;\">\n  <h1 style=\"font-family: Arial, sans-serif; font-size: 32px; color: white;\"> WSDM Cup - Multilingual Chatbot Arena </h1>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Competition Overview\n#### *This competition focuses on predicting user preferences between responses from large language models (LLMs) based on real-world data. Participants will use a dataset from Chatbot Arena where users compare two LLM responses. The goal is to address biases in preference predictions that can affect user satisfaction, such as position and verbosity biases. Various machine-learning techniques are encouraged to develop models that better align LLM outputs with individual user preferences. Successful entries will contribute to more personalized and effective AI-driven conversational systems.*\n\n\n### **üìù Agenda**  \n1. [üìÇ Import Necessary Libraries](#1)  \n2. [üìù Dataset Info](#2)  \n   - [ Null Values](#)\n   - [ Duplicates](#) \n   - [ Data Descriptive Statistics](#)\n3. [üöÄ Preprocessing](#3)  \n   - [Language-Specific Preprocessing](#)\n   - [General Cleaning](#)\n4. [üîç Feature Engineering](#4)  \n   - [Generated Features](#)\n   - [Feature Descriptions](#) \n5. [üß† Data Visualization and Insights](#5)  \n6. [üì¶ Model Ensemble Learning](#6)  \n   - [Model Selection](#)\n   - [Hyperparameter Tuning](#)\n   - [Evaluation Metrics](#)  \n7. [üîó Conclusion and Future Work](#8)\n\n---\n\n","metadata":{"_kg_hide-input":true}},{"cell_type":"markdown","source":"<a id = \"1\"></a><br>\n\n# <div style=\"text-align:center; border-radius:15px; padding:15px; margin:0; font-size:100%; font-family:Arial, sans-serif; background-color:#EB6A20; overflow:hidden; box-shadow:0 3px 6px rgba(0, 0, 0, 0.3);\"><b> 1. Import Necessary Libraries </b></div>\n","metadata":{}},{"cell_type":"code","source":"!pip install langdetect pyvi janome konlpy","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd  \n\n\nfrom langdetect.lang_detect_exception import LangDetectException \nfrom janome.tokenizer import Tokenizer as JapaneseTokenizer  \nfrom pyvi.ViTokenizer import tokenize as ViTokenizer \nfrom langdetect import detect, DetectorFactory  \nfrom sklearn.metrics import accuracy_score\nfrom nltk.stem import WordNetLemmatizer \nimport jieba as chinese_tokenizer  \nfrom nltk.corpus import stopwords  \nfrom bs4 import BeautifulSoup  \nfrom textblob import TextBlob  \nfrom textblob import TextBlob\nfrom konlpy.tag import Okt \n\nimport unicodedata  \nimport emoji  \nimport re  \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-11-30T16:13:00.538736Z","iopub.execute_input":"2024-11-30T16:13:00.539396Z","iopub.status.idle":"2024-11-30T16:13:00.545084Z","shell.execute_reply.started":"2024-11-30T16:13:00.539361Z","shell.execute_reply":"2024-11-30T16:13:00.544108Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a id = \"2\"></a><br>\n\n# <div style=\"text-align:center; border-radius:15px; padding:15px; margin:0; font-size:100%; font-family:Arial, sans-serif; background-color:#EB6A20; overflow:hidden; box-shadow:0 3px 6px rgba(0, 0, 0, 0.3);\"><b> 1. Dataset Info </b></div>\n","metadata":{}},{"cell_type":"code","source":"%%time\ndef display_dataset_info(dataset, name):\n    print(\"-----------------------------------------------------------------\")\n    print(f\"{name} DataFrame Shape: Rows = {dataset.shape[0]}, Columns = {dataset.shape[1]}\")\n    \n    # Numerical and categorical columns information\n    num_cols = dataset.select_dtypes(include='number')\n    cat_cols = dataset.select_dtypes(exclude='number')\n    print(f\"{name} DataFrame numeric columns size = {len(num_cols.columns)}, categorical columns size = {len(cat_cols.columns)}\")\n    \n    # Missing values information\n    total_missing = dataset.isnull().sum().sum()\n    if total_missing > 0:\n        missing_perc = (total_missing / (dataset.shape[0] * dataset.shape[1])) * 100\n        print(f\"There are a total of {total_missing} missing values in the {name} DataFrame ({missing_perc:.2f}% of all values).\")\n        print(\"Missing values per column:\")\n        print(dataset.isnull().sum().sort_values(ascending=False).head(10))\n    else:\n        print(f\"There are no missing values in the {name} DataFrame.\")\n    \n    # Duplicate rows information\n    total_duplicates = dataset.duplicated().sum()\n    if total_duplicates > 0:\n        print(f\"There are {total_duplicates} duplicate rows in the {name} DataFrame.\")\n    else:\n        print(f\"There are no duplicate rows in the {name} DataFrame.\")   \n    \n    # Check for column data types\n    print(\"\\nColumn data types:\")\n    print(dataset.dtypes.value_counts())   \n    \n    print(\"-----------------------------------------------------------------\")\n    print(\"<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n\ntrain = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet')\ntest = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet')","metadata":{"execution":{"iopub.status.busy":"2024-11-30T15:32:40.982458Z","iopub.execute_input":"2024-11-30T15:32:40.982859Z","iopub.status.idle":"2024-11-30T15:32:43.229187Z","shell.execute_reply.started":"2024-11-30T15:32:40.98283Z","shell.execute_reply":"2024-11-30T15:32:43.227925Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\ndisplay_dataset_info(train, \"Train\")  \ndisplay_dataset_info(test, \"Test\")","metadata":{"execution":{"iopub.status.busy":"2024-11-30T15:32:43.232079Z","iopub.execute_input":"2024-11-30T15:32:43.232516Z","iopub.status.idle":"2024-11-30T15:32:44.496434Z","shell.execute_reply.started":"2024-11-30T15:32:43.232465Z","shell.execute_reply":"2024-11-30T15:32:44.495575Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train['language'].value_counts()\ntrain['winner'].value_counts()\n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-30T15:32:44.497346Z","iopub.execute_input":"2024-11-30T15:32:44.497603Z","iopub.status.idle":"2024-11-30T15:32:44.510669Z","shell.execute_reply.started":"2024-11-30T15:32:44.497578Z","shell.execute_reply":"2024-11-30T15:32:44.509891Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.groupby('language')['winner'].value_counts(normalize=True)\ntrain.groupby('model_a')['winner'].value_counts(normalize=True)\ntrain.groupby('model_b')['winner'].value_counts(normalize=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-30T15:32:44.511884Z","iopub.execute_input":"2024-11-30T15:32:44.512197Z","iopub.status.idle":"2024-11-30T15:32:44.558128Z","shell.execute_reply.started":"2024-11-30T15:32:44.51217Z","shell.execute_reply":"2024-11-30T15:32:44.557285Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a id = \"3\"></a><br>\n\n# <div style=\"text-align:center; border-radius:15px; padding:15px; margin:0; font-size:100%; font-family:Arial, sans-serif; background-color:#EB6A20; overflow:hidden; box-shadow:0 3px 6px rgba(0, 0, 0, 0.3);\"><b> 2. Preprocessing </b></div>\n","metadata":{}},{"cell_type":"code","source":"DetectorFactory.seed = 0\n\n# Initialize tokenizers\njapanese_tokenizer = JapaneseTokenizer()\nkorean_tokenizer = Okt()\n\n# Preprocess function with extended language support\ndef preprocess_multilingual(text):\n    # Ensure input is a string\n    text = str(text).strip()\n\n    # Detect the language of the text\n    try:\n        lang = detect(text)\n    except LangDetectException:\n        lang = \"unknown\"\n\n    # Process text based on detected language\n    if lang == \"zh-cn\":  # Chinese \n        text = \" \".join(chinese_tokenizer.cut(text))\n        text = emoji.replace_emoji(text, replace=\"\")\n        text = re.sub(r'\\d+', '', text)   \n        text = re.sub(r'\\s+', ' ', text).strip()\n\n    elif lang == \"ja\":  # Japanese\n        text = \" \".join(token.surface for token in japanese_tokenizer.tokenize(text))\n        text = emoji.replace_emoji(text, replace=\"\")\n        text = re.sub(r'\\d+', '', text)   \n        text = re.sub(r'\\s+', ' ', text).strip()\n\n    elif lang == \"ko\":  # Korean\n        text = \" \".join(korean_tokenizer.morphs(text))\n        text = emoji.replace_emoji(text, replace=\"\")\n        text = re.sub(r'\\d+', '', text)   \n        text = re.sub(r'\\s+', ' ', text).strip()\n\n    elif lang == \"vi\":  # Vietnamese\n        text = ViTokenizer(text)\n        text = emoji.replace_emoji(text, replace=\"\")\n        text = re.sub(r'\\d+', '', text)   \n        text = re.sub(r'\\s+', ' ', text).strip()\n\n    elif lang == \"de\":  # German\n        text = text.lower()\n        text = emoji.replace_emoji(text, replace=\"\")\n        text = re.sub(r'\\d+', '', text) \n        text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n        text = re.sub(r'\\s+', ' ', text).strip()\n\n    elif lang == \"en\":  # English\n        text = text.lower()\n        text = text.replace('%', ' percent').replace('$', ' dollar ').replace('‚Çπ', ' rupee ').replace('‚Ç¨', ' euro ').replace('@', ' at ')\n        text = emoji.replace_emoji(text, replace=\"\")\n        text = re.sub(r'\\d+', '', text)  \n        text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n        text = BeautifulSoup(text, \"html.parser\").get_text()\n        text = re.sub(r'\\W', ' ', text).strip()\n\n    else:\n        # For unknown or unsupported languages, keep it simple\n        text = emoji.replace_emoji(text, replace=\"\")\n        text = re.sub(r'\\d+', '', text)   \n        text = re.sub(r'\\s+', ' ', text).strip()\n\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2024-11-30T15:32:44.559329Z","iopub.execute_input":"2024-11-30T15:32:44.559592Z","iopub.status.idle":"2024-11-30T15:32:45.791502Z","shell.execute_reply.started":"2024-11-30T15:32:44.559567Z","shell.execute_reply":"2024-11-30T15:32:45.790666Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef preprocessing(text):\n    # Initialize stopwords and lemmatizer\n    stop_words = set(stopwords.words('english'))\n    lemmatizer = WordNetLemmatizer()\n\n    # Process question1\n    preprocessing_text1 = text[\"responseA\"].str.lower()\n    preprocessing_text1 = preprocessing_text1.str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n    preprocessing_text1 = preprocessing_text1.str.split()\n\n    preprocessing_text1 = preprocessing_text1.apply(lambda words: [word for word in words if word not in stop_words])\n    preprocessing_text1 = preprocessing_text1.apply(lambda words: [lemmatizer.lemmatize(word) for word in words])\n\n    \n    # Process question2\n    preprocessing_text2 = text[\"response_b\"].str.lower()\n    preprocessing_text2 = preprocessing_text2.str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n    preprocessing_text2 = preprocessing_text2.str.split()\n    preprocessing_text2 = preprocessing_text2.apply(lambda words: [word for word in words if word not in stop_words])\n    preprocessing_text2 = preprocessing_text2.apply(lambda words: [lemmatizer.lemmatize(word) for word in words])\n     # Join the lists back to strings\n    preprocessing_text1 = preprocessing_text1.str.join(' ')\n    preprocessing_text2 = preprocessing_text2.str.join(' ')\n\n    return preprocessing_text1, preprocessing_text2\n\n\"\"\"\ntrain[\"processed_response_a\"], train[\"processed_response_b\"] = preprocessing(train)\n\"\"\"","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-30T15:32:45.792507Z","iopub.execute_input":"2024-11-30T15:32:45.792738Z","iopub.status.idle":"2024-11-30T15:32:45.809862Z","shell.execute_reply.started":"2024-11-30T15:32:45.792715Z","shell.execute_reply":"2024-11-30T15:32:45.808985Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\ntrain[\"prompt\"] = train[\"prompt\"].apply(lambda x: preprocess_multilingual(x))  \ntrain[\"responseA\"] = train[\"response_a\"].apply(lambda x: preprocess_multilingual(x))  \ntrain[\"response_b\"] = train[\"response_b\"].apply(lambda x: preprocess_multilingual(x)) \n\ntest[\"prompt\"] = test[\"prompt\"].apply(lambda x: preprocess_multilingual(x))  \ntest[\"responseA\"] = test[\"response_a\"].apply(lambda x: preprocess_multilingual(x))  \ntest[\"response_b\"] = test[\"response_b\"].apply(lambda x: preprocess_multilingual(x)) \n\n","metadata":{"trusted":true,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-11-30T15:32:45.810923Z","iopub.execute_input":"2024-11-30T15:32:45.811186Z","iopub.status.idle":"2024-11-30T16:02:21.972458Z","shell.execute_reply.started":"2024-11-30T15:32:45.811159Z","shell.execute_reply":"2024-11-30T16:02:21.971468Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a id = \"4\"></a><br>\n\n# <div style=\"text-align:center; border-radius:15px; padding:15px; margin:0; font-size:100%; font-family:Arial, sans-serif; background-color:#EB6A20; overflow:hidden; box-shadow:0 3px 6px rgba(0, 0, 0, 0.3);\"><b> 3. Feature Engineering </b></div>","metadata":{}},{"cell_type":"code","source":"\ndef process_responses(train):  \n    # Calculate the character length of the prompt  \n    train['prompt_length'] = train['prompt'].apply(len)  \n\n    # Calculate the absolute difference in word counts between response_a and response_b  \n    train['response_length_diff'] = abs(  \n        train['response_a'].apply(lambda x: len(x.split())) - train['response_b'].apply(lambda x: len(x.split()))  \n    )  \n\n    # Get the word count of the winning response based on the 'winner' column  \n    train['winner_length'] = train.apply(  \n        lambda x: len(x['response_a'].split()) if x['winner'] == 'model_a' else len(x['response_b'].split()), axis=1  \n    )  \n\n    # Check if the language specified is mentioned in the prompt  \n    train['language_match'] = train.apply(lambda x: 1 if x['language'] in x['prompt'] else 0, axis=1)  \n\n    # Compute sentiment polarity of response_a and response_b using TextBlob  \n    train['response_a_sentiment'] = train['response_a'].apply(lambda x: TextBlob(x).sentiment.polarity)  \n    train['response_b_sentiment'] = train['response_b'].apply(lambda x: TextBlob(x).sentiment.polarity)  \n\n    # Create binary flags to indicate whether model_a or model_b was the winner  \n    train['model_a_winner'] = train['winner'].apply(lambda x: 1 if x == 'model_a' else 0)  \n    train['model_b_winner'] = train['winner'].apply(lambda x: 1 if x == 'model_b' else 0)  \n\n    # Check if the prompt contains a question mark ('?')  \n    train['contains_question'] = train['prompt'].apply(lambda x: 1 if '?' in x else 0)  \n\n    # Combine model_a and model_b values to create a unique identifier for the model pair  \n    train['model_pair'] = train['model_a'] + \"_\" + train['model_b']  \n\n    # Calculate the ratio of unique words to total words for response_a and response_b  \n    train['response_a_unique_ratio'] = train['response_a'].apply(lambda x: len(set(x.split())) / len(x.split()) if len(x.split()) > 0 else 0)  \n    train['response_b_unique_ratio'] = train['response_b'].apply(lambda x: len(set(x.split())) / len(x.split()) if len(x.split()) > 0 else 0)  \n\n    # Check if either response_a or response_b contains code blocks (indicated by triple backticks ```)  \n    train['contains_code'] = train.apply(  \n        lambda x: 1 if '```' in x['response_a'] or '```' in x['response_b'] else 0, axis=1  \n    )  \n\n    return train\ntrain = process_responses(train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:02:21.975877Z","iopub.execute_input":"2024-11-30T16:02:21.976312Z","iopub.status.idle":"2024-11-30T16:05:37.722792Z","shell.execute_reply.started":"2024-11-30T16:02:21.976277Z","shell.execute_reply":"2024-11-30T16:05:37.722048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nnumeric_cols = train.select_dtypes(include=[\"number\"]).columns\n# Calculate Q1 (25th percentile) and Q3 (75th percentile)\nQ1 = train[numeric_cols].quantile(0.25)\nQ3 = train[numeric_cols].quantile(0.75)\n# Calculate IQR (Interquartile Range)\nIQR = Q3 - Q1\n# Define lower and upper bounds for outlier removal\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n# Filter out rows where any value is outside the bounds\ntrain_no_outliers = train[~((train[numeric_cols] < lower_bound) | (train[numeric_cols] > upper_bound)).any(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2024-11-30T16:05:37.723762Z","iopub.execute_input":"2024-11-30T16:05:37.723985Z","iopub.status.idle":"2024-11-30T16:05:37.785033Z","shell.execute_reply.started":"2024-11-30T16:05:37.723961Z","shell.execute_reply":"2024-11-30T16:05:37.784342Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a id = \"5\"></a><br>\n\n# <div style=\"text-align:center; border-radius:15px; padding:15px; margin:0; font-size:100%; font-family:Arial, sans-serif; background-color:#EB6A20; overflow:hidden; box-shadow:0 3px 6px rgba(0, 0, 0, 0.3);\"><b> 4. Visualizing Data Insights </b></div>","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport plotly.express as px  \nimport seaborn as sns\n","metadata":{"execution":{"iopub.status.busy":"2024-11-30T16:05:37.786073Z","iopub.execute_input":"2024-11-30T16:05:37.78645Z","iopub.status.idle":"2024-11-30T16:05:39.066425Z","shell.execute_reply.started":"2024-11-30T16:05:37.786411Z","shell.execute_reply":"2024-11-30T16:05:39.065521Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language_counts = train_no_outliers['language'].value_counts().reset_index()  \nlanguage_counts.columns = ['language', 'count']  \n\n# Create the bar plot  \nfig = px.bar(language_counts, x='language', y='count',   \n             title='Language Count',   \n             labels={'language': 'Language', 'count': 'Count'},  \n             width=1800, height=600)  \n\n# Show the figure  \nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-30T16:05:39.067713Z","iopub.execute_input":"2024-11-30T16:05:39.068596Z","iopub.status.idle":"2024-11-30T16:05:41.094113Z","shell.execute_reply.started":"2024-11-30T16:05:39.068545Z","shell.execute_reply":"2024-11-30T16:05:41.093269Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the distribution of sentiment scores for response_a and response_b\nfig = px.histogram(train_no_outliers, x=\"response_a_sentiment\", nbins=30, color=\"winner\", \n                   title=\"Distribution of Sentiment Scores for Response A\", \n                   labels={\"response_a_sentiment\": \"Sentiment Score\", \"winner\": \"Winner\"})\nfig.show()\n\nfig = px.histogram(train_no_outliers, x=\"response_b_sentiment\", nbins=30, color=\"winner\", \n                   title=\"Distribution of Sentiment Scores for Response B\", \n                   labels={\"response_b_sentiment\": \"Sentiment Score\", \"winner\": \"Winner\"})\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-30T16:05:41.094977Z","iopub.execute_input":"2024-11-30T16:05:41.095252Z","iopub.status.idle":"2024-11-30T16:05:41.309435Z","shell.execute_reply.started":"2024-11-30T16:05:41.095195Z","shell.execute_reply":"2024-11-30T16:05:41.308648Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = px.scatter(train_no_outliers, x='response_a_sentiment', y='response_length_diff', color='winner', \n                 title=\"Response A Sentiment vs. Response Length Difference\", \n                 labels={\"response_a_sentiment\": \"Response A Sentiment\", \n                         \"response_length_diff\": \"Response Length Difference\", \"winner\": \"Winner\"})\nfig.show()\n\nfig = px.scatter(train_no_outliers, x='response_b_sentiment', y='response_length_diff', color='winner', \n                 title=\"Response B Sentiment vs. Response Length Difference\", \n                 labels={\"response_b_sentiment\": \"Response B Sentiment\", \n                         \"response_length_diff\": \"Response Length Difference\", \"winner\": \"Winner\"})\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-30T16:05:41.310593Z","iopub.execute_input":"2024-11-30T16:05:41.310922Z","iopub.status.idle":"2024-11-30T16:05:41.520979Z","shell.execute_reply.started":"2024-11-30T16:05:41.310887Z","shell.execute_reply":"2024-11-30T16:05:41.520226Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\ncorr = train_no_outliers[['prompt_length', 'response_length_diff', 'winner_length',\n           'response_a_sentiment', 'response_b_sentiment', 'response_a_unique_ratio', \n           'response_b_unique_ratio']].corr()\nbarplot = sns.barplot(y= train_no_outliers[\"prompt_length\"], x= train_no_outliers[\"winner\"], palette=\"Paired\", ax = axes[0, 0])\n\naxes[0, 0].set_title(\"Correlation Heatmap\")\n\nsns.boxplot(data=train_no_outliers, x='winner', y='response_length_diff', palette='Set2', ax=axes[0, 1])\naxes[0, 1].set_title(\"Response Length Difference by Winner\")\n\nsns.histplot(train_no_outliers['response_a_sentiment'], kde=True, color='skyblue', ax=axes[1, 0])\naxes[1, 0].set_title(\"Distribution of Response A Sentiment\")\n\nsns.histplot(train_no_outliers['response_b_sentiment'], kde=True, color='salmon', ax=axes[1, 1])\naxes[1, 1].set_title(\"Distribution of Response B Sentiment\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-30T16:05:41.52214Z","iopub.execute_input":"2024-11-30T16:05:41.522755Z","iopub.status.idle":"2024-11-30T16:05:43.531867Z","shell.execute_reply.started":"2024-11-30T16:05:41.522715Z","shell.execute_reply":"2024-11-30T16:05:43.531021Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create subplots  \nfig, ax = plt.subplots(1, 2, figsize=(15, 5))  \n\n# Bar plot on the first subplot  \nbarplot = sns.barplot(x=train_no_outliers[\"language\"].value_counts().nlargest(5).index,   \n                      y=train_no_outliers[\"language\"].value_counts().nlargest(5).values,   \n                      palette=\"Paired\", ax=ax[0])\n\nax[0].set_xlabel('language')  \nax[0].set_ylabel('language Length')  \nax[0].set_title('language lenght Comparison')  \nax[0].tick_params(axis='x', rotation=90)  \nax[0].grid(axis='x', linestyle='--', alpha=0.7, color=\"black\")  \n\n# Pie chart on the second subplot  \ntrain_no_outliers['winner'].value_counts().plot(kind='pie', autopct='%1.1f%%', ax=ax[1], startangle=90)  \nax[1].set_ylabel('')  # Hide the y-label for the pie chart  \nax[1].set_title('Winner Distribution')  \n\n# Adjust layout  \nplt.tight_layout()  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-30T16:05:43.533153Z","iopub.execute_input":"2024-11-30T16:05:43.533802Z","iopub.status.idle":"2024-11-30T16:05:43.931872Z","shell.execute_reply.started":"2024-11-30T16:05:43.533758Z","shell.execute_reply":"2024-11-30T16:05:43.931046Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate correlations between numeric features  \ncorr = train[numeric_cols].corr()  \n\n# Create the heatmap  \nplt.figure(figsize=(10, 6))  \nsns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)  \n# Rotate the x-axis labels  \nplt.title(\"Correlation Heatmap of Features\")  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-30T16:05:43.933134Z","iopub.execute_input":"2024-11-30T16:05:43.93357Z","iopub.status.idle":"2024-11-30T16:05:44.680105Z","shell.execute_reply.started":"2024-11-30T16:05:43.933529Z","shell.execute_reply":"2024-11-30T16:05:44.679254Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a id = \"5\"></a><br>\n\n# <div style=\"text-align:center; border-radius:15px; padding:15px; margin:0; font-size:100%; font-family:Arial, sans-serif; background-color:#EB6A20; overflow:hidden; box-shadow:0 3px 6px rgba(0, 0, 0, 0.3);\"><b> 5. Model Ensemble Learning </b></div>","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import VotingRegressor  \nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier \nimport lightgbm as lgb  \n  ","metadata":{"execution":{"iopub.status.busy":"2024-11-30T16:05:44.681352Z","iopub.execute_input":"2024-11-30T16:05:44.681691Z","iopub.status.idle":"2024-11-30T16:05:48.276512Z","shell.execute_reply.started":"2024-11-30T16:05:44.681656Z","shell.execute_reply":"2024-11-30T16:05:48.275843Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lgb_param_grid = {  \n    'n_estimators': [100, 200],  \n    'learning_rate': [0.01, 0.05],  \n}  \n\nxgb_param_grid = {  \n    'n_estimators': [100, 200],  \n    'learning_rate': [0.01, 0.05],  \n    'max_depth': [3, 5],  \n}  \n\ncatboost_param_grid = {  \n    'iterations': [500, 1000],  \n    'learning_rate': [0.01, 0.05],  \n}  \n\nrf_param_grid = {  \n    'n_estimators': [100, 200],  \n    'max_depth': [10, 20],  \n}","metadata":{"execution":{"iopub.status.busy":"2024-11-30T16:05:48.277432Z","iopub.execute_input":"2024-11-30T16:05:48.277964Z","iopub.status.idle":"2024-11-30T16:05:48.282914Z","shell.execute_reply.started":"2024-11-30T16:05:48.277937Z","shell.execute_reply":"2024-11-30T16:05:48.281996Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\n# Encode categorical columns (like 'language', 'model_a', 'model_b', 'model_pair', etc.)\nlabel_columns = ['language', 'model_a', 'model_b', 'model_pair']  # Add more columns if necessary\nlabel_encoder = LabelEncoder()\n\n# Apply label encoding only to specified categorical columns\nfor col in train_no_outliers.columns:\n    if col in train_no_outliers.columns and train_no_outliers[col].dtypes == \"object\":\n        train_no_outliers[col] = label_encoder.fit_transform(train_no_outliers[col])\n\n# Split data into train and test sets\nX = train_no_outliers.drop(columns=[\"winner\", \"id\"])  # Ensure you're using the correct DataFrame\ny = train_no_outliers[\"winner\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# 1. Define individual models\nlgb_model = lgb.LGBMClassifier()\nxgb_model = XGBClassifier()\ncatboost_model = CatBoostClassifier(silent=True)\nrf_model = RandomForestClassifier(random_state=42)\n\n# 3. Perform hyperparameter tuning\nlgb_search = GridSearchCV(lgb_model, lgb_param_grid, scoring='accuracy', cv=3, n_jobs=-1, verbose=0)\nxgb_search = GridSearchCV(xgb_model, xgb_param_grid, scoring='accuracy', cv=3, n_jobs=-1, verbose=0)\ncatboost_search = GridSearchCV(catboost_model, catboost_param_grid, scoring='accuracy', cv=3, n_jobs=-1, verbose=0)\nrf_search = GridSearchCV(rf_model, rf_param_grid, scoring='accuracy', cv=3, n_jobs=-1, verbose=0)\n\n# Fit the models\nlgb_search.fit(X_train_scaled, y_train)\nxgb_search.fit(X_train_scaled, y_train)\ncatboost_search.fit(X_train, y_train)\nrf_search.fit(X_train_scaled, y_train)\n\n# Extract best models\nbest_lgb_model = lgb_search.best_estimator_\nbest_xgb_model = xgb_search.best_estimator_\nbest_catboost_model = catboost_search.best_estimator_\nbest_rf_model = rf_search.best_estimator_\n\n# 4. Create an ensemble model using VotingClassifier\nensemble_model = VotingClassifier(estimators=[\n    ('lgb', best_lgb_model),\n    ('xgb', best_xgb_model),\n    ('catboost', best_catboost_model),\n    ('rf', best_rf_model)\n], voting='soft')  # Use 'soft' voting for probabilities or 'hard' for majority voting\n\n# 5. Train the ensemble model\nensemble_model.fit(X_train_scaled, y_train)\n\n# 6. Make predictions\nensemble_predictions = ensemble_model.predict(X_test_scaled)\nensemble_probabilities = ensemble_model.predict_proba(X_test_scaled)  # For probabilities (optional)\n","metadata":{"_kg_hide-input":false,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model on training data\ntrain_predictions = ensemble_model.predict(X_train_scaled)\ntrain_accuracy = accuracy_score(y_train, train_predictions)\n\n# Evaluate the model on test data\ntest_predictions = ensemble_model.predict(X_test_scaled)\ntest_accuracy = accuracy_score(y_test, test_predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:13:13.402524Z","iopub.execute_input":"2024-11-30T16:13:13.402892Z","iopub.status.idle":"2024-11-30T16:13:13.615548Z","shell.execute_reply.started":"2024-11-30T16:13:13.402856Z","shell.execute_reply":"2024-11-30T16:13:13.614583Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print performance metrics\nprint(f\"Training Accuracy: {train_accuracy:.2f}\")\nprint(f\"Test Accuracy: {test_accuracy:.2f}\")\n\n# Check for overfitting/underfitting\nif train_accuracy > test_accuracy + 0.1:\n    print(\"The model is likely overfitting.\")\nelif train_accuracy < 0.7 and test_accuracy < 0.7:\n    print(\"The model is likely underfitting.\")\nelse:\n    print(\"The model has a good balance between bias and variance.\")\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix  \n\n# Evaluate the model's performance  \naccuracy = accuracy_score(y_test, ensemble_predictions)  \nreport = classification_report(y_test, ensemble_predictions)  \nconf_matrix = confusion_matrix(y_test, ensemble_predictions)  \n\n# Print out evaluation metrics  \nprint(f\"Accuracy: {accuracy}\")  \nprint(\"Classification Report:\")  \nprint(report)  \nprint(\"Confusion Matrix:\")  \nprint(conf_matrix)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:13:22.635725Z","iopub.execute_input":"2024-11-30T16:13:22.636054Z","iopub.status.idle":"2024-11-30T16:13:22.653451Z","shell.execute_reply.started":"2024-11-30T16:13:22.636023Z","shell.execute_reply":"2024-11-30T16:13:22.652603Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border: 2px solid black; border-radius: 10px; padding: 15px; text-align: left; font-family: Arial, sans-serif; width: 80%; max-width: 700px; margin: auto;\">\r\n   <h2> Upvoting </h2>\r\n\r\n  <ul>\r\n    <li>Quick and Simple Upvoting</li>\r\n  </ul>\r\n  <p>If you found this notebook helpful, please consider upvoting and leaving a comment. Your input helps improve the content and supports a collaborative learning space!</p>\r\n  \r\n  <ol>\r\n    <li>Upvote</li>\r\n    <li>Leave a comment</li>\r\n    <ul>\r\n      <li>Share your thoughts</li>\r\n      <li>Provide feedback</li>\r\n      <li>Ask questions or suggest improvements</li>\r\n    </ul>\r\n  </ol>\r\n  \r\n  <div style=\"margin-top: 20px;\">\r\n    <a href=\"https://www.linkedin.com\" target=\"_blank\">\r\n      <img src=\"https://cdn-icons-png.flaticon.com/512/174/174857.png\" alt=\"LinkedIn\" style=\"width: 30px; height: 30px; margin-right: 10px;\">\r\n    </a>\r\n    <a href=\"https://github.com\" target=\"_blank\">\r\n      <img src=\"https://cdn-icons-png.flaticon.com/512/25/25231.png\" alt=\"GitHub\" style=\"width: 30px; height: 30px; margin-right: 10px;\">\r\n    </a>\r\n    <a href=\"https://twitter.com\" target=\"_blank\">\r\n      <img src=\"https://cdn-icons-png.flaticon.com/512/733/733579.png\" alt=\"Twitter\" style=\"width: 30px; height: 30px;\">\r\n    </a>\r\n  </div>\r\n</div>\r\n","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}}]}