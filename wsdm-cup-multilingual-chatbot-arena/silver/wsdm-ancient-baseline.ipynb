{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86946,"databundleVersionId":10131489,"sourceType":"competition"},{"sourceId":12314,"sourceType":"datasetVersion","datasetId":8821}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Version 3**: Ancient Baseline (CV 0.6062 | LB 0.61).\n\n**Version 4**: Adding some fancy Modern stuff to the Ancient Baseline (CV 0.6106 | LB 0.60).\n\n**Version 6**: Same as Version 4, but replacing single logreg with ensemble logreg + ftrl.","metadata":{"execution":{"iopub.status.busy":"2024-11-19T11:57:29.712121Z","iopub.execute_input":"2024-11-19T11:57:29.712515Z","iopub.status.idle":"2024-11-19T11:57:32.650228Z","shell.execute_reply.started":"2024-11-19T11:57:29.712479Z","shell.execute_reply":"2024-11-19T11:57:32.648927Z"}}},{"cell_type":"code","source":"import sys\nimport scipy\nimport warnings\nfrom tqdm import tqdm\nimport numpy as np, pandas as pd\nfrom sklearn.base import BaseEstimator\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nsys.path.append('/kaggle/input/libftrl-python')\nfrom ftrl import FtrlProximal  # FTRL (Follow The Regularized Leader)\n\nfrom datasets import Dataset\nfrom transformers import PreTrainedTokenizerFast\nfrom tokenizers import models, trainers, normalizers, pre_tokenizers, Tokenizer\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T06:47:12.067222Z","iopub.execute_input":"2024-11-21T06:47:12.067606Z","iopub.status.idle":"2024-11-21T06:47:19.887943Z","shell.execute_reply.started":"2024-11-21T06:47:12.067571Z","shell.execute_reply":"2024-11-21T06:47:19.886962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = \"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/\"\ntrain = pd.read_parquet(path+\"train.parquet\")\ntest = pd.read_parquet(path+\"test.parquet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T06:47:19.889562Z","iopub.execute_input":"2024-11-21T06:47:19.890058Z","iopub.status.idle":"2024-11-21T06:47:22.662772Z","shell.execute_reply.started":"2024-11-21T06:47:19.890026Z","shell.execute_reply":"2024-11-21T06:47:22.661646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\ndef tokenize_text(col: str):\n    LOWERCASE = False\n    VOCAB_SIZE = 30522\n\n    # Creating Byte-Pair Encoding tokenizer\n    raw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n\n    # Adding normalization and pre_tokenizer\n    raw_tokenizer.normalizer = normalizers.Sequence([normalizers.NFC()] +\n                                                    [normalizers.Lowercase()] if LOWERCASE else [])\n    raw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n\n    # Adding special tokens and creating trainer instance\n    special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n    trainer = trainers.BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=special_tokens)\n\n    # Creating huggingface dataset object\n    dataset = Dataset.from_pandas(train[[col]])\n    def train_corp_iter():\n        \"\"\"\n        A generator function for iterating over a dataset in chunks.\n        \"\"\"    \n        for i in range(0, len(dataset), 1000):\n            yield dataset[i : i + 1000][col]\n\n    # Training from iterator, it's training on train set...\n    raw_tokenizer.train_from_iterator(train_corp_iter(), trainer=trainer)\n    tokenizer = PreTrainedTokenizerFast(\n        tokenizer_object=raw_tokenizer,\n        unk_token=\"[UNK]\",\n        pad_token=\"[PAD]\",\n        cls_token=\"[CLS]\",\n        sep_token=\"[SEP]\",\n        mask_token=\"[MASK]\",\n    )\n\n    # Tokenize train set with new tokenizer\n    tokenized_texts_train = []\n    for text in tqdm(train[col].tolist()):\n        tokenized_texts_train.append(tokenizer.tokenize(text))\n\n    # Tokenize test set with new tokenizer\n    tokenized_texts_test = []\n    for text in tqdm(test[col].tolist()):\n        tokenized_texts_test.append(tokenizer.tokenize(text))\n\n    del raw_tokenizer, trainer, dataset, tokenizer\n    return tokenized_texts_train, tokenized_texts_test\n\ntokenized_texts_train_prompt, tokenized_texts_test_prompt = tokenize_text(col='prompt')\ntokenized_texts_train_response_a, tokenized_texts_test_response_a = tokenize_text(col='response_a')\ntokenized_texts_train_response_b, tokenized_texts_test_response_b = tokenize_text(col='response_b')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T06:47:22.664228Z","iopub.execute_input":"2024-11-21T06:47:22.664554Z","iopub.status.idle":"2024-11-21T06:57:17.636568Z","shell.execute_reply.started":"2024-11-21T06:47:22.664523Z","shell.execute_reply":"2024-11-21T06:57:17.635274Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\ndef dummy(text):\n    \"\"\"\n    A dummy function to use as tokenizer for TfidfVectorizer.\n    It returns the text as it is since we already tokenized it.\n    \"\"\"\n    return text\n\ndef vectorize_text(tokenized_texts_train, tokenized_texts_test):\n    # Fitting TfidfVectoizer on train set\n    vectorizer = TfidfVectorizer(ngram_range=(1, 2),\n                                 max_features=80_000,\n                                 lowercase=False,\n                                 sublinear_tf=True,\n                                 tokenizer=dummy,\n                                 preprocessor=dummy,\n                                 token_pattern=None,\n                                 )\n    vectorizer.fit(tokenized_texts_train)\n    # Getting vocab\n    vocab = vectorizer.vocabulary_\n\n    # Fitting vectorizer on train set but this time using vocabulary from train fit.\n    vectorizer = TfidfVectorizer(ngram_range=(1, 2),\n                                 lowercase=False,\n                                 sublinear_tf=True,\n                                 vocabulary=vocab,\n                                 tokenizer=dummy,\n                                 preprocessor=dummy,\n                                 token_pattern=None,\n                                 )\n    train_feats = vectorizer.fit_transform(tokenized_texts_train)\n    test_feats = vectorizer.transform(tokenized_texts_test)\n\n    del vectorizer, vocab, tokenized_texts_train, tokenized_texts_test\n    print(\"train_feats shape:\",train_feats.shape)\n    print(\"test_feats shape:\",train_feats.shape)\n    return train_feats, test_feats\n\ntrain_feats_prompt, test_feats_prompt = vectorize_text(tokenized_texts_train_prompt, tokenized_texts_test_prompt)\ntrain_feats_response_a, test_feats_response_a = vectorize_text(tokenized_texts_train_response_a, tokenized_texts_test_response_a)\ntrain_feats_response_b, test_feats_response_b = vectorize_text(tokenized_texts_train_response_b, tokenized_texts_test_response_b)\n\ntrain_feats_modern = scipy.sparse.hstack((train_feats_prompt, train_feats_response_a, train_feats_response_b))\ntest_feats_modern = scipy.sparse.hstack((test_feats_prompt, test_feats_response_a, test_feats_response_b))\nprint(\"\\ntrain_feats_modern shape:\",train_feats_modern.shape)\nprint(\"test_feats_modern shape:\",test_feats_modern.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T06:57:17.639055Z","iopub.execute_input":"2024-11-21T06:57:17.639409Z","iopub.status.idle":"2024-11-21T07:01:58.311878Z","shell.execute_reply.started":"2024-11-21T06:57:17.639369Z","shell.execute_reply":"2024-11-21T07:01:58.310734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nvectorizer_char = TfidfVectorizer(sublinear_tf=True, analyzer='char', ngram_range=(1, 2), max_features=100_000)\nvectorizer_word = TfidfVectorizer(sublinear_tf=True, analyzer='word', min_df=3)\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('prompt_feats', FeatureUnion([\n            ('prompt_char', vectorizer_char),\n            ('prompt_word', vectorizer_word)\n        ]), 'prompt'),\n        ('response_a_feats', FeatureUnion([\n            ('response_a_char', vectorizer_char),\n            ('response_a_word', vectorizer_word)\n        ]), 'response_a'),\n        ('response_b_feats', FeatureUnion([\n            ('response_b_char', vectorizer_char),\n            ('response_b_word', vectorizer_word)\n        ]), 'response_b')\n    ]\n)\ntrain_feats_ancient = preprocessor.fit_transform(train)\ntest_feats_ancient = preprocessor.transform(test)\nprint(\"train_feats_ancient shape:\",train_feats_ancient.shape)\nprint(\"test_feats_ancient shape:\",test_feats_ancient.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T07:01:58.313602Z","iopub.execute_input":"2024-11-21T07:01:58.313904Z","iopub.status.idle":"2024-11-21T07:05:33.330811Z","shell.execute_reply.started":"2024-11-21T07:01:58.313876Z","shell.execute_reply":"2024-11-21T07:05:33.329755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_feats_combined = scipy.sparse.hstack((train_feats_modern, train_feats_ancient))\ntest_feats_combined = scipy.sparse.hstack((test_feats_modern, test_feats_ancient))\nprint(\"train_feats_combined shape:\",train_feats_combined.shape)\nprint(\"test_feats_combined shape:\",test_feats_combined.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T07:05:33.332318Z","iopub.execute_input":"2024-11-21T07:05:33.332767Z","iopub.status.idle":"2024-11-21T07:05:34.979589Z","shell.execute_reply.started":"2024-11-21T07:05:33.332719Z","shell.execute_reply":"2024-11-21T07:05:34.978432Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Ftrl_sklearn(BaseEstimator):\n    def __init__(self):\n        self._estimator = FtrlProximal(alpha=0.01, beta=1.0, l1=75.0, l2=0.0, model_type='classification')\n        self._estimator_type = \"classifier\"\n        \n    def fit(self, X, y):\n        self._estimator.fit(X, y, num_passes=4)\n        return self\n        \n    def predict(self, X):\n        probas = self._estimator.predict(X)\n        probas_array = np.array([np.clip(np.append(0, probas[i]), 0, None) for i in range(len(probas))])\n        return probas_array.argmax(axis=1)\n\n    def predict_proba(self, X):\n        probas = self._estimator.predict(X)\n        probas_array = np.array([np.clip(np.append(0, probas[i]), 0, None) for i in range(len(probas))])\n        return probas_array\n\nftrl_model = Ftrl_sklearn()\nlog_model = LogisticRegression(C=0.1, solver='liblinear', dual=True, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T08:21:06.902707Z","iopub.execute_input":"2024-11-21T08:21:06.90318Z","iopub.status.idle":"2024-11-21T08:21:06.914971Z","shell.execute_reply.started":"2024-11-21T08:21:06.903128Z","shell.execute_reply":"2024-11-21T08:21:06.913808Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nencoder = LabelEncoder()\ntrain['winner_encoded'] = encoder.fit_transform(train['winner'])\n\nprint('ftrl_model CV performing...')\naccuracy_scores = cross_val_score(ftrl_model, train_feats_combined, train['winner_encoded'].to_numpy(), cv=3, scoring='accuracy')\nprint(f'Accuracy scores for each fold: {accuracy_scores}')\nprint(f'Mean accuracy: {accuracy_scores.mean():.4f}\\n')\n\nprint('log_model CV performing...')\naccuracy_scores = cross_val_score(log_model, train_feats_combined, train['winner_encoded'].to_numpy(), cv=3, scoring='accuracy')\nprint(f'Accuracy scores for each fold: {accuracy_scores}')\nprint(f'Mean accuracy: {accuracy_scores.mean():.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T08:21:07.565393Z","iopub.execute_input":"2024-11-21T08:21:07.565799Z","iopub.status.idle":"2024-11-21T08:21:53.953707Z","shell.execute_reply.started":"2024-11-21T08:21:07.565767Z","shell.execute_reply":"2024-11-21T08:21:53.952456Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nensemble = VotingClassifier(\n    estimators=[\n        ('ftrl', ftrl_model),\n        ('log', log_model)\n    ],\n    weights=[0.50, 0.50], voting='soft'\n)\nensemble.fit(train_feats_combined, train['winner_encoded'].to_numpy())\nprint('ensemble CV performing...')\naccuracy_scores = cross_val_score(ensemble, train_feats_combined, train['winner_encoded'].to_numpy(), cv=3, scoring='accuracy')\nprint(f'Accuracy scores for each fold: {accuracy_scores}')\nprint(f'Mean accuracy: {accuracy_scores.mean():.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T08:21:53.962736Z","iopub.execute_input":"2024-11-21T08:21:53.963188Z","iopub.status.idle":"2024-11-21T08:22:59.694536Z","shell.execute_reply.started":"2024-11-21T08:21:53.963132Z","shell.execute_reply":"2024-11-21T08:22:59.693096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test['winner_'] = ensemble.predict_proba(test_feats_combined).argmax(axis=1)\ntest['winner'] = encoder.inverse_transform(test['winner_'])\ntest[['id','winner']].to_csv('submission.csv', index=False)\ntest[['id','winner']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T08:22:59.695936Z","iopub.execute_input":"2024-11-21T08:22:59.696441Z","iopub.status.idle":"2024-11-21T08:22:59.715459Z","shell.execute_reply.started":"2024-11-21T08:22:59.696392Z","shell.execute_reply":"2024-11-21T08:22:59.714172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}