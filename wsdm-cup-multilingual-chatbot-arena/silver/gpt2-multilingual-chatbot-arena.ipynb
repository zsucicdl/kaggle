{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86946,"databundleVersionId":10131489,"sourceType":"competition"},{"sourceId":79529,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":66816,"modelId":91833}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import Dataset\nimport re\nfrom transformers import GPT2Tokenizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-21T15:04:48.234417Z","iopub.execute_input":"2024-11-21T15:04:48.235381Z","iopub.status.idle":"2024-11-21T15:04:52.762796Z","shell.execute_reply.started":"2024-11-21T15:04:48.235321Z","shell.execute_reply":"2024-11-21T15:04:52.761534Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Data\ntrain_data = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet')\ntest_data = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet')\n\n#Text Cleaning Function\ndef clean_text(text):\n    # Convert to lowercase\n    text = text.lower()\n    \n    # Remove special characters (keep alphanumeric and spaces)\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n    \n    # Remove extra spaces\n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n    return text\n\n# Clean the relevant text columns in the train and test data\ntrain_data['prompt'] = train_data['prompt'].apply(clean_text)\ntrain_data['response_a'] = train_data['response_a'].apply(clean_text)\ntrain_data['response_b'] = train_data['response_b'].apply(clean_text)\n\ntest_data['prompt'] = test_data['prompt'].apply(clean_text)\ntest_data['response_a'] = test_data['response_a'].apply(clean_text)\ntest_data['response_b'] = test_data['response_b'].apply(clean_text)\n\n# Step 3: Tokenization (Using GPT-2 Tokenizer from Hugging Face)\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n\n# Set pad_token to eos_token if not already set\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\n# Tokenize the text (prompt, response_a, response_b)\ntrain_data['prompt_tokens'] = train_data['prompt'].apply(lambda x: tokenizer.encode(x, truncation=True, padding='max_length', max_length=512))\ntrain_data['response_a_tokens'] = train_data['response_a'].apply(lambda x: tokenizer.encode(x, truncation=True, padding='max_length', max_length=512))\ntrain_data['response_b_tokens'] = train_data['response_b'].apply(lambda x: tokenizer.encode(x, truncation=True, padding='max_length', max_length=512))\n\ntest_data['prompt_tokens'] = test_data['prompt'].apply(lambda x: tokenizer.encode(x, truncation=True, padding='max_length', max_length=512))\ntest_data['response_a_tokens'] = test_data['response_a'].apply(lambda x: tokenizer.encode(x, truncation=True, padding='max_length', max_length=512))\ntest_data['response_b_tokens'] = test_data['response_b'].apply(lambda x: tokenizer.encode(x, truncation=True, padding='max_length', max_length=512))\n\n# Optional: Check the cleaned data and tokenized output\nprint(train_data[['prompt', 'response_a', 'response_b', 'prompt_tokens', 'response_a_tokens', 'response_b_tokens']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T15:07:38.95757Z","iopub.execute_input":"2024-11-21T15:07:38.958062Z","iopub.status.idle":"2024-11-21T15:12:20.380927Z","shell.execute_reply.started":"2024-11-21T15:07:38.958024Z","shell.execute_reply":"2024-11-21T15:12:20.379745Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\nimport torch\n\n# Load the fine-tuned model\nmodel = GPT2ForSequenceClassification.from_pretrained('/kaggle/input/gpt2/transformers/gpt21/1')\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\ntokenizer.pad_token = tokenizer.eos_token  # Ensure the padding token is set\n\n# Set the model to evaluation mode\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T15:22:08.994855Z","iopub.execute_input":"2024-11-21T15:22:08.99533Z","iopub.status.idle":"2024-11-21T15:22:10.384062Z","shell.execute_reply.started":"2024-11-21T15:22:08.995285Z","shell.execute_reply":"2024-11-21T15:22:10.382912Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tokenize test data\ntest_data['prompt_tokens'] = test_data['prompt'].apply(lambda x: tokenizer.encode(x, truncation=True, padding='max_length', max_length=512))\ntest_data['response_a_tokens'] = test_data['response_a'].apply(lambda x: tokenizer.encode(x, truncation=True, padding='max_length', max_length=512))\ntest_data['response_b_tokens'] = test_data['response_b'].apply(lambda x: tokenizer.encode(x, truncation=True, padding='max_length', max_length=512))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T15:22:11.490443Z","iopub.execute_input":"2024-11-21T15:22:11.490911Z","iopub.status.idle":"2024-11-21T15:22:11.537107Z","shell.execute_reply.started":"2024-11-21T15:22:11.490871Z","shell.execute_reply":"2024-11-21T15:22:11.535892Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_winner(prompt, response_a, response_b, model, tokenizer):\n    # Concatenate prompt with response_a and response_b\n    input_a = f\"{prompt} [SEP] {response_a}\"\n    input_b = f\"{prompt} [SEP] {response_b}\"\n    \n    # Tokenize both inputs\n    tokens_a = tokenizer.encode(input_a, truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n    tokens_b = tokenizer.encode(input_b, truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n    \n    # Get model logits for each input\n    with torch.no_grad():\n        logits_a = model(tokens_a).logits[0][0].item()  # Logit for class 0 (response_a)\n        logits_b = model(tokens_b).logits[0][0].item()  # Logit for class 0 (response_b)\n    \n    # Compare logits and return the \"winner\"\n    return \"response_a\" if logits_a > logits_b else \"response_b\"\n\n# Apply to test data\ntest_data['predicted_winner'] = test_data.apply(\n    lambda row: predict_winner(row['prompt'], row['response_a'], row['response_b'], model, tokenizer),\n    axis=1\n)\n\n# Optional: Inspect predictions\nprint(test_data[['prompt', 'response_a', 'response_b', 'predicted_winner']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T15:22:13.325521Z","iopub.execute_input":"2024-11-21T15:22:13.325976Z","iopub.status.idle":"2024-11-21T15:22:25.701206Z","shell.execute_reply.started":"2024-11-21T15:22:13.32594Z","shell.execute_reply":"2024-11-21T15:22:25.699974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate accuracy on validation data\naccuracy = (train_data['winner'] == train_data['winner']).mean()\nprint(f\"Validation Accuracy: {accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T15:22:25.703109Z","iopub.execute_input":"2024-11-21T15:22:25.703468Z","iopub.status.idle":"2024-11-21T15:22:25.715069Z","shell.execute_reply.started":"2024-11-21T15:22:25.703432Z","shell.execute_reply":"2024-11-21T15:22:25.713887Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate predictions for test set\ntrain_data['winner'] = train_data['winner']\n\n# Save to submission file\ntrain_data[['id', 'winner']].to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T15:23:36.453803Z","iopub.execute_input":"2024-11-21T15:23:36.454254Z","iopub.status.idle":"2024-11-21T15:23:36.582352Z","shell.execute_reply.started":"2024-11-21T15:23:36.454216Z","shell.execute_reply":"2024-11-21T15:23:36.581221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub_df = pd.read_csv(\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/sample_submission.csv\")\nsub_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.read_csv(\"submission.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#sub = train_data[['id','winner']]\n#sub.to_csv('submission.csv', index=False)\n#sub\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T15:24:01.756645Z","iopub.execute_input":"2024-11-21T15:24:01.757086Z","iopub.status.idle":"2024-11-21T15:24:01.894113Z","shell.execute_reply.started":"2024-11-21T15:24:01.757052Z","shell.execute_reply":"2024-11-21T15:24:01.892956Z"}},"outputs":[],"execution_count":null}]}