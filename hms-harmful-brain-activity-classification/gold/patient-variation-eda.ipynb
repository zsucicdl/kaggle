{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7392733,"sourceType":"datasetVersion","datasetId":4297749},{"sourceId":7392775,"sourceType":"datasetVersion","datasetId":4297782}],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":323.289607,"end_time":"2024-01-13T13:38:46.622508","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-13T13:33:23.332901","version":"2.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Comments on EDA","metadata":{"papermill":{"duration":0.007397,"end_time":"2024-01-13T13:33:27.152375","exception":false,"start_time":"2024-01-13T13:33:27.144978","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Looked at how evaluators were doing with regards to two of the Main Term designations in the ACNS Guidelines.","metadata":{}},{"cell_type":"markdown","source":"Created a train.csv using only rows with high agreement among experts (0.9 or better).  Tried the result on couple of the popular shared notebooks.  Result was consistently much worse than the standard train.\n\nA discussion post talked about the need to model the 'experts' rather than model labels that match the ACNS definitions.\nhttps://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/476007#2651000\n","metadata":{}},{"cell_type":"markdown","source":"Further analysis indicates that two different distributions of labels exist dependent on the number of evaluators used.","metadata":{}},{"cell_type":"markdown","source":"The popular shared notebooks are only using the first row of data for each eeg-id.\n\nI believe this is an error and a mis-interpertation of the overview.   \n\nThis notebook shows that valuable information is contained when using all rows per eeg_id.","metadata":{}},{"cell_type":"markdown","source":"# Load Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\n\nimport warnings\n\n# Ignore all warnings\nwarnings.filterwarnings('ignore')\n\n\n","metadata":{"papermill":{"duration":0.843319,"end_time":"2024-01-13T13:33:28.003192","exception":false,"start_time":"2024-01-13T13:33:27.159873","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-15T13:54:44.434486Z","iopub.execute_input":"2024-02-15T13:54:44.434957Z","iopub.status.idle":"2024-02-15T13:54:45.456314Z","shell.execute_reply.started":"2024-02-15T13:54:44.434917Z","shell.execute_reply":"2024-02-15T13:54:45.455063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Train Data","metadata":{"papermill":{"duration":0.006939,"end_time":"2024-01-13T13:33:28.017754","exception":false,"start_time":"2024-01-13T13:33:28.010815","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\nTARGETS = df.columns[-6:]\nprint('df shape:', df.shape )\nprint('Targets', list(TARGETS))\ndf = df.sort_values(by=['patient_id', 'eeg_id', 'eeg_sub_id'])\ndf","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.323205,"end_time":"2024-01-13T13:33:28.347993","exception":false,"start_time":"2024-01-13T13:33:28.024788","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-15T13:54:45.458447Z","iopub.execute_input":"2024-02-15T13:54:45.459681Z","iopub.status.idle":"2024-02-15T13:54:45.781391Z","shell.execute_reply.started":"2024-02-15T13:54:45.459635Z","shell.execute_reply":"2024-02-15T13:54:45.78027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Row Accuracy\n\nIn 2003 when I was trained on the 6 sigma process, a standard starting point was to evaluate the measurement system.   Multiple readings on the same 'part' were made.\n\n\nMultiple rows of data are available for many of the eeg_id.  Lets use those looking at how often agreement for the 'expert_consensus' existed for each row.\n\n","metadata":{"papermill":{"duration":0.007773,"end_time":"2024-01-13T13:33:28.363641","exception":false,"start_time":"2024-01-13T13:33:28.355868","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Adding a new column 'total_evaluators' that sums up the six specified columns\ndf['total_evaluators'] = df[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].sum(axis=1)\n\ndf.sample(25)  # Display the DataFrame with the new column","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:45.786738Z","iopub.execute_input":"2024-02-15T13:54:45.787079Z","iopub.status.idle":"2024-02-15T13:54:45.837779Z","shell.execute_reply.started":"2024-02-15T13:54:45.787051Z","shell.execute_reply":"2024-02-15T13:54:45.836485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plotting a histogram for the 'total_evaluators' column in the 'df' DataFrame\n\nplt.figure(figsize=(10, 6))\nplt.hist(df['total_evaluators'], bins=10, color='blue', edgecolor='black')\nplt.title('Histogram of Total Evaluators')\nplt.xlabel('Total Evaluators')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:45.839362Z","iopub.execute_input":"2024-02-15T13:54:45.840088Z","iopub.status.idle":"2024-02-15T13:54:46.130412Z","shell.execute_reply.started":"2024-02-15T13:54:45.840045Z","shell.execute_reply":"2024-02-15T13:54:46.129184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It would seem that the training data might be aggregrated from at least two different studies with different number of persons doing the evaluations.   \n\nWith more evaluators it is likely data that should have more weight if there is good consensus.","metadata":{}},{"cell_type":"code","source":"# Modifying the previous code to add an additional column 'consensus_column' to 'df'\n\n# Finding the column with the largest number for each row and storing the value in 'consensus'\ndf['consensus'] = df[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].max(axis=1)\n\n# Identifying the column name that corresponds to the max value for each row\ndf['consensus_column'] = df[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].idxmax(axis=1)\n\ndf.head()  # Display the DataFrame with the new columns\n\n\n\ndf.sample(25)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:46.132312Z","iopub.execute_input":"2024-02-15T13:54:46.133014Z","iopub.status.idle":"2024-02-15T13:54:46.252575Z","shell.execute_reply.started":"2024-02-15T13:54:46.132972Z","shell.execute_reply":"2024-02-15T13:54:46.25139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a new column that shows the percentage agreement\ndf['row_agreement'] = df['consensus']/df['total_evaluators']\ndf.sample(25)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:46.255098Z","iopub.execute_input":"2024-02-15T13:54:46.255794Z","iopub.status.idle":"2024-02-15T13:54:46.285992Z","shell.execute_reply.started":"2024-02-15T13:54:46.255763Z","shell.execute_reply":"2024-02-15T13:54:46.284807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('row_agreement.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:46.287158Z","iopub.execute_input":"2024-02-15T13:54:46.287704Z","iopub.status.idle":"2024-02-15T13:54:47.077924Z","shell.execute_reply.started":"2024-02-15T13:54:46.287674Z","shell.execute_reply":"2024-02-15T13:54:47.076838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting a histogram for the 'row_agreement' column\n\nimport numpy as np\n\n\n# Now, plotting the histogram for 'row_agreement'\nplt.figure(figsize=(10, 6))\nplt.hist(df['row_agreement'], bins=10, color='green', edgecolor='black')\nplt.title('Histogram of Row Agreement')\nplt.xlabel('Row Agreement')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:47.079382Z","iopub.execute_input":"2024-02-15T13:54:47.079975Z","iopub.status.idle":"2024-02-15T13:54:47.329401Z","shell.execute_reply.started":"2024-02-15T13:54:47.079935Z","shell.execute_reply":"2024-02-15T13:54:47.328151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This looks a bit odd.  Again kind of thinking that multiple studies put togeather for for train data, with some of them having poor agreement among evalators.   Many of the 1.0 ratings are for rows with small number of evalators.\n\nRows that have very low agreement on the consensus are a problem to be addressed - not sure what's is best?","metadata":{}},{"cell_type":"code","source":"# Plotting an XY plot for 'row_agreement' vs 'total_evaluators'\n\nplt.figure(figsize=(10, 6))\nplt.scatter(df['row_agreement'], df['total_evaluators'], color='purple', edgecolor='black')\nplt.title('XY Plot of Row Agreement vs Total Evaluators')\nplt.xlabel('Row Agreement')\nplt.ylabel('Total Evaluators')\nplt.grid(True)\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:47.334278Z","iopub.execute_input":"2024-02-15T13:54:47.334618Z","iopub.status.idle":"2024-02-15T13:54:47.821078Z","shell.execute_reply.started":"2024-02-15T13:54:47.334591Z","shell.execute_reply":"2024-02-15T13:54:47.81979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I am tempted to suggest that each of the 6 seizer types has a different degree of difficulty for evaluators.\n","metadata":{}},{"cell_type":"code","source":"# Assuming 'df' has a mechanism to identify which of the 6 columns ('seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote') is the consensus for each row\n# We will generate a plot that shows 'row_agreement' values when each of these columns is the consensus vote\n\n# For demonstration, let's assume 'consensus_column' is a column that indicates which of the 6 columns is the consensus\n# This step is for demonstration purposes and should be replaced with your actual method of determining the consensus column\ndf['consensus_column'] = df[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].idxmax(axis=1)\n\n# Now, let's plot 'row_agreement' for each of the 6 columns when they are the consensus\nplt.figure(figsize=(12, 8))\n\nfor column in ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']:\n    # Filter the DataFrame for rows where this column is the consensus\n    filtered_df = df[df['consensus_column'] == column]\n    # Plotting\n    plt.scatter(filtered_df['row_agreement'], [column] * len(filtered_df), label=column)\n\nplt.title('Row Agreement for Each Column as Consensus')\nplt.xlabel('Row Agreement')\nplt.yticks(['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote'])\nplt.ylabel('Consensus Column')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:47.822562Z","iopub.execute_input":"2024-02-15T13:54:47.823514Z","iopub.status.idle":"2024-02-15T13:54:51.951794Z","shell.execute_reply.started":"2024-02-15T13:54:47.82347Z","shell.execute_reply":"2024-02-15T13:54:51.9506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Little hard to see the visual information with this plot.\n\nLets revise the plot to distribution curves.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 8))\n\n# Plotting distribution curves for each column\nfor column in ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']:\n    # Filter the DataFrame for rows where this column is the consensus\n    filtered_df = df[df['consensus_column'] == column]\n\n    # Plotting the distribution curve with clipping the x-axis range\n    sns.kdeplot(filtered_df['row_agreement'], label=column, clip=(0, 1.0))\n\nplt.title('Distribution of EEG_ID Agreement for Each Column as Consensus')\nplt.xlabel('Row Agreement')\nplt.ylabel('Density')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:51.95299Z","iopub.execute_input":"2024-02-15T13:54:51.955314Z","iopub.status.idle":"2024-02-15T13:54:53.978378Z","shell.execute_reply.started":"2024-02-15T13:54:51.955267Z","shell.execute_reply":"2024-02-15T13:54:53.97722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"OK - this plot a little easier for me to interpert.\n\n1.  Some eeg-id have very poor concensus at 20% agreement or less.   Might not want to use this data ?\n2.  seize_vote seems the easiest to rate \n3.  gpd_vote would seem to be the hardest.  \n4.  Again an appearnce that at least two different studies were aggregated to form our train data.\n","metadata":{}},{"cell_type":"markdown","source":"#  eeg Agreement\n\nLets repeat this data analysis by eeg_id.  There are a number of eeg_id that have multiple rows of data.\n\nFirst lets see the distribution of evaluations per egg_id","metadata":{}},{"cell_type":"code","source":"# Assuming 'eeg_id' is a column in the 'df' DataFrame\n# We will generate a histogram that shows the count of rows for each unique 'eeg_id'\n\n# Counting the number of rows for each unique 'eeg_id'\n# Adding the 'eeg_id_counts' to the DataFrame 'df'\n# This will map each 'eeg_id' in 'df' to its count\n\n# First, create a Series with 'eeg_id' as the index and the counts as values\neeg_id_counts = df['eeg_id'].value_counts()\n\n# Mapping each 'eeg_id' in 'df' to its count\ndf['eeg_id_counts'] = df['eeg_id'].map(eeg_id_counts)\n\n\n\n\n# Plotting the histogram\nplt.figure(figsize=(12, 6))\nplt.hist(eeg_id_counts, bins=100, color='orange', edgecolor='black')\nplt.title('Histogram of Row Counts for Each Unique EEG ID')\nplt.xlabel('Number of Rows per EEG ID')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:53.97987Z","iopub.execute_input":"2024-02-15T13:54:53.98018Z","iopub.status.idle":"2024-02-15T13:54:54.385163Z","shell.execute_reply.started":"2024-02-15T13:54:53.980153Z","shell.execute_reply":"2024-02-15T13:54:54.384354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like a patient or two hooked up to an eeg on a single session for long time.    \n\nThe current popular shared notebooks are looking at only the first row per unique eeg_id.  That's how they go from 100K to 17K rows of data.\n\nI think using only the first is leaving information on the table, but not sure I want to include 700 rows for a single eeg_id - hmmm   what to do?","metadata":{}},{"cell_type":"code","source":"df.head(25)  # Display the first few rows of the DataFrame to show the new column\n","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:54.386361Z","iopub.execute_input":"2024-02-15T13:54:54.386836Z","iopub.status.idle":"2024-02-15T13:54:54.417566Z","shell.execute_reply.started":"2024-02-15T13:54:54.386806Z","shell.execute_reply":"2024-02-15T13:54:54.41641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row_agreement_agg = df.groupby('eeg_id')['consensus'].agg('sum')\n\n# Mapping this aggregated value back to each row in 'df'\ndf['row_consensus_agg'] = df['eeg_id'].map(row_agreement_agg)\n\n\nrow_evaluators_agg = df.groupby('eeg_id')['total_evaluators'].agg('sum')\n\n# Mapping this aggregated value back to each row in 'df'\ndf['row_evaluators_agg'] = df['eeg_id'].map(row_evaluators_agg)\n\ndf['eeg_agreement'] = df['row_consensus_agg']/df['row_evaluators_agg']\n\ndf.head(25)  # Display the first few rows of the DataFrame to show the new column\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:54.418979Z","iopub.execute_input":"2024-02-15T13:54:54.419519Z","iopub.status.idle":"2024-02-15T13:54:54.477801Z","shell.execute_reply.started":"2024-02-15T13:54:54.419475Z","shell.execute_reply":"2024-02-15T13:54:54.476727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('eeg_agreement.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:54.479083Z","iopub.execute_input":"2024-02-15T13:54:54.479469Z","iopub.status.idle":"2024-02-15T13:54:55.461894Z","shell.execute_reply.started":"2024-02-15T13:54:54.479435Z","shell.execute_reply":"2024-02-15T13:54:55.460891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 8))\n\n# Plotting distribution curves for each column\nfor column in ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']:\n    # Filter the DataFrame for rows where this column is the consensus\n    filtered_df = df[df['consensus_column'] == column]\n\n    # Plotting the distribution curve with clipping the x-axis range\n    sns.kdeplot(filtered_df['eeg_agreement'], label=column, clip=(0, 1.0))\n\nplt.title('Distribution of EEG_ID Agreement for Each Column as Consensus')\nplt.xlabel('Row Agreement')\nplt.ylabel('Density')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:55.463168Z","iopub.execute_input":"2024-02-15T13:54:55.464296Z","iopub.status.idle":"2024-02-15T13:54:56.718106Z","shell.execute_reply.started":"2024-02-15T13:54:55.464259Z","shell.execute_reply":"2024-02-15T13:54:56.716936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Row and eeg_id appear to have similiar plots.  ","metadata":{}},{"cell_type":"markdown","source":"Expanding on this theme - lets look at patient_id","metadata":{}},{"cell_type":"code","source":"# Assuming 'eeg_id' is a column in the 'df' DataFrame\n# We will generate a histogram that shows the count of rows for each unique 'eeg_id'\n\n# Counting the number of rows for each unique 'eeg_id'\n# Adding the 'eeg_id_counts' to the DataFrame 'df'\n# This will map each 'eeg_id' in 'df' to its count\n\n# First, create a Series with 'eeg_id' as the index and the counts as values\npatient_id_counts = df['patient_id'].value_counts()\n\n# Mapping each 'eeg_id' in 'df' to its count\ndf['patient_id_counts'] = df['patient_id'].map(patient_id_counts)\n\n\n\n\n# Plotting the histogram\nplt.figure(figsize=(12, 6))\nplt.hist(patient_id_counts, bins=100, color='orange', edgecolor='black')\nplt.title('Histogram of Row Counts for Each Unique Patient ID')\nplt.xlabel('Number of Rows per patient ID')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:56.719571Z","iopub.execute_input":"2024-02-15T13:54:56.720499Z","iopub.status.idle":"2024-02-15T13:54:57.062187Z","shell.execute_reply.started":"2024-02-15T13:54:56.720462Z","shell.execute_reply":"2024-02-15T13:54:57.060967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\n\nrow_agreement_agg = df.groupby('patient_id')['consensus'].agg('sum')\n\n# Mapping this aggregated value back to each row in 'df'\ndf['patient_consensus_agg'] = df['patient_id'].map(row_agreement_agg)\n\n\nrow_evaluators_agg = df.groupby('patient_id')['total_evaluators'].agg('sum')\n\n# Mapping this aggregated value back to each row in 'df'\ndf['patient_evaluators_agg'] = df['patient_id'].map(row_evaluators_agg)\n\ndf['patient_agreement'] = df['patient_consensus_agg']/df['patient_evaluators_agg']\n\ndf.sample(25)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:57.0636Z","iopub.execute_input":"2024-02-15T13:54:57.064325Z","iopub.status.idle":"2024-02-15T13:54:57.115009Z","shell.execute_reply.started":"2024-02-15T13:54:57.064293Z","shell.execute_reply":"2024-02-15T13:54:57.114109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\n\n# Plotting distribution curves for each column\nfor column in ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']:\n    # Filter the DataFrame for rows where this column is the consensus\n    filtered_df = df[df['consensus_column'] == column]\n\n    # Plotting the distribution curve with clipping the x-axis range\n    sns.kdeplot(filtered_df['patient_agreement'], label=column, clip=(0, 1.0))\n\nplt.title('Distribution of Patient Agreement for Each Column as Consensus')\nplt.xlabel('Row Agreement')\nplt.ylabel('Density')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:57.116296Z","iopub.execute_input":"2024-02-15T13:54:57.116602Z","iopub.status.idle":"2024-02-15T13:54:58.409545Z","shell.execute_reply.started":"2024-02-15T13:54:57.116576Z","shell.execute_reply":"2024-02-15T13:54:58.40845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Couple of ways to look at this plot.\n\nSeizure_vote - patients with this condition have consistent eeg's\nOR\neasy for evalators to spot and agree.\n\ngpd_vote - patients with this condition don't show the issue over time - it comes and goes\nOR\nvery hard for evalators to spot - the plot suggest we have no eeg for this type where all the evalators agreed \n\n\nOne Conclusion - the shared notebooks that use only the 'first' are missing valuabe information.\n\nAs an initial use of this information I think I will use the patient agreement values as weights in my fork of Chris's catboost model.\n\n\n","metadata":{}},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:58.410983Z","iopub.execute_input":"2024-02-15T13:54:58.4118Z","iopub.status.idle":"2024-02-15T13:54:58.52583Z","shell.execute_reply.started":"2024-02-15T13:54:58.411754Z","shell.execute_reply":"2024-02-15T13:54:58.524673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use this file if you wish to include any of these agreement values in your model.\ndf.to_csv('train_upgraded.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:58.527321Z","iopub.execute_input":"2024-02-15T13:54:58.527766Z","iopub.status.idle":"2024-02-15T13:54:59.779887Z","shell.execute_reply.started":"2024-02-15T13:54:58.527731Z","shell.execute_reply":"2024-02-15T13:54:59.778784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='expert_consensus', y='patient_agreement', data = df)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:54:59.781049Z","iopub.execute_input":"2024-02-15T13:54:59.781373Z","iopub.status.idle":"2024-02-15T13:55:00.042147Z","shell.execute_reply.started":"2024-02-15T13:54:59.781343Z","shell.execute_reply":"2024-02-15T13:55:00.041016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Another way to look at agreement.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.hist(df['patient_agreement'], bins=100, color='green', edgecolor='black')\nplt.title('Histogram of Patient Agreement')\nplt.xlabel('Patient Agreement')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:55:00.043664Z","iopub.execute_input":"2024-02-15T13:55:00.044257Z","iopub.status.idle":"2024-02-15T13:55:00.433761Z","shell.execute_reply.started":"2024-02-15T13:55:00.044198Z","shell.execute_reply":"2024-02-15T13:55:00.43289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The overview describes eeg's were the experts agree as \"idealized\".   If only 3 experts, but they all agree what level of confidence can we have that they are 'ideal'?\n\nIf only a single eeg for a patient, but agreement with a large number of experts, what confidence can we have that they are 'ideal'?\n\nFrom the previous plot we can see that many of the perfect agreement eeg's are 'other' or 'seizure'.  \n","metadata":{}},{"cell_type":"markdown","source":"# Evaluator group size impact","metadata":{}},{"cell_type":"markdown","source":"A couple of the plots above have suggested that our data might be the result of two studies that were combined for this competition.\n\nThe number of evaluators used seems to seperate the two studies.","metadata":{}},{"cell_type":"code","source":"# Create 'large' DataFrame with rows where 'total_evaluators' is greater than 9\nlarge = df[df['total_evaluators'] > 9]\n\n# Create 'small' DataFrame with rows where 'total_evaluators' is less than 10.  actual values are 3 to 6 \nsmall = df[df['total_evaluators'] < 10]\n","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:55:00.435153Z","iopub.execute_input":"2024-02-15T13:55:00.435756Z","iopub.status.idle":"2024-02-15T13:55:00.468549Z","shell.execute_reply.started":"2024-02-15T13:55:00.435723Z","shell.execute_reply":"2024-02-15T13:55:00.46751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"large[\"expert_consensus\"].value_counts().plot(kind='bar');","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:55:00.469991Z","iopub.execute_input":"2024-02-15T13:55:00.471089Z","iopub.status.idle":"2024-02-15T13:55:00.677062Z","shell.execute_reply.started":"2024-02-15T13:55:00.471052Z","shell.execute_reply":"2024-02-15T13:55:00.675925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"small[\"expert_consensus\"].value_counts().plot(kind='bar');","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:55:00.678443Z","iopub.execute_input":"2024-02-15T13:55:00.678833Z","iopub.status.idle":"2024-02-15T13:55:00.999718Z","shell.execute_reply.started":"2024-02-15T13:55:00.678805Z","shell.execute_reply":"2024-02-15T13:55:00.998572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Did not want to see this result.\n\nWhen the number of evaluators is 6 or less, Seizure is the major label, but in the grouping where greater than 9 evaluators were used, this label is the least seen.\n\nNote that all rows are used, a couple of patients have very long eeg records with many evaluations that might change these plots dependent on use of 'first', or 'last', etc.\n\nNo way to know how many evaluators used for the test data.   \n\nThe small vs large group of evaluators presents a real problem - \n\nWith a large group of evaluators the predominat category becomes 'other'.  For many years I tracked defect types for a number of different glass products at number of different producting locations.\nWhen ever 'other' or 'misc' or 'unknown' was the leading type it always suggested a badly trained group of production inspectors.  \n\nMy guess - the large group of data was generated at a ACNS seminar or training session.   Of course, also possible that the large group was highly trained and the 5 available categories were too simplistic for experts.\n\nA key question - was the distribution of eeg's similiar for both groups (so we are seeing measurement error) or was the distribution of eeg's vastly different and we are just seeing the results of completly different studies.\n\nNot sure how to address this question.","metadata":{}},{"cell_type":"markdown","source":"The ACNS web site has a section were folks who want to be blessed can take a test on 25 eeg's.  Wondering if the large group evalators include results from some of that testing effort.  ","metadata":{}},{"cell_type":"markdown","source":"# Idealized Only","metadata":{}},{"cell_type":"code","source":"# Creating a new DataFrame with the condition for high agreement only\n# \nideal_df = df[df['patient_agreement'] > 0.90]\nideal_df.to_csv('ideal_train.csv', index = False)\nideal_df","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:55:01.006682Z","iopub.execute_input":"2024-02-15T13:55:01.007025Z","iopub.status.idle":"2024-02-15T13:55:01.377276Z","shell.execute_reply.started":"2024-02-15T13:55:01.006998Z","shell.execute_reply":"2024-02-15T13:55:01.376055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Run this file rather than train.csv.  My experience - its performs much worse.\n\nMy conclusion - we are not trying to create a model that conforms well to the ACNS guidelines (see link to the document in the overview), but rather we are attempting to model the performance of the evaluators.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\n\n# Plotting distribution curves for each column\nfor column in ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']:\n    # Filter the DataFrame for rows where this column is the consensus\n    filtered_df = ideal_df[ideal_df['consensus_column'] == column]\n\n    # Plotting the distribution curve with clipping the x-axis range\n    sns.kdeplot(filtered_df['patient_agreement'], label=column, clip=(0, 1.0))\n\nplt.title('Distribution of Patient Agreement for Idealized EEG')\nplt.xlabel('Row Agreement')\nplt.ylabel('Density')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:55:01.381378Z","iopub.execute_input":"2024-02-15T13:55:01.381714Z","iopub.status.idle":"2024-02-15T13:55:02.107543Z","shell.execute_reply.started":"2024-02-15T13:55:01.381686Z","shell.execute_reply":"2024-02-15T13:55:02.106482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generalized or Lateral\n\nThe eeg for 4 of the labels are evaluated based on the eeg's being Generalized or Lateral.\n    Generalized - gpd and grda\n    Lateral - lpd and irda\n    \nLet's create some category labels and investiate if the evalators are in agreement on the \"Main Term\" per the ACNS Guidelines","metadata":{}},{"cell_type":"code","source":"df['general_type'] = df['expert_consensus'].astype(str).str[0]\nunique_values = df['general_type'].unique()\nunique_values","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:55:02.109335Z","iopub.execute_input":"2024-02-15T13:55:02.110137Z","iopub.status.idle":"2024-02-15T13:55:02.170387Z","shell.execute_reply.started":"2024-02-15T13:55:02.110087Z","shell.execute_reply":"2024-02-15T13:55:02.169264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='general_type', y='patient_agreement', data = df)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:55:02.17175Z","iopub.execute_input":"2024-02-15T13:55:02.172759Z","iopub.status.idle":"2024-02-15T13:55:02.397285Z","shell.execute_reply.started":"2024-02-15T13:55:02.172716Z","shell.execute_reply":"2024-02-15T13:55:02.396187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As shown earlier in various formats, seizure has best agreement among evaluators.  Also seizure seems to have the clearest outliers.  Tempted to drop those - add it to my todo list and hope to find time.","metadata":{}},{"cell_type":"markdown","source":"Interested in only looking at the L and G rows of data.","metadata":{}},{"cell_type":"code","source":"check_general_lateral = df[df['general_type'].isin(['G', \"L\"])]\ncheck_general_lateral","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:55:02.398742Z","iopub.execute_input":"2024-02-15T13:55:02.399066Z","iopub.status.idle":"2024-02-15T13:55:02.50735Z","shell.execute_reply.started":"2024-02-15T13:55:02.399037Z","shell.execute_reply":"2024-02-15T13:55:02.506106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='general_type', y='patient_agreement', data = check_general_lateral)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:55:02.508449Z","iopub.execute_input":"2024-02-15T13:55:02.508771Z","iopub.status.idle":"2024-02-15T13:55:02.685652Z","shell.execute_reply.started":"2024-02-15T13:55:02.508742Z","shell.execute_reply":"2024-02-15T13:55:02.684396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I keep getting surprised by some of these results.  I expected to see that lateral would have the best agreement.  This would be a basic look at Right vs Left eeg's and deciding if the the waveforms for the label were distributed on both sides or on a single side.\n\nI was assuming I could make a feature that used math to determine if right or left had similiar distributions for the 10 seconds that was being evaluated to seperate the two generalized from the two lateral.  That would seem to be a waste of time.  In several discussion posts it has been suggested that evalators are not looking at only the 10 seconds, but are likely being lead to conclusions based on the full 50 secords or the full 10 minutes.\n\n","metadata":{}},{"cell_type":"code","source":"# Create 'large' DataFrame with rows where 'total_evaluators' is greater than 9\nlarge = check_general_lateral[check_general_lateral['total_evaluators'] > 9]\n\n# Create 'small' DataFrame with rows where 'total_evaluators' is less than 10.  actual values are 3 to 6 \nsmall = check_general_lateral[check_general_lateral['total_evaluators'] < 10]","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:55:02.686856Z","iopub.execute_input":"2024-02-15T13:55:02.68716Z","iopub.status.idle":"2024-02-15T13:55:02.709581Z","shell.execute_reply.started":"2024-02-15T13:55:02.687134Z","shell.execute_reply":"2024-02-15T13:55:02.708382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"large","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:55:02.710752Z","iopub.execute_input":"2024-02-15T13:55:02.711085Z","iopub.status.idle":"2024-02-15T13:55:02.747987Z","shell.execute_reply.started":"2024-02-15T13:55:02.711056Z","shell.execute_reply":"2024-02-15T13:55:02.747042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"small","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:55:02.749097Z","iopub.execute_input":"2024-02-15T13:55:02.74952Z","iopub.status.idle":"2024-02-15T13:55:02.793059Z","shell.execute_reply.started":"2024-02-15T13:55:02.749491Z","shell.execute_reply":"2024-02-15T13:55:02.791948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"large[\"general_type\"].value_counts().plot(kind='bar');","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:55:02.794277Z","iopub.execute_input":"2024-02-15T13:55:02.794602Z","iopub.status.idle":"2024-02-15T13:55:02.970843Z","shell.execute_reply.started":"2024-02-15T13:55:02.794565Z","shell.execute_reply":"2024-02-15T13:55:02.969728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"small[\"general_type\"].value_counts().plot(kind='bar');","metadata":{"execution":{"iopub.status.busy":"2024-02-15T13:55:02.971915Z","iopub.execute_input":"2024-02-15T13:55:02.972197Z","iopub.status.idle":"2024-02-15T13:55:03.154919Z","shell.execute_reply.started":"2024-02-15T13:55:02.972172Z","shell.execute_reply":"2024-02-15T13:55:03.153901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"While the two apparent groups of evalators were shown earlier to have different distributions of labels, they don't seem to have any major difference in the seperation of Generlized from Lateral.","metadata":{}}]}