{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7418759,"sourceType":"datasetVersion","datasetId":4315969},{"sourceId":7427536,"sourceType":"datasetVersion","datasetId":4322021}],"dockerImageVersionId":30636,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **ℹ️Update Info(2024/01/23)**\n\n* **forked original great work kernels**\n    * [Inference] https://www.kaggle.com/code/ttahara/hms-hbac-resnet34d-baseline-inference\n    * [Training] https://www.kaggle.com/code/ttahara/hms-hbac-resnet34d-baseline-training/\n\n\n* **My Train Info**\n    * tf_efficientnetv2_s\n    * Split 10Fold(SGKF)\n    * resize x512\n    * CV:0.6753573036121466","metadata":{}},{"cell_type":"markdown","source":"## Import","metadata":{}},{"cell_type":"code","source":"import sys\nimport os\nimport gc\nimport copy\nimport yaml\nimport random\nimport shutil\nfrom time import time\nimport typing as tp\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import StratifiedGroupKFold\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nfrom torch.optim import lr_scheduler\nfrom torch.cuda import amp\n\nimport timm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-15T11:04:37.890278Z","iopub.execute_input":"2024-01-15T11:04:37.890645Z","iopub.status.idle":"2024-01-15T11:04:44.425877Z","shell.execute_reply.started":"2024-01-15T11:04:37.890592Z","shell.execute_reply":"2024-01-15T11:04:44.42507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"execution":{"iopub.status.busy":"2024-01-15T11:04:44.427741Z","iopub.execute_input":"2024-01-15T11:04:44.428548Z","iopub.status.idle":"2024-01-15T11:04:44.432804Z","shell.execute_reply.started":"2024-01-15T11:04:44.42851Z","shell.execute_reply":"2024-01-15T11:04:44.431946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT = Path.cwd().parent\nINPUT = ROOT / \"input\"\nOUTPUT = ROOT / \"output\"\nSRC = ROOT / \"src\"\n\nDATA = INPUT / \"hms-harmful-brain-activity-classification\"\nTRAIN_SPEC = DATA / \"train_spectrograms\"\nTEST_SPEC = DATA / \"test_spectrograms\"\nTRAINED_MODEL = INPUT / \"hms-train-a-20111-20240118113811\"\n\nTMP = ROOT / \"tmp\"\nTRAIN_SPEC_SPLIT = TMP / \"train_spectrograms_split\"\nTEST_SPEC_SPLIT = TMP / \"test_spectrograms_split\"\nTMP.mkdir(exist_ok=True)\nTRAIN_SPEC_SPLIT.mkdir(exist_ok=True)\nTEST_SPEC_SPLIT.mkdir(exist_ok=True)\n\n\nRANDAM_SEED = 1086\nCLASSES = [\"seizure_vote\", \"lpd_vote\", \"gpd_vote\", \"lrda_vote\", \"grda_vote\", \"other_vote\"]\nN_CLASSES = len(CLASSES)\nFOLDS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nN_FOLDS = len(FOLDS)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T11:04:44.434015Z","iopub.execute_input":"2024-01-15T11:04:44.434355Z","iopub.status.idle":"2024-01-15T11:04:44.448074Z","shell.execute_reply.started":"2024-01-15T11:04:44.434325Z","shell.execute_reply":"2024-01-15T11:04:44.447242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read Data, Convert Spectrograms to Numpy file","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(DATA / \"test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-01-15T11:04:46.581901Z","iopub.execute_input":"2024-01-15T11:04:46.582236Z","iopub.status.idle":"2024-01-15T11:04:46.598586Z","shell.execute_reply.started":"2024-01-15T11:04:46.582211Z","shell.execute_reply":"2024-01-15T11:04:46.59778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-15T11:04:49.237422Z","iopub.execute_input":"2024-01-15T11:04:49.238287Z","iopub.status.idle":"2024-01-15T11:04:49.254417Z","shell.execute_reply.started":"2024-01-15T11:04:49.238253Z","shell.execute_reply":"2024-01-15T11:04:49.253359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### convert sepectogram files to numpy files","metadata":{}},{"cell_type":"code","source":"for spec_id in test[\"spectrogram_id\"]:\n    spec = pd.read_parquet(TEST_SPEC / f\"{spec_id}.parquet\")\n    \n    spec_arr = spec.fillna(0).values[:, 1:].T.astype(\"float32\")  # (Hz, Time) = (400, 300)\n    \n    np.save(TEST_SPEC_SPLIT / f\"{spec_id}.npy\", spec_arr)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T11:04:52.070826Z","iopub.execute_input":"2024-01-15T11:04:52.071181Z","iopub.status.idle":"2024-01-15T11:04:52.30794Z","shell.execute_reply.started":"2024-01-15T11:04:52.071152Z","shell.execute_reply":"2024-01-15T11:04:52.307122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Difinition, Model, Dataset","metadata":{}},{"cell_type":"markdown","source":"### model","metadata":{}},{"cell_type":"code","source":"class HMSHBACSpecModel(nn.Module):\n\n    def __init__(\n            self,\n            model_name: str,\n            pretrained: bool,\n            in_channels: int,\n            num_classes: int,\n        ):\n        super().__init__()\n        self.model = timm.create_model(\n            model_name=model_name, pretrained=pretrained,\n            num_classes=num_classes, in_chans=in_channels)\n\n    def forward(self, x):\n        h = self.model(x)      \n\n        return h","metadata":{"execution":{"iopub.status.busy":"2024-01-15T11:04:55.095648Z","iopub.execute_input":"2024-01-15T11:04:55.096141Z","iopub.status.idle":"2024-01-15T11:04:55.103917Z","shell.execute_reply.started":"2024-01-15T11:04:55.096105Z","shell.execute_reply":"2024-01-15T11:04:55.102847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataset","metadata":{}},{"cell_type":"code","source":"FilePath = tp.Union[str, Path]\nLabel = tp.Union[int, float, np.ndarray]\n\nclass HMSHBACSpecDataset(torch.utils.data.Dataset):\n\n    def __init__(\n        self,\n        image_paths: tp.Sequence[FilePath],\n        labels: tp.Sequence[Label],\n        transform: A.Compose,\n    ):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, index: int):\n        img_path = self.image_paths[index]\n        label = self.labels[index]\n\n        img = np.load(img_path)  # shape: (Hz, Time) = (400, 300)\n        \n        # log transform\n        img = np.clip(img,np.exp(-4), np.exp(8))\n        img = np.log(img)\n        \n        # normalize per image\n        eps = 1e-6\n        img_mean = img.mean(axis=(0, 1))\n        img = img - img_mean\n        img_std = img.std(axis=(0, 1))\n        img = img / (img_std + eps)\n\n        img = img[..., None] # shape: (Hz, Time) -> (Hz, Time, Channel)\n        img = self._apply_transform(img)\n\n        return {\"data\": img, \"target\": label}\n\n    def _apply_transform(self, img: np.ndarray):\n        \"\"\"apply transform to image and mask\"\"\"\n        transformed = self.transform(image=img)\n        img = transformed[\"image\"]\n        return img","metadata":{"execution":{"iopub.status.busy":"2024-01-15T11:05:00.503969Z","iopub.execute_input":"2024-01-15T11:05:00.504831Z","iopub.status.idle":"2024-01-15T11:05:00.515692Z","shell.execute_reply.started":"2024-01-15T11:05:00.504798Z","shell.execute_reply":"2024-01-15T11:05:00.514344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference Test Data","metadata":{}},{"cell_type":"code","source":"class CFG:\n    model_name = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n    img_size = 512\n    max_epoch = 9\n    batch_size = 32\n    lr = 1.0e-03\n    weight_decay = 1.0e-02\n    es_patience =  5\n    seed = 1086\n    deterministic = True\n    enable_amp = True\n    device = \"cuda\"","metadata":{"execution":{"iopub.status.busy":"2024-01-15T11:05:08.674576Z","iopub.execute_input":"2024-01-15T11:05:08.674961Z","iopub.status.idle":"2024-01-15T11:05:08.680482Z","shell.execute_reply.started":"2024-01-15T11:05:08.674933Z","shell.execute_reply":"2024-01-15T11:05:08.679301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_device(\n    tensors: tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor]],\n    device: torch.device, *args, **kwargs\n):\n    if isinstance(tensors, tuple):\n        return (t.to(device, *args, **kwargs) for t in tensors)\n    elif isinstance(tensors, dict):\n        return {\n            k: t.to(device, *args, **kwargs) for k, t in tensors.items()}\n    else:\n        return tensors.to(device, *args, **kwargs)\n\n    \ndef get_test_path_label(test: pd.DataFrame):\n    \"\"\"Get file path and dummy target info.\"\"\"\n    \n    img_paths = []\n    labels = np.full((len(test), 6), -1, dtype=\"float32\")\n    for spec_id in test[\"spectrogram_id\"].values:\n        img_path = TEST_SPEC_SPLIT / f\"{spec_id}.npy\"\n        img_paths.append(img_path)\n        \n    test_data = {\n        \"image_paths\": img_paths,\n        \"labels\": [l for l in labels]}\n    \n    return test_data\n\ndef get_test_transforms(CFG):\n    test_transform = A.Compose([\n        A.Resize(p=1.0, height=CFG.img_size, width=CFG.img_size),\n        ToTensorV2(p=1.0)\n    ])\n    return test_transform","metadata":{"execution":{"iopub.status.busy":"2024-01-15T11:05:13.449312Z","iopub.execute_input":"2024-01-15T11:05:13.450238Z","iopub.status.idle":"2024-01-15T11:05:13.462548Z","shell.execute_reply.started":"2024-01-15T11:05:13.450193Z","shell.execute_reply":"2024-01-15T11:05:13.461485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_inference_loop(model, loader, device):\n    model.to(device)\n    model.eval()\n    pred_list = []\n    with torch.no_grad():\n        for batch in tqdm(loader):\n            x = to_device(batch[\"data\"], device)\n            y = model(x)\n            pred_list.append(y.softmax(dim=1).detach().cpu().numpy())\n        \n    pred_arr = np.concatenate(pred_list)\n    del pred_list\n    return pred_arr","metadata":{"execution":{"iopub.status.busy":"2024-01-15T11:05:14.232957Z","iopub.execute_input":"2024-01-15T11:05:14.233293Z","iopub.status.idle":"2024-01-15T11:05:14.239881Z","shell.execute_reply.started":"2024-01-15T11:05:14.233269Z","shell.execute_reply":"2024-01-15T11:05:14.238626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds_arr = np.zeros((N_FOLDS, len(test), N_CLASSES))\n\ntest_path_label = get_test_path_label(test)\ntest_transform = get_test_transforms(CFG)\ntest_dataset = HMSHBACSpecDataset(**test_path_label, transform=test_transform)\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n\ndevice = torch.device(CFG.device)\n\nfor fold_id in range(N_FOLDS):\n    print(f\"\\n[fold {fold_id}]\")\n    \n    # # get model\n    model_path = TRAINED_MODEL / f\"best_model_fold{fold_id}.pth\"\n    model = HMSHBACSpecModel(\n        model_name=CFG.model_name, pretrained=False, num_classes=6, in_channels=1)\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    \n    # # inference\n    test_pred = run_inference_loop(model, test_loader, device)\n    test_preds_arr[fold_id] = test_pred\n    \n    del model\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-01-15T11:05:18.596053Z","iopub.execute_input":"2024-01-15T11:05:18.596406Z","iopub.status.idle":"2024-01-15T11:05:27.186252Z","shell.execute_reply.started":"2024-01-15T11:05:18.596377Z","shell.execute_reply":"2024-01-15T11:05:27.185172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make Submission","metadata":{}},{"cell_type":"code","source":"test_pred = test_preds_arr.mean(axis=0)\n\ntest_pred_df = pd.DataFrame(\n    test_pred, columns=CLASSES\n)\n\ntest_pred_df = pd.concat([test[[\"eeg_id\"]], test_pred_df], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T11:05:33.977728Z","iopub.execute_input":"2024-01-15T11:05:33.978106Z","iopub.status.idle":"2024-01-15T11:05:33.989108Z","shell.execute_reply.started":"2024-01-15T11:05:33.978069Z","shell.execute_reply":"2024-01-15T11:05:33.987802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smpl_sub = pd.read_csv(DATA / \"sample_submission.csv\")\n\nsub = pd.merge(\n    smpl_sub[[\"eeg_id\"]], test_pred_df, on=\"eeg_id\", how=\"left\")\n\nsub.to_csv(\"submission.csv\", index=False)\n\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-15T11:05:34.567305Z","iopub.execute_input":"2024-01-15T11:05:34.567782Z","iopub.status.idle":"2024-01-15T11:05:34.599137Z","shell.execute_reply.started":"2024-01-15T11:05:34.567735Z","shell.execute_reply":"2024-01-15T11:05:34.598226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EOF","metadata":{}}]}