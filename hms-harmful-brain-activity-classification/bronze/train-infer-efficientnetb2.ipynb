{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"competition","sourceId":59093,"databundleVersionId":7469972},{"sourceType":"datasetVersion","sourceId":7447509,"datasetId":4334995,"databundleVersionId":7539394},{"sourceType":"datasetVersion","sourceId":7592330,"datasetId":4419301,"databundleVersionId":7687397},{"sourceType":"datasetVersion","sourceId":7450712,"datasetId":4336944,"databundleVersionId":7542629},{"sourceType":"datasetVersion","sourceId":7403069,"datasetId":4304949,"databundleVersionId":7494186},{"sourceType":"datasetVersion","sourceId":7392775,"datasetId":4297782,"databundleVersionId":7483780},{"sourceType":"datasetVersion","sourceId":7392733,"datasetId":4297749,"databundleVersionId":7483738},{"sourceType":"datasetVersion","sourceId":7402356,"datasetId":4304475,"databundleVersionId":7493457},{"sourceType":"kernelVersion","sourceId":158958765}],"dockerImageVersionId":30636,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":270.012179,"end_time":"2024-01-14T22:56:02.916427","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-14T22:51:32.904248","version":"2.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EfficientNetB2 Starter for Brain Comp\nThis notebook is forked from @CHRIS DEOTTE. \n\nThe training dataset consists of 11,138 spectrogram files in Parquet format. These files originate from two sources: the Kaggle spectrograms dataset and [brain-eeg-spectrograms dataset](https://www.kaggle.com/datasets/cdeotte/brain-eeg-spectrograms). Kaggle spectrograms are 10-minute visual representations of EEG signals, while raw EEG spectrograms are 50-second recordings capturing the same events.\n\n\n# Change Logs\n[Version 1] (CV 0.59, LB 0.43) Trained an EfficientNet model using both Kaggle spectrograms and additional EEG spectrograms.\n\n\n**References**\n- [EfficientNetB0 Starter - [LB 0.43]](https://www.kaggle.com/code/cdeotte/efficientnetb0-starter-lb-0-43)\n- [CatBoost Starter - [LB 0.60]](https://www.kaggle.com/code/cdeotte/catboost-starter-lb-0-60?scriptVersionId=159895287)\n- [EfficientNetB0 Starter - [LB 0.43]](https://www.kaggle.com/code/cdeotte/efficientnetb0-starter-lb-0-43)","metadata":{"papermill":{"duration":0.008094,"end_time":"2024-01-14T22:51:36.811998","exception":false,"start_time":"2024-01-14T22:51:36.803904","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Install `EfficientNet` library\nTraditionally, scaling up convolutional neural networks (CNNs) often require tedious manual tuning because of its uncertain results: some models scale with depth, some with width whilst some model scale with image resolution. \n\nEfficientNet used `compound scaling` technique to improve CNNs. Unlike random scaling of individual dimensions like width, depth, or resolution, it uniformly scales all three dimensions together using fixed coefficients. This eliminates manual tuning for efficient and effective scaling.\n\n\n ","metadata":{}},{"cell_type":"code","source":"!pip install --no-index --find-links=/kaggle/input/tf-efficientnet-whl-files /kaggle/input/tf-efficientnet-whl-files/efficientnet-1.1.1-py3-none-any.whl","metadata":{"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2024-02-09T02:08:45.222793Z","iopub.execute_input":"2024-02-09T02:08:45.224144Z","iopub.status.idle":"2024-02-09T02:09:13.771693Z","shell.execute_reply.started":"2024-02-09T02:08:45.224026Z","shell.execute_reply":"2024-02-09T02:09:13.770347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import os, gc, sys, time\nimport tensorflow as tf\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nprint('TensorFlow version =',tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T02:09:13.778531Z","iopub.execute_input":"2024-02-09T02:09:13.778905Z","iopub.status.idle":"2024-02-09T02:09:22.765955Z","shell.execute_reply.started":"2024-02-09T02:09:13.778866Z","shell.execute_reply":"2024-02-09T02:09:22.764612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config\nSpecify computing devices and enabled mix-precisions if possible","metadata":{}},{"cell_type":"code","source":"class CFG:\n    batch_size = 32\n    shuffle = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Enable Distribution using multiple GPUs \ngpus = tf.config.list_physical_devices('GPU')\nif len(gpus) ==0:\n    strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n    print(\"Using CPUs\")\nif len(gpus)==1:\n    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n    print(f'Using {len(gpus)} GPU')\nelse:\n    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n    strategy = tf.distribute.MirroredStrategy()\n    print(f'Using {len(gpus)} GPUs')\n\n# USE MIXED PRECISION\nENABLED = False\nif ENABLED:\n    tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n    print('Mixed precision enabled')\nelse:\n    print('Using full precision')","metadata":{"execution":{"iopub.status.busy":"2024-02-09T02:09:22.767407Z","iopub.execute_input":"2024-02-09T02:09:22.76815Z","iopub.status.idle":"2024-02-09T02:09:22.815432Z","shell.execute_reply.started":"2024-02-09T02:09:22.768111Z","shell.execute_reply":"2024-02-09T02:09:22.814052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random, torch\n# Seed the same seed to all \ndef seed_everything(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n\nSEED = 42\nseed_everything(SEED)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T02:09:22.820046Z","iopub.execute_input":"2024-02-09T02:09:22.820593Z","iopub.status.idle":"2024-02-09T02:09:26.229008Z","shell.execute_reply.started":"2024-02-09T02:09:22.820544Z","shell.execute_reply":"2024-02-09T02:09:26.227681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ctypes, gc\nlibc = ctypes.CDLL(\"libc.so.6\")\ndef clear_memory():\n    libc.malloc_trim(0)\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T02:09:26.230638Z","iopub.execute_input":"2024-02-09T02:09:26.231535Z","iopub.status.idle":"2024-02-09T02:09:26.239621Z","shell.execute_reply.started":"2024-02-09T02:09:26.231493Z","shell.execute_reply":"2024-02-09T02:09:26.238008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Train Data\nLoad training features and training spectrograms files ","metadata":{"papermill":{"duration":0.007846,"end_time":"2024-01-14T22:51:51.688268","exception":false,"start_time":"2024-01-14T22:51:51.680422","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Load Train Features\nCreate spectrogram features like`spectrogram_id` `eeg_id` `spectrogram_label_offset_seconds`\n\nFollowing the competition's data description, the test data contains no overlapping samples with the same `ee_id` and `spectrogram_id`. Therefore, we generate training data by grouping samples based on `spectrogram_id` and averaging the corresponding votes for each unique `spectrogram_id`.\n\n[Relevant Discussion](https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467021)","metadata":{"papermill":{"duration":0.009407,"end_time":"2024-01-14T22:51:52.004075","exception":false,"start_time":"2024-01-14T22:51:51.994668","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def create_train_features(df):\n    # eeg_label_offset_seconds - The time between the beginning of the consolidated EEG and this subsample\n    train_df = df.groupby('eeg_id').agg({'spectrogram_id':'first',\n                       'spectrogram_label_offset_seconds':'min'})\n    # spec_id: `spectrogram_id\n    # min: Minimal time of the same spectogram_id, e.g. 0 for spectrogram_id `353733`\n    train_df.columns = ['spec_id', 'min']\n    # max: Maximal of the same spectrogram_id, 40 for spectrogram_id `353733`\n    train_df['max'] = df.groupby('eeg_id').agg({'spectrogram_label_offset_seconds':'max'})\n    \n    # patient_id: patentid, e.g. 42516 for spectrogram_id `353733`\n    train_df['patient_id'] = df.groupby('eeg_id').agg({'patient_id':'first'})\n    \n    # Generate vote targets ('seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote')\n    # The values is the total votes of a specific target col\n    target_df = df.groupby('eeg_id')[TARGETS].agg({'sum'})\n    # Generate Y values\n    target_data = np.asarray(target_df[TARGETS].values)\n    print(f\"target_data.shape = {target_data.shape}\")\n    y_data = target_data / np.sum(target_data, axis=1, keepdims=True)\n    print(f\"y_data.shape = {y_data.shape}\") # Get 6 columns\n    for i, t  in enumerate(TARGETS):\n        train_df[t] = y_data[:, i]\n\n    # target: expert consensus \n    train_df['target'] = df.groupby('eeg_id').agg({'expert_consensus':'first'})\n    train_df = train_df.reset_index()\n    print('Train data shape:', train_df.shape)\n    return train_df","metadata":{"papermill":{"duration":0.111621,"end_time":"2024-01-14T22:51:52.125134","exception":false,"start_time":"2024-01-14T22:51:52.013513","status":"completed"},"tags":[],"scrolled":true,"execution":{"iopub.status.busy":"2024-02-09T02:09:26.626513Z","iopub.execute_input":"2024-02-09T02:09:26.627763Z","iopub.status.idle":"2024-02-09T02:09:26.639442Z","shell.execute_reply.started":"2024-02-09T02:09:26.627717Z","shell.execute_reply":"2024-02-09T02:09:26.638258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\nTARGETS = df.columns[-6:]\nprint('Train shape:', df.shape )\nprint(f'Target columns: list(TARGETS)')\ndf.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = create_train_features(df)\ntrain_df.head()\ntrain_df.to_csv(\"train.csv\", encoding=\"utf-8\")\nclear_memory()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T02:09:26.641622Z","iopub.execute_input":"2024-02-09T02:09:26.642794Z","iopub.status.idle":"2024-02-09T02:09:27.269906Z","shell.execute_reply.started":"2024-02-09T02:09:26.642747Z","shell.execute_reply":"2024-02-09T02:09:27.268272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Kaggle Training Spectrograms \n\nThe Kaggle training dataset comprises 11,000 individual spectrogram files. To speed the process, load a single file (`eeg_specs.npy`) provided by \"brain-eeg-spectrograms\" dataset, which incorporates all these spectrograms.","metadata":{"papermill":{"duration":0.00881,"end_time":"2024-01-14T22:51:52.142747","exception":false,"start_time":"2024-01-14T22:51:52.133937","status":"completed"},"tags":[]}},{"cell_type":"code","source":"start = time.time()\n# Load all the spectrogram files in a single read (1 minutes)\n# specs = np.load('/kaggle/input/brain-eeg-spectrograms-data/specs.npy', allow_pickle=True).item()\n# Load the spectrogram file one by one (10 minutes)\nPATH = '/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/'\nfiles = os.listdir(PATH)\nprint(f'There are {len(files)} spectrogram parquets')\nspecs = {}\nfor file in tqdm(files):\n    tmp = pd.read_parquet(f'{PATH}{file}')\n    name = int(file.split('.')[0]) # Get file name (spectrogram_id)\n    specs[name] = tmp.iloc[:,1:].values\n# Save to a file\nwith open('specs.npy', 'wb') as f:\n    np.save(f, specs) \nclear_memory()\nprint(f\"Loading specs files in {time.time() - start: .2f} seconds\")","metadata":{"papermill":{"duration":55.16894,"end_time":"2024-01-14T22:52:47.320438","exception":false,"start_time":"2024-01-14T22:51:52.151498","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-09T02:09:27.274114Z","iopub.execute_input":"2024-02-09T02:09:27.274797Z","iopub.status.idle":"2024-02-09T02:09:27.280693Z","shell.execute_reply.started":"2024-02-09T02:09:27.274636Z","shell.execute_reply":"2024-02-09T02:09:27.27933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Additional EEG Spectrograms\nThe additional EEG spectrograms come from @CHRIS DEOTTE's [dataset](https://www.kaggle.com/datasets/cdeotte/brain-eeg-spectrograms) ","metadata":{}},{"cell_type":"code","source":"# DEBUG = True # True: don't include additional EEG data for debugging purpose\n# if not DEBUG:\nstart = time.time()\n# eeg_specs = np.load('/kaggle/input/brain-eeg-spectrograms/eeg_specs.npy',allow_pickle=True).item()    \n\n# Get all eeg_ids from training data\neeg_ids = train_df['eeg_id'].tolist()\neeg_specs= {}\nfor eeg_id in tqdm(eeg_ids):\n    eeg_specs[eeg_id] = np.load(f'/kaggle/input/brain-eeg-spectrograms/EEG_Spectrograms/{eeg_id}.npy')\n\n# # Save to a file\nwith open('eeg_specs.npy', 'wb') as f:\n    np.save(f, eeg_specs) \nclear_memory()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T02:09:27.282465Z","iopub.execute_input":"2024-02-09T02:09:27.283657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sys.exit(0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Train DataLoader\nThis dataloader outputs 4 spectrogram images as a 4 channel image of size 128x256x4 per train sample.\n\n<!-- This notebook version is not using data augmention but the code is available below to experiment with albumentations data augmention. Just add `augment = True` when creating the train data loader. And consider adding new transformations to the augment function below. -->\n\n","metadata":{"papermill":{"duration":0.010384,"end_time":"2024-01-14T22:52:47.341581","exception":false,"start_time":"2024-01-14T22:52:47.331197","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Albumentations is a computer vision tool (https://albumentations.ai/) that perform image augmentations\nimport albumentations as albu\n\nclass DataLoader(tf.keras.utils.Sequence):\n    'Load the data'\n    def __init__(self, data, specs, eeg_specs,\n                 batch_size=32, shuffle=False,\n                 augmentation=False, mode='train'): \n        self.data = data\n        self.specs = specs\n        self.eeg_specs = eeg_specs\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.augmentation = augmentation\n        self.mode = mode\n        self.__update_indexes()\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = int( np.ceil( len(self.data) / self.batch_size ) )\n        return ct\n\n    def __getitem__(self, index):\n        'Get one batch of data'\n        indexes = self.indexes[index*self.batch_size: (index+1)*self.batch_size]\n        X, y = self.__data_generation(indexes)\n        if self.augmentation: # Data argumentation\n            X = self.__augment_batch(X) \n        return X, y\n\n    def __update_indexes(self):\n        'Updates indexes and shuffle indexes if enabled'\n        self.indexes = np.arange( len(self.data) )\n        if self.shuffle: \n            np.random.shuffle(self.indexes)\n                        \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' \n        # X is a collection of 128x256x8 images\n        X = np.zeros((len(indexes), 128, 256, 8), dtype='float32')\n        # Y is 6 targets \n        y = np.zeros((len(indexes), 6), dtype='float32')\n        \n        img = np.ones((128,256),dtype='float32')\n        for i, index in tqdm(enumerate(indexes)):\n            row = self.data.iloc[index]\n            if self.mode=='test': \n                r = 0\n            else: \n                r = int( (row['min'] + row['max'])//4 )\n\n            for k in range(4): # 4 channels\n                # EXTRACT 300 ROWS OF SPECTROGRAM\n                img = self.specs[row.spec_id][r:r+300, k*100:(k+1)*100].T\n                \n                # LOG TRANSFORM SPECTROGRAM\n                img = np.clip(img, np.exp(-4), np.exp(8)) # fall within 10^-4 to 10^8\n                img = np.log(img) # Logarized the img values\n                \n                # STANDARDIZE PER IMAGE\n                ep = 1e-6\n                m = np.nanmean(img.flatten())\n                s = np.nanstd(img.flatten())\n                img = (img-m)/(s+ep)\n                img = np.nan_to_num(img, nan=0.0)\n                \n                # CROP TO 256 TIME STEPS\n                X[i, 14:-14,:, k] = img[:,22:-22] / 2.0\n        \n            # EEG SPECTROGRAMS\n            img = self.eeg_specs[row.eeg_id]\n            X[i, :, :, 4:] = img\n            # Add targets to y\n            if self.mode != 'test':\n                y[i,] = row[TARGETS]\n        print(f\"X.shape = {X.shape}\")    \n        return X, y\n    \n    # Run data augmentation function on training images       \n    def __augment_batch(self, img_batch):        \n        composition = albu.Compose([\n                    albu.HorizontalFlip(p=0.5), \n                    #albu.CoarseDropout(max_holes=8,max_height=32,max_width=32,fill_value=0,p=0.5),\n                ])\n        for i in range(img_batch.shape[0]):\n            img = img_batch[i, ]\n            img_batch[i, ] = composition(image=img)['image']\n        return img_batch","metadata":{"papermill":{"duration":2.369789,"end_time":"2024-01-14T22:52:49.721728","exception":false,"start_time":"2024-01-14T22:52:47.351939","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_loader = DataLoader(train_df, specs, eeg_specs=None, \n                         batch_size=CFG.batch_size, shuffle=CFG.shuffle, \n                         augmentation=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Display DataLoader\nDisplay some example images from data loader","metadata":{"papermill":{"duration":0.00888,"end_time":"2024-01-14T22:52:49.739973","exception":false,"start_time":"2024-01-14T22:52:49.731093","status":"completed"},"tags":[]}},{"cell_type":"code","source":"TARS = {'Seizure':0, 'LPD':1, 'GPD':2, 'LRDA':3, 'GRDA':4, 'Other':5}\nTARS2 = {x:y for y,x in TARS.items()}\n\ndef display_dataLoader(data_loader, train_df):\n    ROWS=2\n    COLS=3\n    BATCHES=2\n    for i, (x,y) in enumerate(data_loader):\n        plt.figure(figsize=(20,8))\n        for j in range(ROWS):\n            for k in range(COLS):\n                plt.subplot(ROWS,COLS,j*COLS+k+1)\n                t = y[j*COLS+k]\n                img = x[j*COLS+k,:,:,0][::-1,]\n                mn = img.flatten().min()\n                mx = img.flatten().max()\n                img = (img-mn)/(mx-mn)\n                plt.imshow(img)\n                tars = f'[{t[0]:0.2f}'\n                for s in t[1:]: tars += f', {s:0.2f}'\n                eeg = train_df.eeg_id.values[i*32+j*COLS+k]\n                plt.title(f'EEG = {eeg}\\nTarget = {tars}',size=12)\n                plt.yticks([])\n                plt.ylabel('Frequencies (Hz)',size=14)\n                plt.xlabel('Time (sec)',size=16)\n        plt.show()\n        if i==BATCHES-1: \n            break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_dataLoader(data_loader)","metadata":{"papermill":{"duration":2.448242,"end_time":"2024-01-14T22:52:52.197249","exception":false,"start_time":"2024-01-14T22:52:49.749007","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sys.exit(0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Scheduler\nWe will train our model with a Step Train Schedule for 4 epochs. First 2 epochs are LR=1e-3. Then epochs 3 and 4 use LR=1e-4 and 1e-5 respectively. (Below we also provide a Cosine Train Schedule if you want to experiment with it. Note it is not used in this notebook).","metadata":{"papermill":{"duration":0.026741,"end_time":"2024-01-14T22:52:52.251841","exception":false,"start_time":"2024-01-14T22:52:52.2251","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import math\nLR_START = 1e-6\nLR_MAX = 1e-3\nLR_MIN = 1e-6\nLR_RAMPUP_EPOCHS = 0\nLR_SUSTAIN_EPOCHS = 0\nEPOCHS2 = 10\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        decay_total_epochs = EPOCHS2 - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1\n        decay_epoch_index = epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n        phase = math.pi * decay_epoch_index / decay_total_epochs\n        cosine_decay = 0.5 * (1 + math.cos(phase))\n        lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN\n    return lr\n\nrng = [i for i in range(EPOCHS2)]\nlr_y = [lrfn(x) for x in rng]\nplt.figure(figsize=(10, 4))\nplt.plot(rng, lr_y, '-o')\nplt.xlabel('epoch',size=14); plt.ylabel('learning rate',size=14)\nplt.title('Cosine Training Schedule',size=16); plt.show()\n\nLR2 = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.304824,"end_time":"2024-01-14T22:52:52.58355","exception":false,"start_time":"2024-01-14T22:52:52.278726","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR_START = 1e-4\nLR_MAX = 1e-3\nLR_RAMPUP_EPOCHS = 0\nLR_SUSTAIN_EPOCHS = 1\nLR_STEP_DECAY = 0.1\nEVERY = 1\nEPOCHS = 4\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//EVERY)\n    return lr\n\nrng = [i for i in range(EPOCHS)]\ny = [lrfn(x) for x in rng]\nplt.figure(figsize=(10, 4))\nplt.plot(rng, y, 'o-'); \nplt.xlabel('epoch',size=14); plt.ylabel('learning rate',size=14)\nplt.title('Step Training Schedule',size=16); plt.show()\n\nLR = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.309296,"end_time":"2024-01-14T22:52:52.92271","exception":false,"start_time":"2024-01-14T22:52:52.613414","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build EfficientNet Model\nVersion 1-3 uses EfficientNet B2. Version 4 uses EfficientNet B0. Our models receives both Kaggle spectrograms and EEG spectrograms from our data loader. We then reshape these 8 spectrograms into 1 large flat image and feed it into EfficientNet.","metadata":{"papermill":{"duration":0.027228,"end_time":"2024-01-14T22:52:52.97653","exception":false,"start_time":"2024-01-14T22:52:52.949302","status":"completed"},"tags":[]}},{"cell_type":"code","source":"VER = 5\n\n# IF THIS EQUALS NONE, THEN WE TRAIN NEW MODELS\n# IF THIS EQUALS DISK PATH, THEN WE LOAD PREVIOUSLY TRAINED MODELS\nLOAD_MODELS_FROM = '/kaggle/input/brain-efficientnet-models-v3-v4-v5/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import efficientnet.tfkeras as efn\n\ndef build_model():\n    \n    inp = tf.keras.Input(shape=(128,256,8))\n    base_model = efn.EfficientNetB0(include_top=False, weights=None, input_shape=None)\n    base_model.load_weights('/kaggle/input/tf-efficientnet-imagenet-weights/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5')\n    \n    # RESHAPE INPUT 128x256x8 => 512x512x3 MONOTONE IMAGE\n    # KAGGLE SPECTROGRAMS\n    x1 = [inp[:,:,:,i:i+1] for i in range(4)]\n    x1 = tf.keras.layers.Concatenate(axis=1)(x1)\n    # EEG SPECTROGRAMS\n    x2 = [inp[:,:,:,i+4:i+5] for i in range(4)]\n    x2 = tf.keras.layers.Concatenate(axis=1)(x2)\n    # MAKE 512X512X3\n    if USE_KAGGLE_SPECTROGRAMS & USE_EEG_SPECTROGRAMS:\n        x = tf.keras.layers.Concatenate(axis=2)([x1,x2])\n    elif USE_EEG_SPECTROGRAMS: x = x2\n    else: x = x1\n    x = tf.keras.layers.Concatenate(axis=3)([x,x,x])\n    \n    # OUTPUT\n    x = base_model(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n        \n    # COMPILE MODEL\n    model = tf.keras.Model(inputs=inp, outputs=x)\n    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n    loss = tf.keras.losses.KLDivergence()\n\n    model.compile(loss=loss, optimizer = opt) \n        \n    return model","metadata":{"papermill":{"duration":0.057714,"end_time":"2024-01-14T22:53:06.682056","exception":false,"start_time":"2024-01-14T22:53:06.624342","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model\nWe train using Group KFold on patient id. If `LOAD_MODELS_FROM = None`, then we will train new models in this notebook version. Otherwise we will load saved models from the path `LOAD_MODELS_FROM`.","metadata":{"papermill":{"duration":0.033717,"end_time":"2024-01-14T22:53:06.742557","exception":false,"start_time":"2024-01-14T22:53:06.70884","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.model_selection import KFold, GroupKFold\nimport tensorflow.keras.backend as K, gc\n\nall_oof = []\nall_true = []\n\ngkf = GroupKFold(n_splits=5)\nfor i, (train_index, valid_index) in enumerate(gkf.split(train, train.target, train.patient_id)):  \n    \n    print('#'*25)\n    print(f'### Fold {i+1}')\n    \n    train_gen = DataGenerator(train.iloc[train_index], shuffle=True, batch_size=32, augment=False)\n    valid_gen = DataGenerator(train.iloc[valid_index], shuffle=False, batch_size=64, mode='valid')\n    \n    print(f'### train size {len(train_index)}, valid size {len(valid_index)}')\n    print('#'*25)\n    \n    K.clear_session()\n    with strategy.scope():\n        model = build_model()\n    if LOAD_MODELS_FROM is None:\n        model.fit(train_gen, verbose=1,\n              validation_data = valid_gen,\n              epochs=EPOCHS, callbacks = [LR])\n        model.save_weights(f'EffNet_v{VER}_f{i}.h5')\n    else:\n        model.load_weights(f'{LOAD_MODELS_FROM}EffNet_v{VER}_f{i}.h5')\n        \n    oof = model.predict(valid_gen, verbose=1)\n    all_oof.append(oof)\n    all_true.append(train.iloc[valid_index][TARGETS].values)\n    \n    del model, oof\n    gc.collect()\n    \nall_oof = np.concatenate(all_oof)\nall_true = np.concatenate(all_true)","metadata":{"papermill":{"duration":161.172,"end_time":"2024-01-14T22:55:47.94776","exception":false,"start_time":"2024-01-14T22:53:06.77576","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV Score for EfficientNet\nThis is CV score for our EfficientNet model.","metadata":{"papermill":{"duration":0.047893,"end_time":"2024-01-14T22:55:48.045405","exception":false,"start_time":"2024-01-14T22:55:47.997512","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/kaggle-kl-div')\nfrom kaggle_kl_div import score\n\noof = pd.DataFrame(all_oof.copy())\noof['id'] = np.arange(len(oof))\n\ntrue = pd.DataFrame(all_true.copy())\ntrue['id'] = np.arange(len(true))\n\ncv = score(solution=true, submission=oof, row_id_column_name='id')\nprint('CV Score KL-Div for EfficientNetB2 =',cv)","metadata":{"papermill":{"duration":0.126007,"end_time":"2024-01-14T22:55:48.222599","exception":false,"start_time":"2024-01-14T22:55:48.096592","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Infer Test and Create Submission CSV\nBelow we use our 5 EfficientNet fold models to infer the test data and create a `submission.csv` file.","metadata":{"papermill":{"duration":0.050491,"end_time":"2024-01-14T22:55:48.321932","exception":false,"start_time":"2024-01-14T22:55:48.271441","status":"completed"},"tags":[]}},{"cell_type":"code","source":"del all_eegs, spectrograms; gc.collect()\ntest = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\nprint('Test shape',test.shape)\ntest.head()","metadata":{"papermill":{"duration":0.073698,"end_time":"2024-01-14T22:55:48.445914","exception":false,"start_time":"2024-01-14T22:55:48.372216","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# READ ALL SPECTROGRAMS\nPATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/'\nfiles2 = os.listdir(PATH2)\nprint(f'There are {len(files2)} test spectrogram parquets')\n    \nspectrograms2 = {}\nfor i,f in enumerate(files2):\n    if i%100==0: print(i,', ',end='')\n    tmp = pd.read_parquet(f'{PATH2}{f}')\n    name = int(f.split('.')[0])\n    spectrograms2[name] = tmp.iloc[:,1:].values\n    \n# RENAME FOR DATALOADER\ntest = test.rename({'spectrogram_id':'spec_id'},axis=1)","metadata":{"papermill":{"duration":0.257975,"end_time":"2024-01-14T22:55:48.757931","exception":false,"start_time":"2024-01-14T22:55:48.499956","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pywt, librosa\n\nUSE_WAVELET = None \n\nNAMES = ['LL','LP','RP','RR']\n\nFEATS = [['Fp1','F7','T3','T5','O1'],\n         ['Fp1','F3','C3','P3','O1'],\n         ['Fp2','F8','T4','T6','O2'],\n         ['Fp2','F4','C4','P4','O2']]\n\n# DENOISE FUNCTION\ndef maddest(d, axis=None):\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n\ndef denoise(x, wavelet='haar', level=1):    \n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1/0.6745) * maddest(coeff[-level])\n\n    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n\n    ret=pywt.waverec(coeff, wavelet, mode='per')\n    \n    return ret\n\ndef spectrogram_from_eeg(parquet_path, display=False):\n    \n    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n    eeg = pd.read_parquet(parquet_path)\n    middle = (len(eeg)-10_000)//2\n    eeg = eeg.iloc[middle:middle+10_000]\n    \n    # VARIABLE TO HOLD SPECTROGRAM\n    img = np.zeros((128,256,4),dtype='float32')\n    \n    if display: plt.figure(figsize=(10,7))\n    signals = []\n    for k in range(4):\n        COLS = FEATS[k]\n        \n        for kk in range(4):\n        \n            # COMPUTE PAIR DIFFERENCES\n            x = eeg[COLS[kk]].values - eeg[COLS[kk+1]].values\n\n            # FILL NANS\n            m = np.nanmean(x)\n            if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n            else: x[:] = 0\n\n            # DENOISE\n            if USE_WAVELET:\n                x = denoise(x, wavelet=USE_WAVELET)\n            signals.append(x)\n\n            # RAW SPECTROGRAM\n            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//256, \n                  n_fft=1024, n_mels=128, fmin=0, fmax=20, win_length=128)\n\n            # LOG TRANSFORM\n            width = (mel_spec.shape[1]//32)*32\n            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n\n            # STANDARDIZE TO -1 TO 1\n            mel_spec_db = (mel_spec_db+40)/40 \n            img[:,:,k] += mel_spec_db\n                \n        # AVERAGE THE 4 MONTAGE DIFFERENCES\n        img[:,:,k] /= 4.0\n        \n        if display:\n            plt.subplot(2,2,k+1)\n            plt.imshow(img[:,:,k],aspect='auto',origin='lower')\n            plt.title(f'EEG {eeg_id} - Spectrogram {NAMES[k]}')\n            \n    if display: \n        plt.show()\n        plt.figure(figsize=(10,5))\n        offset = 0\n        for k in range(4):\n            if k>0: offset -= signals[3-k].min()\n            plt.plot(range(10_000),signals[k]+offset,label=NAMES[3-k])\n            offset += signals[3-k].max()\n        plt.legend()\n        plt.title(f'EEG {eeg_id} Signals')\n        plt.show()\n        print(); print('#'*25); print()\n        \n    return img","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# READ ALL EEG SPECTROGRAMS\nPATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/'\nDISPLAY = 1\nEEG_IDS2 = test.eeg_id.unique()\nall_eegs2 = {}\n\nprint('Converting Test EEG to Spectrograms...'); print()\nfor i,eeg_id in enumerate(EEG_IDS2):\n        \n    # CREATE SPECTROGRAM FROM EEG PARQUET\n    img = spectrogram_from_eeg(f'{PATH2}{eeg_id}.parquet', i<DISPLAY)\n    all_eegs2[eeg_id] = img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INFER EFFICIENTNET ON TEST\npreds = []\nmodel = build_model()\ntest_gen = DataGenerator(test, shuffle=False, batch_size=64, mode='test',\n                         specs = spectrograms2, eeg_specs = all_eegs2)\n\nfor i in range(5):\n    print(f'Fold {i+1}')\n    if LOAD_MODELS_FROM:\n        model.load_weights(f'{LOAD_MODELS_FROM}EffNet_v{VER}_f{i}.h5')\n    else:\n        model.load_weights(f'EffNet_v{VER}_f{i}.h5')\n    pred = model.predict(test_gen, verbose=1)\n    preds.append(pred)\npred = np.mean(preds,axis=0)\nprint()\nprint('Test preds shape',pred.shape)","metadata":{"papermill":{"duration":9.827745,"end_time":"2024-01-14T22:55:58.637732","exception":false,"start_time":"2024-01-14T22:55:48.809987","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame({'eeg_id':test.eeg_id.values})\nsub[TARGETS] = pred\nsub.to_csv('submission.csv',index=False)\nprint('Submissionn shape',sub.shape)\nsub.head()","metadata":{"papermill":{"duration":0.071388,"end_time":"2024-01-14T22:55:58.760368","exception":false,"start_time":"2024-01-14T22:55:58.68898","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\nsub.iloc[:,-6:].sum(axis=1)","metadata":{"papermill":{"duration":0.062742,"end_time":"2024-01-14T22:55:58.873394","exception":false,"start_time":"2024-01-14T22:55:58.810652","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}