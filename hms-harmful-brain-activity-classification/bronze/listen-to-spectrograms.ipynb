{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59093,"databundleVersionId":7457433,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ‚öôÔ∏è Setup","metadata":{}},{"cell_type":"code","source":"# Do imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\n\nimport numpy as np\nimport librosa\nfrom librosa.effects import pitch_shift\nimport soundfile as sf\nimport librosa.display\nimport IPython.display as ipd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-09T20:55:38.885634Z","iopub.execute_input":"2024-01-09T20:55:38.886066Z","iopub.status.idle":"2024-01-09T20:55:38.892278Z","shell.execute_reply.started":"2024-01-09T20:55:38.88603Z","shell.execute_reply":"2024-01-09T20:55:38.891106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comp_path = '/kaggle/input/hms-harmful-brain-activity-classification'\ntrain_spect_dir = '/'.join([comp_path, 'train_spectrograms'])\ntrain_spect_path_list = [entry.path for entry in os.scandir(train_spect_dir)]","metadata":{"execution":{"iopub.status.busy":"2024-01-09T20:55:38.89427Z","iopub.execute_input":"2024-01-09T20:55:38.89474Z","iopub.status.idle":"2024-01-09T20:55:38.913717Z","shell.execute_reply.started":"2024-01-09T20:55:38.894699Z","shell.execute_reply":"2024-01-09T20:55:38.912464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üîä Listen to Spectrogram\nEach spectrogram represents frequencies over time. These are acquired by performing a short-time fourier transform (stft), breaking a signal down into its frequency components over short windows of time.\n\nWe can perform the inverse of this operation (istft) to merge these frequencies back down into the original signal. Then we can listen to the original signal to complement the data we view.\n\nThe actual frequencies in the data are much lower than the human ear will allow, so they've all been boosted to hopefully allow us humans to hear the full freuqnecy spectrum of the data in our audible range.\n\n","metadata":{}},{"cell_type":"code","source":"def play_spectrogram(spectrogram_path, measurement):\n    sample_spect = pd.read_parquet(spectrogram_path)\n    \n    split_spect = {\n        \"LL\": sample_spect.filter(regex='^LL', axis=1),\n        \"RL\": sample_spect.filter(regex='^RL', axis=1),\n        \"RP\": sample_spect.filter(regex='^RP', axis=1),\n        \"LP\": sample_spect.filter(regex='^LP', axis=1),\n    }\n    \n    if measurement not in split_spect.keys():\n        print(f\"Requested measurement '{measurement}' not in options {split_spect.keys()}\")\n        return\n    \n    audio_df = split_spect[measurement].T\n\n    # Transpose the DataFrame and convert it to a NumPy array\n    frequency_data = audio_df.to_numpy(dtype=np.float32)\n    sr = 3000  # Adjust as needed\n    pitch_shift_factor = 5\n    \n    target_frequency_row = 200\n    target_frequency = 1000\n    n_fft = frequency_data.shape[0]\n    delta_f = sr / n_fft\n    all_frequencies = np.arange(0, sr/2, delta_f)\n    frequencies = [column_name[3:] for column_name in split_spect[measurement].columns]\n    \n    closest_frequency_row = np.argmin(np.abs(all_frequencies - target_frequency))\n    print(f\"Row {closest_frequency_row} is closest to {target_frequency} Hz. When pitch-shifted this is {target_frequency*pitch_shift_factor} Hz. Row {closest_frequency_row} is actually {frequencies[closest_frequency_row]} Hz in the data.\")\n    \n    audio_reconstructed = librosa.istft(frequency_data)\n    audio_reconstructed_shifted = pitch_shift(y=audio_reconstructed, sr=sr, n_steps=pitch_shift_factor)\n\n    sf.write('/kaggle/working/reconstructed_audio.wav', audio_reconstructed_shifted, sr)\n    return ipd.Audio('/kaggle/working/reconstructed_audio.wav')\n\ndef plot_spectrogram(spectrogram_path, measurement):\n    sample_spect = pd.read_parquet(spectrogram_path)\n    \n    split_spect = {\n        \"LL\": sample_spect.filter(regex='^LL', axis=1),\n        \"RL\": sample_spect.filter(regex='^RL', axis=1),\n        \"RP\": sample_spect.filter(regex='^RP', axis=1),\n        \"LP\": sample_spect.filter(regex='^LP', axis=1),\n    }\n    \n    if measurement not in split_spect.keys():\n        print(f\"Requested measurement '{measurement}' not in options {split_spect.keys()}\")\n        return\n    \n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 6))\n    label_interval = 5\n    img = ax.imshow(np.log(split_spect[measurement]).T, cmap='viridis', aspect='auto', origin='lower')  # You can choose any colormap (cmap) that suits your preferences\n    cbar = fig.colorbar(img, ax=ax)\n    cbar.set_label('Log(Value)')\n    ax.set_title(measurement)\n    ax.set_ylabel(\"Frequency (Hz)\")\n    ax.set_xlabel(\"Time\")\n\n    ax.set_yticks(np.arange(len(split_spect[measurement].columns)))\n    ax.set_yticklabels([column_name[3:] for column_name in split_spect[measurement].columns])\n    frequencies = [column_name[3:] for column_name in split_spect[measurement].columns]\n    ax.set_yticks(np.arange(0, len(split_spect[measurement].columns), label_interval))\n    ax.set_yticklabels(frequencies[::label_interval])\n    plt.tight_layout()\n    plt.show()\n    return\n\ndef plot_and_play_spectrogram(spectrogram_path, measurement):\n    plot_spectrogram(spectrogram_path, measurement)\n    return play_spectrogram(spectrogram_path, measurement)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T21:02:55.40282Z","iopub.execute_input":"2024-01-09T21:02:55.40374Z","iopub.status.idle":"2024-01-09T21:02:55.422055Z","shell.execute_reply.started":"2024-01-09T21:02:55.403696Z","shell.execute_reply":"2024-01-09T21:02:55.420639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_and_play_spectrogram(train_spect_path_list[35], \"LL\")","metadata":{"execution":{"iopub.status.busy":"2024-01-09T21:09:27.592703Z","iopub.execute_input":"2024-01-09T21:09:27.593144Z","iopub.status.idle":"2024-01-09T21:09:28.582473Z","shell.execute_reply.started":"2024-01-09T21:09:27.593107Z","shell.execute_reply":"2024-01-09T21:09:28.581094Z"},"trusted":true},"execution_count":null,"outputs":[]}]}