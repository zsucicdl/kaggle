{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7392733,"sourceType":"datasetVersion","datasetId":4297749},{"sourceId":7465251,"sourceType":"datasetVersion","datasetId":4317718},{"sourceId":163366179,"sourceType":"kernelVersion"}],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#A51C30\"><b><span style='color:#FFFFFF'>1 |</span></b> <b>INTRODUCTION</b></div>","metadata":{}},{"cell_type":"markdown","source":"### <b><span style='color:#A51C30'> 1.1 </span> GPU Dtype</b> ","metadata":{}},{"cell_type":"markdown","source":"- **`P100 GPU`**: For High Performance Computing(HPC)\n- **`T4 GPU`**: For Deep Learning and AI tasks","metadata":{}},{"cell_type":"markdown","source":"### <b><span style='color:#A51C30'> 1.2 </span> EEG Band</b>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; border: #babab5 solid; padding: 15px; background-color:##A51C30; font-size:100%;\">\n\nüìå **Check out**\n \n - Delta, Belta is most evident in frontally \n - Alpha is both side & posterior region and then c3 & c4 at rest \n - Delta, Belta, Alpha, Theta Frequency is in 0~30Hz","metadata":{}},{"cell_type":"markdown","source":"![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F16438831%2Ffc9b51893c3fcb785de42e2161357ac4%2Feeg%20band.PNG?generation=1708142412775439&alt=media)","metadata":{}},{"cell_type":"markdown","source":"### <b><span style='color:#A51C30'> 1.3 </span> New Chain</b> ","metadata":{}},{"cell_type":"markdown","source":"![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F16438831%2Fee75fb2b76b12fda5c559504eacc09b8%2FCentral.PNG?generation=1708318428173795&alt=media)","metadata":{}},{"cell_type":"markdown","source":"### <b><span style='color:#A51C30'> 1.4 </span> Updated!</b> \n\n<div style=\"border-radius:10px; border: #babab5 solid; padding: 15px; background-color:##A51C30; font-size:100%;\">\n    \nüìå **`VER1`**: Original Chain, 0~30Hz, [4Waveblcok + 1GRU] \n    \nüìå **`VER2`**: Adding Central[Cz,Fz,C4,C3], 0~30Hz, \n","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#A51C30\"><b><span style='color:#FFFFFF'>2 |</span></b> <b>GPUs Setting</b></div>","metadata":{}},{"cell_type":"code","source":"VER = 2\n\nimport os\nimport gc\nimport ctypes\n\nimport numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nprint('tensorflow version:',tf.__version__)\n\n# CUDA 0,1\nos.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n\n# gpu strategy\ngpus = tf.config.list_physical_devices('GPU')\nif len(gpus) <= 1:\n    strategy = tf.distribute.OneDeviceStrategy(device='/gpu:0')\n    print(f'Using {len(gpus)} gpus')\nelse: \n    strategy = tf.distribute.MirroredStrategy()\n    print(f'Using {len(gpus)} gpus')\n    \n# warning filtering\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:20:42.502584Z","iopub.execute_input":"2024-02-19T10:20:42.503558Z","iopub.status.idle":"2024-02-19T10:21:02.13604Z","shell.execute_reply.started":"2024-02-19T10:20:42.503517Z","shell.execute_reply":"2024-02-19T10:21:02.134628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mixed_preicision\n# Helps memeory effectively \n\nMIX=True\n\nif MIX: \n    tf.config.optimizer.set_experimental_options({'auto_mixed_precision':True})\n    print(\"Mixed Precision Enabled\")\nelse:\n    print(\"Using Full Precision\")","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:21:02.140363Z","iopub.execute_input":"2024-02-19T10:21:02.14128Z","iopub.status.idle":"2024-02-19T10:21:02.148075Z","shell.execute_reply.started":"2024-02-19T10:21:02.14124Z","shell.execute_reply":"2024-02-19T10:21:02.146846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Clean Memory**","metadata":{}},{"cell_type":"code","source":"def clean_memory():\n    # malloc_trim: ÌòÑÏû¨ ÏÇ¨Ïö©ÎêòÏßÄ ÏïäÎäî Î©îÎ™®Î¶¨Î•º ÏãúÏä§ÌÖúÏóêÏÑú Îã§Ïãú Î∞òÌôòÌï®0\n    ctypes.CDLL('libc.so.6').malloc_trim(0)\n    gc.collect()\nclean_memory()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:21:02.150366Z","iopub.execute_input":"2024-02-19T10:21:02.151347Z","iopub.status.idle":"2024-02-19T10:21:02.544052Z","shell.execute_reply.started":"2024-02-19T10:21:02.151296Z","shell.execute_reply":"2024-02-19T10:21:02.542847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#A51C30\"><b><span style='color:#FFFFFF'>3 |</span></b> <b>Load Train Data</b></div>","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\")\nprint('train shape: ',train.shape)\ndisplay(train.head())","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:21:02.546841Z","iopub.execute_input":"2024-02-19T10:21:02.547245Z","iopub.status.idle":"2024-02-19T10:21:02.937169Z","shell.execute_reply.started":"2024-02-19T10:21:02.547209Z","shell.execute_reply":"2024-02-19T10:21:02.935756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b><span style='color:#A51C30'> 3.1 </span> Raw EEG Signals</b>","metadata":{}},{"cell_type":"code","source":"New_Chain = True","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:21:02.939029Z","iopub.execute_input":"2024-02-19T10:21:02.939752Z","iopub.status.idle":"2024-02-19T10:21:02.945879Z","shell.execute_reply.started":"2024-02-19T10:21:02.939705Z","shell.execute_reply":"2024-02-19T10:21:02.944324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_parquet('/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/1000913311.parquet')\nFEATS = df.columns\nprint(f'There are {len(FEATS)} raw eeg features')\nprint(list(FEATS))","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:21:02.948146Z","iopub.execute_input":"2024-02-19T10:21:02.948497Z","iopub.status.idle":"2024-02-19T10:21:03.140699Z","shell.execute_reply.started":"2024-02-19T10:21:02.948467Z","shell.execute_reply":"2024-02-19T10:21:03.139374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if New_Chain: \n    print('We will use the follwing subset of 10 raw eeg features:')\n    FEATS = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2','Fz', 'Pz']\n    FEAT2IDX = {x:y for x,y in zip(FEATS, range(len(FEATS)))}\n    print(FEATS)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:21:03.142579Z","iopub.execute_input":"2024-02-19T10:21:03.143075Z","iopub.status.idle":"2024-02-19T10:21:03.150728Z","shell.execute_reply.started":"2024-02-19T10:21:03.143032Z","shell.execute_reply":"2024-02-19T10:21:03.149822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eeg_from_parquet(parquet_path, display=False):\n    \n    # ÌäπÏ†ï electrodeÎßå Ï∂îÏ∂úÌïòÍ∏∞\n    eeg = pd.read_parquet(parquet_path, columns=FEATS)\n    rows = len(eeg)\n    offset = (rows-10000)//2\n    # eegÏùò Íµ¨Í∞Ñ: 50Ï¥à\n    eeg = eeg.iloc[offset:offset+10_000]\n    \n    if display:\n        plt.figure(figsize=(10,5))\n        offset = 0\n        \n    # CONVERT TO NUMPY\n    data = np.zeros((10_000, len(FEATS)))\n    for j,col in enumerate(FEATS):\n        \n        # FILL NAN\n        x = eeg[col].values.astype('float32')\n        m = np.nanmean(x)\n        if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n        else: x[:] = 0\n            \n        data[:,j] = x    \n        \n        if display: \n            if j!=0: offset += x.max()\n            plt.plot(range(10_000), x-offset, label=col)\n            offset -= x.min()\n            \n    if display:\n        plt.legend()\n        name = parquet_path.split('/')[-1]\n        name = name.split('.')[0]\n        plt.title(f'EEG {name}', size=16)\n        plt.show()\n        \n    return data    ","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:21:03.151947Z","iopub.execute_input":"2024-02-19T10:21:03.153452Z","iopub.status.idle":"2024-02-19T10:21:03.165843Z","shell.execute_reply.started":"2024-02-19T10:21:03.153415Z","shell.execute_reply":"2024-02-19T10:21:03.164875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nCREATE_EEGS = False\nall_eegs = {}\nDISPLAY = 4\nEEG_IDS = train.eeg_id.unique()\nPATH = '/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/'\n\nfor i, eeg_id in enumerate(EEG_IDS):\n    if (i%100==0)&(i!=0): print(i, ', ', end='')\n        \n    data = eeg_from_parquet(f'{PATH}{eeg_id}.parquet', display=i<DISPLAY) \n    all_eegs[eeg_id] = data\n    \n    if i==DISPLAY:\n        if CREATE_EEGS:\n            print(f'processing {train.eeg_id.nunique()} eeg parquets... ', end='')\n        else:\n            print(f'Reading {len(EEG_IDS)} eeg Numpys from disk.')\n            \n            break\n\nif New_Chain:   \n    all_eegs = np.load('/kaggle/input/central-part/eegs.npy',allow_pickle=True).item()  ","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:21:03.167293Z","iopub.execute_input":"2024-02-19T10:21:03.168525Z","iopub.status.idle":"2024-02-19T10:23:14.981055Z","shell.execute_reply.started":"2024-02-19T10:21:03.16849Z","shell.execute_reply":"2024-02-19T10:23:14.979653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b><span style='color:#A51C30'> 3.2 </span> Deduplicate Train EEG Id</b>","metadata":{}},{"cell_type":"code","source":"# LOAD TRAIN \ndf = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\nTARGETS = df.columns[-6:]\nTARS = {'Seizure':0, 'LPD':1, 'GPD':2, 'LRDA':3, 'GRDA':4, 'Other':5}\nTARS2 = {x:y for y,x in TARS.items()}\n\ntrain = df.groupby('eeg_id')[['patient_id']].agg('first')\n\ntmp = df.groupby('eeg_id')[TARGETS].agg('sum')\nfor t in TARGETS:\n    train[t] = tmp[t].values\n    \ny_data = train[TARGETS].values\ny_data = y_data / y_data.sum(axis=1,keepdims=True)\ntrain[TARGETS] = y_data\n\ntmp = df.groupby('eeg_id')[['expert_consensus']].agg('first')\ntrain['target'] = tmp\n\ntrain = train.reset_index()\ntrain = train.loc[train.eeg_id.isin(EEG_IDS)]\nprint('Train Data with unique eeg_id shape:', train.shape )\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:14.98586Z","iopub.execute_input":"2024-02-19T10:23:14.986345Z","iopub.status.idle":"2024-02-19T10:23:15.411609Z","shell.execute_reply.started":"2024-02-19T10:23:14.986302Z","shell.execute_reply":"2024-02-19T10:23:15.409363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Expert_Agreement**","metadata":{}},{"cell_type":"code","source":"def expert_agreement(row):\n    max_vote = row[TARGETS].max()\n    if max_vote == 1:\n        return 'Idealized'\n    elif (max_vote < 1) & (max_vote >= 0.85):\n        return 'Well'\n    elif (max_vote <0.85) & (max_vote >= 0.70):\n        return 'Great'\n    elif (max_vote <0.70) & (max_vote >= 0.55):\n        return 'Good'\n    elif (max_vote <0.55) & (max_vote >= 0.40):\n        return 'NotBad'\n    else:\n        return 'Undecided'\n        \ntrain['pattern'] = train.apply(expert_agreement, axis=1)    ","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:15.413919Z","iopub.execute_input":"2024-02-19T10:23:15.414488Z","iopub.status.idle":"2024-02-19T10:23:19.790769Z","shell.execute_reply.started":"2024-02-19T10:23:15.414444Z","shell.execute_reply":"2024-02-19T10:23:19.789381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.countplot(data=train, x='pattern')\nplt.xlabel(\"expert agreement\")\nplt.ylabel(\"Count\")\nplt.legend()\nplt.title(\"Distribution of expert agreeement\")","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:19.792664Z","iopub.execute_input":"2024-02-19T10:23:19.793122Z","iopub.status.idle":"2024-02-19T10:23:20.14439Z","shell.execute_reply.started":"2024-02-19T10:23:19.793081Z","shell.execute_reply":"2024-02-19T10:23:20.143092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b><span style='color:#A51C30'> 3.3 </span> Butter Low-Pass Filter[0~30Hz]</b>","metadata":{}},{"cell_type":"code","source":"from scipy.signal import butter, lfilter\n\ndef butter_lowpass_filter(data, cutoff_freq=30, sampling_rate=200, order=4):\n    nyquist = 0.5 * sampling_rate\n    normal_cutoff = cutoff_freq / nyquist\n    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n    filtered_data = lfilter(b, a, data, axis=0)\n    return filtered_data","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:20.147148Z","iopub.execute_input":"2024-02-19T10:23:20.148204Z","iopub.status.idle":"2024-02-19T10:23:20.368878Z","shell.execute_reply.started":"2024-02-19T10:23:20.148153Z","shell.execute_reply":"2024-02-19T10:23:20.367978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b><span style='color:#A51C30'> 3.4 </span> Wavelet Denoising[db8]</b>","metadata":{}},{"cell_type":"code","source":"import pywt\nprint(\"The wavelet functions we can use:\")\nprint(pywt.wavelist())\n\nUSE_WAVELET = 'db8'","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:20.370065Z","iopub.execute_input":"2024-02-19T10:23:20.370564Z","iopub.status.idle":"2024-02-19T10:23:20.473021Z","shell.execute_reply.started":"2024-02-19T10:23:20.370536Z","shell.execute_reply":"2024-02-19T10:23:20.471786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DENOISE FUNCTION\ndef maddest(d, axis=None):\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n\ndef denoise(x, wavelet='haar', level=1):    \n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1/0.6745) * maddest(coeff[-level])\n\n    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n\n    ret=pywt.waverec(coeff, wavelet, mode='per')\n    \n    return ret","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:20.474695Z","iopub.execute_input":"2024-02-19T10:23:20.47553Z","iopub.status.idle":"2024-02-19T10:23:20.484252Z","shell.execute_reply.started":"2024-02-19T10:23:20.475497Z","shell.execute_reply":"2024-02-19T10:23:20.48296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#A51C30\"><b><span style='color:#FFFFFF'>4 |</span></b> <b>Data Loader</b></div>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nclass DataGenerator(tf.keras.utils.Sequence):\n    # Constructor(init method)\n    def __init__(self,data, batch_size=32, shuffle=True, eegs=all_eegs,\n               mode='train', downsample=5,):\n        \n        self.data = data\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.eegs = eegs \n        self.mode = mode\n        self.downsample = downsample\n        self.on_epoch_end()\n        \n    def __len__(self):\n        ct = int(np.ceil(len(self.data)/self.batch_size))\n        return ct\n        \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X, y = self.__data_generation(indexes)\n        return X[:,::self.downsample,:], y\n        \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.data))\n        if self.shuffle: np.random.shuffle(self.indexes)\n        \n    def __data_generation(self, indexes):\n        # New chain change 8 -> 10\n        X = np.zeros((len(indexes),10_000,10), dtype='float32')\n        y = np.zeros((len(indexes),6),dtype='float32')\n        \n        sample = np.zeros((10_000, X.shape[-1]))\n        for j,i in enumerate(indexes):\n            row = self.data.iloc[i]\n            data = self.eegs[row.eeg_id] \n            \n            # FEATURE ENGINEER\n            sample[:,0] = data[:,FEAT2IDX['Fp1']] - data[:,FEAT2IDX['T3']]\n            sample[:,1] = data[:,FEAT2IDX['T3']] - data[:,FEAT2IDX['O1']]\n            \n            sample[:,2] = data[:,FEAT2IDX['Fp1']] - data[:,FEAT2IDX['C3']]\n            sample[:,3] = data[:,FEAT2IDX['C3']] - data[:,FEAT2IDX['O1']]\n            \n            sample[:,4] = data[:,FEAT2IDX['Fp2']] - data[:,FEAT2IDX['C4']]\n            sample[:,5] = data[:,FEAT2IDX['C4']] - data[:,FEAT2IDX['O2']]\n            \n            sample[:,6] = data[:,FEAT2IDX['Fp2']] - data[:,FEAT2IDX['T4']]\n            sample[:,7] = data[:,FEAT2IDX['T4']] - data[:,FEAT2IDX['O2']]\n            \n            sample[:,8] = data[:,FEAT2IDX['Fz']] - data[:,FEAT2IDX['Pz']]\n            sample[:,9] = data[:,FEAT2IDX['C3']] - data[:,FEAT2IDX['C4']]\n            \n            # crop scaling\n            sample = np.clip(sample, -1024,1024)\n\n            \n            # standarization: (x-mean)/std\n            # The mean of all the raw data: 0\n            # The std of all the raw data: 32\n            sample = np.nan_to_num(sample,nan=0) / 32.0\n            \n            # BUTTER LOW-PASS FILTER[0~30Hz]\n            sample = butter_lowpass_filter(sample)\n            \n            # Wavelet Filtering[db6]\n            sample = denoise(sample,wavelet=USE_WAVELET)\n        \n            X[j,] = sample\n            if self.mode!= 'test':\n                y[j] = row[TARGETS]\n                \n        return X,y\n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:20.485818Z","iopub.execute_input":"2024-02-19T10:23:20.486396Z","iopub.status.idle":"2024-02-19T10:23:20.650998Z","shell.execute_reply.started":"2024-02-19T10:23:20.486365Z","shell.execute_reply":"2024-02-19T10:23:20.649843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#A51C30\"><b><span style='color:#FFFFFF'>5 |</span></b> <b>Build WaveNet Model</b></div>","metadata":{}},{"cell_type":"code","source":"# TRAIN SCHEDULE\n\ndef lrfn(epoch):\n    return [1e-3,1e-3,1e-4,1e-4,1e-5][epoch]\nLR = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\nEPOCHS = 5","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:20.652509Z","iopub.execute_input":"2024-02-19T10:23:20.654291Z","iopub.status.idle":"2024-02-19T10:23:20.661081Z","shell.execute_reply.started":"2024-02-19T10:23:20.654248Z","shell.execute_reply":"2024-02-19T10:23:20.659939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b><span style='color:#A51C30'> 5.1 </span> Wave_Block </b>","metadata":{}},{"cell_type":"markdown","source":"![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F16438831%2F57a7deab91934b33bf8bc3c334a16512%2Fw.PNG?generation=1708167117378209&alt=media)","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense, Multiply, Add, Conv1D, Concatenate,AveragePooling1D, Bidirectional, LSTM\n\n\ndef wave_block(x, filters, kernel_size, n):\n    # dilation_rates: Convultion Layer Îß§Í∞úÎ≥ÄÏàò Ï§ë ÌïòÎÇò\n    # Convultion filterÏùò Í∞ÑÍ≤©ÏùÑ Ï°∞Ï†àÌïòÎäî Ïó≠Ìï†\n    dilation_rates = [2**i for i in range(n)]\n    # Convultion 1D Layer\n    x = Conv1D(filters = filters,\n              kernel_size = 1,\n              padding = 'same')(x)\n    res_x = x\n    # Activation Function: tanh, sigm\n    for dilation_rate in dilation_rates:\n        tanh_out = Conv1D(filters = filters, \n                         kernel_size = kernel_size,\n                         padding = 'same',\n                         activation = 'tanh',\n                         dilation_rate = dilation_rate)(x)\n        \n        sigm_out = Conv1D(filters = filters,\n                         kernel_size = kernel_size,\n                         padding = 'same',\n                         activation = 'sigmoid',\n                         dilation_rate = dilation_rate)(x)\n        # Multiply: Îëê ÌÖêÏÑúÏùò ÏöîÏÜåÎ•º Í≥±ÌïòÎäî Layer\n        x = Multiply()([tanh_out, sigm_out])\n        x = Conv1D(filters=filters,\n                  kernel_size = 1,\n                  padding = 'same')(x)\n        # Add: Îëê ÌÖêÏÑúÏùò ÏöîÏÜåÎ•º ÎçîÌïòÎäî layer \n        res_x = Add()([res_x, x])\n        \n    return res_x    \n        ","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:20.663112Z","iopub.execute_input":"2024-02-19T10:23:20.663464Z","iopub.status.idle":"2024-02-19T10:23:20.680293Z","shell.execute_reply.started":"2024-02-19T10:23:20.663435Z","shell.execute_reply":"2024-02-19T10:23:20.678944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def positional_encoding(maxlen, num_hid):\n        depth = num_hid/2\n        positions = tf.range(maxlen, dtype = tf.float32)[..., tf.newaxis]\n        depths = tf.range(depth, dtype = tf.float32)[np.newaxis, :]/depth\n        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n        angle_rads = tf.linalg.matmul(positions, angle_rates)\n        pos_encoding = tf.concat(\n          [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n          axis=-1)\n        return pos_encoding","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:20.681724Z","iopub.execute_input":"2024-02-19T10:23:20.682599Z","iopub.status.idle":"2024-02-19T10:23:20.694592Z","shell.execute_reply.started":"2024-02-19T10:23:20.682566Z","shell.execute_reply":"2024-02-19T10:23:20.693425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransformerBlock(layers.Layer):\n    def __init__(self, embed_dim, feat_dim, num_heads, ff_dim, rate=0.1):\n        super(TransformerBlock, self).__init__()\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.ffn = keras.Sequential(\n            [layers.Dense(ff_dim, activation=\"gelu\"), layers.Dense(feat_dim),]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training):\n        attn_output = self.att(inputs, inputs)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:24:33.899255Z","iopub.execute_input":"2024-02-19T10:24:33.899778Z","iopub.status.idle":"2024-02-19T10:24:33.912563Z","shell.execute_reply.started":"2024-02-19T10:24:33.899742Z","shell.execute_reply":"2024-02-19T10:24:33.91113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b><span style='color:#A51C30'> 5.2 </span> Wave Net + RNN Architecture </b>","metadata":{}},{"cell_type":"code","source":"embed_dim = 32  \nnum_heads = 4  \nff_dim = 128  \ndropout_rate = 0.0\n\n\ndef build_model():\n    \n    # INPUT\n    inp = tf.keras.Input(shape=(2_000,10))\n    \n    # Waveblock\n    inp2 = tf.keras.Input(shape=(2_000,1))\n    x = layers.Dense(16)(inp2)\n    p = positional_encoding(2000,16)\n    x = x + p\n    \n    x = wave_block(inp2, 16, 3, 12)\n    x = wave_block(x, 16, 5, 12)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = AveragePooling1D(pool_size=2)(x)\n    \n    x = wave_block(x, 32, 3, 8)\n    x = wave_block(x, 32, 5, 8)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = AveragePooling1D(pool_size=2)(x)\n    \n    x = wave_block(x, 64, 3, 4)\n    x = wave_block(x, 64, 5, 4)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = AveragePooling1D(pool_size=2)(x)\n    x = TransformerBlock(embed_dim, 64, num_heads, ff_dim, dropout_rate)(x)\n\n\n    model2 = tf.keras.Model(inputs=inp2, outputs=x)\n    \n    #####\n    \n    # LEFT TEMPORAL CHAIN\n    x1 = model2(inp[:,:,0:1])\n    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n    x2 = model2(inp[:,:,1:2])\n    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n    z1 = tf.keras.layers.Average()([x1,x2])\n    \n    # LEFT PARASAGITTAL CHAIN\n    x1 = model2(inp[:,:,2:3])\n    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n    x2 = model2(inp[:,:,3:4])\n    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n    z2 = tf.keras.layers.Average()([x1,x2])\n    \n    # RIGHT PARASAGITTAL CHAIN\n    x1 = model2(inp[:,:,4:5])\n    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n    x2 = model2(inp[:,:,5:6])\n    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n    z3 = tf.keras.layers.Average()([x1,x2])\n    \n    # RIGHT TEMPORAL CHAIN\n    x1 = model2(inp[:,:,6:7])\n    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n    x2 = model2(inp[:,:,7:8])\n    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n    z4 = tf.keras.layers.Average()([x1,x2])\n    \n    # Central Chain\n    x1 = model2(inp[:,:,8:9])\n    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n    x2 = model2(inp[:,:,9:10])\n    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n    z5 = tf.keras.layers.Average()([x1,x2])\n    \n    # COMBINE CHAINS\n    y = tf.keras.layers.Concatenate()([z1,z2,z3,z4,z5])\n    y = tf.keras.layers.Dense(64, activation='relu')(y)\n    y = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(y)\n    \n    # COMPLIE MODEL \n    model = tf.keras.Model(inputs=inp, outputs=y)\n    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n    loss = tf.keras.losses.KLDivergence()\n    model.compile(loss=loss, optimizer = opt)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:25:59.340291Z","iopub.execute_input":"2024-02-19T10:25:59.340736Z","iopub.status.idle":"2024-02-19T10:25:59.373078Z","shell.execute_reply.started":"2024-02-19T10:25:59.340705Z","shell.execute_reply":"2024-02-19T10:25:59.372035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import plot_model\nmodel = build_model() \n\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:26:00.571396Z","iopub.execute_input":"2024-02-19T10:26:00.572947Z","iopub.status.idle":"2024-02-19T10:26:31.091786Z","shell.execute_reply.started":"2024-02-19T10:26:00.57288Z","shell.execute_reply":"2024-02-19T10:26:31.090161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#A51C30\"><b><span style='color:#FFFFFF'>6 |</span></b> <b>Cross Validation</b></div>","metadata":{}},{"cell_type":"markdown","source":"### <b><span style='color:#A51C30'> 6.1 </span> Train GroupKFold</b>","metadata":{}},{"cell_type":"code","source":"directory_path = 'WaveNet_Model/'\nif not os.path.exists(directory_path):\n       os.makedirs(directory_path)\n\nTRAIN_MODEL = True      \nFOLDS_TO_TRAIN = 5\n\nfrom sklearn.model_selection import GroupKFold\nimport tensorflow.keras.backend as K, gc \n\nall_oof = [] ; all_true = [] \n\ngkf = GroupKFold(n_splits=5)\nfor i, (train_idx, valid_idx) in enumerate(gkf.split(train, train.target, train.patient_id)):\n    \n    # ÏßÑÌñâÏÉÅÌÉú ÌôïÏù∏ÌïòÍ∏∞ \n    print('#'*25)\n    print(f'### Fold {i+1}')\n    print(f'### train size {len(train_idx)}, valid size {len(valid_idx)}')\n    print('#'*25)  \n          \n    # split train & valid       \n    train_gen = DataGenerator(train.iloc[train_idx], shuffle=True, batch_size=32)\n    valid_gen = DataGenerator(train.iloc[valid_idx], shuffle=False, batch_size=64)\n    \n    # model Ï†ïÏùò\n    # WaveNet ModelÏùÄ Ïù¥ÎØ∏ functionÏúºÎ°ú Ï†ïÌï®\n    K.clear_session()\n    with strategy.scope():\n        model = build_model()     \n          \n    # moodel fit\n    if TRAIN_MODEL:      \n        model.fit(train_gen, verbose=1,\n               validation_data = valid_gen, \n              epochs=EPOCHS, callbacks = [LR])  \n    # model save\n    # save_weightsÎäî tf.kerasÏóêÏÑú ÏßÄÏõêÌïòÎäî Í∏∞Îä•\n        model.save_weights(f'{directory_path}WaveNet_fold{i}.h5')\n                           \n    # model predict\n    oof = model.predict(valid_gen, verbose=False) \n    all_oof.append(oof)\n    all_true.append(train.iloc[valid_idx][TARGETS].values)\n                           \n    if i == FOLDS_TO_TRAIN-1: break     \n                           \nall_oof = np.concatenate(all_oof)\nall_true = np.concatenate(all_true)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:26:54.632523Z","iopub.execute_input":"2024-02-19T10:26:54.633032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del oof, train_gen, valid_gen\nclean_memory()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:23.985313Z","iopub.status.idle":"2024-02-19T10:23:23.986238Z","shell.execute_reply.started":"2024-02-19T10:23:23.985911Z","shell.execute_reply":"2024-02-19T10:23:23.985939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <b><span style='color:#A51C30'> 6.2 </span> CV Score</b>","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/kaggle-kl-div')\nfrom kaggle_kl_div import score\n\noof = pd.DataFrame(all_oof.copy())\noof['id'] = np.arange(len(oof))\n\ntrue = pd.DataFrame(all_true.copy())\ntrue['id'] = np.arange(len(true))\n\ncv = score(solution=true, submission=oof, row_id_column_name='id')\nprint('CV Score with WaveNet Raw EEG =',cv)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:23.987895Z","iopub.status.idle":"2024-02-19T10:23:23.988796Z","shell.execute_reply.started":"2024-02-19T10:23:23.988501Z","shell.execute_reply":"2024-02-19T10:23:23.988528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding: 25px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#A51C30\"><b><span style='color:#FFFFFF'>7 |</span></b> <b>Submit to Kaggle LB</b></div>","metadata":{}},{"cell_type":"code","source":"del all_eegs, train; gc.collect()\ntest = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\nprint('Test shape:',test.shape)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:23.990407Z","iopub.status.idle":"2024-02-19T10:23:23.991255Z","shell.execute_reply.started":"2024-02-19T10:23:23.990948Z","shell.execute_reply":"2024-02-19T10:23:23.990975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_eegs2 = {}\nDISPLAY = 1\nEEG_IDS2 = test.eeg_id.unique()\nPATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/'\n\nprint('Processing Test EEG parquets...'); print()\nfor i,eeg_id in enumerate(EEG_IDS2):\n        \n    # SAVE EEG TO PYTHON DICTIONARY OF NUMPY ARRAYS\n    data = eeg_from_parquet(f'{PATH2}{eeg_id}.parquet', i<DISPLAY)\n    all_eegs2[eeg_id] = data","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:23.993047Z","iopub.status.idle":"2024-02-19T10:23:23.99362Z","shell.execute_reply.started":"2024-02-19T10:23:23.993368Z","shell.execute_reply":"2024-02-19T10:23:23.993386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INFER MLP ON TEST\npreds = []\nmodel = build_model()\ntest_gen = DataGenerator(test, shuffle=False, batch_size=64, eegs=all_eegs2, mode='test')\n\nprint('Inferring test... ',end='')\nfor i in range(FOLDS_TO_TRAIN):\n    print(f'fold {i+1}, ',end='')\n    if TRAIN_MODEL:\n        model.load_weights(f'WaveNet_Model/WaveNet_fold{i}.h5')\n    else:\n        model.load_weights(f'/kaggle/input/brain-eegs/WaveNet_Model/WaveNet_fold{i}.h5')\n    pred = model.predict(test_gen, verbose=0)\n    preds.append(pred)\npred = np.mean(preds,axis=0)\nprint()\nprint('Test preds shape',pred.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:23.994916Z","iopub.status.idle":"2024-02-19T10:23:23.995334Z","shell.execute_reply.started":"2024-02-19T10:23:23.995136Z","shell.execute_reply":"2024-02-19T10:23:23.995152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CREATE SUBMISSION.CSV\nfrom IPython.display import display\n\nsub = pd.DataFrame({'eeg_id':test.eeg_id.values})\nsub[TARGETS] = pred\nsub.to_csv('submission.csv',index=False)\nprint('Submission shape',sub.shape)\ndisplay( sub.head() )\n\n# SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\nprint('Sub row 0 sums to:',sub.iloc[0,-6:].sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-19T10:23:23.997867Z","iopub.status.idle":"2024-02-19T10:23:23.998823Z","shell.execute_reply.started":"2024-02-19T10:23:23.998515Z","shell.execute_reply":"2024-02-19T10:23:23.998542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}