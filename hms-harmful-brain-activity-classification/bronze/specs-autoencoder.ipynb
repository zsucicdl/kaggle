{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7564328,"sourceType":"datasetVersion","datasetId":4404591},{"sourceId":7600567,"sourceType":"datasetVersion","datasetId":4421634}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport time\n\nfrom IPython.display import clear_output\nfrom tqdm import tqdm\nfrom tqdm.contrib import tzip\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics.pairwise import euclidean_distances\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import Resize\nimport matplotlib.pyplot as plt\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-10T12:26:55.572278Z","iopub.execute_input":"2024-02-10T12:26:55.573535Z","iopub.status.idle":"2024-02-10T12:27:08.295869Z","shell.execute_reply.started":"2024-02-10T12:26:55.573483Z","shell.execute_reply":"2024-02-10T12:27:08.29446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:27:08.302629Z","iopub.execute_input":"2024-02-10T12:27:08.303066Z","iopub.status.idle":"2024-02-10T12:27:08.680706Z","shell.execute_reply.started":"2024-02-10T12:27:08.303023Z","shell.execute_reply":"2024-02-10T12:27:08.679383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Загружаю все спеки разом\ndct = np.load('/kaggle/input/default-specs/spectograms.npy', allow_pickle=True).item()","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:27:08.684204Z","iopub.execute_input":"2024-02-10T12:27:08.684738Z","iopub.status.idle":"2024-02-10T12:28:15.603581Z","shell.execute_reply.started":"2024-02-10T12:27:08.684694Z","shell.execute_reply":"2024-02-10T12:28:15.602289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Делю по пациентам на трейн, валидацию и тест\npatients = train_df.patient_id.unique()\npatients_train, patients_val_test, _, _ = train_test_split(patients, np.arange(len(patients)), test_size=0.3, random_state=123)\npatients_val, patients_test, _, _ = train_test_split(patients_val_test, np.arange(len(patients_val_test)), test_size=0.5, random_state=123)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:28:15.605453Z","iopub.execute_input":"2024-02-10T12:28:15.605855Z","iopub.status.idle":"2024-02-10T12:28:15.625106Z","shell.execute_reply.started":"2024-02-10T12:28:15.605822Z","shell.execute_reply":"2024-02-10T12:28:15.623874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_patients = train_df.loc[train_df.patient_id.isin(patients_train)].copy()\nval_patients = train_df.loc[train_df.patient_id.isin(patients_val)].copy()\ntest_patients = train_df.loc[train_df.patient_id.isin(patients_test)].copy()","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:28:15.627148Z","iopub.execute_input":"2024-02-10T12:28:15.628639Z","iopub.status.idle":"2024-02-10T12:28:15.671899Z","shell.execute_reply.started":"2024-02-10T12:28:15.628581Z","shell.execute_reply":"2024-02-10T12:28:15.670684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Функция, чтобы считать среднее и стандартное отклонение в цикле, потому мтодами numpy памяти не хватает\ndef online_mean_std(data):\n    n = 0\n    mean = 0\n    M2 = 0\n\n    for x in tqdm(data):\n        n = n + 1\n        x = np.nan_to_num(x)\n        delta = x - mean\n        mean = mean + delta/n\n        M2 = M2 + delta*(x - mean)\n\n    variance = M2/(n - 1)\n    return np.sqrt(variance.mean()), mean.mean()","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:28:15.673688Z","iopub.execute_input":"2024-02-10T12:28:15.674176Z","iopub.status.idle":"2024-02-10T12:28:15.682838Z","shell.execute_reply.started":"2024-02-10T12:28:15.674131Z","shell.execute_reply":"2024-02-10T12:28:15.6817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Считаю средние и ст.отклонения для каждого типа спектограмм\nmeans = []\nstds = []\nfor el in ['LL', 'RL', 'LP', 'RP']:\n    res = np.concatenate([dct[sid][el][None, :, int(slos)//2: int(slos)//2+300] for sid, slos in zip(train_patients.spectrogram_id, train_patients.spectrogram_label_offset_seconds)], axis=0)\n    std, mean = online_mean_std(res)\n    means.append(mean)\n    stds.append(std)\n    del res\n    gc.collect()\n    \nnorm_mean = np.array(means).reshape((4, 1, 1))\nnorm_std = np.array(stds).reshape((4, 1, 1))","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:28:15.684152Z","iopub.execute_input":"2024-02-10T12:28:15.684609Z","iopub.status.idle":"2024-02-10T12:30:02.103916Z","shell.execute_reply.started":"2024-02-10T12:28:15.684574Z","shell.execute_reply":"2024-02-10T12:30:02.102208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### [None, :, int(slos)//2: int(slos)//2+300] Нужно, чтобы по 10 минут из спек вырезать. Новую ось создаю, чтобы по ней конкатить спеки","metadata":{}},{"cell_type":"code","source":"def normalize(x):\n    '''[c, h, w]'''\n    return (x - norm_mean) / norm_std\n\nclass SpecDataset(Dataset):\n# В данных размер спеки 99 x 300    \n    def __init__(self, df, dct, img_size=(99, 300)):\n        self.df = df\n        self.dct = dct\n        self.image_size = img_size\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        spec = self.dct[self.df.iloc[index].spectrogram_id]\n        shift = self.df.iloc[index].spectrogram_label_offset_seconds\n        ll, rl, lp, rp = spec['LL'], spec['RL'], spec['LP'], spec['RP']\n        x = np.concatenate([ll[None, :, int(shift)//2: int(shift)//2+300], rl[None, :, int(shift)//2: int(shift)//2+300], lp[None, :, int(shift)//2: int(shift)//2+300], rp[None, :, int(shift)//2: int(shift)//2+300]], axis=0)\n        x = torch.from_numpy(normalize(x)).float()\n        x = torch.nan_to_num(x, 0)\n        transforms = Resize([self.image_size[0], self.image_size[1]])\n        x = transforms(x)        \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:30:02.10597Z","iopub.execute_input":"2024-02-10T12:30:02.106486Z","iopub.status.idle":"2024-02-10T12:30:02.121958Z","shell.execute_reply.started":"2024-02-10T12:30:02.106439Z","shell.execute_reply":"2024-02-10T12:30:02.12045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Сеть представляет из себя просто ResNet блоки, которые уменьшают/увличивают ширину и высоту в два раза и увличивают/уменьшают число каналов в два раза","metadata":{}},{"cell_type":"code","source":"# class ResNetBlock(nn.Module):\n#     def __init__(self, in_channels, kernel_size, img_size, modify=False, bn=True):\n#         super().__init__()\n#         self.modify = modify\n#         if modify=='downsample':\n#             self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*2, stride=2, kernel_size=kernel_size, padding=kernel_size//2, bias=False)\n#             self.conv2 = nn.Conv2d(in_channels=in_channels*2, out_channels=in_channels*2, kernel_size=kernel_size, padding=kernel_size//2,bias=False)\n# #             [C, H, W]\n#             if bn:\n#                 self.bn1 = nn.LayerNorm([2*in_channels, img_size//2, img_size//2])\n#                 self.bn2 = nn.LayerNorm([2*in_channels, img_size//2, img_size//2])\n#             else:\n#                 self.bn1 = nn.Identity()\n#                 self.bn2 = nn.Identity()\n                \n#         elif modify=='upsample':\n#             self.conv1 = nn.ConvTranspose2d(in_channels=in_channels, out_channels=in_channels//2, stride=2, kernel_size=kernel_size, output_padding=1, padding=kernel_size//2, bias=False)\n#             self.conv2 = nn.Conv2d(in_channels=in_channels//2, out_channels=in_channels//2, kernel_size=kernel_size, padding=kernel_size//2, bias=False)\n#             self.bn1 = nn.LayerNorm([in_channels//2, img_size, img_size])\n#             self.bn2 = nn.LayerNorm([in_channels//2, img_size, img_size])\n#         else:\n#             self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size, padding=kernel_size//2)\n#             self.conv2 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size, padding=kernel_size//2)\n#             self.bn1 = nn.LayerNorm([in_channels, img_size, img_size])\n#             self.bn2 = nn.LayerNorm([in_channels, img_size, img_size])\n#         self.act = nn.ReLU()\n        \n#         if modify=='downsample':\n#             self.proj = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*2, stride=2, kernel_size=kernel_size, padding=kernel_size//2)\n#         if modify=='upsample':\n#             self.proj = nn.ConvTranspose2d(in_channels=in_channels, out_channels=in_channels//2, stride=2, kernel_size=kernel_size, output_padding=1, padding=kernel_size//2)\n\n\n#     def forward(self, x):\n#         out = self.conv1(x)\n#         out = self.bn1(out)\n#         out = self.act(out)\n#         out = self.conv2(out)\n#         out = self.bn2(out)\n#         if self.modify:\n#             x = self.proj(x)\n#         out = x + out\n#         out = self.act(out)\n#         return out\n\n    \n# class Encoder(nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.conv = nn.Conv2d(4, 16, 7, 1, 7//2)\n#         self.rnb1 = ResNetBlock(16, 3, 256, modify='downsample')\n#         self.rnb2 = ResNetBlock(32, 3, 128, modify='downsample')\n#         self.rnb3 = ResNetBlock(64, 3, 64, modify='downsample')\n#         self.rnb4 = ResNetBlock(128, 3, 32, modify='downsample')\n#         self.rnb5 = ResNetBlock(256, 3, 16, modify='downsample')\n#         self.rnb6 = ResNetBlock(512, 3, 8, modify='downsample')\n#         self.rnb7 = ResNetBlock(1024, 3, 4, modify='downsample')\n#         self.rnb8 = ResNetBlock(2048, 3, 2, modify='downsample')\n        \n#     def forward(self, x):\n#         x = self.conv(x)\n#         x = self.rnb1(x)\n#         x = self.rnb2(x)\n#         x = self.rnb3(x)\n#         x = self.rnb4(x)\n#         x = self.rnb5(x)\n#         x = self.rnb6(x)\n#         x = self.rnb7(x)\n#         x = self.rnb8(x)\n#         return x\n    \n# class Decoder(nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.rnb1 = ResNetBlock(4096, 3, 2, modify='upsample')\n#         self.rnb2 = ResNetBlock(2048, 3, 4, modify='upsample')\n#         self.rnb3 = ResNetBlock(1024, 3, 8, modify='upsample')\n#         self.rnb4 = ResNetBlock(512, 3, 16, modify='upsample')\n#         self.rnb5 = ResNetBlock(256, 3, 32, modify='upsample')\n#         self.rnb6 = ResNetBlock(128, 3, 64, modify='upsample')\n#         self.rnb7 = ResNetBlock(64, 3, 128, modify='upsample')\n#         self.rnb8 = ResNetBlock(32, 3, 256, modify='upsample')\n#         self.conv = nn.Conv2d(16, 4, 3, 1, 3//2)\n\n#     def forward(self, x):\n#         x = self.rnb1(x)\n#         x = self.rnb2(x)\n#         x = self.rnb3(x)\n#         x = self.rnb4(x)\n#         x = self.rnb5(x)\n#         x = self.rnb6(x)\n#         x = self.rnb7(x)\n#         x = self.rnb8(x)\n#         x = self.conv(x)\n#         return x","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:30:02.128184Z","iopub.execute_input":"2024-02-10T12:30:02.128754Z","iopub.status.idle":"2024-02-10T12:30:02.141333Z","shell.execute_reply.started":"2024-02-10T12:30:02.128704Z","shell.execute_reply":"2024-02-10T12:30:02.139856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNetBlock(nn.Module):\n    def __init__(self, in_channels, kernel_size, modify=False, bn=True):\n        super().__init__()\n        self.modify = modify\n        if modify=='downsample':\n            self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*2, stride=2, kernel_size=kernel_size, padding=kernel_size//2, bias=False)\n            self.conv2 = nn.Conv2d(in_channels=in_channels*2, out_channels=in_channels*2, kernel_size=kernel_size, padding=kernel_size//2,bias=False)\n            if bn:\n                self.bn1 = nn.BatchNorm2d(in_channels*2)\n                self.bn2 = nn.BatchNorm2d(in_channels*2)\n            else:\n                self.bn1 = nn.Identity()\n                self.bn2 = nn.Identity()\n                \n        elif modify=='upsample':\n            self.conv1 = nn.ConvTranspose2d(in_channels=in_channels, out_channels=in_channels//2, stride=2, kernel_size=kernel_size, output_padding=1, padding=kernel_size//2, bias=False)\n            self.conv2 = nn.Conv2d(in_channels=in_channels//2, out_channels=in_channels//2, kernel_size=kernel_size, padding=kernel_size//2, bias=False)\n            self.bn1 = nn.BatchNorm2d(in_channels//2)\n            self.bn2 = nn.BatchNorm2d(in_channels//2)\n        else:\n            self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size, padding=kernel_size//2)\n            self.conv2 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size, padding=kernel_size//2)\n            self.bn1 = nn.BatchNorm2d(in_channels)\n            self.bn2 = nn.BatchNorm2d(in_channels)\n        self.act = nn.ReLU()\n        \n        if modify=='downsample':\n            self.proj = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*2, stride=2, kernel_size=kernel_size, padding=kernel_size//2)\n        if modify=='upsample':\n            self.proj = nn.ConvTranspose2d(in_channels=in_channels, out_channels=in_channels//2, stride=2, kernel_size=kernel_size, output_padding=1, padding=kernel_size//2)\n\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.act(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        if self.modify:\n            x = self.proj(x)\n        out = x + out\n        out = self.act(out)\n        return out\n\n    \nclass Encoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv = nn.Conv2d(4, 16, 7, 1, 7//2)\n        self.rnb1 = ResNetBlock(16, 3, modify='downsample')\n        self.rnb2 = ResNetBlock(32, 3, modify='downsample')\n        self.rnb3 = ResNetBlock(64, 3, modify='downsample')\n        self.rnb4 = ResNetBlock(128, 3, modify='downsample')\n        self.rnb5 = ResNetBlock(256, 3, modify='downsample')\n        self.rnb6 = ResNetBlock(512, 3, modify='downsample')\n        self.rnb7 = ResNetBlock(1024, 3, modify='downsample')\n        self.rnb8 = ResNetBlock(2048, 3, modify='downsample')\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.rnb1(x)\n        x = self.rnb2(x)\n        x = self.rnb3(x)\n        x = self.rnb4(x)\n        x = self.rnb5(x)\n        x = self.rnb6(x)\n        x = self.rnb7(x)\n        x = self.rnb8(x)\n        return x\n    \nclass Decoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.rnb1 = ResNetBlock(4096, 3, modify='upsample')\n        self.rnb2 = ResNetBlock(2048, 3, modify='upsample')\n        self.rnb3 = ResNetBlock(1024, 3, modify='upsample')\n        self.rnb4 = ResNetBlock(512, 3, modify='upsample')\n        self.rnb5 = ResNetBlock(256, 3, modify='upsample')\n        self.rnb6 = ResNetBlock(128, 3, modify='upsample')\n        self.rnb7 = ResNetBlock(64, 3, modify='upsample')\n        self.rnb8 = ResNetBlock(32, 3, modify='upsample')\n        self.conv = nn.Conv2d(16, 4, 3, 1, 3//2)\n\n    def forward(self, x):\n        x = self.rnb1(x)\n        x = self.rnb2(x)\n        x = self.rnb3(x)\n        x = self.rnb4(x)\n        x = self.rnb5(x)\n        x = self.rnb6(x)\n        x = self.rnb7(x)\n        x = self.rnb8(x)\n        x = self.conv(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:30:02.143524Z","iopub.execute_input":"2024-02-10T12:30:02.143977Z","iopub.status.idle":"2024-02-10T12:30:02.17916Z","shell.execute_reply.started":"2024-02-10T12:30:02.143931Z","shell.execute_reply":"2024-02-10T12:30:02.177901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SimpleAE(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            Encoder(),\n            Decoder()\n        )\n        \n    def forward(self, x):\n        return self.net(x)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:30:02.181081Z","iopub.execute_input":"2024-02-10T12:30:02.181856Z","iopub.status.idle":"2024-02-10T12:30:02.188849Z","shell.execute_reply.started":"2024-02-10T12:30:02.181818Z","shell.execute_reply":"2024-02-10T12:30:02.187431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_epoch(model, dataloader, loss_fn, optimizer, epoch, device, scaler):\n    model = model.to(device)\n    model.train()\n    losses = []\n    for batch in tqdm(dataloader, total=len(dataloader)):\n        x = batch.to(device)\n        \n#         with torch.autocast(device_type='cuda' if device=='cuda' else 'cpu', dtype=torch.float16 if device=='cuda' else torch.bfloat16):\n        x_recon = model(x)\n        loss = loss_fn(x, x_recon)\n\n        loss.backward()\n        optimizer.step()\n#         scaler.scale(loss).backward()\n#         scaler.step(optimizer)\n#         scaler.update()\n        \n        optimizer.zero_grad()\n                \n        losses.append(loss.detach().cpu().item())\n#     print(f'Не нан значений во время train: {np.count_nonzero(~np.isnan(losses))}')\n    return np.nanmean(losses)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:30:02.190708Z","iopub.execute_input":"2024-02-10T12:30:02.191316Z","iopub.status.idle":"2024-02-10T12:30:02.20171Z","shell.execute_reply.started":"2024-02-10T12:30:02.191279Z","shell.execute_reply":"2024-02-10T12:30:02.200207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, dataloader, loss_fn, device, scaler):\n    model = model.to(device)\n    losses = []\n    with torch.no_grad():\n        model.eval()\n        for batch in tqdm(dataloader, total=len(dataloader)):\n            x = batch.to(device)\n\n#             with torch.autocast(device_type='cuda' if device=='cuda' else 'cpu', dtype=torch.float16 if device=='cuda' else torch.bfloat16):\n            x_recon = model(x)\n            loss = loss_fn(x, x_recon)\n#             scaler.scale(loss)\n            losses.append(loss.detach().cpu().item())\n#     print(f'Не нан значений во время eval: {np.count_nonzero(~np.isnan(losses))}')\n    return np.nanmean(losses)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:30:02.203436Z","iopub.execute_input":"2024-02-10T12:30:02.203867Z","iopub.status.idle":"2024-02-10T12:30:02.214849Z","shell.execute_reply.started":"2024-02-10T12:30:02.20382Z","shell.execute_reply":"2024-02-10T12:30:02.213683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = torch.cuda.amp.GradScaler()\ndef run_experiment(model, dataloader_train, dataloader_val, loss_fn, optimizer, num_epochs, device, stop_after=5, scaler=scaler):\n    losses_train = []\n    losses_val = []\n    best_loss_val = np.inf\n    c = 0\n    total_runtime = 0\n    for epoch in range(num_epochs):\n        start = time.time()\n        \n        if c == stop_after:\n            print(f'Обучение остановлено, так как лосс на валидации не падал {stop_after} эпох')\n            break\n        \n        loss_train = run_epoch(model, dataloader_train, loss_fn, optimizer, epoch, device, scaler)\n        loss_val = evaluate(model, dataloader_val, loss_fn, device, scaler)\n        losses_train.append(loss_train)\n        losses_val.append(loss_val)\n        clear_output()\n        if best_loss_val > loss_val:\n            torch.save(model.state_dict(), 'best_model.pth')\n            torch.save(optimizer, 'optimizer.pth')\n            best_loss_val = loss_val\n            c = 0\n        else:\n            c += 1\n            \n        print(f\"epoch: {str(epoch).zfill(3)} | loss_train: {loss_train:5.5f} | loss_val: {loss_val:5.5f} | best_loss: {best_loss_val:5.5f}\")\n        \n        plt.plot(losses_train, label='Loss train')\n        plt.plot(losses_val, label='Loss val')\n        plt.legend()\n        plt.show()\n        \n        stop = time.time()\n        runtime = stop - start\n        total_runtime += runtime\n        if 12*60*60 - 600 - total_runtime < runtime:\n            break\n        \n    return losses_train, losses_val, model","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:30:02.216033Z","iopub.execute_input":"2024-02-10T12:30:02.216451Z","iopub.status.idle":"2024-02-10T12:30:02.238135Z","shell.execute_reply.started":"2024-02-10T12:30:02.216406Z","shell.execute_reply":"2024-02-10T12:30:02.236202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train = SpecDataset(train_patients, dct, img_size=(256, 256))\ndataset_val = SpecDataset(val_patients, dct, img_size=(256, 256))\ndataset_test = SpecDataset(test_patients, dct, img_size=(256, 256))\n\ndataloader_train = DataLoader(\n    dataset=dataset_train,\n    batch_size=128,\n    shuffle=True,\n    drop_last=True\n)\n\ndataloader_val = DataLoader(\n    dataset=dataset_val,\n    batch_size=128,\n    shuffle=False,\n    drop_last=False\n)\n\ndataloader_test = DataLoader(\n    dataset=dataset_test,\n    batch_size=128,\n    shuffle=False,\n    drop_last=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:30:02.239831Z","iopub.execute_input":"2024-02-10T12:30:02.240733Z","iopub.status.idle":"2024-02-10T12:30:02.252385Z","shell.execute_reply.started":"2024-02-10T12:30:02.240687Z","shell.execute_reply":"2024-02-10T12:30:02.251062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# small, _ = torch.utils.data.random_split(dataset_train, [256, len(dataset_train) - 256])\n# small_val, _ = torch.utils.data.random_split(dataset_train, [256, len(dataset_train) - 256])\n# small_dataloader_train = DataLoader(\n#     dataset=small,\n#     batch_size=128,\n#     shuffle=True,\n#     drop_last=True\n# )\n\n# small_dataloader_val = DataLoader(\n#     dataset=small_val,\n#     batch_size=128,\n#     shuffle=False,\n#     drop_last=False\n# )","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:30:02.254091Z","iopub.execute_input":"2024-02-10T12:30:02.255412Z","iopub.status.idle":"2024-02-10T12:30:02.266907Z","shell.execute_reply.started":"2024-02-10T12:30:02.255343Z","shell.execute_reply":"2024-02-10T12:30:02.265379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nlr = 3e-4\nmodel = SimpleAE()\nmodel= nn.DataParallel(model)\nloss_fn = nn.MSELoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=lr)\nnum_epochs = 100","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:30:02.268675Z","iopub.execute_input":"2024-02-10T12:30:02.269573Z","iopub.status.idle":"2024-02-10T12:30:12.333378Z","shell.execute_reply.started":"2024-02-10T12:30:02.269526Z","shell.execute_reply":"2024-02-10T12:30:12.331739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_weights(w):\n    if isinstance(w, nn.Linear) or isinstance(w, nn.Conv2d) or isinstance(w, nn.ConvTranspose2d):\n        nn.init.xavier_uniform_(w.weight)\n    \nmodel.apply(init_weights)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:30:12.335287Z","iopub.execute_input":"2024-02-10T12:30:12.340083Z","iopub.status.idle":"2024-02-10T12:30:18.102162Z","shell.execute_reply.started":"2024-02-10T12:30:12.340017Z","shell.execute_reply":"2024-02-10T12:30:18.100371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/input/autoencoder-weights/best_model.pth', map_location=torch.device(device)))\n# optimizer = torch.load('/kaggle/input/autoencoder-weights/optimizer.pth', map_location=torch.device(device))","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:30:18.104255Z","iopub.execute_input":"2024-02-10T12:30:18.104969Z","iopub.status.idle":"2024-02-10T12:31:33.455942Z","shell.execute_reply.started":"2024-02-10T12:30:18.104925Z","shell.execute_reply":"2024-02-10T12:31:33.454798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def nan_hook(self, inp, output):\n#     if not isinstance(output, tuple):\n#         outputs = [output]\n#     else:\n#         outputs = output\n\n#     for i, out in enumerate(outputs):\n#         nan_mask = torch.isnan(out)\n#         if nan_mask.any():\n#             print(\"In\", self.__class__.__name__)\n#             raise RuntimeError(f\"Found NAN in output {i} at indices: \", nan_mask.nonzero(), \"where:\", out[nan_mask.nonzero()[:, 0].unique(sorted=True)])\n\n# for submodule in model.modules():\n#     submodule.register_forward_hook(nan_hook)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:31:33.458251Z","iopub.execute_input":"2024-02-10T12:31:33.459081Z","iopub.status.idle":"2024-02-10T12:31:33.465131Z","shell.execute_reply.started":"2024-02-10T12:31:33.459037Z","shell.execute_reply":"2024-02-10T12:31:33.463686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"losses_train, losses_val, model = run_experiment(model, dataloader_train, dataloader_val, loss_fn, optimizer, num_epochs, device, stop_after=15)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T12:31:33.466561Z","iopub.execute_input":"2024-02-10T12:31:33.466908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(losses_train, label='Loss train')\nplt.plot(losses_val, label='Loss val')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Test loss:', evaluate(model, dataloader_test, loss_fn, device, scaler))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}