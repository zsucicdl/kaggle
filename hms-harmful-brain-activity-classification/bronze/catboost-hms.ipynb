{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7392775,"sourceType":"datasetVersion","datasetId":4297782},{"sourceId":7447509,"sourceType":"datasetVersion","datasetId":4334995}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install catboost","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-15T19:35:56.620891Z","iopub.execute_input":"2024-02-15T19:35:56.621261Z","iopub.status.idle":"2024-02-15T19:36:08.811984Z","shell.execute_reply.started":"2024-02-15T19:35:56.621231Z","shell.execute_reply":"2024-02-15T19:36:08.81084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostRegressor\nimport os\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport time\nimport sys\nimport psutil\nimport multiprocessing\nimport sklearn.model_selection\n\n\n#warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \nwarnings.filterwarnings(\"ignore\", category=FutureWarning) \nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n\ndef load_data(namespace):\n    \n    # LOAD TRAIN DATA\n    data_train = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\n    TARGETS = data_train.columns[-6:]\n    print('Train shape:', data_train.shape )\n    print('Targets', list(TARGETS))\n    # print(data_train.head())\n\n    number_of_rows = len(data_train)\n\n    # aggregate data by eeg_id computing subset interval ([minOffset, maxOffset])\n    train = data_train.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n        {'spectrogram_id':'first','spectrogram_label_offset_seconds':'min'})\n    train.columns = ['spec_id','min']\n\n    tmp = data_train.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n        {'spectrogram_label_offset_seconds':'max'})\n    train['max'] = tmp\n\n    # add patient_id to the train dataframe\n    tmp = data_train.groupby('eeg_id')[['patient_id']].agg('first')\n    train['patient_id'] = tmp\n\n    # sum targets value for each eeg_id\n    tmp = data_train.groupby('eeg_id')[TARGETS].agg('sum')\n    for t in TARGETS:\n        train[t] = tmp[t].values\n\n    # calculate the relative frequency of every classification based on the total number of votes\n    y_data = train[TARGETS].values\n    y_data = y_data / y_data.sum(axis=1,keepdims=True)\n    train[TARGETS] = y_data\n\n    # add most voted column to the train dataframe \n    tmp = data_train.groupby('eeg_id')[['expert_consensus']].agg('first')\n    train['target'] = tmp\n\n    # reset train index\n    train = train.reset_index()\n    print(\"Number of rows: \", len(train))\n    print('Train non-overlapp eeg_id shape:', train.shape )\n    print(train.head())\n\n    # we are using two datasets created by Chris Deotte [https://www.kaggle.com/datasets/cdeotte/brain-spectrograms],\n    # [https://www.kaggle.com/datasets/cdeotte/brain-eeg-spectrograms]\n    # which contains the raw eeg waveform converted into a spectrogram\n    spectrograms = np.load('/kaggle/input/brain-spectrograms/specs.npy',allow_pickle=True).item()\n    all_eegs = np.load('/kaggle/input/brain-eeg-spectrograms/eeg_specs.npy',allow_pickle=True).item()\n\n    # FEATURE NAMES\n    PATH = '/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/'\n    SPEC_COLS = pd.read_parquet(f'{PATH}1000086677.parquet').columns[1:]\n    FEATURES = [f'{c}_mean_10m' for c in SPEC_COLS]\n    FEATURES += [f'{c}_min_10m' for c in SPEC_COLS]\n    FEATURES += [f'{c}_mean_20s' for c in SPEC_COLS]\n    FEATURES += [f'{c}_min_20s' for c in SPEC_COLS]\n    FEATURES += [f'eeg_mean_f{x}_10s' for x in range(512)]\n    FEATURES += [f'eeg_min_f{x}_10s' for x in range(512)]\n    FEATURES += [f'eeg_max_f{x}_10s' for x in range(512)]\n    FEATURES += [f'eeg_std_f{x}_10s' for x in range(512)]\n\n    print(f'We are creating {len(FEATURES)} features for {len(train)} rows... ',end='')\n\n    data = np.zeros((len(train),len(FEATURES)))\n    for k in range(len(train)):\n        if k%100==0: \n            print(k,', ',end='')\n        row = train.iloc[k]\n        r = int( (row['min'] + row['max'])//4 ) \n\n        # 10 MINUTE WINDOW FEATURES (MEANS and MINS)\n        x = np.nanmean(spectrograms[row.spec_id][r:r+300,:],axis=0)\n        data[k,:400] = x\n        x = np.nanmin(spectrograms[row.spec_id][r:r+300,:],axis=0)\n        data[k,400:800] = x\n\n        # 20 SECOND WINDOW FEATURES (MEANS and MINS)\n        x = np.nanmean(spectrograms[row.spec_id][r+145:r+155,:],axis=0)\n        data[k,800:1200] = x\n        x = np.nanmin(spectrograms[row.spec_id][r+145:r+155,:],axis=0)\n        data[k,1200:1600] = x\n\n        # RESHAPE EEG SPECTROGRAMS 128x256x4 => 512x256\n        eeg_spec = np.zeros((512,256),dtype='float32')\n        xx = all_eegs[row.eeg_id]\n        for j in range(4): \n            eeg_spec[128*j:128*(j+1),] = xx[:,:,j]\n\n        # 10 SECOND WINDOW FROM EEG SPECTROGRAMS \n        x = np.nanmean(eeg_spec.T[100:-100,:],axis=0)\n        data[k,1600:2112] = x\n        x = np.nanmin(eeg_spec.T[100:-100,:],axis=0)\n        data[k,2112:2624] = x\n        x = np.nanmax(eeg_spec.T[100:-100,:],axis=0)\n        data[k,2624:3136] = x\n        x = np.nanstd(eeg_spec.T[100:-100,:],axis=0)\n        data[k,3136:3648] = x\n\n    train[FEATURES] = data\n    print(); print('New train shape:',train.shape)\n\n    namespace.X = train[FEATURES]\n    namespace.y = train[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']]\n    print(\"X.shape: \", namespace.X.shape)\n    print(\"y.shape: \", namespace.y.shape)\n    \n    print('sta per terminare il sottoproc, RAM memory % used:', psutil.virtual_memory()[2])\n\n\n\n\n#create sub-process\nmanager = multiprocessing.Manager()\n\nnamespace = manager.Namespace()\nnamespace.X = X = pd.DataFrame() \nnamespace.y = y = pd.DataFrame()\n\np = multiprocessing.Process(target=load_data, args=(namespace,))\np.start()\np.join()\nprint('dopo aver terminato il sottoproc,RAM memory % used:', psutil.virtual_memory()[2])","metadata":{"execution":{"iopub.status.busy":"2024-02-15T20:52:35.125759Z","iopub.execute_input":"2024-02-15T20:52:35.126374Z","iopub.status.idle":"2024-02-15T20:55:18.279762Z","shell.execute_reply.started":"2024-02-15T20:52:35.126341Z","shell.execute_reply":"2024-02-15T20:55:18.278033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_sub = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\n#sub_eeg_id = test_sub[['eeg_id']]\nprint(\"dividendo tra X_train...\")\n\nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n    namespace.X,\n    namespace.y,\n    random_state=1,\n    train_size = 0.85,\n    test_size = 0.15\n)\n\ntargets = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n    \ndef runModel(y_train, X_train, y_test, X_test):\n\n    # Initialize CatBoostRegressor\n    model = CatBoostRegressor(iterations=499,\n                              learning_rate=0.0035,\n                              depth=11,\n                              task_type=\"GPU\",\n                              devices='0:1',\n                              loss_function= 'MultiRMSE', \n                              eval_metric= 'MultiRMSE', )\n    # Fit model\n    model.fit(X_train, y_train)\n    # Get predictions\n    y_pred = model.predict(X_test)\n    \n    y_pred_df = pd.DataFrame(y_pred.copy(), columns = targets)\n    y_pred_df['id'] = np.arange(len(y_pred))\n\n    y_test_df = pd.DataFrame(y_test.copy())\n    y_test_df['id'] = np.arange(len(y_test))\n    \n    print(\"y_test_df: \", y_test_df)\n    print(\"y_pred_df: \", y_pred_df)\n    \n    for i in range(6):\n        print(\"R^2 \", targets[i], \" : \", sklearn.metrics.r2_score(y_test_df[[targets[i]]], y_pred_df[[targets[i]]]))    \n    \nrunModel(y_train, X_train, y_test, X_test) ","metadata":{"execution":{"iopub.status.busy":"2024-02-15T21:18:06.022798Z","iopub.execute_input":"2024-02-15T21:18:06.023617Z","iopub.status.idle":"2024-02-15T21:35:00.892795Z","shell.execute_reply.started":"2024-02-15T21:18:06.023576Z","shell.execute_reply":"2024-02-15T21:35:00.89064Z"},"trusted":true},"execution_count":null,"outputs":[]}]}