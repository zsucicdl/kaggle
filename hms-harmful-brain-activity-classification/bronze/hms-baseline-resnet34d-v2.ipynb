{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":159396114,"sourceType":"kernelVersion"}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Import all necessary libraries","metadata":{}},{"cell_type":"code","source":"#https://www.kaggle.com/code/ttahara/hms-hbac-resnet34d-baseline-training\n#https://www.kaggle.com/code/ttahara/hms-hbac-resnet34d-baseline-inference\n\n# Importing essential libraries\nimport pandas as pd  # For handling CSV files\nimport numpy as np   # For matrix operations\nimport random\n\n# PyTorch for deep learning\nimport torch\nimport torch.nn as nn  # Neural network module\nimport torch.nn.functional as F  # Neural network functions\n\n# torchvision for image processing and augmentation\nimport torchvision.transforms as transforms\n\n# Setting up a random seed for reproducibility\nrandom.seed(42)\ntorch.manual_seed(42)\n\n# Suppressing minor warnings to keep the output clean\nimport warnings\nwarnings.filterwarnings('ignore', category=Warning)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-19T18:00:27.094866Z","iopub.execute_input":"2024-01-19T18:00:27.095291Z","iopub.status.idle":"2024-01-19T18:00:29.649984Z","shell.execute_reply.started":"2024-01-19T18:00:27.095249Z","shell.execute_reply":"2024-01-19T18:00:29.648247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Config","metadata":{}},{"cell_type":"code","source":"class Config:\n    # Updated the seed year to the current year for relevance\n    seed = 2024\n    \n    # Updated image transformation method for more flexibility\n    # Now includes both resizing and normalization steps\n    image_transform = transforms.Compose([\n        transforms.Resize((512, 512)),\n        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    \n    # Number of folds in a cross-validation setup remains the same\n    num_folds = 5","metadata":{"execution":{"iopub.status.busy":"2024-01-19T18:00:29.652633Z","iopub.execute_input":"2024-01-19T18:00:29.653649Z","iopub.status.idle":"2024-01-19T18:00:29.661218Z","shell.execute_reply.started":"2024-01-19T18:00:29.653602Z","shell.execute_reply":"2024-01-19T18:00:29.659758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### trained_models","metadata":{}},{"cell_type":"code","source":"models = [torch.load(f'/kaggle/input/hms-baseline-resnet34d-512-512-training-5-folds/HMS_resnet_fold{i}.pth') for i in range(Config.num_folds)]","metadata":{"execution":{"iopub.status.busy":"2024-01-19T18:00:29.663083Z","iopub.execute_input":"2024-01-19T18:00:29.663518Z","iopub.status.idle":"2024-01-19T18:00:31.292652Z","shell.execute_reply.started":"2024-01-19T18:00:29.663471Z","shell.execute_reply":"2024-01-19T18:00:31.290907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Seed","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed):\n    # Set the seed for generating random numbers in PyTorch\n    torch.manual_seed(seed)\n    \n    # Ensure that the PyTorch's CuDNN backend behaves deterministically\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False  # Disabling this for reproducibility\n\n    # Set the seed for generating random numbers in NumPy\n    np.random.seed(seed)\n\n    # Set the seed for the default Python random number generator\n    random.seed(seed)\n\nseed_everything(Config.seed)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T18:00:31.297774Z","iopub.execute_input":"2024-01-19T18:00:31.298364Z","iopub.status.idle":"2024-01-19T18:00:31.306087Z","shell.execute_reply.started":"2024-01-19T18:00:31.298311Z","shell.execute_reply":"2024-01-19T18:00:31.30478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### load_and_preprocess_data","metadata":{}},{"cell_type":"code","source":"def load_and_preprocess_data(path):\n    eps = 1e-6\n    data = pd.read_parquet(path)\n    data = data.fillna(-1).values[:, 1:].T  # Transpose and remove first column\n    data = data[:, :300]  # Select first 300 columns\n    data = np.clip(data, np.exp(-6), np.exp(10))\n    data = np.log(data)  # Log transformation\n\n    # Normalize the data\n    data_mean = data.mean(axis=(0, 1))\n    data_std = data.std(axis=(0, 1))\n    normalized_data = (data - data_mean) / (data_std + eps)\n\n    # Convert to PyTorch tensor and apply transformations\n    data_tensor = torch.unsqueeze(torch.Tensor(normalized_data), dim=0)\n    return Config.image_transform(data_tensor)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T18:00:31.307938Z","iopub.execute_input":"2024-01-19T18:00:31.308739Z","iopub.status.idle":"2024-01-19T18:00:31.319647Z","shell.execute_reply.started":"2024-01-19T18:00:31.308688Z","shell.execute_reply":"2024-01-19T18:00:31.317886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction","metadata":{}},{"cell_type":"code","source":"def predict(models, data):\n    test_preds = []\n    for model in models:\n        model.eval()\n        with torch.no_grad():\n            pred = F.softmax(model(data.unsqueeze(0)))[0]\n            pred = pred.detach().cpu().numpy()\n        test_preds.append(pred)\n    return np.array(test_preds).mean(axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T18:00:31.322263Z","iopub.execute_input":"2024-01-19T18:00:31.322873Z","iopub.status.idle":"2024-01-19T18:00:31.332753Z","shell.execute_reply.started":"2024-01-19T18:00:31.322812Z","shell.execute_reply":"2024-01-19T18:00:31.330783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare Submission","metadata":{}},{"cell_type":"code","source":"def prepare_submission(submission_file, test_df, test_preds):\n    submission = pd.read_csv(submission_file)\n    labels = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n    for i, label in enumerate(labels):\n        submission[f'{label}_vote'] = test_preds[:, i]\n    return submission","metadata":{"execution":{"iopub.status.busy":"2024-01-19T18:00:31.334682Z","iopub.execute_input":"2024-01-19T18:00:31.335738Z","iopub.status.idle":"2024-01-19T18:00:31.352319Z","shell.execute_reply.started":"2024-01-19T18:00:31.33569Z","shell.execute_reply":"2024-01-19T18:00:31.350677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main execution","metadata":{}},{"cell_type":"code","source":"# Main execution\ntest_df = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\nsubmission = submission.merge(test_df, on='eeg_id', how='left')\nsubmission['path'] = submission['spectrogram_id'].apply(\n    lambda x: f\"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/{x}.parquet\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T18:00:31.354655Z","iopub.execute_input":"2024-01-19T18:00:31.355106Z","iopub.status.idle":"2024-01-19T18:00:31.382617Z","shell.execute_reply.started":"2024-01-19T18:00:31.355068Z","shell.execute_reply":"2024-01-19T18:00:31.381015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths = submission['path'].values\ntest_preds = [predict(models, load_and_preprocess_data(path)) for path in paths]","metadata":{"execution":{"iopub.status.busy":"2024-01-19T18:00:31.384595Z","iopub.execute_input":"2024-01-19T18:00:31.385062Z","iopub.status.idle":"2024-01-19T18:00:33.7086Z","shell.execute_reply.started":"2024-01-19T18:00:31.385019Z","shell.execute_reply":"2024-01-19T18:00:33.707322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_submission = prepare_submission(\n    \"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\", \n    test_df, \n    np.array(test_preds)\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T18:00:33.710112Z","iopub.execute_input":"2024-01-19T18:00:33.711309Z","iopub.status.idle":"2024-01-19T18:00:33.722297Z","shell.execute_reply.started":"2024-01-19T18:00:33.711247Z","shell.execute_reply":"2024-01-19T18:00:33.721098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_submission.to_csv(\"submission.csv\", index=None)\nfinal_submission.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-19T18:00:33.723805Z","iopub.execute_input":"2024-01-19T18:00:33.724153Z","iopub.status.idle":"2024-01-19T18:00:33.746179Z","shell.execute_reply.started":"2024-01-19T18:00:33.724122Z","shell.execute_reply":"2024-01-19T18:00:33.744824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hey if you like this notebook please upvote it and also share your thoughts ","metadata":{}},{"cell_type":"markdown","source":"btw thanks Inspire notebook YUNSUXIAOZI","metadata":{}},{"cell_type":"markdown","source":"### Created and Updated by JillaniSoftTech","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}