{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\nimport matplotlib.pyplot as plt, gc\nimport joblib  # to pipeline files reading and transforming\nfrom tqdm.notebook import tqdm  # progress bar\nimport keras_cv\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         #print()\n#         os.path.join(dirname, filename)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-08T14:23:16.791483Z","iopub.execute_input":"2024-02-08T14:23:16.792569Z","iopub.status.idle":"2024-02-08T14:23:16.797751Z","shell.execute_reply.started":"2024-02-08T14:23:16.792507Z","shell.execute_reply":"2024-02-08T14:23:16.796888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 0\nfor dirname, _, filenames in os.walk('/tmp/dataset/hms-hbac'):\n    for filename in filenames:\n        i += 1\n        if i < 3:\n            print(filename)\nprint(i)        ","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:32:32.992614Z","iopub.execute_input":"2024-02-05T15:32:32.993021Z","iopub.status.idle":"2024-02-05T15:32:33.039673Z","shell.execute_reply.started":"2024-02-05T15:32:32.992991Z","shell.execute_reply":"2024-02-05T15:32:33.038454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-02-08T14:02:23.74234Z","iopub.execute_input":"2024-02-08T14:02:23.743088Z","iopub.status.idle":"2024-02-08T14:02:23.747132Z","shell.execute_reply.started":"2024-02-08T14:02:23.743056Z","shell.execute_reply":"2024-02-08T14:02:23.746184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = \"/kaggle/input/hms-harmful-brain-activity-classification\"\n\nSPEC_DIR = \"/kaggle/working\"\nos.makedirs(SPEC_DIR+'/train', exist_ok=True)\nos.makedirs(SPEC_DIR+'/test', exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T14:03:17.602362Z","iopub.execute_input":"2024-02-08T14:03:17.603085Z","iopub.status.idle":"2024-02-08T14:03:17.608044Z","shell.execute_reply.started":"2024-02-08T14:03:17.603053Z","shell.execute_reply":"2024-02-08T14:03:17.60711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 6\nimage_size = [200, 600]\nclass_names = ['Seizure', 'LPD', 'GPD', 'LRDA','GRDA', 'Other']\nlabel2name = dict(enumerate(class_names))\nname2label = {v:k for k, v in label2name.items()}\nbatch_size = 64\nLOSS = tf.keras.losses.KLDivergence()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T14:03:28.601304Z","iopub.execute_input":"2024-02-08T14:03:28.601781Z","iopub.status.idle":"2024-02-08T14:03:28.60727Z","shell.execute_reply.started":"2024-02-08T14:03:28.601749Z","shell.execute_reply":"2024-02-08T14:03:28.606302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train + Valid\ndf = pd.read_csv(f'{BASE_PATH}/train.csv')\ndf['eeg_path'] = f'{BASE_PATH}/train_eegs/'+df['eeg_id'].astype(str)+'.parquet'\ndf['spec_path'] = f'{BASE_PATH}/train_spectrograms/'+df['spectrogram_id'].astype(str)+'.parquet'\ndf['spec2_path'] = f'{SPEC_DIR}/train/'+df['spectrogram_id'].astype(str)+'.npy'\ndf['eeg_to_spec'] = f'{SPEC_DIR}/train/'+df['eeg_id'].astype(str)+'.npy'\ndf['class_name'] = df.expert_consensus.copy()\ndf['class_label'] = df.expert_consensus.map(name2label)\ndisplay(df.head(2))\n\n# Test\ntest_df = pd.read_csv(f'{BASE_PATH}/test.csv')\ntest_df['eeg_path'] = f'{BASE_PATH}/test_eegs/'+test_df['eeg_id'].astype(str)+'.parquet'\ntest_df['spec_path'] = f'{BASE_PATH}/test_spectrograms/'+test_df['spectrogram_id'].astype(str)+'.parquet'\ntest_df['spec2_path'] = f'{SPEC_DIR}/test/'+test_df['spectrogram_id'].astype(str)+'.npy'\ntest_df['eeg_to_spec'] = f'{SPEC_DIR}/test/'+test_df['eeg_id'].astype(str)+'.npy'\ndisplay(test_df.head(2))","metadata":{"execution":{"iopub.status.busy":"2024-02-08T14:05:03.799326Z","iopub.execute_input":"2024-02-08T14:05:03.799695Z","iopub.status.idle":"2024-02-08T14:05:04.363054Z","shell.execute_reply.started":"2024-02-08T14:05:03.799667Z","shell.execute_reply":"2024-02-08T14:05:04.362158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import librosa\n\nNAMES = ['LL','LP','RP','RR']\n\nFEATS = [['Fp1','F7','T3','T5','O1'],\n         ['Fp1','F3','C3','P3','O1'],\n         ['Fp2','F8','T4','T6','O2'],\n         ['Fp2','F4','C4','P4','O2']]\n\n\ndef spectrogram_from_eeg(eeg_id, #display=False,\n                        split = \"train\"):\n    \n    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n    #eeg_path = f\"{BASE_PATH}/{split}_eegs/{eeg_id}.parquet\"\n    PATH = f'{BASE_PATH}/{split}_eegs/'\n    eeg = pd.read_parquet(f'{PATH}{eeg_id}.parquet')\n    middle = (len(eeg)-10_000)//2\n    eeg = eeg.iloc[middle:middle+10_000]\n    \n    # VARIABLE TO HOLD SPECTROGRAM\n    img = np.zeros((150, 200, 4),dtype='float32')\n    \n    #if display: plt.figure(figsize=(10,7))\n    signals = []\n    for k in range(4):\n        COLS = FEATS[k]\n        \n        for kk in range(4):\n        \n            # COMPUTE PAIR DIFFERENCES\n            x = eeg[COLS[kk]].values - eeg[COLS[kk+1]].values\n\n            # FILL NANS\n            m = np.nanmean(x)\n            if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n            else: x[:] = 0\n\n            # DENOISE\n#             if USE_WAVELET:\n#                 x = denoise(x, wavelet=USE_WAVELET)\n            signals.append(x)\n\n            # RAW SPECTROGRAM\n            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//200, \n                  n_fft=1024, n_mels=150, fmin=0, fmax=20, win_length=150)\n\n            # LOG TRANSFORM\n            width = (mel_spec.shape[1]//10)*10\n            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n\n            # STANDARDIZE TO -1 TO 1\n            mel_spec_db = (mel_spec_db+40)/40 \n            img[:,:,k] += mel_spec_db\n                \n        # AVERAGE THE 4 MONTAGE DIFFERENCES\n        img[:,:,k] /= 4.0\n        \n#         if display:\n#             plt.subplot(2,2,k+1)\n#             plt.imshow(img[:,:,k],aspect='auto',origin='lower')\n#             plt.title(f'EEG {eeg_id} - Spectrogram {NAMES[k]}')\n            \n#     if display: \n#         plt.show()\n#         plt.figure(figsize=(10,5))\n#         offset = 0\n#         for k in range(4):\n#             if k>0: offset -= signals[3-k].min()\n#             plt.plot(range(10_000),signals[k]+offset,label=NAMES[3-k])\n#             offset += signals[3-k].max()\n#         plt.legend()\n#         plt.title(f'EEG {eeg_id} Signals')\n#         plt.show()\n#         print(); print('#'*25); print()\n#         plt.close()    \n    np.save(f'{SPEC_DIR}/{split}/{eeg_id}',img)    \n    return img","metadata":{"execution":{"iopub.status.busy":"2024-02-08T14:08:31.300581Z","iopub.execute_input":"2024-02-08T14:08:31.30126Z","iopub.status.idle":"2024-02-08T14:08:31.319279Z","shell.execute_reply.started":"2024-02-08T14:08:31.301226Z","shell.execute_reply":"2024-02-08T14:08:31.318443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nDISPLAY = 4\nEEG_IDS = df.eeg_id.unique()\nEEG_IDS_TEST = test_df.eeg_id.unique()\n\n# train eegs\n_ = joblib.Parallel(n_jobs=-1, backend=\"loky\")(\n    joblib.delayed(spectrogram_from_eeg)(eeg_id, \"train\")\n    for eeg_id in tqdm(EEG_IDS, total=len(EEG_IDS))\n)\n\n#test eegs\n_ = joblib.Parallel(n_jobs=-1, backend=\"loky\")(\n    joblib.delayed(spectrogram_from_eeg)(eeg_id, \"test\")\n    for eeg_id in tqdm(EEG_IDS_TEST, total=len(EEG_IDS_TEST))\n)","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-08T14:08:34.458098Z","iopub.execute_input":"2024-02-08T14:08:34.458453Z","iopub.status.idle":"2024-02-08T14:22:59.844041Z","shell.execute_reply.started":"2024-02-08T14:08:34.458425Z","shell.execute_reply":"2024-02-08T14:22:59.84298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to process a single eeg_id\ndef process_spec(spec_id, split=\"train\"):\n    spec_path = f\"{BASE_PATH}/{split}_spectrograms/{spec_id}.parquet\"\n    spec = pd.read_parquet(spec_path)\n    spec = spec.fillna(0).values[:, 1:].T # fill NaN values with 0, transpose for (Time, Freq) -> (Freq, Time)\n    spec = spec.astype(\"float32\")\n    np.save(f\"{SPEC_DIR}/{split}/{spec_id}.npy\", spec)\n\n# Get unique spec_ids of train and valid data\nspec_ids = df[\"spectrogram_id\"].unique()\n\n# Parallelize the processing using joblib for training data\n_ = joblib.Parallel(n_jobs=-1, backend=\"loky\")(\n    joblib.delayed(process_spec)(spec_id, \"train\")\n    for spec_id in tqdm(spec_ids, total=len(spec_ids))\n)\n\n# Get unique spec_ids of test data\ntest_spec_ids = test_df[\"spectrogram_id\"].unique()\n\n# Parallelize the processing using joblib for test data\n_ = joblib.Parallel(n_jobs=-1, backend=\"loky\")(\n    joblib.delayed(process_spec)(spec_id, \"test\")\n    for spec_id in tqdm(test_spec_ids, total=len(test_spec_ids))\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T14:23:24.071353Z","iopub.execute_input":"2024-02-08T14:23:24.071831Z","iopub.status.idle":"2024-02-08T14:26:29.818365Z","shell.execute_reply.started":"2024-02-08T14:23:24.071794Z","shell.execute_reply":"2024-02-08T14:26:29.816339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_augmenter(dim=image_size):\n    augmenters = [\n        keras_cv.layers.MixUp(alpha=2.0),\n        keras_cv.layers.RandomCutout(height_factor=(1.0, 1.0),\n                                     width_factor=(0.06, 0.1)), # freq-masking\n        keras_cv.layers.RandomCutout(height_factor=(0.06, 0.1),\n                                     width_factor=(1.0, 1.0)), # time-masking\n    ]\n    \n    def augment(img, label):\n        data = {\"images\":img, \"labels\":label}\n        for augmenter in augmenters:\n            if tf.random.uniform([]) < 0.5:\n                data = augmenter(data, training=True)\n        return data[\"images\"], data[\"labels\"]\n    \n    return augment\n\n\ndef build_decoder(with_labels=True, target_size=image_size, dtype=32):\n    def decode_signal(path, path_eeg, offset=None):\n        # Read .npy files and process the signal\n        file_bytes = tf.io.read_file(path)\n        sig = tf.io.decode_raw(file_bytes, tf.float32)\n        sig = sig[1024//dtype:]  # Remove header tag\n        sig = tf.reshape(sig, [200, -1])\n        \n        #Extract labeled subsample from full spectrogram using \"offset\"\n        if offset is not None: \n            #offset = offset // 2  # Only odd values are given\n            sig = sig[:, offset:offset+600]\n            \n            # Pad spectrogram to ensure the same input shape of [400, 300]\n            pad_size = tf.math.maximum(0, 600 - tf.shape(sig)[1])\n            sig = tf.pad(sig, [[0, 0], [0, pad_size]])\n            sig = tf.reshape(sig, [200, 600])\n        \n        # Log spectrogram \n        sig = tf.clip_by_value(sig, tf.math.exp(-4.0), tf.math.exp(8.0)) # avoid 0 in log\n        sig = tf.math.log(sig)\n        \n        # Normalize spectrogram\n        sig -= tf.math.reduce_mean(sig)\n        sig /= tf.math.reduce_std(sig) + 1e-6\n        \n        # Adding our eeg_spectogram\n        file_eeg = tf.io.read_file(path_eeg + '\".npy')\n        eeg = tf.io.decode_raw(file_eeg, tf.float32)\n        eeg = eeg[1024//dtype:]\n        eeg = tf.transpose(eeg)\n        eeg = tf.reshape(eeg, [200, -1])\n        \n        sig = tf.concat([sig, eeg], axis = 0)\n        \n        # Mono channel to 3 channels to use \"ImageNet\" weights\n        sig = tf.tile(sig[..., None], [1, 1, 3])\n        return sig\n    \n    def decode_label(label):\n        label = tf.one_hot(label, num_classes)\n        label = tf.cast(label, tf.float32)\n        label = tf.reshape(label, [num_classes])\n        return label\n    \n    def decode_with_labels(path, path_eeg, offset=None, label=None):\n        sig = decode_signal(path, path_eeg, offset)\n        label = decode_label(label)\n        return (sig, label)\n    \n    return decode_with_labels if with_labels else decode_signal\n\n\ndef build_dataset(paths, paths_eeg, offsets=None, labels=None, batch_size=32, cache=True,\n                  decode_fn=None, augment_fn=None,\n                  augment=False, repeat=True, shuffle=1024, \n                  cache_dir=\"\", drop_remainder=False):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n    \n    if augment_fn is None:\n        augment_fn = build_augmenter()\n    \n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = (paths, paths_eeg, offsets) if labels is None else (paths, paths_eeg, offsets, labels)\n    \n    ds = tf.data.Dataset.from_tensor_slices(slices)\n    ds = ds.map(decode_fn, num_parallel_calls=AUTO)\n    ds = ds.cache(cache_dir) if cache else ds\n    ds = ds.repeat() if repeat else ds\n    if shuffle: \n        ds = ds.shuffle(shuffle, seed=42)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n    ds = ds.map(augment_fn, num_parallel_calls=AUTO) if augment else ds\n    ds = ds.prefetch(AUTO)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:33:21.780061Z","iopub.execute_input":"2024-02-05T15:33:21.780854Z","iopub.status.idle":"2024-02-05T15:33:21.802939Z","shell.execute_reply.started":"2024-02-05T15:33:21.780819Z","shell.execute_reply":"2024-02-05T15:33:21.801791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedGroupKFold\n\nsgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n\ndf[\"fold\"] = -1\ndf.reset_index(drop=True, inplace=True)\nfor fold, (train_idx, valid_idx) in enumerate(\n    sgkf.split(df, y=df[\"class_label\"], groups=df[\"patient_id\"])\n):\n    df.loc[valid_idx, \"fold\"] = fold\ndf.groupby([\"fold\", \"class_name\"])[[\"eeg_id\"]].count().T","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:33:27.185979Z","iopub.execute_input":"2024-02-05T15:33:27.186809Z","iopub.status.idle":"2024-02-05T15:33:28.905919Z","shell.execute_reply.started":"2024-02-05T15:33:27.186748Z","shell.execute_reply":"2024-02-05T15:33:28.904948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample from full data\nsample_df = df.groupby(\"spectrogram_id\").head(1).reset_index(drop=True)\ntrain_df = sample_df[sample_df.fold != 0]\nvalid_df = sample_df[sample_df.fold == 0]\nprint(f\"# Num Train: {len(train_df)} | Num Valid: {len(valid_df)}\")\n\n# Train\ntrain_paths = train_df.spec2_path.values\ntrain_eeg_paths = train_df.eeg_to_spec\ntrain_offsets = train_df.spectrogram_label_offset_seconds.values.astype(int)\ntrain_labels = train_df.class_label.values\ntrain_ds = build_dataset(train_paths,train_eeg_paths, train_offsets, train_labels, batch_size=batch_size,\n                         repeat=True, shuffle=True, augment=True, cache=True)\n\n# Valid\nvalid_paths = valid_df.spec2_path.values \nvalid_eeg_paths = valid_df.eeg_to_spec\nvalid_offsets = valid_df.spectrogram_label_offset_seconds.values.astype(int)\nvalid_labels = valid_df.class_label.values\nvalid_ds = build_dataset(valid_paths, valid_eeg_paths, valid_offsets, valid_labels, batch_size=batch_size,\n                         repeat=False, shuffle=False, augment=False, cache=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:33:31.47936Z","iopub.execute_input":"2024-02-05T15:33:31.480619Z","iopub.status.idle":"2024-02-05T15:33:41.153577Z","shell.execute_reply.started":"2024-02-05T15:33:31.48058Z","shell.execute_reply":"2024-02-05T15:33:41.152694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs, tars = next(iter(train_ds))\n\nnum_imgs = 1\nplt.figure(figsize=(16, 20))\nfor i in range(num_imgs):\n    #plt.subplot(1, 4, i + 1)\n    img = imgs[i].numpy()[...,0]  # Adjust as per your image data format\n    img -= img.min()\n    img /= img.max() + 1e-4\n    tar = label2name[np.argmax(tars[i].numpy())]\n    plt.imshow(img)\n    plt.title(f\"Target: {tar}\")\n    plt.axis('off')\n    \n#plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:34:09.661559Z","iopub.execute_input":"2024-02-05T15:34:09.662619Z","iopub.status.idle":"2024-02-05T15:34:12.000103Z","shell.execute_reply.started":"2024-02-05T15:34:09.662576Z","shell.execute_reply":"2024-02-05T15:34:11.998916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\n\ndef get_lr_callback(batch_size=8, mode='cos', epochs=8, plot=False):\n    lr_start, lr_max, lr_min = 5e-5, 6e-6 * batch_size, 1e-5\n    lr_ramp_ep, lr_sus_ep, lr_decay = 3, 0, 0.75\n\n    def lrfn(epoch):  # Learning rate update function\n        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n        elif mode == 'cos':\n            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n            phase = math.pi * decay_epoch_index / decay_total_epochs\n            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n        return lr\n\n    if plot:  # Plot lr curve if plot is True\n        plt.figure(figsize=(10, 5))\n        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n        plt.xlabel('epoch'); plt.ylabel('lr')\n        plt.title('LR Scheduler')\n        plt.show()\n\n    return tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback\n\nlr_cb = get_lr_callback(64, mode='cos', plot=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:34:18.22328Z","iopub.execute_input":"2024-02-05T15:34:18.224379Z","iopub.status.idle":"2024-02-05T15:34:18.791784Z","shell.execute_reply.started":"2024-02-05T15:34:18.224335Z","shell.execute_reply":"2024-02-05T15:34:18.790781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2L","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:34:22.972175Z","iopub.execute_input":"2024-02-05T15:34:22.972563Z","iopub.status.idle":"2024-02-05T15:34:22.978899Z","shell.execute_reply.started":"2024-02-05T15:34:22.972533Z","shell.execute_reply":"2024-02-05T15:34:22.977894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#base_model = EfficientNetV2M(input_shape = (480, 480, 3), include_top = True, weights = 'imagenet')","metadata":{"execution":{"iopub.status.busy":"2024-02-01T21:00:09.301647Z","iopub.execute_input":"2024-02-01T21:00:09.302068Z","iopub.status.idle":"2024-02-01T21:00:18.683846Z","shell.execute_reply.started":"2024-02-01T21:00:09.302043Z","shell.execute_reply":"2024-02-01T21:00:18.682324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = EfficientNetV2L(input_shape = (400, 600, 3), include_top = False, weights = 'imagenet')","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:34:25.824015Z","iopub.execute_input":"2024-02-05T15:34:25.824843Z","iopub.status.idle":"2024-02-05T15:34:38.827945Z","shell.execute_reply.started":"2024-02-05T15:34:25.824811Z","shell.execute_reply":"2024-02-05T15:34:38.827073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in base_model.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:35:03.607298Z","iopub.execute_input":"2024-02-05T15:35:03.607704Z","iopub.status.idle":"2024-02-05T15:35:03.653343Z","shell.execute_reply.started":"2024-02-05T15:35:03.607672Z","shell.execute_reply":"2024-02-05T15:35:03.652557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = base_model.output\nx = tf.keras.layers.Flatten()(x)\nx = tf.keras.layers.Dense(64, activation=\"relu\")(x)\nx = tf.keras.layers.Dropout(0.1)(x)\n\n# Add a final sigmoid layer with 1 node for classification output\npredictions = tf.keras.layers.Dense(6, activation=\"softmax\")(x)\nmodel_final = tf.keras.models.Model(inputs = base_model.input, outputs = predictions)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:35:05.260305Z","iopub.execute_input":"2024-02-05T15:35:05.261169Z","iopub.status.idle":"2024-02-05T15:35:05.391303Z","shell.execute_reply.started":"2024-02-05T15:35:05.261124Z","shell.execute_reply":"2024-02-05T15:35:05.390415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n              loss=LOSS, metrics = [LOSS])","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:35:07.047849Z","iopub.execute_input":"2024-02-05T15:35:07.048757Z","iopub.status.idle":"2024-02-05T15:35:07.0922Z","shell.execute_reply.started":"2024-02-05T15:35:07.048724Z","shell.execute_reply":"2024-02-05T15:35:07.091386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt_cb = tf.keras.callbacks.ModelCheckpoint(\"best_model.keras\",\n                                         monitor='val_loss',\n                                         save_best_only=True,\n                                         save_weights_only=False,\n                                         mode='min')","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:35:08.624418Z","iopub.execute_input":"2024-02-05T15:35:08.624799Z","iopub.status.idle":"2024-02-05T15:35:08.632264Z","shell.execute_reply.started":"2024-02-05T15:35:08.624768Z","shell.execute_reply":"2024-02-05T15:35:08.631186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model_final.fit(\n    train_ds, \n    epochs=5,\n    callbacks=[ckpt_cb, lr_cb], \n    steps_per_epoch=len(train_df)//64,\n    validation_data=valid_ds, \n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T15:35:13.130246Z","iopub.execute_input":"2024-02-05T15:35:13.131015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"test_paths = test_df.spec2_path.values\ntest_eeg_paths = test_df.eeg_to_spec\ntest_ds = build_dataset(test_paths, test_eeg_paths, batch_size=min(CFG.batch_size, len(test_df)),\n                         repeat=False, shuffle=False, cache=False, augment=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model_final.predict(test_ds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df = test_df[[\"eeg_id\"]].copy()\ntarget_cols = [x.lower()+'_vote' for x in class_names]\npred_df[target_cols] = preds.tolist()\n\nsub_df = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')\nsub_df = sub_df[[\"eeg_id\"]].copy()\nsub_df = sub_df.merge(pred_df, on=\"eeg_id\", how=\"left\")\nsub_df.to_csv(\"submission.csv\", index=False)\nsub_df.head()","metadata":{},"execution_count":null,"outputs":[]}]}