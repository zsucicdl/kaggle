{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7700249,"sourceType":"datasetVersion","datasetId":4491141,"isSourceIdPinned":true},{"sourceId":164443259,"sourceType":"kernelVersion"}],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About this notebook\n\nThis is the inference of this model trained [here](https://www.kaggle.com/code/medali1992/hms-efficientnetb0-train/notebook).\n\n## Version 1\n\n### Hyperparams\n\n\n```\nscheduler='OneCycleLR' \nprint_freq=50\nnum_workers = 1\nmodel_name = 'tf_efficientnet_b0_ns'\noptimizer='Adam'\nstage1_epochs = 5\nstage1_epochs = 7\neps = 1e-6\nlr = 1e-3\nbatch_size = 64\nweight_decay = 1e-2\nseed = 2024\n```\n\n## Version2 No tta\n\n* I changed the CV sheme, first stage train on all data second stage train on data with `total_evaluators >= 10`\n* Added Time masking augmentation from [here](https://www.kaggle.com/code/iglovikov/xymasking-aug).\n* `LB=0.36`\n\n## Version2 With tta\n\n* I changed the CV sheme, first stage train on all data second stage train on data with `total_evaluators >= 10`\n* Added Time masking augmentation from [here](https://www.kaggle.com/code/iglovikov/xymasking-aug).\n\n### Hyperparams\n\n```\nscheduler='OneCycleLR' \nprint_freq=50\nnum_workers = 1\n model_name = 'tf_efficientnet_b0_ns'\noptimizer='Adam'\nstage1_epochs = 5\nstage1_epochs = 5\neps = 1e-6\nlr = 1e-3\nbatch_size = 64\nweight_decay = 1e-2\nseed = 2024\n```","metadata":{}},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"!pip install /kaggle/input/wheel-albumentation/albumentations-1.4.0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2024-02-27T02:44:17.545967Z","iopub.execute_input":"2024-02-27T02:44:17.546531Z","iopub.status.idle":"2024-02-27T02:44:51.779326Z","shell.execute_reply.started":"2024-02-27T02:44:17.546502Z","shell.execute_reply":"2024-02-27T02:44:51.777794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nfrom glob import glob\nimport sys\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom typing import Dict, List\nfrom scipy.stats import entropy\nfrom scipy.signal import butter, lfilter, freqz\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom tqdm.auto import tqdm\nfrom functools import partial\nimport cv2\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport pytorch_lightning as pl\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, CosineAnnealingLR, CosineAnnealingWarmRestarts\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchvision.transforms import v2\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.model_selection import train_test_split\nimport albumentations as A\nfrom albumentations import (Compose, Normalize, Resize, RandomResizedCrop, HorizontalFlip, VerticalFlip, ShiftScaleRotate, Transpose)\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\nimport timm\nimport warnings \nwarnings.filterwarnings('ignore')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nfrom matplotlib import pyplot as plt\nimport joblib\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\nVERSION=2","metadata":{"execution":{"iopub.status.busy":"2024-02-27T02:44:51.782371Z","iopub.execute_input":"2024-02-27T02:44:51.782778Z","iopub.status.idle":"2024-02-27T02:45:03.035857Z","shell.execute_reply.started":"2024-02-27T02:44:51.782749Z","shell.execute_reply":"2024-02-27T02:45:03.034424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class CFG:\n    PATH = '/kaggle/input/hms-harmful-brain-activity-classification/'\n    test_eeg = \"/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/\"\n    test_csv = \"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\"\n    test_spectrograms = \"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/\"\n    model_name = 'tf_efficientnet_b0_ns'\n    SparK = False\n    FREEZE = False\n    seed = 2024\n    in_channels = 8\n    target_size = 6\n    batch_size = 32\n    num_workers = 1\n\n    \nmodel_weights = [x for x in glob(\"/kaggle/input/hms-efficientnetb0-weights/pop_2_weight_oof/*.pth\")]\nmodel_weights","metadata":{"execution":{"iopub.status.busy":"2024-02-27T02:45:03.037051Z","iopub.execute_input":"2024-02-27T02:45:03.037365Z","iopub.status.idle":"2024-02-27T02:45:03.052858Z","shell.execute_reply.started":"2024-02-27T02:45:03.037336Z","shell.execute_reply":"2024-02-27T02:45:03.051552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils ","metadata":{}},{"cell_type":"code","source":"import pywt, librosa\n\nUSE_WAVELET = None \n\nNAMES = ['LL','LP','RP','RR']\n\nFEATS = [['Fp1','F7','T3','T5','O1'],\n         ['Fp1','F3','C3','P3','O1'],\n         ['Fp2','F8','T4','T6','O2'],\n         ['Fp2','F4','C4','P4','O2']]\n\n# DENOISE FUNCTION\ndef maddest(d, axis=None):\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n\ndef denoise(x, wavelet='haar', level=1):    \n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1/0.6745) * maddest(coeff[-level])\n\n    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n\n    ret=pywt.waverec(coeff, wavelet, mode='per')\n    \n    return ret\n\ndef spectrogram_from_eeg(parquet_path, display=False, offset=None):\n    \n    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n    eeg = pd.read_parquet(parquet_path)\n#     print(eeg.shape)\n    if offset is None:\n        middle = (len(eeg)-10_000)//2\n        eeg = eeg.iloc[middle:middle+10_000]\n    else:\n        eeg = eeg.iloc[offset:offset+10_000]\n    \n    # VARIABLE TO HOLD SPECTROGRAM\n    img = np.zeros((128,256,4),dtype='float32')\n    \n    if display: plt.figure(figsize=(10,7))\n    signals = []\n    for k in range(4):\n        COLS = FEATS[k]\n        \n        for kk in range(4):\n        \n            # COMPUTE PAIR DIFFERENCES\n            x = eeg[COLS[kk]].values - eeg[COLS[kk+1]].values\n\n            # FILL NANS\n            m = np.nanmean(x)\n            if np.isnan(x).mean() < 1: \n                x = np.nan_to_num(x,nan=m)\n            else: x[:] = 0\n\n            # DENOISE\n            if USE_WAVELET:\n                x = denoise(x, wavelet=USE_WAVELET)\n            signals.append(x)\n\n            # RAW SPECTROGRAM\n            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//256, \n                  n_fft=1024, n_mels=128, fmin=0, fmax=20, win_length=128)\n\n            # LOG TRANSFORM\n            width = (mel_spec.shape[1]//32)*32\n            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n\n            # STANDARDIZE TO -1 TO 1\n            mel_spec_db = (mel_spec_db+40)/40 \n            img[:,:,k] += mel_spec_db\n                \n        # AVERAGE THE 4 MONTAGE DIFFERENCES\n        img[:,:,k] /= 4.0\n        \n        if display:\n            plt.subplot(2,2,k+1)\n            plt.imshow(img[:,:,k],aspect='auto',origin='lower')\n#             plt.title(f'EEG {eeg_id} - Spectrogram {NAMES[k]}')\n            \n    if display: \n        plt.show()\n        plt.figure(figsize=(10,5))\n        offset = 0\n        for k in range(4):\n            if k>0: offset -= signals[3-k].min()\n            plt.plot(range(10_000),signals[k]+offset,label=NAMES[3-k])\n            offset += signals[3-k].max()\n        plt.legend()\n#         plt.title(f'EEG {eeg_id} Signals')\n        plt.show()\n        print(); print('#'*25); print()\n        \n    return img","metadata":{"execution":{"iopub.status.busy":"2024-02-27T02:45:03.056684Z","iopub.execute_input":"2024-02-27T02:45:03.057129Z","iopub.status.idle":"2024-02-27T02:45:03.155644Z","shell.execute_reply.started":"2024-02-27T02:45:03.057092Z","shell.execute_reply":"2024-02-27T02:45:03.15481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(CFG.test_csv)\nprint('Test shape',test.shape)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-27T02:45:03.156879Z","iopub.execute_input":"2024-02-27T02:45:03.157794Z","iopub.status.idle":"2024-02-27T02:45:03.184091Z","shell.execute_reply.started":"2024-02-27T02:45:03.157756Z","shell.execute_reply":"2024-02-27T02:45:03.182864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# READ ALL SPECTROGRAMS\nfiles2 = os.listdir(CFG.test_spectrograms)\nprint(f'There are {len(files2)} test spectrogram parquets')\n    \nall_spectrograms = {}\nfor i,f in enumerate(files2):\n    if i%100==0: print(i,', ',end='')\n    tmp = pd.read_parquet(f'{CFG.test_spectrograms}{f}')\n    name = int(f.split('.')[0])\n    all_spectrograms[name] = tmp.iloc[:,1:].values\n    \n# RENAME FOR DATALOADER\ntest = test.rename({'spectrogram_id':'spec_id'},axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T02:45:03.185673Z","iopub.execute_input":"2024-02-27T02:45:03.186981Z","iopub.status.idle":"2024-02-27T02:45:03.385241Z","shell.execute_reply.started":"2024-02-27T02:45:03.186931Z","shell.execute_reply":"2024-02-27T02:45:03.383798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# READ ALL EEG SPECTROGRAMS\nDISPLAY = 1\nEEG_IDS2 = test.eeg_id.unique()\nall_eegs = {}\n\nprint('Converting Test EEG to Spectrograms...'); print()\nfor i,eeg_id in enumerate(EEG_IDS2):\n        \n    # CREATE SPECTROGRAM FROM EEG PARQUET\n    img = spectrogram_from_eeg(f'{CFG.test_eeg}{eeg_id}.parquet', i<DISPLAY)\n    all_eegs[eeg_id] = img","metadata":{"execution":{"iopub.status.busy":"2024-02-27T02:45:03.387957Z","iopub.execute_input":"2024-02-27T02:45:03.38838Z","iopub.status.idle":"2024-02-27T02:45:17.643166Z","shell.execute_reply.started":"2024-02-27T02:45:03.388342Z","shell.execute_reply":"2024-02-27T02:45:17.642129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(\n        self, df: pd.DataFrame,\n        transform=ToTensorV2(), mode: str = 'tta',\n        specs: Dict[int, np.ndarray] = all_spectrograms,\n        eeg_specs: Dict[int, np.ndarray] = all_eegs\n    ): \n        self.df = df\n        self.transform = transform\n        self.mode = mode\n        self.spectograms = specs\n        self.eeg_spectograms = eeg_specs\n        \n    def __len__(self):\n        \"\"\"\n        Denotes the number of batches per epoch.\n        \"\"\"\n        return len(self.df)\n        \n    def __getitem__(self, index):\n        \"\"\"\n        Generate one batch of data.\n        \"\"\"\n        X, y = self.__data_generation(index)\n        if self.transform:\n            X = self.__transform(X) \n        return {\"spectrogram\": X, \"labels\": y}\n                        \n    def __data_generation(self, index):\n        \"\"\"\n        Generates data containing batch_size samples.\n        \"\"\"\n        X = np.zeros((128, 256, 8), dtype='float32')\n        y = np.zeros(6, dtype='float32')\n        img = np.ones((128,256), dtype='float32')\n        row = self.df.iloc[index]\n        if self.mode=='tta': \n            r = 0\n        else: \n            r = int(row['spectrogram_label_offset_seconds'] // 2)\n            \n        for region in range(4):\n            img = self.spectograms[row.spec_id][r:r+300, region*100:(region+1)*100].T\n            \n            # Log transform spectogram\n            img = np.clip(img, np.exp(-4), np.exp(8))\n            img = np.log(img)\n\n            # Standarize per image\n            ep = 1e-6\n            mu = np.nanmean(img.flatten())\n            std = np.nanstd(img.flatten())\n            img = (img-mu)/(std+ep)\n            img = np.nan_to_num(img, nan=0.0)\n            X[14:-14, :, region] = img[:, 22:-22] / 2.0\n            img = self.eeg_spectograms[row.eeg_id]\n            X[:, :, 4:] = img\n                \n            if self.mode != 'tta':\n                y = row[TARGETS].values.astype(np.float32)\n            \n        return X, y\n    \n    def __transform(self, img):\n        transforms = A.Compose([\n            self.transform,\n        ])\n        return transforms(image=img)['image']","metadata":{"execution":{"iopub.status.busy":"2024-02-27T02:45:17.644544Z","iopub.execute_input":"2024-02-27T02:45:17.645077Z","iopub.status.idle":"2024-02-27T02:45:17.661036Z","shell.execute_reply.started":"2024-02-27T02:45:17.645049Z","shell.execute_reply":"2024-02-27T02:45:17.659506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = CustomDataset(test, mode=\"tta\")\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=CFG.batch_size,\n    shuffle=False,\n    num_workers=CFG.num_workers, pin_memory=True, drop_last=False\n)\nX = test_dataset[0]\nprint(f\"X shape: {X['spectrogram'].shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-27T02:45:17.66244Z","iopub.execute_input":"2024-02-27T02:45:17.662968Z","iopub.status.idle":"2024-02-27T02:45:17.687204Z","shell.execute_reply.started":"2024-02-27T02:45:17.662937Z","shell.execute_reply":"2024-02-27T02:45:17.685308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, config, num_classes: int = 6, pretrained: bool = True):\n        super(CustomModel, self).__init__()\n        self.USE_KAGGLE_SPECTROGRAMS = True\n        self.USE_EEG_SPECTROGRAMS = True\n        self.model = timm.create_model(\n            config.model_name,\n            pretrained=pretrained,\n        )\n        # Optionally load state from checkpoint\n        if config.SparK:\n            state = torch.load('/kaggle/input/resnet50d-spark/resnet50_1kpretrained_timm_style.pth', 'cpu')\n            self.model.load_state_dict(state.get('module', state), strict=False)\n        if config.FREEZE:\n            for i,(name, param) in enumerate(list(self.model.named_parameters())\\\n                                             [0:config.NUM_FROZEN_LAYERS]):\n                param.requires_grad = False\n\n        self.features = nn.Sequential(*list(self.model.children())[:-2])\n        self.custom_layers = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Linear(self.model.num_features, num_classes)\n        )\n\n    def __reshape_input(self, x):\n        \"\"\"\n        Reshapes input (128, 256, 8) -> (512, 512, 3) monotone image.\n        \"\"\" \n        # === Get spectograms ===\n        spectograms = [x[:, :, :, i:i+1] for i in range(4)]\n        spectograms = torch.cat(spectograms, dim=1)\n        \n        # === Get EEG spectograms ===\n        eegs = [x[:, :, :, i:i+1] for i in range(4,8)]\n        eegs = torch.cat(eegs, dim=1)\n        \n        # === Reshape (512,512,3) ===\n        if self.USE_KAGGLE_SPECTROGRAMS & self.USE_EEG_SPECTROGRAMS:\n            x = torch.cat([spectograms, eegs], dim=2)\n        elif self.USE_EEG_SPECTROGRAMS:\n            x = eegs\n        else:\n            x = spectograms\n            \n        x = torch.cat([x,x,x], dim=3)\n        x = x.permute(0, 3, 1, 2)\n        return x\n    \n    def forward(self, x):\n        x = self.__reshape_input(x)\n        x = self.features(x)\n        x = self.custom_layers(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-02-27T02:45:17.69038Z","iopub.execute_input":"2024-02-27T02:45:17.69072Z","iopub.status.idle":"2024-02-27T02:45:17.704255Z","shell.execute_reply.started":"2024-02-27T02:45:17.690695Z","shell.execute_reply":"2024-02-27T02:45:17.703417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference Function","metadata":{}},{"cell_type":"code","source":"def inference_function(test_loader, model, device):\n    model.eval() # set model in evaluation mode\n    softmax = nn.Softmax(dim=1)\n    prediction_dict = {}\n    preds = []\n    with tqdm(test_loader, unit=\"test_batch\", desc='Inference') as tqdm_test_loader:\n        for step, batch in enumerate(tqdm_test_loader):\n            X = batch.pop(\"spectrogram\").to(device) # send inputs to `device`\n            batch_size = X.size(0)\n                \n            with torch.no_grad():\n                y_preds = model(X) # forward propagation pass\n            y_preds = softmax(y_preds)\n            preds.append(y_preds.to('cpu').numpy()) # save predictions\n                \n    prediction_dict[\"predictions\"] = np.concatenate(preds) # np.array() of shape (fold_size, target_cols)\n    return prediction_dict","metadata":{"execution":{"iopub.status.busy":"2024-02-27T02:47:04.139485Z","iopub.execute_input":"2024-02-27T02:47:04.139947Z","iopub.status.idle":"2024-02-27T02:47:04.149758Z","shell.execute_reply.started":"2024-02-27T02:47:04.139916Z","shell.execute_reply":"2024-02-27T02:47:04.147854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"params1 = {\n            \"num_masks_x\": 1,    \n            \"mask_x_length\": (0, 20), # This line changed from fixed  to a range\n            \"fill_value\": (0, 1, 2, 3, 4, 5, 6, 7),\n            }\nparams2 = {    \n            \"num_masks_y\": 1,    \n            \"mask_y_length\": (0, 20),\n            \"fill_value\": (0, 1, 2, 3, 4, 5, 6, 7),    \n            }\nparams3 = {    \n            \"num_masks_x\": (2, 4),\n            \"num_masks_y\": 5,    \n            \"mask_y_length\": 8,\n            \"mask_x_length\": (10, 20),\n            \"fill_value\": (0, 1, 2, 3, 4, 5, 6, 7),  \n            }\n\npredictions = []\naug_list = [A.Compose(ToTensorV2(p=1.0)), A.Compose([A.XYMasking(**params1, p=1.0), ToTensorV2(p=1.0)]), A.Compose([A.XYMasking(**params2, p=1.0), ToTensorV2(p=1.0)]), A.Compose([A.XYMasking(**params3, p=1.0), ToTensorV2(p=1.0)])]\nfor model_weight in model_weights:\n    tta_predictions = []\n    for transform in tqdm(aug_list, unit=\"test_batch\", desc='TTA', colour='blue'):\n        test_dataset = CustomDataset(test, transform=transform, mode=\"tta\")\n        train_loader = DataLoader(\n        test_dataset,\n        batch_size=CFG.batch_size,\n        shuffle=False,\n        num_workers=CFG.num_workers,\n        pin_memory=True,\n        drop_last=False\n        )\n        model = CustomModel(CFG, pretrained=False)\n        checkpoint = torch.load(model_weight, map_location=device)\n        model.load_state_dict(checkpoint[\"model\"])\n        model.to(device)\n        prediction_dict = inference_function(test_loader, model, device)\n        tta_predictions.append(prediction_dict[\"predictions\"])\n    tta_predictions = np.mean(tta_predictions, axis=0)\n    predictions.append(tta_predictions)\n    torch.cuda.empty_cache()\n    gc.collect()\n    \npredictions = np.array(predictions)\npredictions = np.mean(predictions, axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T02:47:04.682505Z","iopub.execute_input":"2024-02-27T02:47:04.683102Z","iopub.status.idle":"2024-02-27T02:48:56.870711Z","shell.execute_reply.started":"2024-02-27T02:47:04.683071Z","shell.execute_reply":"2024-02-27T02:48:56.869165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\nsub = pd.DataFrame({'eeg_id': test.eeg_id.values})\nsub[TARGETS] = predictions\nsub.to_csv(f'submission.csv',index=False)\nprint(f'Submission shape: {sub.shape}')\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-27T02:49:05.151317Z","iopub.execute_input":"2024-02-27T02:49:05.151803Z","iopub.status.idle":"2024-02-27T02:49:05.176882Z","shell.execute_reply.started":"2024-02-27T02:49:05.151762Z","shell.execute_reply":"2024-02-27T02:49:05.175993Z"},"trusted":true},"execution_count":null,"outputs":[]}]}