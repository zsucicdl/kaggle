{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":159396114,"sourceType":"kernelVersion"}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":16.134266,"end_time":"2024-01-18T09:25:13.659607","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-18T09:24:57.525341","version":"2.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Explained: HMS Baseline & Resources üìö\n\nThis notebook is part of a series exploring the Harmful Brain Activity Classification task. The baseline model is built using ResNet34d, and resources from the [HMS Kaggle competition](https://www.kaggle.com/c/hms-harmful-brain-activity-classification) have been used for training and inference.\n\n### Baseline Model\n- The baseline model architecture is ResNet34d, a variant of ResNet.\n- PyTorch is the primary deep learning library utilized for model training and evaluation.\n- The model is trained using a configuration that includes seed, image transformation, and the number of folds for cross-validation.\n\n### Key Resources\n- Training data is handled using Pandas for CSV manipulation and Torchvision for image transformations.\n- The loading of pre-trained models for inference involves reading the saved models for each fold.\n- Seed initialization ensures reproducibility in the training process.\n- The submission process involves loading the test data, preprocessing, model inference, and generating class probabilities.\n- The final submission CSV includes class probabilities for each class.\n\n","metadata":{}},{"cell_type":"markdown","source":"## Import necessary libraries","metadata":{"papermill":{"duration":0.003009,"end_time":"2024-01-18T09:25:00.579193","exception":false,"start_time":"2024-01-18T09:25:00.576184","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Importing necessary libraries\nimport pandas as pd  # üìä Library for handling CSV files\nimport numpy as np  # üßÆ Library for matrix operations\nimport torch  # üöÄ Deep learning library - PyTorch\nimport torch.nn as nn  # üí° Neural network module in PyTorch\nimport torch.nn.functional as F  # üß† Functional module for neural network operations\nimport torchvision.transforms as transforms  # üñºÔ∏è Image processing library in PyTorch for data augmentation\n\n# Setting the random seed for reproducibility\nimport random  # üé≤ Library for generating random numbers\nimport warnings  # ‚ö†Ô∏è Library for handling warnings\nwarnings.filterwarnings('ignore')  # üö´ Ignore specific warnings during execution\n","metadata":{"papermill":{"duration":3.931876,"end_time":"2024-01-18T09:25:04.514248","exception":false,"start_time":"2024-01-18T09:25:00.582372","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## üõ†Ô∏è Configuration Settings for Model Training ü§ñ","metadata":{"papermill":{"duration":0.003346,"end_time":"2024-01-18T09:25:04.521262","exception":false,"start_time":"2024-01-18T09:25:04.517916","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**Explanation:**\n\n1. `seed = 2024`: This parameter sets the random seed for reproducibility. Setting a seed ensures that the same sequence of random numbers is generated, making experiments reproducible. üå± [Random Seed - Wikipedia](https://en.wikipedia.org/wiki/Random_seed)\n\n2. `image_transform = transforms.Resize((512, 512))`: This line defines an image transformation using the `transforms` module from PyTorch. The `Resize` transformation resizes images to a specified size of (512, 512). Image transformations are commonly used for data preprocessing in deep learning pipelines. üñºÔ∏è [Torchvision Transforms Documentation](https://pytorch.org/vision/stable/transforms.html)\n\n3. `num_folds = 5`: This parameter represents the number of folds used in cross-validation. Cross-validation is a technique used to assess the performance of a model and reduce the risk of overfitting. It involves splitting the dataset into multiple folds, training the model on different combinations of folds, and evaluating its performance. üî¢ [Cross-Validation - Wikipedia](https://en.wikipedia.org/wiki/Cross-validation)\n\nThese configuration settings are essential for defining the experimental setup, ensuring reproducibility, and preparing data for model training. The seed is set for reproducibility, image transformation is specified for preprocessing, and the number of folds is set for cross-validation.","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n\nclass Config:\n    seed = 2024\n    image_transform = transforms.Resize((512, 512))\n    num_folds = 5\n    \n    # Additional parameters\n    num_classes = 10  # Number of output classes in the model\n    dropout_rate = 0.2  # Dropout rate for regularization in the model\n    learning_rate_scheduler = \"cosine\"  # Learning rate scheduler type (e.g., cosine, step, etc.)\n    warmup_epochs = 2  # Number of warm-up epochs for learning rate scheduler\n    augmentation_prob = 0.5  # Probability of applying data augmentation during training\n    logging_interval = 100  # Interval for logging training information\n    batch_size = 24  # Training batch size\n    num_epochs = 10  # Number of training epochs\n    weight_decay = 1e-4  # Weight decay for regularization\n    model_type = \"resnet\"  # Type of model architecture (e.g., resnet, vgg, etc.)\n    optimizer = \"adam\"  # Optimizer type (e.g., adam, sgd, etc.)\n    lr = 0.0008  # Initial learning rate\n    momentum = 0.9  # Momentum for optimizer (if applicable)\n","metadata":{"papermill":{"duration":0.012147,"end_time":"2024-01-18T09:25:04.536923","exception":false,"start_time":"2024-01-18T09:25:04.524776","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ü§ñ Model Loading for Inference üöÄ","metadata":{}},{"cell_type":"markdown","source":"**Explanation:**\n\n1. `models = []`: This line initializes an empty list named `models` to store the loaded models. ü§ñ\n\n2. `for i in range(Config.num_folds):`: This is a loop that iterates over the specified number of folds (given by `Config.num_folds`). It is used to load a model for each fold. üîÅ\n\n3. `model = torch.load(f'/kaggle/input/hms-baseline-resnet34d-512-512-training-5-folds/HMS_resnet_fold{i}.pth')`: This line loads a pre-trained PyTorch model for the ith fold from a specified file path. `torch.load` is used to load the model from a saved state. üìÇ [PyTorch Load and Save Model Documentation](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n\n4. `models.append(model)`: After loading a model for a fold, the model is appended to the `models` list. This creates a list of models, one for each fold. üìã [Python List Documentation](https://docs.python.org/3/tutorial/introduction.html#lists)\n\nTo load pre-trained models for each fold from a specified directory path and store them in a list (`models`). These loaded models can then be used for making predictions or further analysis during inference.","metadata":{}},{"cell_type":"code","source":"# List to store loaded models\nmodels = []\n\n# Loop to load trained models for each fold\nfor i in range(Config.num_folds):\n    # Loading a pre-trained model for the ith fold\n    model = torch.load(f'/kaggle/input/hms-baseline-resnet34d-512-512-training-5-folds/HMS_resnet_fold{i}.pth')\n    \n    # Appending the loaded model to the list\n    models.append(model)\n","metadata":{"papermill":{"duration":5.347694,"end_time":"2024-01-18T09:25:09.895288","exception":false,"start_time":"2024-01-18T09:25:04.547594","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## üå± Seed Initialization for Reproducibility üåê","metadata":{}},{"cell_type":"markdown","source":"**Explanation:**\n\n1. `torch.backends.cudnn.deterministic = True`: This line sets the CuDNN (CUDA Deep Neural Network library) to deterministic mode. It ensures that the GPU operations produce the same results on each run. üß† [CuDNN Documentation](https://docs.nvidia.com/deeplearning/cudnn/index.html#deterministic-behavior)\n\n2. `torch.backends.cudnn.benchmark = True`: Disabling CuDNN benchmarking helps achieve consistent results by avoiding dynamic adjustment of convolution algorithms. This is particularly useful for reproducibility. ‚öôÔ∏è [CuDNN Documentation](https://docs.nvidia.com/deeplearning/cudnn/index.html#library-behavior)\n\n3. `torch.manual_seed(seed)`: This line sets the manual seed for PyTorch operations, ensuring that random operations within PyTorch are also reproducible. üåê [PyTorch Random Seed Documentation](https://pytorch.org/docs/stable/notes/randomness.html)\n\n4. `np.random.seed(seed)`: Setting the NumPy random seed ensures that operations involving NumPy arrays produce the same results across different runs. üåê [NumPy Random Seed Documentation](https://numpy.org/doc/stable/reference/random/generated/numpy.random.seed.html)\n\n5. `random.seed(seed)`: Setting the built-in Python random seed ensures reproducibility for other Python-based random operations. üåê [Python Random Seed Documentation](https://docs.python.org/3/library/random.html#random.seed)\n\nThe purpose of this code snippet is to initialize seeds for various libraries to achieve reproducibility in the training process. Reproducible results are essential for debugging, understanding model behavior, and comparing different experimental runs.","metadata":{}},{"cell_type":"code","source":"# Function to set seeds for reproducibility\ndef seed_everything(seed):\n    torch.backends.cudnn.deterministic = True  # üß† Set CuDNN to deterministic mode for GPU\n    torch.backends.cudnn.benchmark = True  # ‚öôÔ∏è Disable CuDNN benchmarking for consistent results\n    torch.manual_seed(seed)  # üåê Set PyTorch manual seed for reproducibility\n    np.random.seed(seed)  # üåê Set NumPy random seed for reproducibility\n    random.seed(seed)  # üåê Set Python built-in random seed for reproducibility\n\n# Calling the seed initialization function with the specified seed value\nseed_everything(Config.seed)\n","metadata":{"papermill":{"duration":0.018973,"end_time":"2024-01-18T09:25:09.924834","exception":false,"start_time":"2024-01-18T09:25:09.905861","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## üìä Loading Test Data and Preparing Submission DataFrame üßæ","metadata":{}},{"cell_type":"markdown","source":"**Explanation:**\n\n1. `test_df = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\")`: This line reads the test data CSV file into a Pandas DataFrame (`test_df`). üìä [Pandas read_csv Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)\n\n2. `submission = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")`: This line reads the sample submission CSV file into a Pandas DataFrame (`submission`). üìä [Pandas read_csv Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)\n\n3. `submission = submission.merge(test_df, on='eeg_id', how='left')`: Merging the `submission` DataFrame with the `test_df` DataFrame based on the 'eeg_id' column. The resulting DataFrame contains information from both DataFrames. üîÑ [Pandas Merge, Join, and Concatenate Documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)\n\n4. `submission['path'] = submission['spectrogram_id'].apply(lambda x: \"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/\" + str(x) + \".parquet\")`: This line creates a new column 'path' in the `submission` DataFrame by applying a lambda function to the 'spectrogram_id' column. The lambda function constructs the file path for each spectrogram in the test set. üßæ [Pandas apply Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html)\n\n5. `submission.head()`: This line displays the first few rows of the `submission` DataFrame to verify the data loading and preprocessing steps. üßê [Pandas DataFrame head Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html)\n\nThe code is responsible for loading the test dataset, preparing the submission DataFrame, and creating a new column 'path' that contains the file paths for the test spectrograms. This process is crucial for inputting test data into the trained models during inference.","metadata":{}},{"cell_type":"code","source":"# Loading the test dataset from CSV file\ntest_df = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\")\n\n# Loading the sample submission dataframe\nsubmission = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\n\n# Merging test dataframe with the submission dataframe based on the 'eeg_id' column\nsubmission = submission.merge(test_df, on='eeg_id', how='left')\n\n# Creating a new column 'path' by applying a lambda function to the 'spectrogram_id' column\nsubmission['path'] = submission['spectrogram_id'].apply(lambda x: \"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/\" + str(x) + \".parquet\")\n\n# Displaying the first few rows of the submission dataframe\nsubmission.head()\n","metadata":{"papermill":{"duration":0.076636,"end_time":"2024-01-18T09:25:10.012886","exception":false,"start_time":"2024-01-18T09:25:09.93625","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## üß† Inference on Test Data and Prediction Aggregation ü§ñ","metadata":{}},{"cell_type":"markdown","source":"\n**Explanation:**\n\n1. `paths = submission['path'].values`: Extracts the file paths from the 'path' column in the submission dataframe. üìä [Pandas DataFrame Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)\n\n2. `eps = 1e-6`: Defines a small epsilon value to avoid division by zero during normalization.\n\n3. `data = pd.read_parquet(path)`: Reads the parquet file specified by the file path using Pandas. Parquet is a columnar storage file format. üìä [Pandas read_parquet Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_parquet.html)\n\n4. Data Preprocessing:\n   - Fills NaN values with -1.\n   - Transposes the data to have time along rows and different features along columns.\n   - Selects the first 300 time points for training.\n   - Clips the data to be within a certain range and applies a logarithmic transformation.\n   - Normalizes the data by subtracting the mean and dividing by the standard deviation.\n\n5. `data_tensor = torch.unsqueeze(torch.Tensor(data), dim=0)`: Converts the preprocessed data to a PyTorch tensor and adds an extra dimension using `unsqueeze`. üß† [PyTorch Tensor Documentation](https://pytorch.org/docs/stable/tensors.html)\n\n6. `data = Config.image_transform(data_tensor)`: Applies the image transformation specified in the configuration to the data. üñºÔ∏è [Torchvision Transforms Documentation](https://pytorch.org/vision/stable/transforms.html)\n\n7. `test_pred = []`: Initializes an empty list to store predictions for each model.\n\n8. Model Inference:\n   - Loops over each loaded model.\n   - Sets the model to evaluation mode using `model.eval()`.\n   - Performs a forward pass to obtain predictions using the softmax function.\n   - Detaches the predictions, moves them to CPU, and converts them to a NumPy array.\n\n9. Aggregation:\n   - Aggregates predictions across models by taking the mean along the model dimension.\n\n10. `test_preds = np.array(test_preds)`: Converts the list of predictions to a NumPy array for further analysis.\n\nThis code conducts inference on the test data using the loaded models, aggregates predictions, and produces the final predictions for submission. The models are expected to have been loaded in a previous code cell.","metadata":{}},{"cell_type":"code","source":"# Extracting file paths from the 'path' column in the submission dataframe\npaths = submission['path'].values\n\n# List to store predictions for each test spectrogram\ntest_preds = []\n\n# Loop over each file path in the test dataset\nfor path in paths:\n    eps = 1e-6  # Small epsilon value to avoid division by zero\n    \n    # Reading the parquet file and preprocessing the data\n    data = pd.read_parquet(path)\n    data = data.fillna(-1).values[:, 1:].T\n    data = data[:, 0:300]\n    data = np.clip(data, np.exp(-6), np.exp(10))\n    data = np.log(data)\n    \n    # Normalizing the data\n    data_mean = data.mean(axis=(0, 1))\n    data_std = data.std(axis=(0, 1))\n    data = (data - data_mean) / (data_std + eps)\n    \n    # Converting the data to PyTorch tensor and applying image transformation\n    data_tensor = torch.unsqueeze(torch.Tensor(data), dim=0)\n    data = Config.image_transform(data_tensor)\n    \n    # List to store predictions for each model\n    test_pred = []\n    \n    # Loop over each model in the list of loaded models\n    for model in models:\n        model.eval()  # Set the model to evaluation mode\n        with torch.no_grad():\n            # Forward pass to obtain model predictions\n            pred = F.softmax(model(data.unsqueeze(0)))[0]\n            pred = pred.detach().cpu().numpy()\n        test_pred.append(pred)\n    \n    # Aggregating predictions by taking the mean across models\n    test_pred = np.array(test_pred).mean(axis=0)\n    test_preds.append(test_pred)\n\n# Converting the list of predictions to a NumPy array\ntest_preds = np.array(test_preds)\ntest_preds\n","metadata":{"papermill":{"duration":2.366554,"end_time":"2024-01-18T09:25:12.391966","exception":false,"start_time":"2024-01-18T09:25:10.025412","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## üìä Generating Submission CSV with Class Probabilities üìÑ","metadata":{}},{"cell_type":"markdown","source":"```python\n# Cell Title: üìä Generating Submission CSV with Class Probabilities üìÑ\n\n# Reading the sample submission dataframe\nsubmission = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\n\n# List of class labels\nlabels = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n\n# Adding columns for class probabilities based on the aggregated test predictions\nfor i in range(len(labels)):\n    submission[f'{labels[i]}_vote'] = test_preds[:, i]\n\n# Saving the submission dataframe to a CSV file\nsubmission.to_csv(\"submission.csv\", index=None)\n\n# Displaying the first few rows of the submission dataframe with added columns\nsubmission.head()\n```\n\n**Explanation:**\n\n1. `submission = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")`: Reads the sample submission CSV file into a Pandas DataFrame (`submission`). üìä [Pandas read_csv Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)\n\n2. `labels = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']`: Defines a list of class labels corresponding to the target classes.\n\n3. Adding Class Probability Columns:\n   - Loops over each class label.\n   - Adds a new column to the submission dataframe for each class, containing the corresponding class probabilities from the aggregated test predictions.\n\n4. `submission.to_csv(\"submission.csv\", index=None)`: Saves the modified submission dataframe to a CSV file named \"submission.csv\" without including the index column. üìÑ [Pandas to_csv Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html)\n\n5. `submission.head()`: Displays the first few rows of the modified submission dataframe with added class probability columns. üßê [Pandas DataFrame head Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html)\n\nAugments the original submission dataframe with additional columns containing the class probabilities for each class based on the aggregated test predictions. The resulting dataframe is then saved to a CSV file for submission.","metadata":{}},{"cell_type":"code","source":"# Reading the sample submission dataframe\nsubmission = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\n\n# List of class labels\nlabels = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n\n# Adding columns for class probabilities based on the aggregated test predictions\nfor i in range(len(labels)):\n    submission[f'{labels[i]}_vote'] = test_preds[:, i]\n\n# Saving the submission dataframe to a CSV file\nsubmission.to_csv(\"submission.csv\", index=None)\n\n# Displaying the first few rows of the submission dataframe with added columns\nsubmission.head()\n","metadata":{"papermill":{"duration":0.027736,"end_time":"2024-01-18T09:25:12.431453","exception":false,"start_time":"2024-01-18T09:25:12.403717","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Explore More! üëÄ\n\nI appreciate you taking the time to explore this notebook! If you found it insightful or helpful in any way, feel free to delve into more of my projects on my profile.\n\nüëâ [Check out My Profile](https://www.kaggle.com/zulqarnainali) üëà\n\n## Share Your Thoughts! üó£Ô∏è\nYour feedback is invaluable! If you have any comments, questions, or ideas to share, I'm eager to hear from you. Your insights contribute significantly to my ongoing improvement.\n\nüì¨ Drop me an email at: [zulqar445ali@gmail.com](mailto:zulqar445ali@gmail.com)\n\nI want to express my gratitude for your time and engagement. Your support motivates me to create more meaningful content.\n\nHappy coding, and I wish you the best in all your data science endeavors! üöÄ","metadata":{}}]}