{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7392733,"sourceType":"datasetVersion","datasetId":4297749},{"sourceId":7465251,"sourceType":"datasetVersion","datasetId":4317718},{"sourceId":7517324,"sourceType":"datasetVersion","datasetId":4378712}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About this notebook\n\nThis is a modifyed version of this amazing [notebook](https://www.kaggle.com/code/nischaydnk/hms-submission-1d-eegnet-pipeline-lightning) shared by @nischaydnk.\n\nAs stated [here](https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/477498), adding ` 0.166666667` to the targets will reduce the CV/LB gap.\n\nI also used the data preprocessing from this [notebook](https://www.kaggle.com/code/alejopaullier/hms-wavenet-pytorch-train/notebook).\n\nChanging the optimizer to [Adan](https://github.com/lucidrains/Adan-pytorch) improved the CV score.\n\nThis model only uses only 8 channels from raw EEG signals as shared by [Chris Deotte](https://www.kaggle.com/code/cdeotte/how-to-make-spectrogram-from-eeg/notebook).\nI'll do a lot of experimentation in this notebook, change the archtecture of the model, add crossentropy loss and play with data to see if their improve our score.\n\n**If you find this notebook usefull please upvote and stay tuned**\n\n## Version1\n\n* `CV=0.5162483866506282` `LB=0.48`\n\n### Hyperparams\n\n```\n\n   scheduler='CosineAnnealingWarmRestarts' \n    print_freq=50\n    num_workers = 1\n    model_name = 'resnet501d_lstm'\n    optimizer='Adam'\n    epochs = 20\n    eps = 1e-6\n    lr = 8e-3\n    min_lr = 1e-6\n    in_channels = 1\n    batch_size = 64\n    weight_decay = 1e-3\n    seed = 2024\n```\n\n## Version 2 \n\n### Hyperparams\n```\n\n   scheduler='CosineAnnealingWarmRestarts' \n    print_freq=50\n    num_workers = 1\n    model_name = 'resnet501d_lstm'\n    optimizer='Adam'\n    epochs = 20\n    eps = 1e-6\n    lr = 8e-3\n    min_lr = 1e-6\n    in_channels = 1\n    batch_size = 32\n    weight_decay = 1e-2\n    max_grad_norm = 1e7\n    seed = 2024\n```\n* In this version, the model evaluate the montages separtely like this [notebook](https://www.kaggle.com/code/alejopaullier/hms-wavenet-pytorch-train).\n* `CV=0.5162483866506282` `LB=0.55`\n\n\n## Version 3\n\n* Added sequence pooling for the rrnn output\n\nThe Sequence Pooling Layer is used instead of a [CLASS] token in CCTs. This layer introduces a learnable weight which allows the model to perform a weighted average over all the sequences instead of taking output from one special [CLASS] token or from simple average across all the sequences.\nTaken from this [notebook](https://www.kaggle.com/code/utsavnandi/compact-convolutional-transformer-using-pytorch).\n```\nclass SeqPool(nn.Module):\n    def __init__(self, emb_dim=192):\n        super().__init__()\n        self.dense = nn.Linear(emb_dim, 1)\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, x):\n        bs, seq_len, emb_dim = x.shape\n        identity = x\n        x = self.dense(x)\n        x = x.permute(0, 2, 1)\n        x = self.softmax(x)\n        x = x @ identity\n        x = x.reshape(x.shape[0], -1)\n        return x\n```\n\n### Hyperparams\n```\n\n   scheduler='CosineAnnealingWarmRestarts' \n    print_freq=50\n    num_workers = 1\n    model_name = 'resnet501d_gru'\n    optimizer='Adan'\n    epochs = 20\n    eps = 1e-6\n    lr = 8e-3\n    min_lr = 1e-6\n    in_channels = 8\n    batch_size = 64\n    weight_decay = 1e-2\n    max_grad_norm = 1e7\n    seed = 2024\n```\n\n## Version 4\n\nI divided my data set into two population and trained a two stage model from version1. I took the idea from this [notebook](https://www.kaggle.com/code/seanbearden/effnetb0-2-pop-model-train-twice-lb-0-39/notebook).\n\n### Hyperparams\n\n```\n\n    scheduler='CosineAnnealingWarmRestarts' \n    print_freq=50\n    num_workers = 1\n    model_name = 'resnet501d_gru'\n    optimizer='Adan'\n    epochs = 20\n    eps = 1e-6\n    lr = 8e-3\n    min_lr = 1e-6\n    in_channels = 8\n    batch_size = 64\n    weight_decay = 1e-2\n    max_grad_norm = 1e7\n    seed = 2024\n```\n\n## Version 5\n\n* Changed the CV scheme as state [here](https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/477461).\n* Forget to `optimizer.zero_grad()` in the previous version.\n* `CV=0.5607182806499342` `LB=0.44`\n\n### Hyperparams\n\n```\n\n    scheduler='CosineAnnealingWarmRestarts' \n    print_freq=50\n    num_workers = 1\n    model_name = 'resnet501d_gru'\n    optimizer='Adan'\n    stage1_epochs = 10\n    stage2_epochs = 20\n    eps = 1e-6\n    lr = 8e-3\n    min_lr = 1e-6\n    in_channels = 8\n    batch_size = 64\n    weight_decay = 1e-2\n    max_grad_norm = 1e7\n    seed = 2024\n    \n```\n\n## Version 6\n\n* I changed the CV sheme, first stage train on all data second stage train on data with `total_evaluators >= 10`\n\n### Hyperparams\n\n```\n\n    scheduler='OneCycleLR' \n    print_freq=50\n    num_workers = 1\n    model_name = 'resnet501d_gru'\n    optimizer='Adan'\n    stage1_epochs = 10\n    stage2_epochs = 20\n    eps = 1e-6\n    lr = 1e-3\n    min_lr = 1e-6\n    in_channels = 8\n    batch_size = 100\n    weight_decay = 1e-2\n    max_grad_norm = 1e7\n    seed = 2024\n    \n```\n\n## Version 7\n\n* I changed the CV sheme, first stage train on all data second stage train on train_pop2\n\n### Hyperparams\n\n```\n\n    scheduler='OneCycleLR' \n    print_freq=50\n    num_workers = 1\n    model_name = 'resnet501d_gru'\n    optimizer='Adan'\n    stage1_epochs = 10\n    stage2_epochs = 10\n    eps = 1e-6\n    lr = 1e-3\n    min_lr = 1e-6\n    in_channels = 8\n    batch_size = 64\n    weight_decay = 1e-2\n    max_grad_norm = 1e7\n    seed = 2024\n    \n```\n\n## Version 8\n\n* Apply downsampling of factor five\n* `Stage1 LB=0.6` `Stage2 LB=0.59`\n\n### Hyperparams\n\n```\n\n    scheduler='CosineAnnealingWarmRestarts' \n    print_freq=50\n    num_workers = 1\n    model_name = 'resnet501d_gru'\n    optimizer='Adan'\n    stage1_epochs = 10\n    stage2_epochs = 20\n    eps = 1e-6\n    lr = 1e-3\n    min_lr = 1e-6\n    in_channels = 8\n    batch_size = 64\n    weight_decay = 1e-2\n    downsample_factor = 5\n    max_grad_norm = 1e7\n    seed = 2024\n    \n```\n\n## Version9\n\n* Stage2 votes >= 5\n* Downsampling factor 5\n\n\n### Hyperparams\n\n\n```\n\n    scheduler='CosineAnnealingWarmRestarts' \n    print_freq=50\n    num_workers = 1\n    model_name = 'resnet501d_gru'\n    optimizer='Adan'\n    stage1_epochs = 10\n    stage2_epochs = 10\n    eps = 1e-6\n    lr = 1e-3\n    min_lr = 1e-6\n    in_channels = 8\n    batch_size = 64\n    weight_decay = 1e-2\n    downsample_factor = 5\n    max_grad_norm = 1e7\n    seed = 2024\n    \n```","metadata":{}},{"cell_type":"markdown","source":"# Directory settings","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# directory settings\n# ====================================================\n\nimport os\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    \nPOP_2_DIR = OUTPUT_DIR + 'pop_2_weight_oof/'\nif not os.path.exists(POP_2_DIR):\n    os.makedirs(POP_2_DIR)\n    \nPOP_1_DIR = OUTPUT_DIR + 'pop_1_weight_oof/'\nif not os.path.exists(POP_1_DIR):\n    os.makedirs(POP_1_DIR)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:23:57.853751Z","iopub.execute_input":"2024-03-03T03:23:57.854281Z","iopub.status.idle":"2024-03-03T03:23:57.865251Z","shell.execute_reply.started":"2024-03-03T03:23:57.854242Z","shell.execute_reply":"2024-03-03T03:23:57.863062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nfrom glob import glob\nimport sys\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom typing import Dict, List\nfrom scipy.stats import entropy\nfrom scipy.signal import butter, lfilter, freqz\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nsys.path.append('/kaggle/input/kaggle-kl-div')\nfrom kaggle_kl_div import score\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom tqdm.auto import tqdm\nfrom functools import partial\nimport cv2\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport pytorch_lightning as pl\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, CosineAnnealingLR, CosineAnnealingWarmRestarts\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchvision.transforms import v2\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.model_selection import train_test_split\nimport albumentations as A\nfrom albumentations import (Compose, Normalize, Resize, RandomResizedCrop, HorizontalFlip, VerticalFlip, ShiftScaleRotate, Transpose)\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\nimport timm\nimport warnings \nwarnings.filterwarnings('ignore')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nfrom matplotlib import pyplot as plt\nimport joblib\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\nVERSION=9","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:23:58.380548Z","iopub.execute_input":"2024-03-03T03:23:58.381052Z","iopub.status.idle":"2024-03-03T03:23:58.401566Z","shell.execute_reply.started":"2024-03-03T03:23:58.381011Z","shell.execute_reply":"2024-03-03T03:23:58.39961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\n\nclass CFG:\n    wandb = False\n    debug = False\n    train=True\n    apex=True\n    visualize=True\n    stage1_pop1=True\n    stage2_pop2=False\n    scheduler='CosineAnnealingWarmRestarts' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts','OneCycleLR']\n    # CosineAnnealingLR params\n    cosanneal_params={\n        'T_max':6,\n        'eta_min':1e-5,\n        'last_epoch':-1\n    }\n    #ReduceLROnPlateau params\n    reduce_params={\n        'mode':'min',\n        'factor':0.2,\n        'patience':4,\n        'eps':1e-6,\n        'verbose':True\n    }\n    # CosineAnnealingWarmRestarts params\n    cosanneal_res_params={\n        'T_0':20,\n        'eta_min':1e-6,\n        'T_mult':1,\n        'last_epoch':-1\n    }\n    print_freq=50\n    num_workers = 1\n    model_name = 'resnet1d_gru'\n    optimizer='Adan'\n    epochs = 10\n    factor = 0.9\n    patience = 2\n    eps = 1e-6\n    lr = 1e-3\n    min_lr = 1e-6\n    in_channels = 8\n    batch_size = 64\n    weight_decay = 1e-2\n    batch_scheduler = True\n    gradient_accumulation_steps = 1\n    max_grad_norm = 1e7\n    seed = 2024\n    target_cols = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n    target_size = 6\n    pred_cols = ['pred_seizure_vote', 'pred_lpd_vote', 'pred_gpd_vote', 'pred_lrda_vote', 'pred_grda_vote', 'pred_other_vote']\n    n_fold = 5\n    trn_fold = [0, 1, 2, 3, 4]\n    PATH = '/kaggle/input/hms-harmful-brain-activity-classification/'\n    data_root = \"/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/\"\n    raw_eeg_path = \"/kaggle/input/brain-eegs/eegs.npy\"","metadata":{"execution":{"iopub.status.busy":"2024-03-03T02:56:29.620294Z","iopub.execute_input":"2024-03-03T02:56:29.620778Z","iopub.status.idle":"2024-03-03T02:56:29.636227Z","shell.execute_reply.started":"2024-03-03T02:56:29.620742Z","shell.execute_reply":"2024-03-03T02:56:29.634325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def init_logger(log_file=OUTPUT_DIR+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\ndef get_score(preds, targets):\n    oof = pd.DataFrame(preds.copy())\n    oof['id'] = np.arange(len(oof))\n\n    true = pd.DataFrame(targets.copy())\n    true['id'] = np.arange(len(true))\n\n    cv = score(solution=true, submission=oof, row_id_column_name='id')\n    return cv\n\ndef butter_bandpass(lowcut, highcut, fs, order=5):\n    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n\ndef butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n    y = lfilter(b, a, data)\n    return y\n\n\ndef denoise_filter(x):\n    # Sample rate and desired cutoff frequencies (in Hz).\n    fs = 200.0\n    lowcut = 1.0\n    highcut = 25.0\n    \n    # Filter a noisy signal.\n    T = 50\n    nsamples = T * fs\n    t = np.arange(0, nsamples) / fs\n    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=6)\n    y = (y + np.roll(y,-1)+ np.roll(y,-2)+ np.roll(y,-3))/4\n    y = y[0:-1:4]\n    \n    return y\n\nclass KLDivLossWithLogits(nn.KLDivLoss):\n\n    def __init__(self):\n        super().__init__(reduction=\"batchmean\")\n\n    def forward(self, y, t):\n        y = nn.functional.log_softmax(y,  dim=1)\n        loss = super().forward(y, t)\n\n        return loss\n\n\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    \ntarget_preds = [x + \"_pred\" for x in ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']]\nlabel_to_num = {'Seizure': 0, 'LPD': 1, 'GPD': 2, 'LRDA': 3, 'GRDA': 4, 'Other':5}\nnum_to_label = {v: k for k, v in label_to_num.items()}    \nseed_torch(seed=CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:30:02.092895Z","iopub.execute_input":"2024-03-02T02:30:02.093161Z","iopub.status.idle":"2024-03-02T02:30:02.11603Z","shell.execute_reply.started":"2024-03-02T02:30:02.093137Z","shell.execute_reply":"2024-03-02T02:30:02.115266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load train data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\nTARGETS = train.columns[-6:]\nprint('Train shape:', train.shape )\nprint('Targets', list(TARGETS))\n\ntrain['total_evaluators'] = train[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].sum(axis=1)\n\ntrain_uniq = train.drop_duplicates(subset=['eeg_id'] + list(TARGETS))\n\nprint(f'There are {train.patient_id.nunique()} patients in the training data.')\nprint(f'There are {train.eeg_id.nunique()} EEG IDs in the training data.')\nprint(f'There are {train_uniq.shape[0]} unique eeg_id + votes in the training data.')\n\ntrain_uniq.eeg_id.value_counts().value_counts().plot(kind='bar', title=f'Distribution of Count of EEG w Unique Vote: '\n                                                                    f'{train_uniq.shape[0]} examples');\n\ndel train_uniq\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:30:02.11702Z","iopub.execute_input":"2024-03-02T02:30:02.117279Z","iopub.status.idle":"2024-03-02T02:30:03.078437Z","shell.execute_reply.started":"2024-03-02T02:30:02.117256Z","shell.execute_reply":"2024-03-02T02:30:03.077379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.hist(train['total_evaluators'], bins=10, color='blue', edgecolor='black')\nplt.title('Histogram of Total Evaluators')\nplt.xlabel('Total Evaluators')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:30:03.079715Z","iopub.execute_input":"2024-03-02T02:30:03.080073Z","iopub.status.idle":"2024-03-02T02:30:03.389879Z","shell.execute_reply.started":"2024-03-02T02:30:03.080028Z","shell.execute_reply":"2024-03-02T02:30:03.388891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eeg_df = pd.read_parquet(CFG.data_root + \"100261680.parquet\")\neeg_features = eeg_df.columns\nprint(f'There are {len(eeg_features)} raw eeg features')\nprint(list(eeg_features))\neeg_features = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\nfeature_to_index = {x:y for x,y in zip(eeg_features, range(len(eeg_features)))}\n\ndel eeg_df\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:30:03.391208Z","iopub.execute_input":"2024-03-02T02:30:03.39159Z","iopub.status.idle":"2024-03-02T02:30:03.911085Z","shell.execute_reply.started":"2024-03-02T02:30:03.391553Z","shell.execute_reply":"2024-03-02T02:30:03.910058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nall_eeg_specs = np.load('/kaggle/input/eeg-spectrogram-by-lead-id-unique/eeg_specs.npy',allow_pickle=True).item()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:30:03.912218Z","iopub.execute_input":"2024-03-02T02:30:03.912502Z","iopub.status.idle":"2024-03-02T02:31:28.639269Z","shell.execute_reply.started":"2024-03-02T02:30:03.912462Z","shell.execute_reply":"2024-03-02T02:31:28.63824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deduplicate Train EEG Id","metadata":{}},{"cell_type":"code","source":"train = train[train['label_id'].isin(all_eeg_specs.keys())].copy()\n\ny_data = train[TARGETS].values +  0.166666667 # Regularization value\ny_data = y_data / y_data.sum(axis=1,keepdims=True)\ntrain[TARGETS] = y_data\n\ntrain['target'] = train['expert_consensus']\ntrain = train.reset_index(drop=True)\n\n\n\nplt.figure(figsize=(10, 6))\nplt.hist(train['total_evaluators'], bins=10, color='blue', edgecolor='black')\nplt.title('Histogram of Total Evaluators')\nplt.xlabel('Total Evaluators')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()\n\ndel all_eeg_specs\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:31:28.643383Z","iopub.execute_input":"2024-03-02T02:31:28.643698Z","iopub.status.idle":"2024-03-02T02:31:29.179647Z","shell.execute_reply.started":"2024-03-02T02:31:28.643671Z","shell.execute_reply":"2024-03-02T02:31:29.178686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV Scheme","metadata":{}},{"cell_type":"code","source":"gkf = GroupKFold(n_splits=CFG.n_fold)\n\ntrain[\"fold\"] = -1\n\nfor fold_id, (_, val_idx) in enumerate(\n    gkf.split(train, y=train[\"target\"], groups=train[\"patient_id\"])\n):\n    train.loc[val_idx, \"fold\"] = fold_id","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:31:29.18107Z","iopub.execute_input":"2024-03-02T02:31:29.181461Z","iopub.status.idle":"2024-03-02T02:31:29.207525Z","shell.execute_reply.started":"2024-03-02T02:31:29.181424Z","shell.execute_reply":"2024-03-02T02:31:29.206783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parquet to EEG Signals Numpy Processing","metadata":{}},{"cell_type":"code","source":"def eeg_from_parquet(parquet_path: str, display: bool = False) -> np.ndarray:\n    \"\"\"\n    This function reads a parquet file and extracts the middle 50 seconds of readings. Then it fills NaN values\n    with the mean value (ignoring NaNs).\n    :param parquet_path: path to parquet file.\n    :param display: whether to display EEG plots or not.\n    :return data: np.array of shape  (time_steps, eeg_features) -> (10_000, 8)\n    \"\"\"\n    # === Extract middle 50 seconds ===\n    eeg = pd.read_parquet(parquet_path, columns=eeg_features)\n    rows = len(eeg)\n    offset = (rows - 10_000) // 2 # 50 * 200 = 10_000\n    eeg = eeg.iloc[offset:offset+10_000] # middle 50 seconds, has the same amount of readings to left and right\n    if display: \n        plt.figure(figsize=(10,5))\n        offset = 0\n    # === Convert to numpy ===\n    data = np.zeros((10_000, len(eeg_features))) # create placeholder of same shape with zeros\n    for index, feature in enumerate(eeg_features):\n        x = eeg[feature].values.astype('float32') # convert to float32\n        mean = np.nanmean(x) # arithmetic mean along the specified axis, ignoring NaNs\n        nan_percentage = np.isnan(x).mean() # percentage of NaN values in feature\n        # === Fill nan values ===\n        if nan_percentage < 1: # if some values are nan, but not all\n            x = np.nan_to_num(x, nan=mean)\n        else: # if all values are nan\n            x[:] = 0\n        data[:, index] = x\n        if display: \n            if index != 0:\n                offset += x.max()\n            plt.plot(range(10_000), x-offset, label=feature)\n            offset -= x.min()\n    if display:\n        plt.legend()\n        name = parquet_path.split('/')[-1].split('.')[0]\n        plt.yticks([])\n        plt.title(f'EEG {name}',size=16)\n        plt.show()    \n    return data","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:31:29.235027Z","iopub.execute_input":"2024-03-02T02:31:29.235254Z","iopub.status.idle":"2024-03-02T02:31:29.245334Z","shell.execute_reply.started":"2024-03-02T02:31:29.235233Z","shell.execute_reply":"2024-03-02T02:31:29.244485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nCREATE_EEGS = False\nall_eegs = {}\nvisualize = 1\neeg_paths = glob(CFG.data_root + \"*.parquet\")\neeg_ids = train.eeg_id.unique()\n\nfor i, eeg_id in tqdm(enumerate(eeg_ids)):  \n    # Save EEG to Python dictionary of numpy arrays\n    eeg_path = CFG.data_root + str(eeg_id) + \".parquet\"\n    data = eeg_from_parquet(eeg_path, display=i<visualize)              \n    all_eegs[eeg_id] = data\n    \n    if i == visualize:\n        if CREATE_EEGS:\n            print(f'Processing {train_df.eeg_id.nunique()} eeg parquets... ',end='')\n        else:\n            print(f'Reading {len(eeg_ids)} eeg NumPys from disk.')\n            break\n            \nif CREATE_EEGS: \n    np.save('eegs', all_eegs)\nelse:\n    all_eegs = np.load('/kaggle/input/brain-eegs/eegs.npy',allow_pickle=True).item()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:31:29.24654Z","iopub.execute_input":"2024-03-02T02:31:29.246832Z","iopub.status.idle":"2024-03-02T02:33:00.098545Z","shell.execute_reply.started":"2024-03-02T02:31:29.246801Z","shell.execute_reply":"2024-03-02T02:33:00.097522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"from scipy.signal import butter, lfilter\n\ndef quantize_data(data, classes):\n    mu_x = mu_law_encoding(data, classes)\n    return mu_x#quantized\n\ndef mu_law_encoding(data, mu):\n    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n    return mu_x\n\ndef mu_law_expansion(data, mu):\n    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n    return s\n\ndef butter_lowpass_filter(data, cutoff_freq=20, sampling_rate=200, order=4):\n    nyquist = 0.5 * sampling_rate\n    normal_cutoff = cutoff_freq / nyquist\n    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n    filtered_data = lfilter(b, a, data, axis=0)\n    return filtered_data\n\nclass EEGDataset(Dataset):\n    def __init__(\n        self, df: pd.DataFrame, config, mode: str = 'train',\n        eegs: Dict[int, np.ndarray] = all_eegs, downsample: int = None\n    ): \n        self.df = df\n        self.config = config\n        self.mode = mode\n        self.eegs = eegs\n        self.downsample = downsample\n        \n    def __len__(self):\n        \"\"\"\n        Length of dataset.\n        \"\"\"\n        return len(self.df)\n        \n    def __getitem__(self, index):\n        \"\"\"\n        Get one item.\n        \"\"\"\n        X, y_prob = self.__data_generation(index)\n        if self.downsample is not None:\n            X = X[::self.downsample,:]\n        output = {\n            \"eeg\": torch.tensor(X, dtype=torch.float32),\n            \"labels\": torch.tensor(y_prob, dtype=torch.float32)\n        }\n        return output\n                        \n    def __data_generation(self, index):\n        row = self.df.iloc[index]\n        X = np.zeros((10_000, 8), dtype='float32')\n        y = np.zeros(6, dtype='float32')\n        data = self.eegs[row.eeg_id]\n\n        # === Feature engineering ===\n        X[:,0] = data[:,feature_to_index['Fp1']] - data[:,feature_to_index['T3']]\n        X[:,1] = data[:,feature_to_index['T3']] - data[:,feature_to_index['O1']]\n\n        X[:,2] = data[:,feature_to_index['Fp1']] - data[:,feature_to_index['C3']]\n        X[:,3] = data[:,feature_to_index['C3']] - data[:,feature_to_index['O1']]\n\n        X[:,4] = data[:,feature_to_index['Fp2']] - data[:,feature_to_index['C4']]\n        X[:,5] = data[:,feature_to_index['C4']] - data[:,feature_to_index['O2']]\n\n        X[:,6] = data[:,feature_to_index['Fp2']] - data[:,feature_to_index['T4']]\n        X[:,7] = data[:,feature_to_index['T4']] - data[:,feature_to_index['O2']]\n\n        # === Standarize ===\n        X = np.clip(X,-1024, 1024)\n        X = np.nan_to_num(X, nan=0) / 32.0\n\n        # === Butter Low-pass Filter ===\n        X = butter_lowpass_filter(X)\n        if self.mode != 'test':\n            y_prob = row[self.config.target_cols].values.astype(np.float32)\n        return X, y_prob","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:24:05.354235Z","iopub.execute_input":"2024-03-03T03:24:05.354707Z","iopub.status.idle":"2024-03-03T03:24:05.535255Z","shell.execute_reply.started":"2024-03-03T03:24:05.354669Z","shell.execute_reply":"2024-03-03T03:24:05.533238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frequencies = [1,2,4,8,16][::-1] # frequencies in Hz\nx = [all_eegs[eeg_ids[0]][:,0]] # select one EEG feature\n\nfor frequency in frequencies:\n    x.append(butter_lowpass_filter(x[0], cutoff_freq=frequency))\n\nplt.figure(figsize=(12,8))\nplt.plot(range(10_000), x[0], label='without filter')\nfor k in range(1,len(x)):\n    plt.plot(range(10_000),x[k]-k*(x[0].max()-x[0].min()), label=f'with filter {frequencies[k-1]}Hz')\n\nplt.legend()\nplt.yticks([])\nplt.title('Butter Low-Pass Filter Examples',size=18)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:33:00.119986Z","iopub.execute_input":"2024-03-02T02:33:00.120314Z","iopub.status.idle":"2024-03-02T02:33:00.719782Z","shell.execute_reply.started":"2024-03-02T02:33:00.120281Z","shell.execute_reply":"2024-03-02T02:33:00.718884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = EEGDataset(train, CFG, mode=\"train\")\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=CFG.batch_size,\n    shuffle=False,\n    num_workers=CFG.num_workers, pin_memory=True, drop_last=True\n)\noutput = train_dataset[0]\nX, y = output[\"eeg\"], output[\"labels\"]\nprint(f\"X shape: {X.shape}\")\nprint(f\"y shape: {y.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:33:00.7209Z","iopub.execute_input":"2024-03-02T02:33:00.721186Z","iopub.status.idle":"2024-03-02T02:33:00.754995Z","shell.execute_reply.started":"2024-03-02T02:33:00.721161Z","shell.execute_reply":"2024-03-02T02:33:00.754052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.visualize:\n    for batch in train_loader:\n        X = batch.pop(\"eeg\")\n        y = batch.pop(\"labels\")\n        for item in range(4):\n            plt.figure(figsize=(20,4))\n            offset = 0\n            for col in range(X.shape[-1]):\n                if col != 0:\n                    offset -= X[item,:,col].min()\n                plt.plot(range(10000), X[item,:,col]+offset,label=f'feature {col+1}')\n                offset += X[item,:,col].max()\n            tt = f'{y[col][0]:0.1f}'\n            for t in y[col][1:]:\n                tt += f', {t:0.1f}'\n            plt.title(f'EEG_Id = {eeg_ids[item]}\\nTarget = {tt}',size=14)\n            plt.legend()\n            plt.show()\n        break","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:33:36.266345Z","iopub.execute_input":"2024-03-02T02:33:36.26724Z","iopub.status.idle":"2024-03-02T02:33:39.627634Z","shell.execute_reply.started":"2024-03-02T02:33:36.267204Z","shell.execute_reply":"2024-03-02T02:33:39.626492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class ResNet_1D_Block(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, downsampling):\n        super(ResNet_1D_Block, self).__init__()\n        self.bn1 = nn.BatchNorm1d(num_features=in_channels)\n        self.relu = nn.ReLU(inplace=False)\n        self.dropout = nn.Dropout(p=0.0, inplace=False)\n        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n                               stride=stride, padding=padding, bias=False)\n        self.bn2 = nn.BatchNorm1d(num_features=out_channels)\n        self.conv2 = nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size,\n                               stride=stride, padding=padding, bias=False)\n        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n        self.downsampling = downsampling\n\n    def forward(self, x):\n        identity = x\n\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.conv1(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.conv2(out)\n\n        out = self.maxpool(out)\n        identity = self.downsampling(x)\n\n        out += identity\n        return out\n\n\nclass EEGNet(nn.Module):\n\n    def __init__(self, kernels, in_channels=20, fixed_kernel_size=17, num_classes=6):\n        super(EEGNet, self).__init__()\n        self.kernels = kernels\n        self.planes = 24\n        self.parallel_conv = nn.ModuleList()\n        self.in_channels = in_channels\n        \n        for i, kernel_size in enumerate(list(self.kernels)):\n            sep_conv = nn.Conv1d(in_channels=in_channels, out_channels=self.planes, kernel_size=(kernel_size),\n                               stride=1, padding=0, bias=False,)\n            self.parallel_conv.append(sep_conv)\n\n        self.bn1 = nn.BatchNorm1d(num_features=self.planes)\n        self.relu = nn.ReLU(inplace=False)\n        self.conv1 = nn.Conv1d(in_channels=self.planes, out_channels=self.planes, kernel_size=fixed_kernel_size,\n                               stride=2, padding=2, bias=False)\n        self.block = self._make_resnet_layer(kernel_size=fixed_kernel_size, stride=1, padding=fixed_kernel_size//2)\n        self.bn2 = nn.BatchNorm1d(num_features=self.planes)\n        self.avgpool = nn.AvgPool1d(kernel_size=6, stride=6, padding=2)\n        self.rnn = nn.GRU(input_size=self.in_channels, hidden_size=128, num_layers=1, bidirectional=True)\n        self.fc = nn.Linear(in_features=424, out_features=num_classes)\n\n    def _make_resnet_layer(self, kernel_size, stride, blocks=9, padding=0):\n        layers = []\n        downsample = None\n        base_width = self.planes\n\n        for i in range(blocks):\n            downsampling = nn.Sequential(\n                    nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n                )\n            layers.append(ResNet_1D_Block(in_channels=self.planes, out_channels=self.planes, kernel_size=kernel_size,\n                                       stride=stride, padding=padding, downsampling=downsampling))\n\n        return nn.Sequential(*layers)\n    def extract_features(self, x):\n        x = x.permute(0, 2, 1)\n        out_sep = []\n\n        for i in range(len(self.kernels)):\n            sep = self.parallel_conv[i](x)\n            out_sep.append(sep)\n\n        out = torch.cat(out_sep, dim=2)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv1(out)  \n\n        out = self.block(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.avgpool(out)  \n        \n        out = out.reshape(out.shape[0], -1)  \n        rnn_out, _ = self.rnn(x.permute(0, 2, 1))\n        new_rnn_h = rnn_out[:, -1, :]  \n        \n        \n\n        new_out = torch.cat([out, new_rnn_h], dim=1) \n        return new_out\n    \n    def forward(self, x):\n        new_out = self.extract_features(x)\n        result = self.fc(new_out)  \n\n        return result","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:24:13.153867Z","iopub.execute_input":"2024-03-03T03:24:13.154305Z","iopub.status.idle":"2024-03-03T03:24:13.187149Z","shell.execute_reply.started":"2024-03-03T03:24:13.154271Z","shell.execute_reply":"2024-03-03T03:24:13.185097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\niot = torch.randn(2, 10000, 8)#.cuda()\nmodel = EEGNet(kernels=[3,5,7,9], in_channels=CFG.in_channels, fixed_kernel_size=5, num_classes=CFG.target_size)\noutput = model(iot)\nprint(output.shape)\n\ndel iot, model\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T03:24:13.353455Z","iopub.execute_input":"2024-03-03T03:24:13.353886Z","iopub.status.idle":"2024-03-03T03:24:14.218963Z","shell.execute_reply.started":"2024-03-03T03:24:13.353853Z","shell.execute_reply":"2024-03-03T03:24:14.217962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport torch\nfrom torch.optim.optimizer import Optimizer\n\n\nclass Adan(Optimizer):\n    \"\"\"\n    Implements a pytorch variant of Adan\n    Adan was proposed in\n    Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models[J]. arXiv preprint arXiv:2208.06677, 2022.\n    https://arxiv.org/abs/2208.06677\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining parameter groups.\n        lr (float, optional): learning rate. (default: 1e-3)\n        betas (Tuple[float, float, flot], optional): coefficients used for computing \n            running averages of gradient and its norm. (default: (0.98, 0.92, 0.99))\n        eps (float, optional): term added to the denominator to improve \n            numerical stability. (default: 1e-8)\n        weight_decay (float, optional): decoupled weight decay (L2 penalty) (default: 0)\n        max_grad_norm (float, optional): value used to clip \n            global grad norm (default: 0.0 no clip)\n        no_prox (bool): how to perform the decoupled weight decay (default: False)\n    \"\"\"\n\n    def __init__(self, params, lr=1e-3, betas=(0.98, 0.92, 0.99), eps=1e-8,\n                 weight_decay=0.2, max_grad_norm=0.0, no_prox=False):\n        if not 0.0 <= max_grad_norm:\n            raise ValueError(\"Invalid Max grad norm: {}\".format(max_grad_norm))\n        if not 0.0 <= lr:\n            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n        if not 0.0 <= betas[2] < 1.0:\n            raise ValueError(\"Invalid beta parameter at index 2: {}\".format(betas[2]))\n        defaults = dict(lr=lr, betas=betas, eps=eps,\n                        weight_decay=weight_decay,\n                        max_grad_norm=max_grad_norm, no_prox=no_prox)\n        super(Adan, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(Adan, self).__setstate__(state)\n        for group in self.param_groups:\n            group.setdefault('no_prox', False)\n\n    @torch.no_grad()\n    def restart_opt(self):\n        for group in self.param_groups:\n            group['step'] = 0\n            for p in group['params']:\n                if p.requires_grad:\n                    state = self.state[p]\n                    # State initialization\n\n                    # Exponential moving average of gradient values\n                    state['exp_avg'] = torch.zeros_like(p)\n                    # Exponential moving average of squared gradient values\n                    state['exp_avg_sq'] = torch.zeros_like(p)\n                    # Exponential moving average of gradient difference\n                    state['exp_avg_diff'] = torch.zeros_like(p)\n\n    @torch.no_grad()\n    def step(self):\n        \"\"\"\n            Performs a single optimization step.\n        \"\"\"\n        if self.defaults['max_grad_norm'] > 0:\n            device = self.param_groups[0]['params'][0].device\n            global_grad_norm = torch.zeros(1, device=device)\n\n            max_grad_norm = torch.tensor(self.defaults['max_grad_norm'], device=device)\n            for group in self.param_groups:\n\n                for p in group['params']:\n                    if p.grad is not None:\n                        grad = p.grad\n                        global_grad_norm.add_(grad.pow(2).sum())\n\n            global_grad_norm = torch.sqrt(global_grad_norm)\n\n            clip_global_grad_norm = torch.clamp(max_grad_norm / (global_grad_norm + group['eps']), max=1.0)\n        else:\n            clip_global_grad_norm = 1.0\n\n        for group in self.param_groups:\n            beta1, beta2, beta3 = group['betas']\n            # assume same step across group now to simplify things\n            # per parameter step can be easily support by making it tensor, or pass list into kernel\n            if 'step' in group:\n                group['step'] += 1\n            else:\n                group['step'] = 1\n\n            bias_correction1 = 1.0 - beta1 ** group['step']\n\n            bias_correction2 = 1.0 - beta2 ** group['step']\n\n            bias_correction3 = 1.0 - beta3 ** group['step']\n\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n\n                state = self.state[p]\n                if len(state) == 0:\n                    state['exp_avg'] = torch.zeros_like(p)\n                    state['exp_avg_sq'] = torch.zeros_like(p)\n                    state['exp_avg_diff'] = torch.zeros_like(p)\n\n                grad = p.grad.mul_(clip_global_grad_norm)\n                if 'pre_grad' not in state or group['step'] == 1:\n                    state['pre_grad'] = grad\n\n                copy_grad = grad.clone()\n\n                exp_avg, exp_avg_sq, exp_avg_diff = state['exp_avg'], state['exp_avg_sq'], state['exp_avg_diff']\n                diff = grad - state['pre_grad']\n\n                update = grad + beta2 * diff\n                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)  # m_t\n                exp_avg_diff.mul_(beta2).add_(diff, alpha=1 - beta2)  # diff_t\n                exp_avg_sq.mul_(beta3).addcmul_(update, update, value=1 - beta3)  # n_t\n\n                denom = ((exp_avg_sq).sqrt() / math.sqrt(bias_correction3)).add_(group['eps'])\n                update = ((exp_avg / bias_correction1 + beta2 * exp_avg_diff / bias_correction2)).div_(denom)\n\n                if group['no_prox']:\n                    p.data.mul_(1 - group['lr'] * group['weight_decay'])\n                    p.add_(update, alpha=-group['lr'])\n                else:\n                    p.add_(update, alpha=-group['lr'])\n                    p.data.div_(1 + group['lr'] * group['weight_decay'])\n\n                state['pre_grad'] = copy_grad","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:34:08.116001Z","iopub.execute_input":"2024-03-02T02:34:08.116361Z","iopub.status.idle":"2024-03-02T02:34:08.143008Z","shell.execute_reply.started":"2024-03-02T02:34:08.116329Z","shell.execute_reply":"2024-03-02T02:34:08.141924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    model.train()\n    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n    losses = AverageMeter()\n    start = end = time.time()\n    global_step = 0\n    for step, batch in enumerate(train_loader):\n        eegs = batch['eeg'].to(device)\n        labels = batch['labels'].to(device)\n        batch_size = labels.size(0)\n        with torch.cuda.amp.autocast(enabled=CFG.apex):\n            y_preds= model(eegs)\n            loss = criterion(F.log_softmax(y_preds, dim=1), labels)\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        losses.update(loss.item(), batch_size)\n        scaler.scale(loss).backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            global_step += 1\n            if CFG.batch_scheduler:\n                scheduler.step()\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}/{2}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  'LR: {lr:.8f}  '\n                  .format(epoch+1, step, len(train_loader), \n                          remain=timeSince(start, float(step+1)/len(train_loader)),\n                          loss=losses,\n                          grad_norm=grad_norm,\n                          lr=scheduler.get_lr()[0]))\n        if CFG.wandb:\n            wandb.log({f\"[fold{fold}] loss\": losses.val,\n                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    losses = AverageMeter()\n    model.eval()\n    preds = []\n    targets = []\n    start = end = time.time()\n    for step, batch in enumerate(valid_loader):\n        eegs = batch['eeg'].to(device)\n        labels = batch['labels'].to(device)\n        batch_size = labels.size(0)\n        with torch.no_grad():\n            y_preds = model(eegs)\n            loss = criterion(F.log_softmax(y_preds, dim=1), labels)\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        losses.update(loss.item(), batch_size)\n        preds.append(nn.Softmax(dim=1)(y_preds).to('cpu').numpy())\n        targets.append(labels.to('cpu').numpy())\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}/{1}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(step, len(valid_loader),\n                          loss=losses,\n                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n    predictions = np.concatenate(preds)\n    targets = np.concatenate(targets)\n    return losses.avg, predictions","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:34:09.300862Z","iopub.execute_input":"2024-03-02T02:34:09.301629Z","iopub.status.idle":"2024-03-02T02:34:09.323527Z","shell.execute_reply.started":"2024-03-02T02:34:09.301598Z","shell.execute_reply":"2024-03-02T02:34:09.322535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Loop","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# train loop\n# ====================================================\ndef train_loop(folds, fold, directory):\n    \n    LOGGER.info(f\"========== fold: {fold} training ==========\")\n\n    # ====================================================\n    # loader\n    # ====================================================\n    if CFG.stage1_pop1:\n        train_folds = folds[(folds['fold'] != fold)].reset_index(drop=True)\n    else:\n        train_folds = folds[(folds['fold'] != fold) & (folds['total_evaluators'] >= 5)].reset_index(drop=True)\n    valid_folds = folds[(folds['fold'] == fold)].reset_index(drop=True)\n    valid_labels = valid_folds[ CFG.target_cols].values\n    \n    train_dataset = EEGDataset(train_folds, CFG, mode=\"train\")\n    valid_dataset = EEGDataset(valid_folds, CFG, mode=\"train\")\n\n    train_loader = DataLoader(train_dataset,\n                              batch_size=CFG.batch_size,\n                              shuffle=True,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset,\n                              batch_size=CFG.batch_size * 2,\n                              shuffle=False,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    model = EEGNet(kernels=[3,5,7,9], in_channels=CFG.in_channels, fixed_kernel_size=5, num_classes=CFG.target_size)\n    if CFG.stage2_pop2:\n        model_weight = POP_1_DIR + f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage1.pth\"\n        checkpoint = torch.load(model_weight, map_location=device)\n        model.load_state_dict(checkpoint[\"model\"])\n    model.to(device)\n    # CPMP: wrap the model to use all GPUs\n    model = nn.DataParallel(model)\n    \n    def build_optimizer(cfg, model, device):\n        lr = cfg.lr\n        if cfg.optimizer == \"SAM\":\n            base_optimizer = torch.optim.SGD  # define an optimizer for the \"sharpness-aware\" update\n            optimizer_model = SAM(model.parameters(), base_optimizer, lr=lr, momentum=0.9, weight_decay=cfg.weight_decay, adaptive=True)\n        elif cfg.optimizer == \"Ranger21\":\n            optimizer_model = Ranger21(model.parameters(), lr=lr, weight_decay=cfg.weight_decay, \n            num_epochs=cfg.epochs, num_batches_per_epoch=len(train_loader))\n        elif cfg.optimizer == \"SGD\":\n            optimizer_model = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=cfg.weight_decay, momentum=0.9)\n        elif cfg.optimizer == \"Adam\":\n            optimizer_model = Adam(model.parameters(), lr=lr, weight_decay=CFG.weight_decay)\n        elif cfg.optimizer == \"Lion\":\n            optimizer_model = Lion(model.parameters(), lr=lr, weight_decay=cfg.weight_decay)\n        elif cfg.optimizer == \"Adan\":\n            optimizer_model = Adan(model.parameters(), lr=lr, weight_decay=cfg.weight_decay)\n    \n        return optimizer_model\n    \n    optimizer = build_optimizer(CFG, model, device)\n    \n    # ====================================================\n    # scheduler\n    # ====================================================\n    # ====================================================\n\n    def get_scheduler(optimizer):\n        if CFG.scheduler=='ReduceLROnPlateau':\n            scheduler = ReduceLROnPlateau(optimizer, **CFG.reduce_params)\n        elif CFG.scheduler=='CosineAnnealingLR':\n            scheduler = CosineAnnealingLR(optimizer, **CFG.cosanneal_params)\n        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n            scheduler = CosineAnnealingWarmRestarts(optimizer, **CFG.cosanneal_res_params)\n        elif CFG.scheduler=='OneCycleLR':\n            steps_per_epoch=len(train_loader),\n            scheduler = OneCycleLR(optimizer=optimizer, epochs=CFG.epochs, anneal_strategy=\"cos\", pct_start=0.05, steps_per_epoch=len(train_loader),\n        max_lr=CFG.lr, final_div_factor=100)\n        return scheduler\n    \n    scheduler = get_scheduler(optimizer)\n\n    # ====================================================\n    # loop\n    # ====================================================\n    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n\n    \n    best_score = np.inf\n\n    for epoch in range(CFG.epochs):\n\n        start_time = time.time()\n\n        # train\n        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n\n        # eval\n        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        if CFG.wandb:\n            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n                       f\"[fold{fold}] score\": score})\n        \n        if best_score > avg_val_loss:\n            best_score = avg_val_loss\n            LOGGER.info(f'Epoch {epoch+1} - Save Best valid loss: {avg_val_loss:.4f} Model')\n            # CPMP: save the original model. It is stored as the module attribute of the DP model.\n            if CFG.stage1_pop1:\n                \n                torch.save({'model': model.module.state_dict(),\n                            'predictions': predictions},\n                             directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage1.pth\")\n            else:\n                \n                torch.save({'model': model.module.state_dict(),\n                            'predictions': predictions},\n                             directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage2.pth\")\n                \n    if CFG.stage1_pop1:\n        predictions = torch.load(directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage1.pth\", \n                             map_location=torch.device('cpu'))['predictions']\n    else:\n        predictions = torch.load(directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage2.pth\", \n                             map_location=torch.device('cpu'))['predictions']\n    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n    valid_folds[CFG.target_cols] = valid_labels \n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    return valid_folds, best_score","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:34:09.922551Z","iopub.execute_input":"2024-03-02T02:34:09.922908Z","iopub.status.idle":"2024-03-02T02:34:09.947316Z","shell.execute_reply.started":"2024-03-02T02:34:09.922878Z","shell.execute_reply":"2024-03-02T02:34:09.946344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    \n    if CFG.train:\n        oof_df = pd.DataFrame()\n        scores = []\n        for fold in range(CFG.n_fold):\n            if fold in CFG.trn_fold:\n                _oof_df, score = train_loop(train, fold, POP_1_DIR)\n                oof_df = pd.concat([oof_df, _oof_df])\n                scores.append(score)\n                LOGGER.info(f\"========== fold: {fold} result ==========\")\n                LOGGER.info(f'Score with best loss weights stage1: {score}')\n        oof_df = oof_df.reset_index(drop=True)\n        LOGGER.info(f\"========== CV ==========\")\n        LOGGER.info(f'Score with best loss weights: {np.mean(scores)}')\n        oof_df.to_csv(POP_1_DIR+f'{CFG.model_name}_oof_df_version{VERSION}_stage1.csv', index=False)\n        \n    if CFG.wandb:\n        wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:34:10.522941Z","iopub.execute_input":"2024-03-02T02:34:10.523638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.stage1_pop1 = False\nCFG.stage2_pop2 = True\nCFG.epochs = 20\n\n\nif __name__ == '__main__':\n    \n    if CFG.train:\n        oof_df = pd.DataFrame()\n        scores = []\n        for fold in range(CFG.n_fold):\n            if fold in CFG.trn_fold:\n                _oof_df, score = train_loop(train, fold, POP_2_DIR)\n                oof_df = pd.concat([oof_df, _oof_df])\n                scores.append(score)\n                LOGGER.info(f\"========== fold: {fold} result ==========\")\n                LOGGER.info(f'Score with best loss weights stage2: {score}')\n        oof_df = oof_df.reset_index(drop=True)\n        LOGGER.info(f\"========== CV ==========\")\n        LOGGER.info(f'Score with best loss weights: {np.mean(scores)}')\n        oof_df.to_csv(POP_2_DIR+f'{CFG.model_name}_oof_df_version{VERSION}_stage2.csv', index=False)\n        \n    if CFG.wandb:\n        wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:33:03.98363Z","iopub.status.idle":"2024-03-02T02:33:03.984004Z","shell.execute_reply.started":"2024-03-02T02:33:03.983833Z","shell.execute_reply":"2024-03-02T02:33:03.983849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/kaggle-kl-div')\nfrom kaggle_kl_div import score\n\n# === Pre-process OOF ===\nlabel_cols = CFG.target_cols\ngt = oof_df[[\"eeg_id\"] + CFG.target_cols]\ngt.sort_values(by=\"eeg_id\", inplace=True)\ngt.reset_index(inplace=True, drop=True)\n\npreds = oof_df[[\"eeg_id\"] + CFG.pred_cols]\npreds.columns = [\"eeg_id\"] + CFG.target_cols\npreds.sort_values(by=\"eeg_id\", inplace=True)\npreds.reset_index(inplace=True, drop=True)\n\ny_trues = gt[CFG.target_cols]\ny_preds = preds[CFG.target_cols]\n\noof = pd.DataFrame(y_preds.copy())\noof['id'] = np.arange(len(oof))\n\ntrue = pd.DataFrame(y_trues.copy())\ntrue['id'] = np.arange(len(true))\n\ncv = score(solution=true, submission=oof, row_id_column_name='id')\nprint('CV Stage2 Score with resnet1D_gru Raw EEG =',cv)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T02:33:03.985605Z","iopub.status.idle":"2024-03-02T02:33:03.985979Z","shell.execute_reply.started":"2024-03-02T02:33:03.985807Z","shell.execute_reply":"2024-03-02T02:33:03.985824Z"},"trusted":true},"execution_count":null,"outputs":[]}]}