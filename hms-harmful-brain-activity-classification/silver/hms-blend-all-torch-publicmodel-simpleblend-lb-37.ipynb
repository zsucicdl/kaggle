{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7392733,"sourceType":"datasetVersion","datasetId":4297749},{"sourceId":7392775,"sourceType":"datasetVersion","datasetId":4297782},{"sourceId":7402356,"sourceType":"datasetVersion","datasetId":4304475},{"sourceId":7403069,"sourceType":"datasetVersion","datasetId":4304949},{"sourceId":7447509,"sourceType":"datasetVersion","datasetId":4334995},{"sourceId":7450712,"sourceType":"datasetVersion","datasetId":4336944},{"sourceId":7581697,"sourceType":"datasetVersion","datasetId":4413439},{"sourceId":7581715,"sourceType":"datasetVersion","datasetId":4413451},{"sourceId":7581720,"sourceType":"datasetVersion","datasetId":4413454},{"sourceId":7585255,"sourceType":"datasetVersion","datasetId":4415285,"isSourceIdPinned":true},{"sourceId":158958765,"sourceType":"kernelVersion"},{"sourceId":159333316,"sourceType":"kernelVersion"},{"sourceId":159396114,"sourceType":"kernelVersion"}],"dockerImageVersionId":30636,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## ℹ️Update Info\n\n* **2024/02/10 forked original great work kernels**\n    * [Blend][Inference] https://www.kaggle.com/code/kitsuha/3-model-ensemble-lb-0-38\n    * [Blend][Inference] https://www.kaggle.com/code/andreasbis/hms-inference-lb-0-41\n    * [Single][Inference] https://www.kaggle.com/code/yunsuxiaozi/hms-baseline-resnet34d-512-512-inference-6-models\n    * [Single][Inference] https://www.kaggle.com/code/crackle/efficientnetb0-pytorch-starter-lb-0-40\n    \n\n* **2024/02/16**\n    * add Blend Weights. Use param by https://www.kaggle.com/code/kitsuha/3-model-ensemble-lb-0-37https://www.kaggle.com/code/kitsuha/3-model-ensemble-lb-0-37","metadata":{}},{"cell_type":"markdown","source":"---\n# **《《《　Model 1　》》》**\n---","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport gc\nsys.path.append('/kaggle/input/kaggle-kl-div')\nfrom kaggle_kl_div import score\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\nimport pytorch_lightning as pl\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nimport albumentations as albu\nfrom sklearn.model_selection import KFold, GroupKFold","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:04:57.404869Z","iopub.execute_input":"2024-02-16T12:04:57.405311Z","iopub.status.idle":"2024-02-16T12:05:06.871165Z","shell.execute_reply.started":"2024-02-16T12:04:57.405263Z","shell.execute_reply":"2024-02-16T12:05:06.870348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VER = 5\n# IF THIS EQUALS NONE, THEN WE TRAIN NEW MODELS\n# IF THIS EQUALS DISK PATH, THEN WE LOAD PREVIOUSLY TRAINED MODELS\nLOAD_MODELS_FROM = '/kaggle/input/hms-efficientnetb0-pt-ckpts/'\n\nUSE_KAGGLE_SPECTROGRAMS = True\nUSE_EEG_SPECTROGRAMS = True","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:05:06.872841Z","iopub.execute_input":"2024-02-16T12:05:06.873254Z","iopub.status.idle":"2024-02-16T12:05:06.877743Z","shell.execute_reply.started":"2024-02-16T12:05:06.873226Z","shell.execute_reply":"2024-02-16T12:05:06.876725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\nTARGETS = df.columns[-6:]\nprint('Train shape:', df.shape )\nprint('Targets', list(TARGETS))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:05:06.879221Z","iopub.execute_input":"2024-02-16T12:05:06.879615Z","iopub.status.idle":"2024-02-16T12:05:07.179021Z","shell.execute_reply.started":"2024-02-16T12:05:06.879584Z","shell.execute_reply":"2024-02-16T12:05:07.178124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df.groupby('eeg_id')[\n    ['spectrogram_id', 'spectrogram_label_offset_seconds']\n].agg({'spectrogram_id': 'first', 'spectrogram_label_offset_seconds': 'min'})\ntrain.columns = ['spec_id', 'min']\n\ntmp = df.groupby('eeg_id')[\n    ['spectrogram_id','spectrogram_label_offset_seconds']\n].agg({'spectrogram_label_offset_seconds' :'max'})\ntrain['max'] = tmp\n\ntmp = df.groupby('eeg_id')[['patient_id']].agg('first')\ntrain['patient_id'] = tmp\n\ntmp = df.groupby('eeg_id')[TARGETS].agg('sum')\nfor t in TARGETS:\n    train[t] = tmp[t].values\n    \ny_data = train[TARGETS].values\ny_data = y_data / y_data.sum(axis=1, keepdims=True)\ntrain[TARGETS] = y_data\n\ntmp = df.groupby('eeg_id')[['expert_consensus']].agg('first')\ntrain['target'] = tmp\n\ntrain = train.reset_index()\nprint('Train non-overlapp eeg_id shape:', train.shape )\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:05:07.182353Z","iopub.execute_input":"2024-02-16T12:05:07.183149Z","iopub.status.idle":"2024-02-16T12:05:07.281432Z","shell.execute_reply.started":"2024-02-16T12:05:07.18311Z","shell.execute_reply":"2024-02-16T12:05:07.280476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"READ_SPEC_FILES = False\n\n# READ ALL SPECTROGRAMS\nPATH = '/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/'\nfiles = os.listdir(PATH)\nprint(f'There are {len(files)} spectrogram parquets')\n\nif READ_SPEC_FILES:    \n    spectrograms = {}\n    for i,f in enumerate(files):\n        if i % 100 == 0:\n            print(i, ', ', end='')\n        tmp = pd.read_parquet(f'{PATH}{f}')\n        name = int(f.split('.')[0])\n        spectrograms[name] = tmp.iloc[:,1:].values\nelse:\n    spectrograms = np.load('/kaggle/input/brain-spectrograms/specs.npy',allow_pickle=True).item()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:05:07.282476Z","iopub.execute_input":"2024-02-16T12:05:07.282745Z","iopub.status.idle":"2024-02-16T12:06:31.611048Z","shell.execute_reply.started":"2024-02-16T12:05:07.282724Z","shell.execute_reply":"2024-02-16T12:06:31.61008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"READ_EEG_SPEC_FILES = False\n\nif READ_EEG_SPEC_FILES:\n    all_eegs = {}\n    for i,e in enumerate(train.eeg_id.values):\n        if i % 100 == 0:\n            print(i, ', ', end='')\n        x = np.load(f'/kaggle/input/brain-eeg-spectrograms/EEG_Spectrograms/{e}.npy')\n        all_eegs[e] = x\nelse:\n    all_eegs = np.load('/kaggle/input/brain-eeg-spectrograms/eeg_specs.npy',allow_pickle=True).item()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:06:31.612218Z","iopub.execute_input":"2024-02-16T12:06:31.612541Z","iopub.status.idle":"2024-02-16T12:08:15.173369Z","shell.execute_reply.started":"2024-02-16T12:06:31.612515Z","shell.execute_reply":"2024-02-16T12:08:15.172494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TARS = {'Seizure':0, 'LPD':1, 'GPD':2, 'LRDA':3, 'GRDA':4, 'Other':5}\nTARS2 = {x: y for y, x in TARS.items()}\n\n\nclass EEGDataset(Dataset):\n    \n    def __init__(self, data, augment=False, mode='train', specs=spectrograms, eeg_specs=all_eegs): \n        self.data = data\n        self.augment = augment\n        self.mode = mode\n        self.specs = specs\n        self.eeg_specs = eeg_specs\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        return self.__getitems__([index])\n    \n    def __getitems__(self, indices):\n        X, y = self._generate_data(indices)\n        if self.augment:\n            X = self._augment(X) \n        if self.mode == 'train':\n            return list(zip(X, y))\n        else:\n            return X\n    \n    def _generate_data(self, indexes):\n        X = np.zeros((len(indexes), 128, 256, 8),dtype='float32')\n        y = np.zeros((len(indexes), 6),dtype='float32')\n        img = np.ones((128, 256),dtype='float32')\n        \n        for j, i in enumerate(indexes):\n            row = self.data.iloc[i]\n            if self.mode == 'test': \n                r = 0\n            else: \n                r = int((row['min'] + row['max'])//4)\n\n            for k in range(4):\n                # EXTRACT 300 ROWS OF SPECTROGRAM\n                img = self.specs[row.spec_id][r:r+300, k*100:(k+1)*100].T\n                \n                # LOG TRANSFORM SPECTROGRAM\n                img = np.clip(img, np.exp(-4), np.exp(8))\n                img = np.log(img)\n                \n                # STANDARDIZE PER IMAGE\n                ep = 1e-6\n                m = np.nanmean(img.flatten())\n                s = np.nanstd(img.flatten())\n                img = (img - m) / (s + ep)\n                img = np.nan_to_num(img, nan=0.0)\n                \n                # CROP TO 256 TIME STEPS\n                X[j, 14:-14, :, k] = img[:, 22:-22] / 2.0\n        \n            # EEG SPECTROGRAMS\n            img = self.eeg_specs[row.eeg_id]\n            X[j, :, :, 4:] = img\n                \n            if self.mode != 'test':\n                y[j,] = row[TARGETS]\n            \n        return X, y\n    \n    def _random_transform(self, img):\n        composition = albu.Compose([\n            albu.HorizontalFlip(p=0.5),\n            # albu.CoarseDropout(max_holes=8,max_height=32,max_width=32,fill_value=0,p=0.5),\n        ])\n        return composition(image=img)['image']\n            \n    def __augment(self, img_batch):\n        for i in range(img_batch.shape[0]):\n            img_batch[i,] = self._random_transform(img_batch[i,])\n        return img_batch","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:08:15.174611Z","iopub.execute_input":"2024-02-16T12:08:15.174924Z","iopub.status.idle":"2024-02-16T12:08:15.191807Z","shell.execute_reply.started":"2024-02-16T12:08:15.174898Z","shell.execute_reply":"2024-02-16T12:08:15.190813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = EEGDataset(train)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:08:15.193061Z","iopub.execute_input":"2024-02-16T12:08:15.193432Z","iopub.status.idle":"2024-02-16T12:08:15.207468Z","shell.execute_reply.started":"2024-02-16T12:08:15.193399Z","shell.execute_reply":"2024-02-16T12:08:15.206586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROWS = 2\nCOLS = 3\nBATCHES = 2\n\nfor i, (x, y) in enumerate(dataloader):\n    plt.figure(figsize=(20, 8))\n    for j in range(ROWS):\n        for k in range(COLS):\n            plt.subplot(ROWS, COLS, j*COLS + k + 1)\n            t = y[j*COLS + k]\n            img = torch.flip(x[j*COLS+k, :, :, 0], (0,))\n            mn = img.flatten().min()\n            mx = img.flatten().max()\n            img = (img-mn)/(mx-mn)\n            plt.imshow(img)\n            tars = f'[{t[0]:0.2f}]'\n            for s in t[1:]:\n                tars += f', {s:0.2f}'\n            eeg = train.eeg_id.values[i*32+j*COLS+k]\n            plt.title(f'EEG = {eeg}\\nTarget = {tars}',size=12)\n            plt.yticks([])\n            plt.ylabel('Frequencies (Hz)',size=14)\n            plt.xlabel('Time (sec)',size=16)\n    plt.show()\n    if i == BATCHES-1:\n        break","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:08:15.208656Z","iopub.execute_input":"2024-02-16T12:08:15.209068Z","iopub.status.idle":"2024-02-16T12:08:18.397294Z","shell.execute_reply.started":"2024-02-16T12:08:15.209034Z","shell.execute_reply":"2024-02-16T12:08:18.396277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del dataset, dataloader\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:08:18.40215Z","iopub.execute_input":"2024-02-16T12:08:18.402525Z","iopub.status.idle":"2024-02-16T12:08:18.60192Z","shell.execute_reply.started":"2024-02-16T12:08:18.402492Z","shell.execute_reply":"2024-02-16T12:08:18.600813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WEIGHTS_FILE = '/kaggle/input/hms-efficientnetb0-pt-ckpts/efficientnet_b0_rwightman-7f5810bc.pth'\n\n\nclass EEGEffnetB0(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n        self.base_model = efficientnet_b0()\n        self.base_model.load_state_dict(torch.load(WEIGHTS_FILE))\n        self.base_model.classifier[1] = nn.Linear(self.base_model.classifier[1].in_features, 6, dtype=torch.float32)\n        self.prob_out = nn.Softmax()\n        \n    def forward(self, x):\n        x1 = [x[:, :, :, i:i+1] for i in range(4)]\n        x1 = torch.concat(x1, dim=1)\n        x2 = [x[:, :, :, i+4:i+5] for i in range(4)]\n        x2 = torch.concat(x2, dim=1)\n        \n        if USE_KAGGLE_SPECTROGRAMS & USE_EEG_SPECTROGRAMS:\n            x = torch.concat([x1, x2], dim=2)\n        elif USE_EEG_SPECTROGRAMS:\n            x = x2\n        else:\n            x = x1\n        x = torch.concat([x, x, x], dim=3)\n        x = x.permute(0, 3, 1, 2)\n        \n        out = self.base_model(x)\n        return out\n    \n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        out = self.forward(x)\n        out = F.log_softmax(out, dim=1)\n        kl_loss = nn.KLDivLoss(reduction='batchmean')\n        loss = kl_loss(out, y)\n        return loss\n    \n    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n        return F.softmax(self(batch), dim=1)\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:08:18.60312Z","iopub.execute_input":"2024-02-16T12:08:18.603521Z","iopub.status.idle":"2024-02-16T12:08:18.619517Z","shell.execute_reply.started":"2024-02-16T12:08:18.60349Z","shell.execute_reply":"2024-02-16T12:08:18.618544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_oof = []\nall_true = []\nvalid_loaders = []\n\ngkf = GroupKFold(n_splits=5)\nfor i, (train_index, valid_index) in enumerate(gkf.split(train, train.target, train.patient_id)):  \n    print('#'*25)\n    print(f'### Fold {i+1}')\n    \n    train_ds = EEGDataset(train.iloc[train_index])\n    train_loader = DataLoader(train_ds, shuffle=True, batch_size=32, num_workers=3)\n    valid_ds = EEGDataset(train.iloc[valid_index], mode='valid')\n    valid_loader = DataLoader(valid_ds, shuffle=False, batch_size=64, num_workers=3)\n    \n    print(f'### Train size: {len(train_index)}, Valid size: {len(valid_index)}')\n    print('#'*25)\n    \n    trainer = pl.Trainer(max_epochs=4)\n    model = EEGEffnetB0()\n    if LOAD_MODELS_FROM is None:\n        trainer.fit(model=model, train_dataloaders=train_loader)\n        trainer.save_checkpoint(f'EffNet_v{VER}_f{i}.ckpt')\n\n    valid_loaders.append(valid_loader)\n    all_true.append(train.iloc[valid_index][TARGETS].values)\n    del trainer, model\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:08:18.620708Z","iopub.execute_input":"2024-02-16T12:08:18.621054Z","iopub.status.idle":"2024-02-16T12:08:21.865908Z","shell.execute_reply.started":"2024-02-16T12:08:18.621024Z","shell.execute_reply":"2024-02-16T12:08:21.865071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:08:21.867139Z","iopub.execute_input":"2024-02-16T12:08:21.86745Z","iopub.status.idle":"2024-02-16T12:08:21.872073Z","shell.execute_reply.started":"2024-02-16T12:08:21.867423Z","shell.execute_reply":"2024-02-16T12:08:21.871212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    print('#'*25)\n    print(f'### Validating Fold {i+1}')\n\n    ckpt_file = f'EffNet_v{VER}_f{i}.ckpt' if LOAD_MODELS_FROM is None else f'{LOAD_MODELS_FROM}/EffNet_v{VER}_f{i}.ckpt'\n    model = EEGEffnetB0.load_from_checkpoint(ckpt_file)\n    model.to(device).eval()\n    with torch.inference_mode():\n        for val_batch in valid_loaders[i]:\n            val_batch = val_batch.to(device)\n            oof = torch.softmax(model(val_batch), dim=1).cpu().numpy()\n            all_oof.append(oof)\n    del model\n    gc.collect()\n\nall_oof = np.concatenate(all_oof)\nall_true = np.concatenate(all_true)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:08:21.873348Z","iopub.execute_input":"2024-02-16T12:08:21.873748Z","iopub.status.idle":"2024-02-16T12:10:17.655352Z","shell.execute_reply.started":"2024-02-16T12:08:21.873714Z","shell.execute_reply":"2024-02-16T12:10:17.654223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = pd.DataFrame(all_oof.copy())\noof['id'] = np.arange(len(oof))\n\ntrue = pd.DataFrame(all_true.copy())\ntrue['id'] = np.arange(len(true))\n\ncv = score(solution=true, submission=oof, row_id_column_name='id')\nprint('CV Score KL-Div for EfficientNetB2 =',cv)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:17.657642Z","iopub.execute_input":"2024-02-16T12:10:17.657962Z","iopub.status.idle":"2024-02-16T12:10:17.721913Z","shell.execute_reply.started":"2024-02-16T12:10:17.657932Z","shell.execute_reply":"2024-02-16T12:10:17.721033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```\nCV Score KL-Div for EfficientNetB2 = 0.6431805911043548\n```","metadata":{}},{"cell_type":"code","source":"del all_eegs, spectrograms\ngc.collect()\n\ntest = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\nprint('Test shape',test.shape)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:17.723225Z","iopub.execute_input":"2024-02-16T12:10:17.724013Z","iopub.status.idle":"2024-02-16T12:10:17.915916Z","shell.execute_reply.started":"2024-02-16T12:10:17.723975Z","shell.execute_reply":"2024-02-16T12:10:17.915024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# READ ALL SPECTROGRAMS\nPATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/'\nfiles2 = os.listdir(PATH2)\nprint(f'There are {len(files2)} test spectrogram parquets')\n    \nspectrograms2 = {}\nfor i, f in enumerate(files2):\n    if i % 100 == 0:\n        print(i, ', ',end='')\n    tmp = pd.read_parquet(f'{PATH2}{f}')\n    name = int(f.split('.')[0])\n    spectrograms2[name] = tmp.iloc[:, 1:].values\n    \n# RENAME FOR DATALOADER\ntest = test.rename({'spectrogram_id': 'spec_id'}, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:17.916901Z","iopub.execute_input":"2024-02-16T12:10:17.917151Z","iopub.status.idle":"2024-02-16T12:10:18.219093Z","shell.execute_reply.started":"2024-02-16T12:10:17.917129Z","shell.execute_reply":"2024-02-16T12:10:18.218172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pywt, librosa\n\nUSE_WAVELET = None \n\nNAMES = ['LL','LP','RP','RR']\n\nFEATS = [['Fp1','F7','T3','T5','O1'],\n         ['Fp1','F3','C3','P3','O1'],\n         ['Fp2','F8','T4','T6','O2'],\n         ['Fp2','F4','C4','P4','O2']]\n\n\n# DENOISE FUNCTION\ndef maddest(d, axis=None):\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n\n\ndef denoise(x, wavelet='haar', level=1):    \n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1/0.6745) * maddest(coeff[-level])\n\n    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n\n    ret=pywt.waverec(coeff, wavelet, mode='per')\n    \n    return ret\n\n\ndef spectrogram_from_eeg(parquet_path, display=False):\n    \n    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n    eeg = pd.read_parquet(parquet_path)\n    middle = (len(eeg)-10_000)//2\n    eeg = eeg.iloc[middle:middle+10_000]\n    \n    # VARIABLE TO HOLD SPECTROGRAM\n    img = np.zeros((128,256,4),dtype='float32')\n    \n    if display: plt.figure(figsize=(10,7))\n    signals = []\n    for k in range(4):\n        COLS = FEATS[k]\n        \n        for kk in range(4):\n        \n            # COMPUTE PAIR DIFFERENCES\n            x = eeg[COLS[kk]].values - eeg[COLS[kk+1]].values\n\n            # FILL NANS\n            m = np.nanmean(x)\n            if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n            else: x[:] = 0\n\n            # DENOISE\n            if USE_WAVELET:\n                x = denoise(x, wavelet=USE_WAVELET)\n            signals.append(x)\n\n            # RAW SPECTROGRAM\n            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//256, \n                  n_fft=1024, n_mels=128, fmin=0, fmax=20, win_length=128)\n\n            # LOG TRANSFORM\n            width = (mel_spec.shape[1]//32)*32\n            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n\n            # STANDARDIZE TO -1 TO 1\n            mel_spec_db = (mel_spec_db+40)/40 \n            img[:,:,k] += mel_spec_db\n                \n        # AVERAGE THE 4 MONTAGE DIFFERENCES\n        img[:,:,k] /= 4.0\n        \n        if display:\n            plt.subplot(2,2,k+1)\n            plt.imshow(img[:,:,k],aspect='auto',origin='lower')\n            plt.title(f'EEG {eeg_id} - Spectrogram {NAMES[k]}')\n            \n    if display: \n        plt.show()\n        plt.figure(figsize=(10,5))\n        offset = 0\n        for k in range(4):\n            if k>0: offset -= signals[3-k].min()\n            plt.plot(range(10_000),signals[k]+offset,label=NAMES[3-k])\n            offset += signals[3-k].max()\n        plt.legend()\n        plt.title(f'EEG {eeg_id} Signals')\n        plt.show()\n        print(); print('#'*25); print()\n        \n    return img","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:18.220524Z","iopub.execute_input":"2024-02-16T12:10:18.220842Z","iopub.status.idle":"2024-02-16T12:10:18.243655Z","shell.execute_reply.started":"2024-02-16T12:10:18.220811Z","shell.execute_reply":"2024-02-16T12:10:18.24278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# READ ALL EEG SPECTROGRAMS\nPATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/'\nDISPLAY = 1\nEEG_IDS2 = test.eeg_id.unique()\nall_eegs2 = {}\n\nprint('Converting Test EEG to Spectrograms...'); print()\nfor i, eeg_id in enumerate(EEG_IDS2):\n        \n    # CREATE SPECTROGRAM FROM EEG PARQUET\n    img = spectrogram_from_eeg(f'{PATH2}{eeg_id}.parquet', i < DISPLAY)\n    all_eegs2[eeg_id] = img","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:18.244857Z","iopub.execute_input":"2024-02-16T12:10:18.245852Z","iopub.status.idle":"2024-02-16T12:10:29.535828Z","shell.execute_reply.started":"2024-02-16T12:10:18.245811Z","shell.execute_reply":"2024-02-16T12:10:29.534713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INFER EFFICIENTNET ON TEST\npreds = []\ntest_ds = EEGDataset(test, mode='test', specs=spectrograms2, eeg_specs=all_eegs2)\ntest_loader = DataLoader(test_ds, shuffle=False, batch_size=64, num_workers=3)\n\nfor i in range(5):\n    print('#'*25)\n    print(f'### Testing Fold {i+1}')\n\n    ckpt_file = f'EffNet_v{VER}_f{i}.ckpt' if LOAD_MODELS_FROM is None else f'{LOAD_MODELS_FROM}/EffNet_v{VER}_f{i}.ckpt'\n    model = EEGEffnetB0.load_from_checkpoint(ckpt_file)\n    model.to(device).eval()\n    fold_preds = []\n\n    with torch.inference_mode():\n        for test_batch in test_loader:\n            test_batch = test_batch.to(device)\n            pred = torch.softmax(model(test_batch), dim=1).cpu().numpy()\n            fold_preds.append(pred)\n        fold_preds = np.concatenate(fold_preds)\n\n    preds.append(fold_preds)\n\npred = np.mean(preds,axis=0)\nprint()\nprint('Test preds shape',pred.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:29.537135Z","iopub.execute_input":"2024-02-16T12:10:29.537649Z","iopub.status.idle":"2024-02-16T12:10:36.164728Z","shell.execute_reply.started":"2024-02-16T12:10:29.53762Z","shell.execute_reply":"2024-02-16T12:10:36.163471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub1 = pd.DataFrame({'eeg_id':test.eeg_id.values})\nsub1[TARGETS] = pred\nprint('Submission shape',sub1.shape)\nsub1.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:36.167478Z","iopub.execute_input":"2024-02-16T12:10:36.167783Z","iopub.status.idle":"2024-02-16T12:10:36.184714Z","shell.execute_reply.started":"2024-02-16T12:10:36.167755Z","shell.execute_reply":"2024-02-16T12:10:36.183811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub1 = pd.DataFrame({'eeg_id':test.eeg_id.values})\nsub1[TARGETS] = pred\nprint('Submission shape',sub1.shape)\nsub1.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:36.185859Z","iopub.execute_input":"2024-02-16T12:10:36.186431Z","iopub.status.idle":"2024-02-16T12:10:36.203808Z","shell.execute_reply.started":"2024-02-16T12:10:36.186404Z","shell.execute_reply":"2024-02-16T12:10:36.202669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_combine = pred\npreds_combine","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:36.204953Z","iopub.execute_input":"2024-02-16T12:10:36.205256Z","iopub.status.idle":"2024-02-16T12:10:36.211442Z","shell.execute_reply.started":"2024-02-16T12:10:36.205231Z","shell.execute_reply":"2024-02-16T12:10:36.210615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\nsub1.iloc[:,-6:].sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:36.212542Z","iopub.execute_input":"2024-02-16T12:10:36.212807Z","iopub.status.idle":"2024-02-16T12:10:36.225754Z","shell.execute_reply.started":"2024-02-16T12:10:36.212785Z","shell.execute_reply":"2024-02-16T12:10:36.224778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **《《《　Model 2　》》》**\n---","metadata":{}},{"cell_type":"code","source":"#https://www.kaggle.com/code/ttahara/hms-hbac-resnet34d-baseline-training\n#https://www.kaggle.com/code/ttahara/hms-hbac-resnet34d-baseline-inference\n#necessary\nimport pandas as pd#导入csv文件的库\nimport numpy as np#进行矩阵运算的库\nimport torch #一个深度学习的库Pytorch\nimport torch.nn as nn#neural network,神经网络\nimport torch.nn.functional as F#神经网络函数库\nimport torchvision.transforms as transforms#Pytorch下面的图像处理库,用于对图像进行数据增强\n#设置随机种子\nimport random\nimport warnings#避免一些可以忽略的报错\nwarnings.filterwarnings('ignore')#filterwarnings()方法是用于设置警告过滤器的方法，它可以控制警告信息的输出方式和级别。","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:36.226932Z","iopub.execute_input":"2024-02-16T12:10:36.227187Z","iopub.status.idle":"2024-02-16T12:10:36.235397Z","shell.execute_reply.started":"2024-02-16T12:10:36.227165Z","shell.execute_reply":"2024-02-16T12:10:36.23459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    seed=2024\n    image_transform=transforms.Resize((512, 512))\n    num_folds=5","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:36.236469Z","iopub.execute_input":"2024-02-16T12:10:36.236729Z","iopub.status.idle":"2024-02-16T12:10:36.246596Z","shell.execute_reply.started":"2024-02-16T12:10:36.236706Z","shell.execute_reply":"2024-02-16T12:10:36.245805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models=[]\nfor i in range(Config.num_folds):\n    model = torch.load(f'/kaggle/input/hms-baseline-resnet34d-512-512-training-5-folds/HMS_resnet_fold{i}.pth')\n    models.append(model)\n# model = torch.load(\"/kaggle/input/hms-baseline-resnet34d-512-512-training/HMS_resnet.pth\")\n# models.append(model)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:36.247705Z","iopub.execute_input":"2024-02-16T12:10:36.247954Z","iopub.status.idle":"2024-02-16T12:10:44.001158Z","shell.execute_reply.started":"2024-02-16T12:10:36.247932Z","shell.execute_reply":"2024-02-16T12:10:44.000272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    torch.backends.cudnn.deterministic = True#将cuda加速的随机数生成器设为确定性模式\n    torch.backends.cudnn.benchmark = True#关闭CuDNN框架的自动寻找最优卷积算法的功能，以避免不同的算法对结果产生影响\n    torch.manual_seed(seed)#pytorch的随机种子\n    np.random.seed(seed)#numpy的随机种子\n    random.seed(seed)#python内置的随机种子\nseed_everything(Config.seed)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:44.006734Z","iopub.execute_input":"2024-02-16T12:10:44.007064Z","iopub.status.idle":"2024-02-16T12:10:44.014781Z","shell.execute_reply.started":"2024-02-16T12:10:44.007037Z","shell.execute_reply":"2024-02-16T12:10:44.01366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\")\nsubmission=pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\nsubmission=submission.merge(test_df,on='eeg_id',how='left')\nsubmission['path']=submission['spectrogram_id'].apply(lambda x: \"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/\"+str(x)+\".parquet\" )\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:44.016117Z","iopub.execute_input":"2024-02-16T12:10:44.016454Z","iopub.status.idle":"2024-02-16T12:10:44.062697Z","shell.execute_reply.started":"2024-02-16T12:10:44.016427Z","shell.execute_reply":"2024-02-16T12:10:44.061799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths=submission['path'].values\ntest_preds=[]\nfor path in paths:\n    eps=1e-6\n    data=pd.read_parquet(path)\n    #这里最小值是0,故用-1填充.第一列是时间列,故去掉 ,行是不同列,列是时间\n    data = data.fillna(-1).values[:,1:].T\n    #选取一段时间的数据进行训练\n    data=data[:,0:300]#(400,300)\n    data=np.clip(data,np.exp(-6),np.exp(10))#最大值为89209464.0\n    data= np.log(data)#对数变换\n    #对数据进行归一化\n    data_mean=data.mean(axis=(0,1))\n    data_std=data.std(axis=(0,1))\n    data=(data-data_mean)/(data_std+eps)\n    data_tensor = torch.unsqueeze(torch.Tensor(data), dim=0)\n    data=Config.image_transform(data_tensor)\n    test_pred=[]\n    for model in models:\n        model.eval()\n        with torch.no_grad():\n            pred=F.softmax(model(data.unsqueeze(0)))[0]\n            pred=pred.detach().cpu().numpy()\n        test_pred.append(pred)\n    test_pred=np.array(test_pred).mean(axis=0)\n    test_preds.append(test_pred)\ntest_preds=np.array(test_preds)\ntest_preds","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:44.063799Z","iopub.execute_input":"2024-02-16T12:10:44.064071Z","iopub.status.idle":"2024-02-16T12:10:45.813913Z","shell.execute_reply.started":"2024-02-16T12:10:44.064046Z","shell.execute_reply":"2024-02-16T12:10:45.812756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub2=pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\nlabels=['seizure','lpd','gpd','lrda','grda','other']\nfor i in range(len(labels)):\n    sub2[f'{labels[i]}_vote']=test_preds[:,i]\nsub2.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:45.815342Z","iopub.execute_input":"2024-02-16T12:10:45.81569Z","iopub.status.idle":"2024-02-16T12:10:45.833142Z","shell.execute_reply.started":"2024-02-16T12:10:45.815661Z","shell.execute_reply":"2024-02-16T12:10:45.832218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **《《《　Model 3　》》》**\n---","metadata":{}},{"cell_type":"code","source":"# Importing essential libraries\nimport gc\nimport os\nimport random\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display\n\n# PyTorch for deep learning\nimport timm\nimport torch\nimport torch.nn as nn  \nimport torch.optim as optim\nimport torch.nn.functional as F\n\n# torchvision for image processing and augmentation\nimport torchvision.transforms as transforms\n\n# Suppressing minor warnings to keep the output clean\nwarnings.filterwarnings('ignore', category=Warning)\n\n# Reclaim memory no longer in use.\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:45.835089Z","iopub.execute_input":"2024-02-16T12:10:45.835721Z","iopub.status.idle":"2024-02-16T12:10:46.130346Z","shell.execute_reply.started":"2024-02-16T12:10:45.835688Z","shell.execute_reply":"2024-02-16T12:10:46.129437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    seed=42\n    image_transform=transforms.Resize((512, 512))\n    num_folds=5\n    \n# Set the seed for reproducibility across multiple libraries\ndef set_seed(seed):\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \nset_seed(Config.seed)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:46.133402Z","iopub.execute_input":"2024-02-16T12:10:46.133752Z","iopub.status.idle":"2024-02-16T12:10:46.141456Z","shell.execute_reply.started":"2024-02-16T12:10:46.133714Z","shell.execute_reply":"2024-02-16T12:10:46.140625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load and store the trained models for each fold into a list\nmodels = []\n\n# Load ResNet34d\nfor i in range(Config.num_folds):\n    # Create the same model architecture as during training\n    model_resnet = timm.create_model('resnet34d', pretrained=False, num_classes=6, in_chans=1)\n    \n    # Load the trained weights from the corresponding file\n    model_resnet.load_state_dict(torch.load(f'/kaggle/input/resnet34d/hms-train-resnet34d/resnet34d_fold{i}.pth', map_location=torch.device('cpu')))\n    \n    # Append the loaded model to the models list\n    models.append(model_resnet)\n\n# Reclaim memory no longer in use.\ngc.collect()\n\n# Load EfficientNetB0\nfor j in range(Config.num_folds):\n    # Create the same model architecture as during training\n    model_effnet_b0 = timm.create_model('efficientnet_b0', pretrained=False, num_classes=6, in_chans=1)\n    \n    # Load the trained weights from the corresponding file\n    model_effnet_b0.load_state_dict(torch.load(f'/kaggle/input/efficientnetb0/hms-train-efficientnetb0/efficientnet_b0_fold{j}.pth', map_location=torch.device('cpu')))\n    \n    # Append the loaded model to the models list\n    models.append(model_effnet_b0)\n    \n# Reclaim memory no longer in use.\ngc.collect()\n    \n# Load EfficientNetB1\nfor k in range(Config.num_folds):\n    # Create the same model architecture as during training\n    model_effnet_b1 = timm.create_model('efficientnet_b1', pretrained=False, num_classes=6, in_chans=1)\n    \n    # Load the trained weights from the corresponding file\n    model_effnet_b1.load_state_dict(torch.load(f'/kaggle/input/efficientnetb1/hms-train-efficientnetb1/efficientnet_b1_fold{k}.pth', map_location=torch.device('cpu')))\n    \n    # Append the loaded model to the models list\n    models.append(model_effnet_b1)\n\n# Reclaim memory no longer in use.\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:46.142604Z","iopub.execute_input":"2024-02-16T12:10:46.142891Z","iopub.status.idle":"2024-02-16T12:10:59.826213Z","shell.execute_reply.started":"2024-02-16T12:10:46.142853Z","shell.execute_reply":"2024-02-16T12:10:59.825164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load test data and sample submission dataframe\ntest_df = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\n\n# Merge the submission dataframe with the test data on EEG IDs\nsubmission = submission.merge(test_df, on='eeg_id', how='left')\n\n# Generate file paths for each spectrogram based on the EEG data in the submission dataframe\nsubmission['path'] = submission['spectrogram_id'].apply(lambda x: f\"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/{x}.parquet\")\n\n# Display the first few rows of the submission dataframe\ndisplay(submission.head())\n\n# Reclaim memory no longer in use\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:10:59.827618Z","iopub.execute_input":"2024-02-16T12:10:59.827997Z","iopub.status.idle":"2024-02-16T12:11:00.113679Z","shell.execute_reply.started":"2024-02-16T12:10:59.827961Z","shell.execute_reply":"2024-02-16T12:11:00.112717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the weights for each model\nweight_resnet34d = 0.25\nweight_effnetb0 = 0.42\nweight_effnetb1 = 0.33\n\n# Get file paths for test spectrograms\npaths = submission['path'].values\ntest_predss = []\n\n# Generate predictions for each spectrogram using all models\nfor path in paths:\n    eps = 1e-6\n    # Read and preprocess spectrogram data\n    data = pd.read_parquet(path)\n    data = data.fillna(-1).values[:, 1:].T\n    data = np.clip(data, np.exp(-6), np.exp(10))\n    data = np.log(data)\n    \n    # Normalize the data\n    data_mean = data.mean(axis=(0, 1))\n    data_std = data.std(axis=(0, 1))\n    data = (data - data_mean) / (data_std + eps)\n    data_tensor = torch.unsqueeze(torch.Tensor(data), dim=0)\n    data = Config.image_transform(data_tensor)\n\n    test_pred = []\n    \n    # Generate predictions using all models\n    for model in models:\n        model.eval()\n        with torch.no_grad():\n            pred = F.softmax(model(data.unsqueeze(0)))[0]\n            pred = pred.detach().cpu().numpy()\n        test_pred.append(pred)\n        \n    # Combine predictions from all models using weighted voting\n    weighted_pred = weight_resnet34d * np.mean(test_pred[:Config.num_folds], axis=0) + \\\n                     weight_effnetb0 * np.mean(test_pred[Config.num_folds:2*Config.num_folds], axis=0) + \\\n                     weight_effnetb1 * np.mean(test_pred[2*Config.num_folds:], axis=0)\n    \n    test_predss.append(weighted_pred)\n\n# Convert the list of predictions to a NumPy array for further processing\ntest_predss = np.array(test_predss)\n\n# Reclaim memory no longer in use\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:11:00.116209Z","iopub.execute_input":"2024-02-16T12:11:00.116544Z","iopub.status.idle":"2024-02-16T12:11:03.487706Z","shell.execute_reply.started":"2024-02-16T12:11:00.116517Z","shell.execute_reply":"2024-02-16T12:11:03.486787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predss","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:11:03.489044Z","iopub.execute_input":"2024-02-16T12:11:03.489454Z","iopub.status.idle":"2024-02-16T12:11:03.496971Z","shell.execute_reply.started":"2024-02-16T12:11:03.489418Z","shell.execute_reply":"2024-02-16T12:11:03.495953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **《《《　Sub　》》》**\n---","metadata":{}},{"cell_type":"code","source":"preds_combine","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:11:03.498117Z","iopub.execute_input":"2024-02-16T12:11:03.498445Z","iopub.status.idle":"2024-02-16T12:11:03.509203Z","shell.execute_reply.started":"2024-02-16T12:11:03.498419Z","shell.execute_reply":"2024-02-16T12:11:03.508247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\nlabels=['seizure','lpd','gpd','lrda','grda','other']\nfor i in range(len(labels)):\n    submission[f'{labels[i]}_vote']=(test_preds[:,i]*0.099 + preds_combine[:, i]*0.545 + test_predss[:, i]*0.356)\nsubmission.to_csv(\"submission.csv\",index=None)\ndisplay(submission.head())","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:11:03.510466Z","iopub.execute_input":"2024-02-16T12:11:03.510867Z","iopub.status.idle":"2024-02-16T12:11:03.541545Z","shell.execute_reply.started":"2024-02-16T12:11:03.510838Z","shell.execute_reply":"2024-02-16T12:11:03.540556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\nsubmission.iloc[:,-6:].sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T12:11:03.542545Z","iopub.execute_input":"2024-02-16T12:11:03.54282Z","iopub.status.idle":"2024-02-16T12:11:03.551365Z","shell.execute_reply.started":"2024-02-16T12:11:03.542786Z","shell.execute_reply":"2024-02-16T12:11:03.550334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}