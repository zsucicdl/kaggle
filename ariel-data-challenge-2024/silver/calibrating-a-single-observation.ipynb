{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 70367,
     "databundleVersionId": 9188054,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Calibrating a single observation",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "**This notebook is almost identical to the other one - but is delibrately made to process image by image, hopefully it will be easier for users who would like to parallelise their code to save on time.**",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Data reduction is crucial in astronomical observations, and this challenge is no exception. This notebook outlines essential calibration steps typically employed by astronomers to mitigate noise in data.\n\nKey points:\n\n- The notebook guides participants through pre-processing data and saving it in a more convenient, lighter format.\n- If you plan to use the baseline models (which will be released soon), you must run this notebook first before training.\n\nImportant note: While these steps help reduce noise and data size, they may not be the most effective approach for achieving the optimal model for this challenge. Participants are encouraged to explore alternative methods that could yield better results.\n\n\n\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "**Acknowledgement**: This notebook is prepared by Angèle Syty and Virginie Batista (IAP), with support from Andrea Bocchieri, Orphée Faucoz (CNES), Lorenzo V. Mugnai (Cardiff University & UCL), Tara Tahseen (UCL),  Gordon Yip (UCL). ",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Last modified: 14 Aug 2024. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport pandas as pd\nimport itertools\nimport os\nimport glob \nfrom astropy.stats import sigma_clip\n\nfrom tqdm import tqdm",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-14T15:33:35.641042Z",
     "iopub.execute_input": "2024-08-14T15:33:35.641498Z",
     "iopub.status.idle": "2024-08-14T15:33:36.736375Z",
     "shell.execute_reply.started": "2024-08-14T15:33:35.641462Z",
     "shell.execute_reply": "2024-08-14T15:33:36.735244Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Below, we define the corrections we want to apply, the size of the data chunks and the different path used to import data and save the light ones. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\npath_folder = '/kaggle/input/ariel-data-challenge-2024/' # path to the folder containing the data\npath_out = '/kaggle/tmp/data_light_raw/' # path to the folder to store the light data\noutput_dir = '/kaggle/tmp/data_light_raw/' # path for the output directory\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-14T15:33:36.738954Z",
     "iopub.execute_input": "2024-08-14T15:33:36.739432Z",
     "iopub.status.idle": "2024-08-14T15:33:36.745267Z",
     "shell.execute_reply.started": "2024-08-14T15:33:36.7394Z",
     "shell.execute_reply": "2024-08-14T15:33:36.74393Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "If the *path_out* folder doesn't exist yet, it is created. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if not os.path.exists(path_out):\n    os.makedirs(path_out)\n    print(f\"Directory {path_out} created.\")\nelse:\n    print(f\"Directory {path_out} already exists.\")\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-14T15:33:36.746833Z",
     "iopub.execute_input": "2024-08-14T15:33:36.74724Z",
     "iopub.status.idle": "2024-08-14T15:33:36.764542Z",
     "shell.execute_reply.started": "2024-08-14T15:33:36.747203Z",
     "shell.execute_reply": "2024-08-14T15:33:36.762988Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "**Data import:**\n\n The files are imported by chunks of size 'CHUNK_SIZE' to avoid exceeding the memory capacity. ",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Step 1: Analog-to-Digital Conversion\n\nThe Analog-to-Digital Conversion (adc) is performed by the detector to convert the pixel voltage into an integer number. We revert this operation by using the gain and offset for the calibration files *'train_adc_info.csv'*. \n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-02T14:38:41.270117Z",
     "iopub.execute_input": "2024-08-02T14:38:41.270597Z",
     "iopub.status.idle": "2024-08-02T14:38:41.303633Z",
     "shell.execute_reply.started": "2024-08-02T14:38:41.270558Z",
     "shell.execute_reply": "2024-08-02T14:38:41.30235Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": "def ADC_convert(signal, gain, offset):\n    signal = signal.astype(np.float64)\n    signal /= gain\n    signal += offset\n    return signal",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-14T15:33:36.766461Z",
     "iopub.execute_input": "2024-08-14T15:33:36.766836Z",
     "iopub.status.idle": "2024-08-14T15:33:36.779561Z",
     "shell.execute_reply.started": "2024-08-14T15:33:36.766803Z",
     "shell.execute_reply": "2024-08-14T15:33:36.778149Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 2: Mask hot/dead pixel",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "The dead pixels map is a map of the pixels that do not respond to light and, thus, can’t be accounted for any calculation. \nIn all these frames the dead pixels are masked using python masked arrays. The bad pixels are thus masked but left uncorrected. Some methods can be used to correct bad-pixels but this task, if needed, is left to the participants.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def mask_hot_dead(signal, dead, dark):\n    hot = sigma_clip(\n        dark, sigma=5, maxiters=5\n    ).mask\n    hot = np.tile(hot, (signal.shape[0], 1, 1))\n    dead = np.tile(dead, (signal.shape[0], 1, 1))\n    signal = np.ma.masked_where(dead, signal)\n    signal = np.ma.masked_where(hot, signal)\n    return signal",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-14T15:33:36.783173Z",
     "iopub.execute_input": "2024-08-14T15:33:36.783636Z",
     "iopub.status.idle": "2024-08-14T15:33:36.798407Z",
     "shell.execute_reply.started": "2024-08-14T15:33:36.783605Z",
     "shell.execute_reply": "2024-08-14T15:33:36.796813Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "The following steps used the calibration files attached to each dataset to correct for various effects in the data. ",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Step 2: linearity Correction",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "\n\n**Non-linearity of pixels' response:**\n\nThe non-linearity of the pixels’ response can be explained as capacitive leakage on the readout electronics of each pixel during the integration time. The number of electrons in the well is proportional to the number of photons that hit the pixel, with a quantum efficiency coefficient. However, the response of the pixel is not linear with the number of electrons in the well. This effect can be described by a polynomial function of the number of electrons actually in the well. The data is provided with calibration files *linear_corr.parquet* that are the coefficients of the inverse polynomial function and can be used to correct this non-linearity effect. \n\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def apply_linear_corr(linear_corr,clean_signal):\n    linear_corr = np.flip(linear_corr, axis=0)\n    for x, y in itertools.product(\n                range(clean_signal.shape[1]), range(clean_signal.shape[2])\n            ):\n        poli = np.poly1d(linear_corr[:, x, y])\n        clean_signal[:, x, y] = poli(clean_signal[:, x, y])\n    return clean_signal\n    ",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-14T15:33:36.80028Z",
     "iopub.execute_input": "2024-08-14T15:33:36.800644Z",
     "iopub.status.idle": "2024-08-14T15:33:36.816632Z",
     "shell.execute_reply.started": "2024-08-14T15:33:36.800612Z",
     "shell.execute_reply": "2024-08-14T15:33:36.81524Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 3: dark current subtraction\n\nThe data provided include calibration for dark current estimation, which can be used to pre-process the observations. Dark current represents a constant signal that accumulates in each pixel during the integration time, independent of the incoming light. To obtain the corrected image, the following conventional approach is applied:\nThe data provided include calibration files such as dark frames or dead pixels' maps. They can be used to pre-process the observations. The dark frame is a map of the detector response to a very short exposure time, to correct for the dark current of the detector. \n$$\\text{image - dark} \\cdot \\Delta t$$ \nThe corrected image is conventionally obtained via the following: \nwhere the dark current map is first corrected for the dead pixel.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def clean_dark(signal, dead, dark, dt):\n\n    dark = np.ma.masked_where(dead, dark)\n    dark = np.tile(dark, (signal.shape[0], 1, 1))\n\n    signal -= dark* dt[:, np.newaxis, np.newaxis]\n    return signal\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-14T15:33:36.818691Z",
     "iopub.execute_input": "2024-08-14T15:33:36.819033Z",
     "iopub.status.idle": "2024-08-14T15:33:36.832183Z",
     "shell.execute_reply.started": "2024-08-14T15:33:36.819002Z",
     "shell.execute_reply": "2024-08-14T15:33:36.830952Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 4: Get Correlated Double Sampling (CDS)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "The science frames are alternating between the start of the exposure and the end of the exposure. The lecture scheme is a ramp with a double sampling, called Correlated Double Sampling (CDS), the detector is read twice, once at the start of the exposure and once at the end of the exposure. The final CDS is the difference (End of exposure) - (Start of exposure).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def get_cds(signal):\n    cds = signal[:,1::2,:,:] - signal[:,::2,:,:]\n    return cds",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-14T15:33:36.833542Z",
     "iopub.execute_input": "2024-08-14T15:33:36.833868Z",
     "iopub.status.idle": "2024-08-14T15:33:36.84669Z",
     "shell.execute_reply.started": "2024-08-14T15:33:36.833815Z",
     "shell.execute_reply": "2024-08-14T15:33:36.845274Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 5 (Optional): Time Binning\nThis step is performed mianly to save space. Time series observations are binned together at specified frequency. \n\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def bin_obs(cds_signal,binning):\n    cds_transposed = cds_signal.transpose(0,1,3,2)\n    cds_binned = np.zeros((cds_transposed.shape[0], cds_transposed.shape[1]//binning, cds_transposed.shape[2], cds_transposed.shape[3]))\n    for i in range(cds_transposed.shape[1]//binning):\n        cds_binned[:,i,:,:] = np.sum(cds_transposed[:,i*binning:(i+1)*binning,:,:], axis=1)\n    return cds_binned",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-14T15:33:36.848117Z",
     "iopub.execute_input": "2024-08-14T15:33:36.848429Z",
     "iopub.status.idle": "2024-08-14T15:33:36.863743Z",
     "shell.execute_reply.started": "2024-08-14T15:33:36.848399Z",
     "shell.execute_reply": "2024-08-14T15:33:36.862329Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 6: Flat Field Correction\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "The flat field is a map of the detector response to uniform illumination, to correct for the pixel-to-pixel variations of the detector, for example the different quantum efficiencies of each pixel. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def correct_flat_field(flat,dead, signal):\n    flat = flat.transpose(1, 0)\n    dead = dead.transpose(1, 0)\n    flat = np.ma.masked_where(dead, flat)\n    flat = np.tile(flat, (signal.shape[0], 1, 1))\n    signal = signal / flat\n    return signal",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-14T15:33:36.865402Z",
     "iopub.execute_input": "2024-08-14T15:33:36.865764Z",
     "iopub.status.idle": "2024-08-14T15:33:36.885614Z",
     "shell.execute_reply.started": "2024-08-14T15:33:36.865734Z",
     "shell.execute_reply": "2024-08-14T15:33:36.884327Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Calibrating all training data",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "you can choose to correct the non-linearity of the pixels' response, to apply flat field, dark and dead map or to leave the data unchanged. The observations are binned in time by group of 30 frames for AIRS and 360 frames for FGS1, to obtain a lighter data-cube, easier to use. The images are cut along the wavelength axis between pixels 39 and 321, so that the 282 pixels left in the wavelength dimension match the last 282 targets' points, from AIRS. The 283rd targets' point is the one for FGS1 that will be added later on. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\nimage_id = 612015401\n\ntrain_adc_info = pd.read_csv(os.path.join(path_folder, 'train_adc_info.csv'))\ntrain_adc_info = train_adc_info.set_index('planet_id')\naxis_info = pd.read_parquet(os.path.join(path_folder,'axis_info.parquet'))\n\nDO_MASK = True\nDO_THE_NL_CORR = True # most time consuming step, you can choose to ignore it for rapid prototyping\nDO_DARK = True\nDO_FLAT = True\nTIME_BINNING = True\n\ncut_inf, cut_sup = 39, 321\nl = cut_sup - cut_inf\n\nAIRS_CH0_clean = np.zeros((1, 11250, 32, l))\nFGS1_clean = np.zeros((1, 135000, 32, 32))\n\ndf = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/AIRS-CH0_signal.parquet'))\nsignal = df.values.reshape((df.shape[0], 32, 356))\ngain = train_adc_info['AIRS-CH0_adc_gain'].loc[image_id]\noffset = train_adc_info['AIRS-CH0_adc_offset'].loc[image_id]\nsignal = ADC_convert(signal, gain, offset)\ndt_airs = axis_info['AIRS-CH0-integration_time'].dropna().values\nchopped_signal = signal[:, :, cut_inf:cut_sup]\ndel signal, df\n\n# CLEANING THE DATA: AIRS\nflat = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/AIRS-CH0_calibration/flat.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\ndark = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/AIRS-CH0_calibration/dark.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\ndead_airs = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/AIRS-CH0_calibration/dead.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\nlinear_corr = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/AIRS-CH0_calibration/linear_corr.parquet')).values.astype(np.float64).reshape((6, 32, 356))[:, :, cut_inf:cut_sup]\n\nif DO_MASK:\n    chopped_signal = mask_hot_dead(chopped_signal, dead_airs, dark)\n    AIRS_CH0_clean[0] = chopped_signal\nelse:\n    AIRS_CH0_clean[0] = chopped_signal\n\nif DO_THE_NL_CORR: \n    linear_corr_signal = apply_linear_corr(linear_corr,AIRS_CH0_clean[0])\n    AIRS_CH0_clean[0] = linear_corr_signal\ndel linear_corr\n\nif DO_DARK: \n    cleaned_signal = clean_dark(AIRS_CH0_clean[0], dead_airs, dark,dt_airs)\n    AIRS_CH0_clean[0] = cleaned_signal\nelse: \n    pass\ndel dark\n\ndf = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/FGS1_signal.parquet'))\nfgs_signal = df.values.reshape((df.shape[0], 32, 32))\nFGS1_gain = train_adc_info['FGS1_adc_gain'].loc[image_id]\nFGS1_offset = train_adc_info['FGS1_adc_offset'].loc[image_id]\nfgs_signal = ADC_convert(fgs_signal, FGS1_gain, FGS1_offset)\ndt_fgs1 = np.ones(len(fgs_signal))*0.1  ## please refer to data documentation for more information\nchopped_FGS1 = fgs_signal\n\ndel fgs_signal, df\n\n# CLEANING THE DATA: FGS1\nflat = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/FGS1_calibration/flat.parquet')).values.astype(np.float64).reshape((32, 32))\ndark = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/FGS1_calibration/dark.parquet')).values.astype(np.float64).reshape((32, 32))\ndead_fgs1 = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/FGS1_calibration/dead.parquet')).values.astype(np.float64).reshape((32, 32))\nlinear_corr = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/FGS1_calibration/linear_corr.parquet')).values.astype(np.float64).reshape((6, 32, 32))\n\nif DO_MASK:\n    chopped_FGS1 = mask_hot_dead(chopped_FGS1, dead_fgs1, dark)\n    FGS1_clean[0] = chopped_FGS1\nelse:\n    FGS1_clean[0] = chopped_FGS1\n\nif DO_THE_NL_CORR: \n    linear_corr_signal = apply_linear_corr(linear_corr,FGS1_clean[0])\n    FGS1_clean[0,:, :, :] = linear_corr_signal\ndel linear_corr\n\nif DO_DARK: \n    cleaned_signal = clean_dark(FGS1_clean[0], dead_fgs1, dark,dt_fgs1)\n    FGS1_clean[0] = cleaned_signal\nelse: \n    pass\ndel dark \n\n# SAVE DATA AND FREE SPACE\nAIRS_cds = get_cds(AIRS_CH0_clean)\nFGS1_cds = get_cds(FGS1_clean)\n\ndel AIRS_CH0_clean, FGS1_clean\n\n## (Optional) Time Binning to reduce space\nif TIME_BINNING:\n    AIRS_cds_binned = bin_obs(AIRS_cds,binning=30)\n    FGS1_cds_binned = bin_obs(FGS1_cds,binning=30*12)\nelse:\n    AIRS_cds = AIRS_cds.transpose(0,1,3,2) ## this is important to make it consistent for flat fielding, but you can always change it\n    AIRS_cds_binned = AIRS_cds\n    FGS1_cds = FGS1_cds.transpose(0,1,3,2)\n    FGS1_cds_binned = FGS1_cds\n\ndel AIRS_cds, FGS1_cds\n\nflat_airs = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/AIRS-CH0_calibration/flat.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\nflat_fgs = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/FGS1_calibration/flat.parquet')).values.astype(np.float64).reshape((32, 32))\nif DO_FLAT:\n    corrected_AIRS_cds_binned = correct_flat_field(flat_airs,dead_airs, AIRS_cds_binned[0])\n    AIRS_cds_binned[0] = corrected_AIRS_cds_binned\n    corrected_FGS1_cds_binned = correct_flat_field(flat_fgs,dead_fgs1, FGS1_cds_binned[0])\n    FGS1_cds_binned[0] = corrected_FGS1_cds_binned\nelse:\n    pass\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-14T15:33:36.88746Z",
     "iopub.execute_input": "2024-08-14T15:33:36.887803Z",
     "iopub.status.idle": "2024-08-14T15:34:32.992695Z",
     "shell.execute_reply.started": "2024-08-14T15:33:36.887772Z",
     "shell.execute_reply": "2024-08-14T15:34:32.991433Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Plots",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Let us checks that everything went well",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt ",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-14T15:34:32.994494Z",
     "iopub.execute_input": "2024-08-14T15:34:32.994863Z",
     "iopub.status.idle": "2024-08-14T15:34:33.001178Z",
     "shell.execute_reply.started": "2024-08-14T15:34:32.994831Z",
     "shell.execute_reply": "2024-08-14T15:34:32.999893Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Plot of the light-curves: ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\nfor i in range(len(AIRS_cds_binned)) : \n    light_curve = AIRS_cds_binned[i,:,:,:].sum(axis=(1,2))\n    plt.plot(light_curve/light_curve.mean(), '-', alpha=0.3)\n\nplt.xlabel('Time (frame index)')\nplt.ylabel('Normalized flux in the frame')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-14T15:34:33.002655Z",
     "iopub.execute_input": "2024-08-14T15:34:33.003102Z",
     "iopub.status.idle": "2024-08-14T15:34:33.430587Z",
     "shell.execute_reply.started": "2024-08-14T15:34:33.003048Z",
     "shell.execute_reply": "2024-08-14T15:34:33.429331Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
