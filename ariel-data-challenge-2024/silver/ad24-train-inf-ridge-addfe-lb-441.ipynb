{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 70367,
     "databundleVersionId": 9188054,
     "sourceType": "competition"
    },
    {
     "sourceId": 191155259,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "### ℹ️ **Info**\n* **forked original great work kernels**\n\n    * https://www.kaggle.com/code/ambrosm/adc24-intro-inference\n    * https://www.kaggle.com/code/hugowjd/neurips-ariel-2024-starter\n    * https://www.kaggle.com/code/xiaocao123/neurips-ariel-2024-starter?scriptVersionId=193156800\n    * https://www.kaggle.com/code/bingyuniu/neurips-ariel-2024-starter-withdifferentparametr\n\n* **2024/08/26 My Additional**\n    * percentile FE add.\n```\nnp.percentile(window, 5, axis=1),\nnp.percentile(window, 10, axis=1),\nnp.percentile(window, 15, axis=1),\nnp.percentile(window, 20, axis=1),\nnp.percentile(window, 25, axis=1),\nnp.percentile(window, 30, axis=1),\nnp.percentile(window, 35, axis=1),\nnp.percentile(window, 40, axis=1),\nnp.percentile(window, 60, axis=1),\nnp.percentile(window, 65, axis=1),\nnp.percentile(window, 70, axis=1),\nnp.percentile(window, 75, axis=1),\nnp.percentile(window, 80, axis=1),\nnp.percentile(window, 85, axis=1),\nnp.percentile(window, 90, axis=1),\nnp.percentile(window, 95, axis=1),\nnp.median(window, axis=1),\nnp.var(window, axis=1),\n```\n\n* **2024/08/29 My Additional**\n    * add FE\n```\nf_sliding_features2 = sliding_window_features(f_raw, 100, 10)\na_sliding_features2 = sliding_window_features(a_raw, 100, 10)\n```\n\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport polars as pl\nimport numpy as np\nimport torch\n# import torch.nn as nn\n# import torch.optim as optim\n# from torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nimport pickle\nimport time\nimport os\nimport pickle\nimport seaborn as sns\nimport scipy.stats\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom scipy.stats import kurtosis\nfrom scipy.stats import skew",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:37:43.861286Z",
     "iopub.execute_input": "2024-08-29T02:37:43.861737Z",
     "iopub.status.idle": "2024-08-29T02:37:43.871152Z",
     "shell.execute_reply.started": "2024-08-29T02:37:43.861706Z",
     "shell.execute_reply": "2024-08-29T02:37:43.869769Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Load Meta-Data\nPATH = \"/kaggle/input/ariel-data-challenge-2024\"\ntrain_adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/train_adc_info.csv', \n                             index_col='planet_id')\ntrain_labels = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/train_labels.csv',\n                           index_col='planet_id')\nwavelengths = pd.read_csv(f'{PATH}/wavelengths.csv')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:37:43.873364Z",
     "iopub.execute_input": "2024-08-29T02:37:43.87384Z",
     "iopub.status.idle": "2024-08-29T02:37:43.961156Z",
     "shell.execute_reply.started": "2024-08-29T02:37:43.873802Z",
     "shell.execute_reply": "2024-08-29T02:37:43.960122Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Pre-Processing\n## Load Functions",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%writefile utils.py\nimport pandas as pd\nimport polars as pl\nimport numpy as np\nfrom tqdm import tqdm\nimport pickle\nPATH = \"/kaggle/input/ariel-data-challenge-2024\"\ndef load_signal_data(planet_id, dataset, instrument, img_size):\n    file_path = f'{PATH}/{dataset}/{planet_id}/{instrument}_signal.parquet'\n    signal = pl.read_parquet(file_path)\n    mean_signal = signal.cast(pl.Int32).sum_horizontal().cast(pl.Float32).to_numpy() / img_size # mean over the 32*32 pixels\n    net_signal = mean_signal[1::2] - mean_signal[0::2]\n    return net_signal\n\ndef read_and_preprocess(dataset, planet_ids, instrument = \"AIRS-CH0\"):\n    \"\"\"Read the files for all planet_ids and extract the time series.\n    Parameters\n    dataset: 'train' or 'test'\n    planet_ids: list of planet ids\n    instrument: the instrument of observation, 'AIRS-CH0' or 'FGS1', default to 'AIRS-CH0'\n    Returns\n    dataframe with one row per planet_id and 67500 values per row for FGS1 and 5624 for AIRS-CH0\n    \"\"\"\n    img_size = 1024 if instrument == \"FGS1\" else 32*356\n    column_num = 67500 if instrument == 'FGS1' else 5625\n    raw_train = np.full((len(planet_ids), column_num), np.nan, dtype=np.float32)\n    for i, planet_id in tqdm(list(enumerate(planet_ids))):\n        raw_train[i] = load_signal_data(planet_id, dataset, instrument, img_size)\n    return raw_train\n\ndef feature_engineering(f_raw, a_raw, adc_info, window_size=60, step_size=15):\n    \"\"\"Create a dataframe with combined features from the raw data, including sliding window and time-series statistics.\n    \n    Parameters:\n    f_raw: ndarray of shape (n_planets, 67500)\n    a_raw: ndarray of shape (n_planets, 5625)\n    window_size: int, size of the sliding window for time-series statistics\n    step_size: int, step size for the sliding window\n    \n    Return value:\n    df: DataFrame of shape (n_planets, several features)\n    \"\"\"\n    f_obscured = f_raw[:, 23500:44000].mean(axis=1)\n    f_unobscured = (f_raw[:, :20500].mean(axis=1) + f_raw[:, 47000:].mean(axis=1)) / 2\n    f_relative_reduction = (f_unobscured - f_obscured) / f_unobscured\n    f_std_dev = f_raw.std(axis=1)\n    f_signal_to_noise = f_unobscured / f_std_dev\n\n    a_obscured = a_raw[:, 1958:3666].mean(axis=1)\n    a_unobscured = (a_raw[:, :1708].mean(axis=1) + a_raw[:, 3916:].mean(axis=1)) / 2\n    a_relative_reduction = (a_unobscured - a_obscured) / a_unobscured\n    a_std_dev = a_raw.std(axis=1)\n    a_signal_to_noise = a_unobscured / a_std_dev\n\n    f_variance = f_raw.var(axis=1)\n    a_variance = a_raw.var(axis=1)\n    \n    f_skewness = pd.DataFrame(f_raw).skew(axis=1).values\n    a_skewness = pd.DataFrame(a_raw).skew(axis=1).values\n\n    f_kurtosis = pd.DataFrame(f_raw).kurtosis(axis=1).values\n    a_kurtosis = pd.DataFrame(a_raw).kurtosis(axis=1).values\n    \n    f_half_obscured1 = f_raw[:, 20500:23500].mean(axis=1)\n    f_half_obscured2 = f_raw[:, 44000:47000].mean(axis=1)\n    f_half_reduction1 = (f_unobscured - f_half_obscured1) / f_unobscured\n    f_half_reduction2 = (f_unobscured - f_half_obscured2) / f_unobscured\n\n    a_half_obscured1 = a_raw[:, 1708:1958].mean(axis=1)\n    a_half_obscured2 = a_raw[:, 3666:3916].mean(axis=1)\n    a_half_reduction1 = (a_unobscured - a_half_obscured1) / a_unobscured\n    a_half_reduction2 = (a_unobscured - a_half_obscured2) / a_unobscured\n\n    # Sliding window features\n    def sliding_window_features(data, window_size, step_size):\n        features = []\n        max_index = data.shape[1]\n        for start in range(0, max_index - window_size + 1, step_size):\n            end = start + window_size\n            window = data[:, start:end]\n            features.append([\n                np.mean(window, axis=1),\n                np.std(window, axis=1),\n                np.min(window, axis=1),\n                np.max(window, axis=1),\n                np.percentile(window, 5, axis=1),\n                np.percentile(window, 10, axis=1),\n                np.percentile(window, 15, axis=1),\n                np.percentile(window, 20, axis=1),\n                np.percentile(window, 25, axis=1),\n                np.percentile(window, 30, axis=1),\n                np.percentile(window, 35, axis=1),\n                np.percentile(window, 40, axis=1),\n                np.percentile(window, 60, axis=1),\n                np.percentile(window, 65, axis=1),\n                np.percentile(window, 70, axis=1),\n                np.percentile(window, 75, axis=1),\n                np.percentile(window, 80, axis=1),\n                np.percentile(window, 85, axis=1),\n                np.percentile(window, 90, axis=1),\n                np.percentile(window, 95, axis=1),\n                np.median(window, axis=1),\n                np.var(window, axis=1),\n#                 kurtosis(window, axis=1),\n#                 skew(window, axis=1),\n            ])\n        if features:\n            return np.vstack(features).T  # Stack vertically and transpose to get the correct shape\n        else:\n            return np.empty((data.shape[0], 0))  # Return empty array with correct shape\n    \n    f_sliding_features = sliding_window_features(f_raw, window_size, step_size)\n    a_sliding_features = sliding_window_features(a_raw, window_size, step_size)\n    \n    f_sliding_features2 = sliding_window_features(f_raw, 100, 10)\n    a_sliding_features2 = sliding_window_features(a_raw, 100, 10)\n\n\n    print(f'f_sliding_features.shape: {f_sliding_features.shape}')\n    print(f'a_sliding_features.shape: {a_sliding_features.shape}')\n\n\n    df = pd.DataFrame({\n        'f_relative_reduction': f_relative_reduction,\n        'f_signal_to_noise': f_signal_to_noise,\n        'f_variance': f_variance,\n        'f_skewness': f_skewness,\n        'f_kurtosis': f_kurtosis,\n        'a_relative_reduction': a_relative_reduction,\n        'a_signal_to_noise': a_signal_to_noise,\n        'a_variance': a_variance,\n        'a_skewness': a_skewness,\n        'a_kurtosis': a_kurtosis,\n        'f_half_reduction1': f_half_reduction1,\n        'f_half_reduction2': f_half_reduction2,\n        'a_half_reduction1': a_half_reduction1,\n        'a_half_reduction2': a_half_reduction2\n    })\n\n\n    if f_sliding_features.size > 0:\n        f_sliding_df = pd.DataFrame(f_sliding_features, columns=[f'f_slide_{i}' for i in range(f_sliding_features.shape[1])])\n        df = pd.concat([df, f_sliding_df], axis=1)\n    if a_sliding_features.size > 0:\n        a_sliding_df = pd.DataFrame(a_sliding_features, columns=[f'a_slide_{i}' for i in range(a_sliding_features.shape[1])])\n        df = pd.concat([df, a_sliding_df], axis=1)\n    \n    if f_sliding_features2.size > 0:\n        f_sliding_df = pd.DataFrame(f_sliding_features2, columns=[f'f_slide2_{i}' for i in range(f_sliding_features2.shape[1])])\n        df = pd.concat([df, f_sliding_df], axis=1)\n    if a_sliding_features2.size > 0:\n        a_sliding_df = pd.DataFrame(a_sliding_features2, columns=[f'a_slide2_{i}' for i in range(a_sliding_features2.shape[1])])\n        df = pd.concat([df, a_sliding_df], axis=1)\n    \n    \n    df = pd.concat([df, adc_info.reset_index().iloc[:, 1:6]], axis=1)\n    \n    return df",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:37:43.962847Z",
     "iopub.execute_input": "2024-08-29T02:37:43.963247Z",
     "iopub.status.idle": "2024-08-29T02:37:43.978526Z",
     "shell.execute_reply.started": "2024-08-29T02:37:43.96321Z",
     "shell.execute_reply": "2024-08-29T02:37:43.977185Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%writefile -a utils.py\n\ndef postprocessing(pred_array, index, sigma_pred):\n    \"\"\"Create a submission dataframe from its components\n    \n    Parameters:\n    pred_array: ndarray of shape (n_samples, 283)\n    index: pandas.Index of length n_samples with name 'planet_id'\n    sigma_pred: float\n    \n    Return value:\n    df: DataFrame of shape (n_samples, 566) with planet_id as index\n    \"\"\"\n    return pd.concat([pd.DataFrame(pred_array.clip(0, None), index=index, columns=wavelengths.columns),\n                      pd.DataFrame(sigma_pred, index=index, columns=[f\"sigma_{i}\" for i in range(1, 284)])],\n                     axis=1)\n\nclass ParticipantVisibleError(Exception):\n    pass\n\ndef competition_score(\n        solution: pd.DataFrame,\n        submission: pd.DataFrame,\n        naive_mean: float,\n        naive_sigma: float,\n        sigma_true: float,\n        row_id_column_name='planet_id',\n    ) -> float:\n    '''\n    This is a Gaussian Log Likelihood based metric. For a submission, which contains the predicted mean (x_hat) and variance (x_hat_std),\n    we calculate the Gaussian Log-likelihood (GLL) value to the provided ground truth (x). We treat each pair of x_hat,\n    x_hat_std as a 1D gaussian, meaning there will be 283 1D gaussian distributions, hence 283 values for each test spectrum,\n    the GLL value for one spectrum is the sum of all of them.\n\n    Inputs:\n        - solution: Ground Truth spectra (from test set)\n            - shape: (nsamples, n_wavelengths)\n        - submission: Predicted spectra and errors (from participants)\n            - shape: (nsamples, n_wavelengths*2)\n        naive_mean: (float) mean from the train set.\n        naive_sigma: (float) standard deviation from the train set.\n        sigma_true: (float) essentially sets the scale of the outputs.\n    '''\n\n    del solution[row_id_column_name]\n    del submission[row_id_column_name]\n\n    if submission.min().min() < 0:\n        raise ParticipantVisibleError('Negative values in the submission')\n    for col in submission.columns:\n        if not pd.api.types.is_numeric_dtype(submission[col]):\n            raise ParticipantVisibleError(f'Submission column {col} must be a number')\n\n    n_wavelengths = len(solution.columns)\n    if len(submission.columns) != n_wavelengths*2:\n        raise ParticipantVisibleError('Wrong number of columns in the submission')\n\n    y_pred = submission.iloc[:, :n_wavelengths].values\n    # Set a non-zero minimum sigma pred to prevent division by zero errors.\n    sigma_pred = np.clip(submission.iloc[:, n_wavelengths:].values, a_min=10**-15, a_max=None)\n    y_true = solution.values\n\n    GLL_pred = np.sum(scipy.stats.norm.logpdf(y_true, loc=y_pred, scale=sigma_pred))\n    GLL_true = np.sum(scipy.stats.norm.logpdf(y_true, loc=y_true, scale=sigma_true * np.ones_like(y_true)))\n    GLL_mean = np.sum(scipy.stats.norm.logpdf(y_true, loc=naive_mean * np.ones_like(y_true), scale=naive_sigma * np.ones_like(y_true)))\n\n    submit_score = (GLL_pred - GLL_mean)/(GLL_true - GLL_mean)\n    return float(np.clip(submit_score, 0.0, 1.0))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:37:44.017866Z",
     "iopub.execute_input": "2024-08-29T02:37:44.01843Z",
     "iopub.status.idle": "2024-08-29T02:37:44.028762Z",
     "shell.execute_reply.started": "2024-08-29T02:37:44.018389Z",
     "shell.execute_reply": "2024-08-29T02:37:44.02752Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "exec(open('utils.py', 'r').read())",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:37:44.031066Z",
     "iopub.execute_input": "2024-08-29T02:37:44.031786Z",
     "iopub.status.idle": "2024-08-29T02:37:44.047779Z",
     "shell.execute_reply.started": "2024-08-29T02:37:44.031745Z",
     "shell.execute_reply": "2024-08-29T02:37:44.046432Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Load Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%time\nif os.path.exists(\"/kaggle/input/adc24-intro-training/f_raw_train.pickle\"):\n    f_raw_train = np.load('/kaggle/input/adc24-intro-training/f_raw_train.pickle', allow_pickle=True)\nelse:\n    f_raw_train = read_and_preprocess('train', train_labels.index, 'FGS1')\n    with open('f_raw_train.pickle', 'wb') as f:\n        pickle.dump(f_raw_train, f)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:37:44.049303Z",
     "iopub.execute_input": "2024-08-29T02:37:44.049832Z",
     "iopub.status.idle": "2024-08-29T02:37:44.139288Z",
     "shell.execute_reply.started": "2024-08-29T02:37:44.049792Z",
     "shell.execute_reply": "2024-08-29T02:37:44.138059Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%time\nif os.path.exists(\"/kaggle/input/adc24-intro-training/a_raw_train.pickle\"):\n    a_raw_train = np.load('/kaggle/input/adc24-intro-training/a_raw_train.pickle', allow_pickle=True)\nelse:\n    a_raw_train = read_and_preprocess('train', train_labels.index)\n    with open('a_raw_train.pickle', 'wb') as f:\n        pickle.dump(a_raw_train, f)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:37:44.14231Z",
     "iopub.execute_input": "2024-08-29T02:37:44.142695Z",
     "iopub.status.idle": "2024-08-29T02:37:44.158Z",
     "shell.execute_reply.started": "2024-08-29T02:37:44.142626Z",
     "shell.execute_reply": "2024-08-29T02:37:44.156761Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Feature Engineering",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%time\ntrain = feature_engineering(f_raw_train, a_raw_train, train_adc_info)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:37:44.159572Z",
     "iopub.execute_input": "2024-08-29T02:37:44.159949Z",
     "iopub.status.idle": "2024-08-29T02:42:38.777601Z",
     "shell.execute_reply.started": "2024-08-29T02:37:44.15992Z",
     "shell.execute_reply": "2024-08-29T02:42:38.776375Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:42:38.779068Z",
     "iopub.execute_input": "2024-08-29T02:42:38.77943Z",
     "iopub.status.idle": "2024-08-29T02:42:38.887247Z",
     "shell.execute_reply.started": "2024-08-29T02:42:38.779387Z",
     "shell.execute_reply": "2024-08-29T02:42:38.886183Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train = train.iloc[:,:-1]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:42:38.889029Z",
     "iopub.execute_input": "2024-08-29T02:42:38.889458Z",
     "iopub.status.idle": "2024-08-29T02:42:39.366626Z",
     "shell.execute_reply.started": "2024-08-29T02:42:38.889421Z",
     "shell.execute_reply": "2024-08-29T02:42:39.365555Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Data Plot",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(6, 2))\nplt.plot(f_raw_train.mean(axis=0))\nfor time_step in [20500, 23500, 44000, 47000]:\n    plt.axvline(time_step, color='gray')\nplt.xlabel('time step')\nplt.title('FGS1: Overall mean')\nplt.show()\n\nplt.figure(figsize=(6, 2))\nplt.plot(a_raw_train.mean(axis=0))\nfor time_step in [20500, 23500, 44000, 47000]:\n    plt.axvline(time_step * 11250 // 135000, color='gray')\nplt.xlabel('time step')\nplt.title('AIRS-CH0: Overall mean')\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:42:39.368037Z",
     "iopub.execute_input": "2024-08-29T02:42:39.368344Z",
     "iopub.status.idle": "2024-08-29T02:42:40.116472Z",
     "shell.execute_reply.started": "2024-08-29T02:42:39.368318Z",
     "shell.execute_reply": "2024-08-29T02:42:40.115247Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "color_array = np.array(plt.rcParams['axes.prop_cycle'].by_key()['color'])\nplt.scatter(train.a_relative_reduction, train_labels.wl_1, s=15, alpha=0.5,\n            c=color_array[train_adc_info.star])\nplt.xlabel('relative signal reduction when planet is in front')\nplt.ylabel('target')\nplt.title('Correlation between relative signal reduction and target')\n# plt.gca().set_aspect('equal')\npoints = [plt.Line2D([0], [0], label=f'star {i}', marker='o', markersize=3,\n         markeredgecolor=color_array[i], markerfacecolor=color_array[i], linestyle='') for i in range(2)]\n\nplt.legend(handles=points)\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:42:40.117914Z",
     "iopub.execute_input": "2024-08-29T02:42:40.118303Z",
     "iopub.status.idle": "2024-08-29T02:42:40.603978Z",
     "shell.execute_reply.started": "2024-08-29T02:42:40.118273Z",
     "shell.execute_reply": "2024-08-29T02:42:40.602828Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Model\n## Rigde Model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model = Ridge(alpha=1e-12)\n\noof_pred = cross_val_predict(model, train, train_labels)\n\nprint(f\"# R2 score: {r2_score(train_labels, oof_pred):.4f}\")\nsigma_pred = mean_squared_error(train_labels, oof_pred, squared=False)\nprint(f\"# Root mean squared error: {sigma_pred:.7f}\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:42:40.607122Z",
     "iopub.execute_input": "2024-08-29T02:42:40.607495Z",
     "iopub.status.idle": "2024-08-29T02:44:09.37017Z",
     "shell.execute_reply.started": "2024-08-29T02:42:40.607464Z",
     "shell.execute_reply": "2024-08-29T02:44:09.367779Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "oof_df = postprocessing(oof_pred, train_adc_info.index, sigma_pred)\ndisplay(oof_df)\n\ngll_score = competition_score(train_labels.copy().reset_index(),\n                              oof_df.copy().reset_index(),\n                              naive_mean=train_labels.values.mean(),\n                              naive_sigma=train_labels.values.std(),\n                              sigma_true=0.000003)\nprint(f\"# Estimated competition score: {gll_score:.4f}\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:44:09.373891Z",
     "iopub.execute_input": "2024-08-29T02:44:09.375694Z",
     "iopub.status.idle": "2024-08-29T02:44:09.505435Z",
     "shell.execute_reply.started": "2024-08-29T02:44:09.37562Z",
     "shell.execute_reply": "2024-08-29T02:44:09.504238Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model.fit(train, train_labels)\nwith open('model.pickle', 'wb') as f:\n    pickle.dump(model, f)\nwith open('sigma_pred.pickle', 'wb') as f:\n    pickle.dump(sigma_pred, f)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:44:09.506889Z",
     "iopub.execute_input": "2024-08-29T02:44:09.507292Z",
     "iopub.status.idle": "2024-08-29T02:44:24.494919Z",
     "shell.execute_reply.started": "2024-08-29T02:44:09.507258Z",
     "shell.execute_reply": "2024-08-29T02:44:24.493692Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Inference",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Load the data\ntest_adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/test_adc_info.csv',\n                           index_col='planet_id')\nsample_submission = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/sample_submission.csv',\n                                index_col='planet_id')\nf_raw_test = read_and_preprocess('test', sample_submission.index, 'FGS1')\na_raw_test = read_and_preprocess('test', sample_submission.index)\ntest = feature_engineering(f_raw_test, a_raw_test, test_adc_info)\ntest = test.iloc[: , :-1]\n# Load the model\nwith open('model.pickle', 'rb') as f:\n    model = pickle.load(f)\nwith open('sigma_pred.pickle', 'rb') as f:\n    sigma_pred = pickle.load(f)\n\n# Predict\ntest_pred = model.predict(test)\n\n# Package into submission file\nsub_df = sub_df = postprocessing(test_pred,\n                        test_adc_info.index,\n                        sigma_pred=np.tile(np.where(test_adc_info[['star']] <= 1, 0.0001555, 0.00085), (1, 283)))\ndisplay(sub_df)\nsub_df.to_csv('submission.csv')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-29T02:44:24.49673Z",
     "iopub.execute_input": "2024-08-29T02:44:24.497412Z",
     "iopub.status.idle": "2024-08-29T02:45:05.85588Z",
     "shell.execute_reply.started": "2024-08-29T02:44:24.497379Z",
     "shell.execute_reply": "2024-08-29T02:45:05.854344Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
