{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70089,"databundleVersionId":9515283,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Code submission example\n\nThis competition is different than a standard Code competition. It uses a backend to serve chunks of the test data, which your model must run inference on before the next chunk is served. Because of this, you have to include some required code for your submission to work.\n\nThe evaluation API requires that you set up a server which will respond to inference requests. We have already defined the server; you just need write the predict function. When we evaluate your submission on the hidden test set the client defined in `mcts_gateway` will run in a different container with direct access to the hidden test set and hand off the data in batches of 100.\n\nYour code will always have access to the published copies of the files.","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\n\nimport polars as pl\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom pathlib import Path\n\nimport polars as pl\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\n# XGBoost, CatBoost, LightGBM\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor\nimport lightgbm as lgb\n\n\ncomp_path = Path('/kaggle/input/um-game-playing-strength-of-mcts-variants')","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:24:05.803489Z","iopub.execute_input":"2024-09-06T06:24:05.80397Z","iopub.status.idle":"2024-09-06T06:24:08.733151Z","shell.execute_reply.started":"2024-09-06T06:24:05.803921Z","shell.execute_reply":"2024-09-06T06:24:08.732107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Critical import","metadata":{}},{"cell_type":"code","source":"import kaggle_evaluation.mcts_inference_server","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:24:08.735028Z","iopub.execute_input":"2024-09-06T06:24:08.735545Z","iopub.status.idle":"2024-09-06T06:24:08.962203Z","shell.execute_reply.started":"2024-09-06T06:24:08.735506Z","shell.execute_reply":"2024-09-06T06:24:08.961171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building a model\n\nThis example trains a model inline, but you will probably want to train a model offline, import it, and just use the notebook for inference.\n\nIt's wrapped in a function because this Code format requires you to get to the `predict` function within 15 minutes. So, if you have something expensive to do up-front (e.g., training a model, loading a model, etc.), and it will take longer than 15 minutes, those operations need to happen in the first call of `predict` so the gateway server doesn't time out.","metadata":{}},{"cell_type":"code","source":"def rmse(y_true, y_pred):\n    return sqrt(mean_squared_error(y_true, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:24:08.963289Z","iopub.execute_input":"2024-09-06T06:24:08.963777Z","iopub.status.idle":"2024-09-06T06:24:08.969138Z","shell.execute_reply.started":"2024-09-06T06:24:08.963741Z","shell.execute_reply":"2024-09-06T06:24:08.967917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:24:08.971587Z","iopub.execute_input":"2024-09-06T06:24:08.971945Z","iopub.status.idle":"2024-09-06T06:24:08.982692Z","shell.execute_reply.started":"2024-09-06T06:24:08.971887Z","shell.execute_reply":"2024-09-06T06:24:08.981707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pwd","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:24:08.983994Z","iopub.execute_input":"2024-09-06T06:24:08.984336Z","iopub.status.idle":"2024-09-06T06:24:08.99602Z","shell.execute_reply.started":"2024-09-06T06:24:08.984304Z","shell.execute_reply":"2024-09-06T06:24:08.994798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = 'utility_agent1'\n\n# 读取数据\ntrain = pl.read_csv(comp_path / 'train.csv')\ny_train = train[target]\n\n# 删除不需要的列\ncols_to_drop = ['num_draws_agent1', 'num_losses_agent1', 'num_wins_agent1', target]\ntrain = train.drop(cols_to_drop)\n\n# 提取字符串类型的列进行编码\nobj_cols = train.select(pl.col(pl.String)).columns\nenc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-999, encoded_missing_value=-9999)\nenc.fit(train[obj_cols])\ntrain_transformed = enc.transform(train[obj_cols])\n\nfor e, c in enumerate(obj_cols):\n    train = train.with_columns(pl.Series(c, train_transformed[:, e]))\n\n# 划分训练集和测试集\nX_train, X_test, y_train_split, y_test_split = train_test_split(train, y_train, test_size=0.2, random_state=42)\n\nglobal best_model\n    \n# 定义模型\nmodels = {\n        \"RandomForest\": RandomForestRegressor(n_estimators=100, max_depth=5, n_jobs=-1),\n        \"ExtraTrees\": ExtraTreesRegressor(n_estimators=100, max_depth=5, n_jobs=-1),\n        \"XGBoost\": xgb.XGBRegressor(n_estimators=100, max_depth=5, n_jobs=-1),\n        \"LightGBM\": lgb.LGBMRegressor(n_estimators=100, max_depth=5, n_jobs=-1)\n}\n\n# 存储模型的 RMSE\nrmse_scores = {}\n\n# 训练并评估每个模型\nfor model_name, model in models.items():\n    model.fit(X_train, y_train_split)\n    y_pred = model.predict(X_test)\n    rmse_scores[model_name] = rmse(y_test_split, y_pred)\n    print(f'{model_name} RMSE: {rmse_scores[model_name]:.4f}')\n\n# 找到RMSE最低的模型\nbest_model_name = min(rmse_scores, key=rmse_scores.get)\nglobal best_model\nbest_model = models[best_model_name]\nprint(f'Best model: {best_model_name} with RMSE: {rmse_scores[best_model_name]:.4f}')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-06T06:24:08.997332Z","iopub.execute_input":"2024-09-06T06:24:08.997686Z","iopub.status.idle":"2024-09-06T06:35:45.834891Z","shell.execute_reply.started":"2024-09-06T06:24:08.997651Z","shell.execute_reply":"2024-09-06T06:35:45.833656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef train_and_evaluate():\n    pass","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:36:10.308824Z","iopub.execute_input":"2024-09-06T06:36:10.309814Z","iopub.status.idle":"2024-09-06T06:36:10.314506Z","shell.execute_reply.started":"2024-09-06T06:36:10.309771Z","shell.execute_reply":"2024-09-06T06:36:10.313147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference should be in a function named `predict` as similar to the following:\n\nIf you're not doing anything \"expensive\" in the first `predict` call, you don't technically need the counter code.","metadata":{}},{"cell_type":"code","source":"counter = 0\ndef predict(test, submission):\n    global counter\n    if counter == 0:\n        # Perform any additional slow steps in the first call to `predict`\n        train_and_evaluate()\n    counter += 1    \n    test_transformed = enc.transform(test[obj_cols])\n    for e, c in enumerate(obj_cols):\n        test = test.with_columns(pl.Series(c, test_transformed[:, e]))\n    return submission.with_columns(pl.Series(target, best_model.predict(test)))","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:36:11.614874Z","iopub.execute_input":"2024-09-06T06:36:11.615318Z","iopub.status.idle":"2024-09-06T06:36:11.621999Z","shell.execute_reply.started":"2024-09-06T06:36:11.61528Z","shell.execute_reply":"2024-09-06T06:36:11.620749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Calling the gateway server\n\nYou must run the cell below within 15 minutes of the notebook re-run or the gateway will throw an error. If you need more than 15 minutes time to load your model, train your model, etc, you should do it during the very first `predict` call, as shown previously.","metadata":{}},{"cell_type":"code","source":"inference_server = kaggle_evaluation.mcts_inference_server.MCTSInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv',\n            '/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv'\n        )\n    )","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:36:13.181206Z","iopub.execute_input":"2024-09-06T06:36:13.18238Z","iopub.status.idle":"2024-09-06T06:36:13.269703Z","shell.execute_reply.started":"2024-09-06T06:36:13.182338Z","shell.execute_reply":"2024-09-06T06:36:13.268855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that nothing past `inference_server.serve()` will be run when your submission is evaluated on the hidden test set.","metadata":{}}]}