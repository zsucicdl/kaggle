{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70089,"databundleVersionId":9515283,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Created by <a href=\"https://github.com/yunsuxiaozi/\">yunsuxiaozi </a>  2024/9/20\n\n#### Currently, the top two contestants in the competition have changed their names to 'trust LB'.\n\n#### So is LB really worthy of our trust? In this notebook, I will conduct experiments on this issue.\n\n\n#### This experiment was learned from the just concluded <a href=\"https://www.kaggle.com/competitions/isic-2024-challenge/overview\">ISIC2024 competition</a>, and the code is as follows:<a href=\"https://www.kaggle.com/code/richolson/isic-2024-shake-up-lb-overfitting-simulator\">ISIC 2024 Shake Up / LB Overfitting Simulator</a>.\n\n\n#### Hint:\n\n- 1.Regarding this issue, if you have any other experiments that interest you, you can leave a message in the discussion section, and I will continuously improve this notebook.\n\n- 2.If you find any errors in my code or have any better suggestions, please feel free to point them out.\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Import Libraries</h1></span>","metadata":{}},{"cell_type":"code","source":"import polars as pl#和pandas类似,但是处理大型数据集有更好的性能.\nimport pandas as pd#导入csv文件的库\nimport numpy as np#对矩阵进行科学计算的库\nimport warnings#避免一些可以忽略的报错\nwarnings.filterwarnings('ignore')#filterwarnings()方法是用于设置警告过滤器的方法，它可以控制警告信息的输出方式和级别。\n\nimport random#提供了一些用于生成随机数的函数\n#设置随机种子,保证模型可以复现\ndef seed_everything(seed):\n    np.random.seed(seed)#numpy的随机种子\n    random.seed(seed)#python内置的随机种子\nseed_everything(seed=2024)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">random sample test data</h1></span>\n\n####  In the data introduction, it is mentioned that there are approximately 60000 test data. Here, we sample 60000 training data, and since each data comes from a different game, we sample based on the game.","metadata":{}},{"cell_type":"code","source":"train=pl.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv\")\ntrain=train.to_pandas()\nprint(f\"len(train):{len(train)}\")\n\n#采样大约60000的数据,考虑一次采样1种游戏\nunique_games=list(train['GameRulesetName'].unique())\nnp.random.shuffle(unique_games)\ntest=train[train['GameRulesetName'].isin(unique_games[:360])].sort_values(['GameRulesetName']).reset_index(drop=True)\n\nprint(f\"len(test):{len(test)}\")\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">public private split</h1></span>\n\n#### Since the sampling of the test data is already random, we will divide it directly according to 0.35.","metadata":{}},{"cell_type":"code","source":"test_games=list(test['GameRulesetName'].unique())\nsplit=list(test[test['GameRulesetName']==test_games[128]].index)[0]\nprint(f\"public_private_split:{split/len(test)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">public private distribution</h1></span>\n\n#### We can observe that the distributions of LB, final, and train each have their own characteristics.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.kdeplot(train['utility_agent1'].values,label='train')\nsns.kdeplot(test[:split]['utility_agent1'].values,label='LB')\nsns.kdeplot(test[split:]['utility_agent1'].values,label='final')\n# 显示图例\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">public private score</h1></span>\n\n#### Here, we increase the RMSE of LB to the desired size by adding noise to the target, and observe the final score at this point.","metadata":{}},{"cell_type":"code","source":"test['pred']=test['utility_agent1']\ndef RMSE(y_true,y_pred):\n    return np.sqrt(np.mean((y_true-y_pred)**2))\ndef find_final_score(test,split,LB):#测试数据test根据split划分LB和final,输入LB的分数,看看final_score为多少\n    test_copy=test.copy()\n    LB_score=RMSE(test_copy[:split]['utility_agent1'].values,test_copy[:split]['pred'].values)\n    while LB_score<LB:\n        test_copy['pred']=test_copy['pred']+np.random.normal(loc=0, scale=0.5*(LB-LB_score+0.05), size=len(test))\n        test_copy['pred']=test_copy['pred'].clip(-1,1)\n        LB_score=RMSE(test_copy[:split]['utility_agent1'].values,test_copy[:split]['pred'].values)\n        final_score=RMSE(test_copy[split:]['utility_agent1'].values,test_copy[split:]['pred'].values)\n    return final_score\nLB=0.434\nfinal_score=find_final_score(test,split,LB=LB)\nprint(f\"LB_score:{LB},final_score:{final_score}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">public private Correlation</h1></span>\n\n#### Here, through multiple experiments, we will examine the correlation between public rankings and final scores.\n\n#### We can observe that final_stcore is slightly larger than LB, and there is still a clear correlation between them.","metadata":{}},{"cell_type":"code","source":"LB=[num/1000 for num in range(430,440)]*20\nfinal_scores=[]\nfor lb in LB:\n    final_scores.append(find_final_score(test,split,LB=lb))\nplt.xlim(0.425,0.455)\nplt.ylim(0.425,0.455)\nplt.scatter(LB,final_scores)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### By calculating the Pearson correlation coefficient, it can also be found that there is a high correlation between LB and final_stcore.","metadata":{}},{"cell_type":"code","source":"df=pd.DataFrame({'LB':LB,'final':final_scores})\ndf.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Do you think we can trust LB?","metadata":{}}]}