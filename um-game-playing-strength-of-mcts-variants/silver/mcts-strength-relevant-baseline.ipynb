{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70089,"databundleVersionId":9515283,"sourceType":"competition"},{"sourceId":9341631,"sourceType":"datasetVersion","datasetId":5661348}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## MCTS-Strength | Relevant Baseline\nThis notebook aims at providing a neat reusable baseline for training regressors, without any redundant code that may make it harder to understand the key concepts. It surely is not complete nor comprehensive.\n\nInspired by: \n- https://www.kaggle.com/competitions/um-game-playing-strength-of-mcts-variants/discussion/532341\n- https://www.kaggle.com/code/andreasbis/um-mcts-lightgbm-baseline\n\nThe key added features are: \n- **split_agent_features** which converts agent names to four categorical features covering their component characteristics\n- **GroupKFold** with *GameRulesetName* used as the group - motivated by the clue that the test sets contain the same agent types but different set of games (see this [Best Single Model CV LB thread](https://www.kaggle.com/competitions/um-game-playing-strength-of-mcts-variants/discussion/532617)) - this seems to give CV results much closer to those achieved in Private LB","metadata":{"execution":{"iopub.status.busy":"2024-09-07T06:06:10.13405Z","iopub.execute_input":"2024-09-07T06:06:10.134575Z","iopub.status.idle":"2024-09-07T06:06:10.149152Z","shell.execute_reply.started":"2024-09-07T06:06:10.134515Z","shell.execute_reply":"2024-09-07T06:06:10.147117Z"}}},{"cell_type":"code","source":"import os\nimport sys\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport polars as pl\nimport pandas as pd\nfrom sklearn.model_selection import GroupKFold\nimport lightgbm as lgb\nfrom lightgbm import early_stopping, log_evaluation\n\nimport kaggle_evaluation.mcts_inference_server","metadata":{"execution":{"iopub.status.busy":"2024-09-08T00:08:34.885093Z","iopub.execute_input":"2024-09-08T00:08:34.886282Z","iopub.status.idle":"2024-09-08T00:08:34.896468Z","shell.execute_reply.started":"2024-09-08T00:08:34.886213Z","shell.execute_reply":"2024-09-08T00:08:34.895051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"constant_cols = pd.read_csv('/kaggle/input/um-gps-of-mcts-variants-constant-columns/constant_columns.csv').columns.to_list()\ngame_col = 'GameRulesetName'\ntarget_col = 'utility_agent1'\ngame_rule_cols = ['EnglishRules', 'LudRules']\noutput_cols = ['num_wins_agent1', 'num_draws_agent1', 'num_losses_agent1']\nagent_cols = ['agent1', 'agent2']\ndropped_cols = ['Id'] + output_cols + constant_cols + game_rule_cols","metadata":{"execution":{"iopub.status.busy":"2024-09-08T00:08:35.025681Z","iopub.execute_input":"2024-09-08T00:08:35.026174Z","iopub.status.idle":"2024-09-08T00:08:35.070895Z","shell.execute_reply.started":"2024-09-08T00:08:35.026132Z","shell.execute_reply":"2024-09-08T00:08:35.069657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    train_path = '/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv'\n    \n    early_stop = 100\n    n_splits = 5\n    split_agent_features = True\n    \n    lgbm_params = {\n#         num_boost_round: \n#         - big enough to ensure early_stopping is triggerd in most cases\n#         - but small enough not to take forever to compute in case it isn't\n        'num_boost_round': 10_000,\n        'seed': 1212,\n        'verbose': -1,\n#         Some common params to experiment with (here are default values):\n#         The full list: https://lightgbm.readthedocs.io/en/latest/Parameters.html\n        \n#         'learning_rate': 0.1,\n#         'reg_lambda': 0.0,\n#         'num_leaves': 31,\n#         'max_depth': -1,\n#         'max_bin': 255,\n#         'extra_trees': False,\n    }","metadata":{"execution":{"iopub.status.busy":"2024-09-08T00:08:35.185331Z","iopub.execute_input":"2024-09-08T00:08:35.185963Z","iopub.status.idle":"2024-09-08T00:08:35.192738Z","shell.execute_reply.started":"2024-09-08T00:08:35.185915Z","shell.execute_reply":"2024-09-08T00:08:35.191437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(df): \n    df = df.drop(filter(lambda x: x in df.columns, dropped_cols))\n    if Config.split_agent_features:\n        for col in agent_cols:\n            df = df.with_columns(pl.col(col).str.split(by=\"-\").list.to_struct(fields=lambda idx: f\"{col}_{idx}\")).unnest(col).drop(f\"{col}_0\")\n    df = df.with_columns([pl.col(col).cast(pl.Categorical) for col in df.columns if col[:6] in agent_cols])            \n    df = df.with_columns([pl.col(col).cast(pl.Float32) for col in df.columns if col[:6] not in agent_cols and col != game_col])\n    return df.to_pandas()","metadata":{"execution":{"iopub.status.busy":"2024-09-08T00:08:35.329236Z","iopub.execute_input":"2024-09-08T00:08:35.329647Z","iopub.status.idle":"2024-09-08T00:08:35.339028Z","shell.execute_reply.started":"2024-09-08T00:08:35.329613Z","shell.execute_reply":"2024-09-08T00:08:35.337006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_lgb(data):\n    X = data.drop([target_col, game_col], axis=1)\n    y = data[target_col]\n    groups = data[game_col]\n\n    cv = GroupKFold(n_splits=Config.n_splits)\n    models = []\n    for fi, (train_idx, valid_idx) in enumerate(cv.split(X, y, groups)):\n        print(f'Fold {fi+1}/{Config.n_splits} ...')\n        model = lgb.LGBMRegressor(**Config.lgbm_params)\n        model.fit(X.iloc[train_idx], y.iloc[train_idx],\n                  eval_set=[(X.iloc[valid_idx], y.iloc[valid_idx])],\n                  eval_metric='rmse',\n                  callbacks=[lgb.early_stopping(Config.early_stop)])\n        models.append(model)\n    return models\n\ndef infer_lgb(data, models):\n    return np.mean([model.predict(data) for model in models], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T00:08:35.473076Z","iopub.execute_input":"2024-09-08T00:08:35.473533Z","iopub.status.idle":"2024-09-08T00:08:35.482726Z","shell.execute_reply.started":"2024-09-08T00:08:35.473491Z","shell.execute_reply":"2024-09-08T00:08:35.481418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission via the competition API\nWe follow https://www.kaggle.com/code/sohier/mcts-demo-submission/ \\\nWe add **run_i** global counter to train (or load) models in the first **predict** call, which is not limited to 10 minutes runtime.\n    ","metadata":{}},{"cell_type":"code","source":"run_i = 0\ndef predict(test_data, submission):\n    global run_i, models\n    if run_i == 0:\n        train_df = pl.read_csv(Config.train_path)\n        models = train_lgb(preprocess_data(train_df))\n    run_i += 1\n    \n    test_data = preprocess_data(test_data).drop(columns=game_col)\n    return submission.with_columns(pl.Series(target_col, infer_lgb(test_data, models)))\n\ninference_server = kaggle_evaluation.mcts_inference_server.MCTSInferenceServer(predict)\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv',\n            '/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv'\n        )\n    )","metadata":{"execution":{"iopub.status.busy":"2024-09-08T00:08:36.434951Z","iopub.execute_input":"2024-09-08T00:08:36.435411Z","iopub.status.idle":"2024-09-08T00:09:26.434985Z","shell.execute_reply.started":"2024-09-08T00:08:36.43537Z","shell.execute_reply":"2024-09-08T00:09:26.433306Z"},"trusted":true},"execution_count":null,"outputs":[]}]}