{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":82695,"databundleVersionId":9738540,"sourceType":"competition"},{"sourceId":9502328,"sourceType":"datasetVersion","datasetId":5755831},{"sourceId":9503395,"sourceType":"datasetVersion","datasetId":5750064},{"sourceId":9534632,"sourceType":"datasetVersion","datasetId":5784947},{"sourceId":199269375,"sourceType":"kernelVersion"}],"dockerImageVersionId":30776,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## About this notebook\n\nThe idea behind this notebook is inspired by [**Eedi | Ensemble of solutions**](https://www.kaggle.com/code/vyacheslavbolotin/eedi-ensemble-of-solutions). I wanted to experiment with three different sentence transformer models and apply a voting ensemble to see if the score improves.\n\nI am only sharing the model weights to preserve the integrity of the competition, and I hope this notebook helps the Kaggle community.\n\n## Individual model LB scores\n- `BAAI/bge-large-en-v1.5` → `LB=0.257`\n- `sentence-transformers/all-mpnet-base-v2` → `LB=0.251`\n- `Alibaba-NLP/gte-base-en-v1.5` → `LB=0.281`\n\nI encountered the same issue mentioned [here](https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/discussion/536640). You can find a workaround in this [notebook](https://www.kaggle.com/code/medali1992/modified-gte-base-weights/notebook), where I solved the problem (I used this [link](https://huggingface.co/Alibaba-NLP/new-impl/discussions/2)).\n\nOnce again, this is an experimental notebook, and I hope it inspires some novel ideas.\n\n## Version2\nI replaced the mode ensembling with random choice `LB=0.227`\n\n## Version3\nI used a bad bge_weights(should be version2 not version3) still no improvement `LB=0.243`\n## Version 4\nI apply mean average on the embeddings (truncate to dim=768), we can see some improvement `LB=0.282`\n\n## Version 5\n\nI apply mean average on the embeddings (padding to dim=1024)\n\n## Version 6\nConcatenate the embeddings into one vector.","metadata":{}},{"cell_type":"markdown","source":"# Setting","metadata":{}},{"cell_type":"code","source":"K=25\nVER=5\nBS=16\nD = 1024\n\n\nDATA_PATH = \"/kaggle/input/eedi-mining-misconceptions-in-mathematics\"\nBGE_MODEL_PATH = \"/kaggle/input/bge-weights-version1/bge_trained_model_version3\"\nGTE_BASE_MODEL_PATH = \"/kaggle/input/mod-gte-base-weights/gte-base-weights/gte-base_trained_model_version2\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-11T10:06:25.355282Z","iopub.execute_input":"2024-10-11T10:06:25.355822Z","iopub.status.idle":"2024-10-11T10:06:25.365978Z","shell.execute_reply.started":"2024-10-11T10:06:25.355788Z","shell.execute_reply":"2024-10-11T10:06:25.365016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Install","metadata":{}},{"cell_type":"code","source":"!pip uninstall -qq -y \\\npolars","metadata":{"execution":{"iopub.status.busy":"2024-10-11T10:06:25.368222Z","iopub.execute_input":"2024-10-11T10:06:25.368523Z","iopub.status.idle":"2024-10-11T10:06:28.252042Z","shell.execute_reply.started":"2024-10-11T10:06:25.368491Z","shell.execute_reply":"2024-10-11T10:06:28.250809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m pip install -qq --no-index --find-links=/kaggle/input/eedi-library-from-sinchiro \\\npolars\\\nsentence-transformers\\\nfaiss-gpu","metadata":{"execution":{"iopub.status.busy":"2024-10-11T10:06:28.255416Z","iopub.execute_input":"2024-10-11T10:06:28.255855Z","iopub.status.idle":"2024-10-11T10:06:44.688766Z","shell.execute_reply.started":"2024-10-11T10:06:28.255815Z","shell.execute_reply":"2024-10-11T10:06:44.687677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import ","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\n\nimport polars as pl\nimport numpy as np\nfrom scipy import stats\nimport torch\nimport torch.nn.functional as F\n\nimport faiss\n\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sentence_transformers import SentenceTransformer\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-10-11T10:06:44.690483Z","iopub.execute_input":"2024-10-11T10:06:44.690931Z","iopub.status.idle":"2024-10-11T10:07:03.973283Z","shell.execute_reply.started":"2024-10-11T10:06:44.690882Z","shell.execute_reply":"2024-10-11T10:07:03.972426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sentence_transformers\n\nassert pl.__version__ == \"1.7.1\"\nassert sentence_transformers.__version__ == \"3.1.1\"","metadata":{"execution":{"iopub.status.busy":"2024-10-11T10:07:03.975488Z","iopub.execute_input":"2024-10-11T10:07:03.97622Z","iopub.status.idle":"2024-10-11T10:07:03.980845Z","shell.execute_reply.started":"2024-10-11T10:07:03.97618Z","shell.execute_reply":"2024-10-11T10:07:03.979786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Load","metadata":{}},{"cell_type":"code","source":"test = pl.read_csv(f\"{DATA_PATH}/test.csv\")\nmisconception_mapping = pl.read_csv(f\"{DATA_PATH}/misconception_mapping.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-11T10:07:03.984973Z","iopub.execute_input":"2024-10-11T10:07:03.985382Z","iopub.status.idle":"2024-10-11T10:07:04.274237Z","shell.execute_reply.started":"2024-10-11T10:07:03.985338Z","shell.execute_reply":"2024-10-11T10:07:04.273401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess","metadata":{}},{"cell_type":"code","source":"common_col = [\n    \"QuestionId\",\n    \"ConstructName\",\n    \"SubjectName\",\n    \"QuestionText\",\n    \"CorrectAnswer\",\n]\n\ntest_long = (\n    test\n    .select(\n        pl.col(common_col + [f\"Answer{alpha}Text\" for alpha in [\"A\", \"B\", \"C\", \"D\"]])\n    )\n    .unpivot(\n        index=common_col,\n        variable_name=\"AnswerType\",\n        value_name=\"AnswerText\",\n    )\n    .with_columns(\n        pl.concat_str(\n            [\n               '<Construct> ' +  pl.col(\"ConstructName\"),\n               '<Subject> ' + pl.col(\"SubjectName\"),\n               '<Question> '+ pl.col(\"QuestionText\"),\n               '<Answer> ' + pl.col(\"AnswerText\"),\n            ],\n            separator=\" \",\n        ).alias(\"AllText\"),\n        pl.col(\"AnswerType\").str.extract(r\"Answer([A-D])Text$\").alias(\"AnswerAlphabet\"),\n    )\n    .with_columns(\n        pl.concat_str(\n            [pl.col(\"QuestionId\"), pl.col(\"AnswerAlphabet\")], separator=\"_\"\n        ).alias(\"QuestionId_Answer\"),\n    )\n    .sort(\"QuestionId_Answer\")\n)\ntest_long.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-11T10:07:04.275448Z","iopub.execute_input":"2024-10-11T10:07:04.275768Z","iopub.status.idle":"2024-10-11T10:07:04.298535Z","shell.execute_reply.started":"2024-10-11T10:07:04.275735Z","shell.execute_reply":"2024-10-11T10:07:04.297638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentence transformer models","metadata":{}},{"cell_type":"markdown","source":"### Utils","metadata":{}},{"cell_type":"code","source":"def encode_texts(test_long, misconception_mapping, model_path, batch_size=8, progress_bar=True):\n    model = SentenceTransformer(model_path, local_files_only=True, trust_remote_code=True)\n    model.to(device)\n    # wrap the model to use all GPUs\n    model = torch.nn.DataParallel(model)\n    model.eval()\n    \n    # Encode all text from the test_long DataFrame\n    all_text_vec = model.module.encode(test_long[\"AllText\"].to_list(), batch_size=batch_size , normalize_embeddings=True, show_progress_bar=progress_bar)\n    \n    # Encode misconception names from the misconception_mapping DataFrame\n    misconception_mapping_vec = model.module.encode(misconception_mapping[\"MisconceptionName\"].to_list(), batch_size=batch_size, normalize_embeddings=True, show_progress_bar=progress_bar)\n    \n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    return all_text_vec, misconception_mapping_vec\n\ndef search_faiss(k, d, vectors_to_add, query_vectors):\n    \"\"\"\n    Perform a FAISS search with L2 distance.\n    \n    Parameters:\n        k (int): Number of nearest neighbors to search for.\n        d (int): Dimension of the vectors.\n        vectors_to_add (numpy.ndarray): The vectors to add to the FAISS index.\n        query_vectors (numpy.ndarray): The vectors to search for the nearest neighbors.\n        \n    Returns:\n        D (numpy.ndarray): The distances to the k nearest neighbors.\n        I (numpy.ndarray): The indices of the k nearest neighbors.\n    \"\"\"\n    # Create the index\n    index = faiss.IndexFlatL2(d)\n    \n    # Add vectors to the index\n    index.add(vectors_to_add)\n    \n    # Search for k nearest neighbors\n    D, I = index.search(query_vectors, k)\n    \n    return D, I\n\ndef ensemble_majority_vote(*indices):\n    \"\"\"\n    Apply ensembling with majority voting across multiple index arrays.\n    \n    Parameters:\n        indices (numpy.ndarray): Variable number of index arrays to ensemble.\n        \n    Returns:\n        numpy.ndarray: The majority-voted indices.\n    \"\"\"\n    # Stack indices along a new axis (shape: (num_searches, num_queries, k))\n    stacked_indices = np.stack(indices, axis=0)\n    \n    # Apply mode to find the majority vote along the first axis (searches)\n    majority_indices, _ = stats.mode(stacked_indices, axis=0)\n    \n    # Remove the extra dimension added by mode and return the majority-voted indices\n    return majority_indices.squeeze()\n\ndef ensemble_random_choice(*indices):\n    \"\"\"\n    Apply ensembling with random choice across multiple index arrays.\n    \n    Parameters:\n        indices (numpy.ndarray): Variable number of index arrays to ensemble.\n        \n    Returns:\n        numpy.ndarray: Randomly selected indices from the given index arrays.\n    \"\"\"\n    # Stack indices along a new axis (shape: (num_searches, num_queries, k))\n    stacked_indices = np.stack(indices, axis=0)\n    \n    # Number of searches (i.e., how many index arrays we have)\n    num_searches = stacked_indices.shape[0]\n    \n    # Randomly choose indices from the 3 arrays\n    # For each query and each nearest neighbor (k), randomly select an index from the available searches\n    random_choices = np.random.randint(0, num_searches, size=stacked_indices.shape[1:])\n    \n    # Use the random choices to pick the corresponding indices\n    random_indices = np.choose(random_choices, stacked_indices)\n    \n    return random_indices","metadata":{"execution":{"iopub.status.busy":"2024-10-11T10:07:04.300036Z","iopub.execute_input":"2024-10-11T10:07:04.300317Z","iopub.status.idle":"2024-10-11T10:07:04.312369Z","shell.execute_reply.started":"2024-10-11T10:07:04.300286Z","shell.execute_reply":"2024-10-11T10:07:04.311299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GTE-base Model","metadata":{}},{"cell_type":"code","source":"gte_base_all_text_vec, gte_misconception_mapping_vec = encode_texts(test_long, misconception_mapping, GTE_BASE_MODEL_PATH, BS)\ngte_base_all_text_vec = np.pad(gte_base_all_text_vec, ((0, 0), (0, 256)), mode='constant')\ngte_misconception_mapping_vec = np.pad(gte_misconception_mapping_vec, ((0, 0), (0, 256)), mode='constant')\nprint(gte_base_all_text_vec.shape)\nprint(gte_misconception_mapping_vec.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T10:07:04.313876Z","iopub.execute_input":"2024-10-11T10:07:04.314316Z","iopub.status.idle":"2024-10-11T10:07:15.407354Z","shell.execute_reply.started":"2024-10-11T10:07:04.31427Z","shell.execute_reply":"2024-10-11T10:07:15.406381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## BGE Model","metadata":{}},{"cell_type":"code","source":"bge_base_all_text_vec, bge_misconception_mapping_vec = encode_texts(test_long, misconception_mapping, BGE_MODEL_PATH, BS)\nprint(bge_base_all_text_vec.shape)\nprint(bge_misconception_mapping_vec.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T10:07:15.408806Z","iopub.execute_input":"2024-10-11T10:07:15.409226Z","iopub.status.idle":"2024-10-11T10:07:38.219054Z","shell.execute_reply.started":"2024-10-11T10:07:15.409178Z","shell.execute_reply":"2024-10-11T10:07:38.218016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model ensemble","metadata":{}},{"cell_type":"code","source":"ensemble_text_vecs = np.mean(np.stack([gte_base_all_text_vec, bge_base_all_text_vec]), axis=0)\nensemble_misconception_vecs = np.mean(np.stack([gte_misconception_mapping_vec, bge_misconception_mapping_vec]), axis=0)\n_, ensemble_indices = search_faiss(K, D, ensemble_misconception_vecs, ensemble_text_vecs)\nprint(ensemble_text_vecs.shape)\nprint(ensemble_misconception_vecs.shape)\nprint(ensemble_indices.shape)\n\ndel ensemble_text_vecs, ensemble_misconception_vecs, gte_base_all_text_vec, bge_base_all_text_vec, gte_misconception_mapping_vec \n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-10-11T10:07:38.222519Z","iopub.execute_input":"2024-10-11T10:07:38.222962Z","iopub.status.idle":"2024-10-11T10:07:38.590163Z","shell.execute_reply.started":"2024-10-11T10:07:38.222925Z","shell.execute_reply":"2024-10-11T10:07:38.589052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make Submit File","metadata":{}},{"cell_type":"code","source":"submission = (\n    test_long.with_columns(\n        pl.Series(ensemble_indices[:, :25].tolist()).alias(\"MisconceptionId\")\n    )\n    .with_columns(\n        pl.col(\"MisconceptionId\").map_elements(\n            lambda x: \" \".join(map(str, x)), return_dtype=pl.String\n        )\n    ).filter(\n        pl.col(\"CorrectAnswer\") != pl.col(\"AnswerAlphabet\")\n    ).select(\n        pl.col([\"QuestionId_Answer\", \"MisconceptionId\"])\n    ).sort(\"QuestionId_Answer\")\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T10:07:38.591677Z","iopub.execute_input":"2024-10-11T10:07:38.592028Z","iopub.status.idle":"2024-10-11T10:07:38.603867Z","shell.execute_reply.started":"2024-10-11T10:07:38.591991Z","shell.execute_reply":"2024-10-11T10:07:38.602842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-11T10:07:38.605205Z","iopub.execute_input":"2024-10-11T10:07:38.606171Z","iopub.status.idle":"2024-10-11T10:07:38.613099Z","shell.execute_reply.started":"2024-10-11T10:07:38.606119Z","shell.execute_reply":"2024-10-11T10:07:38.611871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.write_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-11T10:07:38.614532Z","iopub.execute_input":"2024-10-11T10:07:38.614969Z","iopub.status.idle":"2024-10-11T10:07:38.620092Z","shell.execute_reply.started":"2024-10-11T10:07:38.614921Z","shell.execute_reply":"2024-10-11T10:07:38.619207Z"},"trusted":true},"execution_count":null,"outputs":[]}]}