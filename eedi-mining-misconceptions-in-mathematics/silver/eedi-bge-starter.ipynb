{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":82695,"databundleVersionId":9551816,"sourceType":"competition"},{"sourceId":27644,"sourceType":"modelInstanceVersion","modelInstanceId":23286,"modelId":33601}],"dockerImageVersionId":30762,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:19:10.796614Z","iopub.execute_input":"2024-09-15T16:19:10.796939Z","iopub.status.idle":"2024-09-15T16:19:10.803654Z","shell.execute_reply.started":"2024-09-15T16:19:10.796906Z","shell.execute_reply":"2024-09-15T16:19:10.80272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nimport re\nfrom scipy.spatial.distance import cdist\n\n# Data Loading\ntrain = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\nmisconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n\n# Load the model and tokenizer\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ntokenizer = AutoTokenizer.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\nmodel = AutoModel.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\nmodel.to(device)\n\n# Function to generate embeddings\ndef generate_embeddings(texts, model, tokenizer, device, batch_size=8):\n    all_embeddings = []\n    for i in range(0, len(texts), batch_size):\n        batch_texts = texts[i:i+batch_size]\n        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=1024).to(device)\n        with torch.no_grad():\n            outputs = model(**inputs)\n        embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n        all_embeddings.append(embeddings.cpu().numpy())\n    return np.concatenate(all_embeddings, axis=0)\n\n# Generate embeddings for misconceptions\nMisconceptionName = list(misconception_mapping['MisconceptionName'].values)\nall_ctx_vector = generate_embeddings(MisconceptionName, model, tokenizer, device)\n\ndef preprocess_text(text):\n    # Convert to lowercase\n    text = text.lower()\n    # Remove special characters and digits\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n    # Remove extra whitespace\n    text = ' '.join(text.split())\n    return text\n\n# Prepare test data\ndef make_all_question_text(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"all_question_text\"] = df[\"ConstructName\"] + \" \" + df[\"QuestionText\"]\n    df[\"all_question_text\"] = df[\"all_question_text\"].apply(preprocess_text)\n    return df\n\ntest = make_all_question_text(test)\n\ndef wide_to_long(df: pd.DataFrame) -> pd.DataFrame:\n    df = pd.melt(\n        df[\n            [\n                \"QuestionId\",\n                \"all_question_text\",\n                \"CorrectAnswer\",\n                \"AnswerAText\",\n                \"AnswerBText\",\n                \"AnswerCText\",\n                \"AnswerDText\"\n            ]\n        ],\n        id_vars    = [\"QuestionId\", \"all_question_text\", \"CorrectAnswer\"],\n        var_name   = 'Answer',\n        value_name = 'value'\n    )\n    return df\n\ntest_long = wide_to_long(test)\n\ndef make_all_text(df: pd.DataFrame) -> pd.DataFrame:\n    text_components = []\n    if \"all_question_text\" in df.columns:\n        text_components.append(df[\"all_question_text\"])\n    if \"value\" in df.columns:\n        text_components.append(df[\"value\"].apply(preprocess_text))\n    \n    df[\"all_text\"] = pd.concat(text_components, axis=1).apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n    return df\n\ntest_long = make_all_text(test_long)\ntest_long = test_long.sort_values([\"QuestionId\", \"Answer\"]).reset_index(drop=True)\n\n# Generate embeddings for test data\ntest_texts = list(test_long['all_text'].values)\nall_text_vector = generate_embeddings(test_texts, model, tokenizer, device)\n\n# Compute similarities\ncosine_similarities = cosine_similarity(all_text_vector, all_ctx_vector)\n\n# Euclidean distance\neuclidean_distances = cdist(all_text_vector, all_ctx_vector, metric='euclidean')\neuclidean_similarities = 1 / (1 + euclidean_distances)  # Convert distance to similarity\n\n# Combination of cosine and euclidean\ncombined_similarities = (cosine_similarities + euclidean_similarities) / 2\n\n# Use the combined_similarities for sorting\ntest_sorted_indices = np.argsort(-combined_similarities, axis=1)\n\n# Prepare submission\ntest_long[\"Answer_alphabet\"] = test_long[\"Answer\"].str.extract(r'Answer([A-Z])Text$')\ntest_long[\"QuestionId_Answer\"] = test_long[\"QuestionId\"].astype(\"str\") + \"_\" + test_long[\"Answer_alphabet\"]\ntest_long[\"MisconceptionId\"] = test_sorted_indices[:, :25].tolist()\ntest_long[\"MisconceptionId\"] = test_long[\"MisconceptionId\"].apply(lambda x: ' '.join(map(str, x)))\n# filter correct row\ntest_long = test_long[test_long[\"CorrectAnswer\"] != test_long[\"Answer_alphabet\"]]\nsubmission = test_long[[\"QuestionId_Answer\", \"MisconceptionId\"]].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:24:03.529702Z","iopub.execute_input":"2024-09-15T16:24:03.530547Z","iopub.status.idle":"2024-09-15T16:24:07.131257Z","shell.execute_reply.started":"2024-09-15T16:24:03.530507Z","shell.execute_reply":"2024-09-15T16:24:07.13012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:24:58.246713Z","iopub.execute_input":"2024-09-15T16:24:58.247474Z","iopub.status.idle":"2024-09-15T16:24:58.258315Z","shell.execute_reply.started":"2024-09-15T16:24:58.247431Z","shell.execute_reply":"2024-09-15T16:24:58.257317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)\nprint(\"Submission file created successfully!\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:24:58.792639Z","iopub.execute_input":"2024-09-15T16:24:58.793238Z","iopub.status.idle":"2024-09-15T16:24:58.79931Z","shell.execute_reply.started":"2024-09-15T16:24:58.793199Z","shell.execute_reply":"2024-09-15T16:24:58.798352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat submission.csv","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:25:04.614223Z","iopub.execute_input":"2024-09-15T16:25:04.614612Z","iopub.status.idle":"2024-09-15T16:25:05.666211Z","shell.execute_reply.started":"2024-09-15T16:25:04.614575Z","shell.execute_reply":"2024-09-15T16:25:05.665049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}