{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":82695,"databundleVersionId":9551816,"sourceType":"competition"},{"sourceId":197114197,"sourceType":"kernelVersion"},{"sourceId":27644,"sourceType":"modelInstanceVersion","modelInstanceId":23286,"modelId":33601}],"dockerImageVersionId":30762,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"markdown","source":"This notebook was created with reference to https://www.kaggle.com/code/jaejohn/eedi-bge-starter \n\nI trained the retriever on train set.\n\nPlease let me know if there are any mistakes.\n\nI think more inprovements should be made. I apologize for the unorganized and messy code.","metadata":{}},{"cell_type":"code","source":"#!pip install -q sentence_transformers","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:19:47.174253Z","iopub.execute_input":"2024-09-18T07:19:47.174864Z","iopub.status.idle":"2024-09-18T07:19:47.179738Z","shell.execute_reply.started":"2024-09-18T07:19:47.17482Z","shell.execute_reply":"2024-09-18T07:19:47.178708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nimport re\nfrom scipy.spatial.distance import cdist\n\nimport gc, torch\ndef flush():\n    gc.collect()\n    torch.cuda.empty_cache()\n    \ndevice = torch.device(\"cuda\")\n\ntrain = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\nmisconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:19:47.203633Z","iopub.execute_input":"2024-09-18T07:19:47.203922Z","iopub.status.idle":"2024-09-18T07:19:53.63362Z","shell.execute_reply.started":"2024-09-18T07:19:47.20389Z","shell.execute_reply":"2024-09-18T07:19:53.632506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n    # Convert to lowercase\n    text = text.lower()\n    # Remove special characters and digits\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n    # Remove extra whitespace\n    text = ' '.join(text.split())\n    return text\n\ndef make_all_question_text(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"all_question_text\"] = df[\"ConstructName\"] + \" \" + df[\"QuestionText\"]\n    df[\"all_question_text\"] = df[\"all_question_text\"].apply(preprocess_text)\n    return df\n\ndef wide_to_long_train_ans(df: pd.DataFrame) -> pd.DataFrame:\n    df = pd.melt(\n        df[\n            [\n                \"QuestionId\",\n                \"all_question_text\",\n                \"CorrectAnswer\",\n                \"AnswerAText\",\n                \"AnswerBText\",\n                \"AnswerCText\",\n                \"AnswerDText\",\n                #\"MisconceptionAId\",\n                #\"MisconceptionBId\",\n                #\"MisconceptionCId\",\n                #\"MisconceptionDId\"\n            ]\n        ],\n        id_vars    = [\"QuestionId\", \"all_question_text\", \"CorrectAnswer\"], \n        var_name   = 'Answer',\n        value_name = 'ans_value'\n    )\n    return df\n\ndef wide_to_long_train_mis(df: pd.DataFrame) -> pd.DataFrame:\n    df = pd.melt(\n        df[\n            [\n                \"QuestionId\",\n                \"all_question_text\",\n                \"CorrectAnswer\",\n                #\"AnswerAText\",\n                #\"AnswerBText\",\n                #\"AnswerCText\",\n                #\"AnswerDText\",\n                \"MisconceptionAId\",\n                \"MisconceptionBId\",\n                \"MisconceptionCId\",\n                \"MisconceptionDId\"\n            ]\n        ],\n        id_vars    = [\"QuestionId\", \"all_question_text\", \"CorrectAnswer\"],      \n        var_name   = 'Misconception',\n        value_name = 'mis_value'\n    )\n    return df\n\ndef make_all_text_train(df: pd.DataFrame) -> pd.DataFrame:\n    text_components = []\n    if \"all_question_text\" in df.columns:\n        text_components.append(df[\"all_question_text\"])\n    if \"ans_value\" in df.columns:\n        text_components.append(df[\"ans_value\"].apply(preprocess_text))\n    \n    df[\"all_text\"] = pd.concat(text_components, axis=1).apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:19:53.635551Z","iopub.execute_input":"2024-09-18T07:19:53.635886Z","iopub.status.idle":"2024-09-18T07:19:53.648523Z","shell.execute_reply.started":"2024-09-18T07:19:53.635851Z","shell.execute_reply":"2024-09-18T07:19:53.647607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")\ntrain = make_all_question_text(train)\ntrain_long_ans = make_all_text_train(wide_to_long_train_ans(train))\ntrain_long_mis = make_all_text_train(wide_to_long_train_mis(train))\ntrain_long_ans[\"Id\"] = list(range(len(train_long_ans)))\ntrain_long_mis[\"Id\"] = list(range(len(train_long_mis)))\ntrain_long = pd.merge(train_long_ans, train_long_mis, on=[\"QuestionId\", \"Id\", \"all_question_text\", \"CorrectAnswer\"], how=\"left\")\ntrain_long = train_long.sort_values([\"QuestionId\", \"Misconception\"]).reset_index(drop=True)\ntrain_long.loc[3, \"all_text_x\"]","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:19:53.649858Z","iopub.execute_input":"2024-09-18T07:19:53.65066Z","iopub.status.idle":"2024-09-18T07:19:56.062204Z","shell.execute_reply.started":"2024-09-18T07:19:53.650617Z","shell.execute_reply":"2024-09-18T07:19:56.061256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_long_drop = train_long.dropna(subset=[\"mis_value\"])\ntrain_long_drop[\"mis_value\"] = train_long_drop[\"mis_value\"].astype(int)\ntrain_long_drop","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:19:56.064722Z","iopub.execute_input":"2024-09-18T07:19:56.065067Z","iopub.status.idle":"2024-09-18T07:19:56.091483Z","shell.execute_reply.started":"2024-09-18T07:19:56.065031Z","shell.execute_reply":"2024-09-18T07:19:56.090575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from sentence_transformers import SentenceTransformer, InputExample\n#from sentence_transformers import models, losses\n#from torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:19:56.092932Z","iopub.execute_input":"2024-09-18T07:19:56.093618Z","iopub.status.idle":"2024-09-18T07:19:56.097834Z","shell.execute_reply.started":"2024-09-18T07:19:56.093572Z","shell.execute_reply":"2024-09-18T07:19:56.09673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_retriever = AutoModelForSequenceClassification.from_pretrained(\n#    '/kaggle/input/bge-small-en-v1.5/transformers/bge/2', \n#    num_labels=len(misconception_mapping['MisconceptionName']))\n#tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\n#model_name = '/kaggle/input/bge-small-en-v1.5/transformers/bge/2'\n#word_embedding_model = models.Transformer(model_name)\n#pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n#model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n\n# Define a list with sentences (1k - 100k sentences)\n#train_sentences = list(train_long_drop[\"all_text_x\"])\n\n# Convert train sentences to sentence pairs\n#train_data = [InputExample(texts=[s, s]) for s in train_sentences]\n\n# DataLoader to batch your data\n#train_dataloader = DataLoader(train_data, batch_size=8, shuffle=True)\n\n# Use the denoising auto-encoder loss\n#train_loss = losses.MultipleNegativesRankingLoss(model)\n\n# Call the fit method\n#model.fit(\n#    train_objectives=[(train_dataloader, train_loss)], epochs=1, show_progress_bar=True, use_amp=True\n#)\n\n#model.save(\"output/simcse-model\")\n#model_retriever.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:19:56.099183Z","iopub.execute_input":"2024-09-18T07:19:56.099627Z","iopub.status.idle":"2024-09-18T07:19:56.107171Z","shell.execute_reply.started":"2024-09-18T07:19:56.099577Z","shell.execute_reply":"2024-09-18T07:19:56.10623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from datasets import Dataset\n\n#train_long_drop = train_long.dropna(subset=[\"mis_value\"])\n#train_long_drop[\"mis_value\"] = train_long_drop[\"mis_value\"].astype(int)\n#train_long_drop\n\n# train_model\n#train_data = Dataset.from_pandas(train_long_drop)\n# train_data[\"mis_value\"][10]\n\n#def preproc(example):\n#    encoded_example = tokenizer(example[\"all_text_x\"], max_length=1024)\n#    encoded_example[\"labels\"] = example[\"mis_value\"]\n#    return encoded_example\n\n#encoded_train_data = train_data.map(\n#    preproc,\n#    remove_columns = train_data.column_names\n#)\n\n#encoded_train_data","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:19:56.108383Z","iopub.execute_input":"2024-09-18T07:19:56.109039Z","iopub.status.idle":"2024-09-18T07:19:56.120952Z","shell.execute_reply.started":"2024-09-18T07:19:56.108994Z","shell.execute_reply":"2024-09-18T07:19:56.120185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from transformers import DataCollatorWithPadding\n\n#data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:19:56.1219Z","iopub.execute_input":"2024-09-18T07:19:56.122243Z","iopub.status.idle":"2024-09-18T07:19:56.130463Z","shell.execute_reply.started":"2024-09-18T07:19:56.1222Z","shell.execute_reply":"2024-09-18T07:19:56.12972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from transformers import Trainer, TrainingArguments\n\n#training_args = TrainingArguments(\n#    output_dir=\"/kaggle/working/logs\",\n#    per_device_train_batch_size=32,\n#    fp16=True,learning_rate=1e-4,\n#    lr_scheduler_type=\"cosine\",\n#    report_to=\"none\",\n#    logging_strategy=\"steps\",\n#    logging_steps=50,\n#)\n\n#trainer = Trainer(\n#    model=model_retriever,\n#    tokenizer=tokenizer,\n#    train_dataset = encoded_train_data,\n#    data_collator=data_collator,\n#    args=training_args,\n#)\n\n#trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:19:56.131727Z","iopub.execute_input":"2024-09-18T07:19:56.132747Z","iopub.status.idle":"2024-09-18T07:19:56.140069Z","shell.execute_reply.started":"2024-09-18T07:19:56.132705Z","shell.execute_reply":"2024-09-18T07:19:56.139224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#trainer.save_model()","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:19:56.143125Z","iopub.execute_input":"2024-09-18T07:19:56.143385Z","iopub.status.idle":"2024-09-18T07:19:56.151706Z","shell.execute_reply.started":"2024-09-18T07:19:56.143353Z","shell.execute_reply":"2024-09-18T07:19:56.150816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#text = [\"this is a text\"]\n#inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", max_length=1024).to(device)\n#with torch.no_grad():\n#    outputs = model_retriever(**inputs, output_hidden_states=True)\n#outputs.hidden_states[-1].shape","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:19:56.152781Z","iopub.execute_input":"2024-09-18T07:19:56.15303Z","iopub.status.idle":"2024-09-18T07:19:56.162689Z","shell.execute_reply.started":"2024-09-18T07:19:56.153002Z","shell.execute_reply":"2024-09-18T07:19:56.161802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nimport re\nfrom scipy.spatial.distance import cdist\n\n# Data Loading\ntrain = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\nmisconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n\n# Load the model and tokenizer\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ntokenizer = AutoTokenizer.from_pretrained('/kaggle/input/eedi-simcse-simple-baseline-train/output/simcse-model')\nmodel = AutoModel.from_pretrained('/kaggle/input/eedi-simcse-simple-baseline-train/output/simcse-model')\nmodel.to(device)\n\n# Function to generate embeddings\ndef generate_embeddings(texts, model, tokenizer, device, batch_size=8):\n    all_embeddings = []\n    for i in range(0, len(texts), batch_size):\n        batch_texts = texts[i:i+batch_size]\n        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=1024).to(device)\n        with torch.no_grad():\n            outputs = model(**inputs, output_hidden_states=True)\n        embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n        all_embeddings.append(embeddings.cpu().numpy())\n    return np.concatenate(all_embeddings, axis=0)\n\n# Generate embeddings for misconceptions\nMisconceptionName = list(misconception_mapping['MisconceptionName'].values)\nall_ctx_vector = generate_embeddings(MisconceptionName, model, tokenizer, device)\n\ndef preprocess_text(text):\n    # Convert to lowercase\n    text = text.lower()\n    # Remove special characters and digits\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n    # Remove extra whitespace\n    text = ' '.join(text.split())\n    return text\n\n# Prepare test data\ndef make_all_question_text(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"all_question_text\"] = df[\"ConstructName\"] + \" \" + df[\"QuestionText\"]\n    df[\"all_question_text\"] = df[\"all_question_text\"].apply(preprocess_text)\n    return df\n\ntest = make_all_question_text(test)\n\ndef wide_to_long(df: pd.DataFrame) -> pd.DataFrame:\n    df = pd.melt(\n        df[\n            [\n                \"QuestionId\",\n                \"all_question_text\",\n                \"CorrectAnswer\",\n                \"AnswerAText\",\n                \"AnswerBText\",\n                \"AnswerCText\",\n                \"AnswerDText\"\n            ]\n        ],\n        id_vars    = [\"QuestionId\", \"all_question_text\", \"CorrectAnswer\"],\n        var_name   = 'Answer',\n        value_name = 'value'\n    )\n    return df\n\ntest_long = wide_to_long(test)\n\ndef make_all_text(df: pd.DataFrame) -> pd.DataFrame:\n    text_components = []\n    if \"all_question_text\" in df.columns:\n        text_components.append(df[\"all_question_text\"])\n    if \"value\" in df.columns:\n        text_components.append(df[\"value\"].apply(preprocess_text))\n    \n    df[\"all_text\"] = pd.concat(text_components, axis=1).apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n    return df\n\ntest_long = make_all_text(test_long)\ntest_long = test_long.sort_values([\"QuestionId\", \"Answer\"]).reset_index(drop=True)\n\n# Generate embeddings for test data\ntest_texts = list(test_long['all_text'].values)\nall_text_vector = generate_embeddings(test_texts, model, tokenizer, device)\n\n# Compute similarities\ncosine_similarities = cosine_similarity(all_text_vector, all_ctx_vector)\n\n# Euclidean distance\neuclidean_distances = cdist(all_text_vector, all_ctx_vector, metric='euclidean')\neuclidean_similarities = 1 / (1 + euclidean_distances)  # Convert distance to similarity\n\n# Combination of cosine and euclidean\ncombined_similarities = (cosine_similarities + euclidean_similarities) / 2\n\n# Use the combined_similarities for sorting\ntest_sorted_indices = np.argsort(-combined_similarities, axis=1)\n\n# Prepare submission\ntest_long[\"Answer_alphabet\"] = test_long[\"Answer\"].str.extract(r'Answer([A-Z])Text$')\ntest_long[\"QuestionId_Answer\"] = test_long[\"QuestionId\"].astype(\"str\") + \"_\" + test_long[\"Answer_alphabet\"]\ntest_long[\"MisconceptionId\"] = test_sorted_indices[:, :25].tolist()\ntest_long[\"MisconceptionId\"] = test_long[\"MisconceptionId\"].apply(lambda x: ' '.join(map(str, x)))\n# filter correct row\ntest_long = test_long[test_long[\"CorrectAnswer\"] != test_long[\"Answer_alphabet\"]]\nsubmission = test_long[[\"QuestionId_Answer\", \"MisconceptionId\"]].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:21:00.793724Z","iopub.execute_input":"2024-09-18T07:21:00.794103Z","iopub.status.idle":"2024-09-18T07:21:06.773133Z","shell.execute_reply.started":"2024-09-18T07:21:00.794068Z","shell.execute_reply":"2024-09-18T07:21:06.771676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:21:15.052998Z","iopub.execute_input":"2024-09-18T07:21:15.053416Z","iopub.status.idle":"2024-09-18T07:21:15.063992Z","shell.execute_reply.started":"2024-09-18T07:21:15.053367Z","shell.execute_reply":"2024-09-18T07:21:15.062866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)\nprint(\"Submission file created successfully!\")","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:19:57.153907Z","iopub.status.idle":"2024-09-18T07:19:57.154239Z","shell.execute_reply.started":"2024-09-18T07:19:57.154074Z","shell.execute_reply":"2024-09-18T07:19:57.15409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat submission.csv","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:19:57.155798Z","iopub.status.idle":"2024-09-18T07:19:57.156146Z","shell.execute_reply.started":"2024-09-18T07:19:57.155977Z","shell.execute_reply":"2024-09-18T07:19:57.155994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}