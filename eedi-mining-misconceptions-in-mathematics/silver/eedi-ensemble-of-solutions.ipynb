{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":82695,"databundleVersionId":9738540,"sourceType":"competition"},{"sourceId":6530547,"sourceType":"datasetVersion","datasetId":3775395},{"sourceId":8218776,"sourceType":"datasetVersion","datasetId":4871830},{"sourceId":9379178,"sourceType":"datasetVersion","datasetId":5689609},{"sourceId":9402433,"sourceType":"datasetVersion","datasetId":5707844},{"sourceId":9449548,"sourceType":"datasetVersion","datasetId":5743552},{"sourceId":9502328,"sourceType":"datasetVersion","datasetId":5755831},{"sourceId":9503395,"sourceType":"datasetVersion","datasetId":5750064},{"sourceId":9534632,"sourceType":"datasetVersion","datasetId":5784947},{"sourceId":9600626,"sourceType":"datasetVersion","datasetId":5856973},{"sourceId":9611969,"sourceType":"datasetVersion","datasetId":2148194},{"sourceId":9684003,"sourceType":"datasetVersion","datasetId":4581967},{"sourceId":9687536,"sourceType":"datasetVersion","datasetId":5922197},{"sourceId":142022752,"sourceType":"kernelVersion"},{"sourceId":193175737,"sourceType":"kernelVersion"},{"sourceId":196883629,"sourceType":"kernelVersion"},{"sourceId":197114197,"sourceType":"kernelVersion"},{"sourceId":197114846,"sourceType":"kernelVersion"},{"sourceId":197890556,"sourceType":"kernelVersion"},{"sourceId":199269375,"sourceType":"kernelVersion"},{"sourceId":200554622,"sourceType":"kernelVersion"},{"sourceId":200567623,"sourceType":"kernelVersion"},{"sourceId":27644,"sourceType":"modelInstanceVersion","modelInstanceId":23286,"modelId":33601},{"sourceId":113573,"sourceType":"modelInstanceVersion","modelInstanceId":95303,"modelId":119502},{"sourceId":118141,"sourceType":"modelInstanceVersion","modelInstanceId":99348,"modelId":123513},{"sourceId":118192,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":99392,"modelId":123481}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"One of the [outstanding members](https://www.kaggle.com/cdeotte) of the Kaggle community, grandmaster, gives a link to his [work](https://www.kaggle.com/code/cdeotte/top-solutions-ensemble-0-947), where he shows the refinement of the prediction using an experimental example. In order to try to refine our predictions at the [Eedi - Mining Misconceptions in Mathematics](https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/overview) competition\n\nThis approach has proven itself in the following competitions: 1. [ISIC 2024 - Skin Cancer Detection with 3D-TBP](https://www.kaggle.com/competitions/isic-2024-challenge/code?competitionId=63056&sortBy=scoreDescending&excludeNonAccessedDatasources=true), 2. [RSNA 2024 Lumbar Spine Degenerative Classification](https://www.kaggle.com/competitions/rsna-2024-lumbar-spine-degenerative-classification/code?competitionId=71549&sortBy=scoreAscending&excludeNonAccessedDatasources=true), 3. [NeurIPS - Ariel Data Challenge 2024](https://www.kaggle.com/competitions/ariel-data-challenge-2024/code?competitionId=70367&sortBy=scoreDescending&excludeNonAccessedDatasources=true), 4. [Child Mind Institute â€” Problematic Internet Use](https://www.kaggle.com/competitions/child-mind-institute-problematic-internet-use/code?competitionId=81933&sortBy=scoreDescending&excludeNonAccessedDatasources=true), 5. [BrisT1D Blood Glucose Prediction Competition](https://www.kaggle.com/competitions/brist1d/code?competitionId=82611&sortBy=scoreAscending&excludeNonAccessedDatasources=true), 6. [Eedi - Mining Misconceptions in Mathematics](https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/code?competitionId=82695&sortBy=scoreDescending&excludeNonAccessedDatasources=true), 7. [Connect X](https://www.kaggle.com/competitions/connectx/leaderboard?), 8. [Loan Approval Prediction {PS-S4.E10}](https://www.kaggle.com/competitions/brist1d/code), 9. [Jane Street Real-Time Market Data Forecasting](https://www.kaggle.com/competitions/jane-street-real-time-market-data-forecasting/code?competitionId=84493&sortBy=scoreDescending&excludeNonAccessedDatasources=true), 10. [UM - Game-Playing Strength of MCTS Variants](https://www.kaggle.com/competitions/um-game-playing-strength-of-mcts-variants/code?competitionId=70089&sortBy=scoreAscending&excludeNonAccessedDatasources=true)\n\nAnd accordingly in the following notebooks: 1. [ISIC | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/isic-2024-ensemble-of-solutions), 2. [RSNA | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/rsna-ensemble-of-solutions), 3. [Ariel | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/ariel-ensemble-of-solutions), 4. [CMI | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/cmi-ensemble-of-solutions), 5. [BrisT1D | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/brist1d-ensemble-of-solutions), 6. [Eedi | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/eedi-ensemble-of-solutions), 7. [agents Connect X](https://www.kaggle.com/code/vyacheslavbolotin/agents-connect-x), 8. [PS-S4.E10 | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/pss4e10-ensemble-of-solutions), 9. [Jane Street | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/jane-street-ensemble-of-solutions), 10. [MCTS | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/mcts-ensemble-of-solutions/)\n\n#### Eedi | Ensemble of solutions:\n\n1. (**0.147**) China [baseline_bge_cos_sim](https://www.kaggle.com/code/pingfan/baseline-bge-cos-sim) by expert [Baiph](https://www.kaggle.com/pingfan)\n2. (**0.166**) Indonezia [starter-bge](https://www.kaggle.com/code/cindybtari/starter-bge) by expert [ABC](https://www.kaggle.com/cindybtari)\n3. (**0.177**) India [cosine similarity - bge](https://www.kaggle.com/code/jaytonde/cosine-similarity-bge) by contributor [Jaydev Tonde](https://www.kaggle.com/jaytonde)\n4. (**0.180**) India [[Eedi] Zero-shot w/ LLM feature (LB: 0.180)](https://www.kaggle.com/code/ubamba98/eedi-zero-shot-w-llm-feature-lb-0-180) by master [Udbhav Bamba](https://www.kaggle.com/ubamba98)\n5. (**0.188**) India [[Eedi] BGE Starter](https://www.kaggle.com/code/jaejohn/eedi-bge-starter) by expert [G John Rao](https://www.kaggle.com/jaejohn)\n6. ()\n7. (**0.191**) Japan [[Eedi] simcse simple baseline [inference]](https://www.kaggle.com/code/osakanateishoku/eedi-simcse-simple-baseline-inference) by contributor [OsakanaTeishoku](https://www.kaggle.com/osakanateishoku)\n8. (**0.190**) India [similarity+preprocessing](https://www.kaggle.com/code/pshikk/similarity-preprocessing) by expert [PUN](https://www.kaggle.com/pshikk)\n9. (**0.192**) Vietnam [Start Mining Misconceptions](https://www.kaggle.com/code/levantaokkz/start-mining-misconceptions) by expert [le van tao](https://www.kaggle.com/levantaokkz)\n10. (**0.192**) Germany [Simple-baseline](https://www.kaggle.com/code/arunodhayan/simple-baseline) by expert [Arunodhayan](https://www.kaggle.com/arunodhayan)\n11. (**0.200**) India [Zero-shot w/ LLM feature + bge small](https://www.kaggle.com/code/ashwanibhat/zero-shot-w-llm-feature-bge-small) by contributor [Ashwani](https://www.kaggle.com/ashwanibhat)\n12. ()\n13. (**0.232**) UAE [[Eedi] [Infer] Finetune BGE Embedding Model ðŸš€ðŸš€](https://www.kaggle.com/code/abdullahmeda/eedi-infer-finetune-bge-embedding-model) by expert [Abdullah Meda](https://www.kaggle.com/abdullahmeda)\n14. (**0.246**) Japan [Fine-tuning bge [Infer]](https://www.kaggle.com/code/sinchir0/fine-tuning-bge-infer) by expert [sinchir0](https://www.kaggle.com/sinchir0)\n15. (**0.241**) Tunisia [Ensemble MPNETV2+BGE+GTE with Faiss-GPU](https://www.kaggle.com/code/medali1992/ensemble-mpnetv2-bge-gte-with-faiss-gpu) by expert [Med Ali Bouchhioua](https://www.kaggle.com/medali1992)\n16. (**0.277**) World [Infer BGE Synthetic Data](https://www.kaggle.com/code/minhnguyendichnhat/infer-bge-synthetic-data) by contributor [Minh Nguyen Dich Nhat](https://www.kaggle.com/minhnguyendichnhat)\n17. (**0.288**) Japan [[Eedi] Copy Fine-tuning bge [Infer]](https://www.kaggle.com/code/takaito/eedi-copy-fine-tuning-bge-infer) by master [takaito](https://www.kaggle.com/takaito)\n18. ()\n19. (**0.282**) Tunisia [Ensemble MPNETV2+BGE+GTE with Faiss-GPU](https://www.kaggle.com/code/medali1992/ensemble-mpnetv2-bge-gte-with-faiss-gpu) by expert [Med Ali Bouchhioua](https://www.kaggle.com/medali1992)\n20. (**0.291**) Tunisia [Ensemble MPNETV2+BGE+GTE with Faiss-GPU](https://www.kaggle.com/code/medali1992/ensemble-mpnetv2-bge-gte-with-faiss-gpu) by expert [Med Ali Bouchhioua](https://www.kaggle.com/medali1992)\n21. (**0.300**) World [Weighted Ensemble MPNETV2+BGE+GTE with Faiss](https://www.kaggle.com/code/yourlh/weighted-ensemble-mpnetv2-bge-gte-with-faiss) by contributor [Your_LH](https://www.kaggle.com/yourlh)\n22. (**0.315**) India [Hybrid Search (Ensemble Encoder + BM25)](https://www.kaggle.com/code/prtm1908/hybrid-search-ensemble-encoder-bm25) by contributor [Pratham Batra](https://www.kaggle.com/prtm1908)\n23. (**0.362**) Australia [Eedi Qwen-2.5 32B AWQ two-time retrieval](https://www.kaggle.com/code/takanashihumbert/eedi-qwen-2-5-32b-awq-two-time-retrieval) by master [Joseph](https://www.kaggle.com/takanashihumbert)\n\n#### options\n- RANDOM\n- \n- option 1 -> Lb=0.147 solutions (1,3)    \n- option 2 -> Lb=0.188 solutions (1,5)\n- option 3 -> Lb=0.188 solutions (3,5)\n- option 4 -> Lb=0.188 solutions (1,3,5) \n- option 5 -> Lb=0.160 solutions (5,7)\n- option 7 -> Lb=0.160 solutions (5,7)\n- option 10-> Lb=0.188 solutions (3,5,5)\n- option 8 -> Lb=0.160 solutions (3,5,7) \n- option 9 -> Lb=0.160 solutions (7,7,7)\n- option 11-> Lb=0.190 solutions (5,8)\n- option 12-> Lb=0.177 solutions (5,8,3)\n- \n- option 15-> V44 solutions (13,16) Lb=0.277\n- option 15-> V45 solutions (13,16) Lb=0.232\n- option 15-> V46 solutions (13,16) Lb=0.277\n- option 15-> V47 solutions (13,16) Lb=0.232\n- option 15-> V48 solutions (13,16) Lb=0.277\n- \n- option 17-> V54 solutions (5,16) Lb=0.277\n- option 17-> V55 solutions (5,16) Lb=0.277\n- option 17-> V56 solutions (5,16) Lb=0.188\n- option 17-> V57 solutions (5,16) Lb=0.188\n- option 17-> V58 solutions (5,16) Lb=0.188\n- \n- option 18-> V60 solutions (5,13,16) Lb=0.277\n- option 18-> V61 solutions (5,13,16) Lb=0.277\n- option 18-> V62 solutions (5,13,16) Lb=0.277\n- option 18-> V63 solutions (5,13,16) Lb=0.188\n- option 18-> V64 solutions (5,13,16) Lb=0.232\n- \n- option 19-> V68 solutions (5,13,16,19) Lb=0.277\n- option 19-> V69 solutions (5,13,16,19) Lb=0.277\n- option 19-> V70 solutions (5,13,16,19) Lb=0.282\n- option 19-> V71 solutions (5,13,16,19) Lb=0.277\n- option 19-> V72 solutions (5,13,16,19) Lb=0.188\n- \n- option 19-> tv1 solutions (5,13,16,19) Lb=0.212\n- option 19-> tv1 solutions (5,13,16,19) Lb=0.217\n- \n- option 20-> V74 solutions (13,16,19) Lb=0.228\n- option 20-> V75 solutions (13,16,19) Lb=0.236\n- \n- option 21-> V76 solutions (16,19) Lb=0.243\n- option 21-> V77 solutions (16,19) Lb=0.243\n- \n- option 22-> V80 solutions (16,19) Lb=0.266, random(s.16-1/3 + s.19-2/3)\n- option 22-> V81 solutions (16,19) Lb=0.250, random(s.16-1/3 + s.19-2/3)\n- \n- option 23-> V82 solutions (16,19,20) Lb=0.262\n- option 23-> V83 solutions (16,19,20) Lb=0.245\n- \n- option 24-> V84 solutions (16,19,20), random(s.16-1/7 + s.19-2/7 + s.20-4/7), Lb=0.273\n- option 24-> V85 solutions (16,19,20), random(s.16-1/7 + s.19-2/7 + s.20-4/7), Lb=0.269\n- option 24-> V86 solutions (16,19,20), random(s.16-1/7 + s.19-2/7 + s.20-4/7), Lb=0.267\n- option 24-> V87 solutions (16,19,20), random(s.16-1/7 + s.19-2/7 + s.20-4/7), Lb=0.265\n- \n- option 25-> V88 solutions (16,19,20), random(s.16-1/10+ s.19-2/10+ s.20-7/10), Lb=0.271\n- \n- option 26-> V90 solutions (16,19,20), random(s.16-1/11+ s.19-0/11+ s.20-10/11), Lb=0.280\n- option 26-> V91 solutions (16,19,20), random(s.16-1/11+ s.19-0/11+ s.20-10/11), Lb=0.283\n- option 27-> V92 solutions (16,19,20), random(s.16-0/11+ s.19-1/11+ s.20-10/11), Lb=0.289 - prev.best\n- option 27-> V93 solutions (16,19,20), random(s.16-0/11+ s.19-1/11+ s.20-10/11), Lb=0.286\n- option 28-> V94 solutions (16,19,20), random(s.16-1/22+ s.19-1/22+ s.20-20/22), Lb=0.288\n- \n- MAJORITY\n- \n- option 30-> V109 solutions.(20,19,16), majority_1, Lb=0.292 - prev.best\n- \n- option 31-> V110 solutions.(19,16), majority_1, Lb=0.282\n- option 32-> V111 solutions.(20,16), majority_1, Lb=0.291\n- option 33-> V112 solutions.(20,19), majority_1, Lb=0.291\n- \n- option 34-> V113 solutions.(20,19,16,13), majority_1, Lb=0.288\n- \n- option 35-> V115 solu.289tions.(21,20,19,16), majority_1, weights.21(0.50, 0.35, 0.29), Lb=00.289\n- \n- option 36-> V116 solutions.(21,20,19,16), majority_1, weights.21(0.60, 0.20, 0.20), Lb=0.282\n- option 37-> V117 solutions.(21,20,19,16), majority_1, weights.21(0.70, 0.15, 0.15), Lb=0.284\n- \n- option 38-> V118 solutions.(21,20,19,16), majority_1, weights.21(0.20, 0.20, 0.60), Lb=0.275\n- option 39-> V119 solutions.(21,20,19,16), majority_1, weights.21(0.15, 0.15, 0.70), Lb=0.278\n- \n- option 40->V123 solutions.(21,20,19), majority_1, weights.21(0.50, 0.35, 0.29), Lb=0.287\n- option 41->V125 solutions.(21,20,19), majority_1, weights.21(0.50, 0.28, 0.30), Lb=0.304 **BEST** \n- option 42->V126 solutions.(21,20,19), majority_1, weights.21(0.52, 0.28, 0.30), Lb=0.302\n- option 43->V127 solutions.(21,20,19), majority_1, weights.21(0.48, 0.28, 0.30), Lb=0.302\n- option 44->V128 solutions.(21,20,19), majority_1, weights.21(0.50, 0.30, 0.28), Lb=**?**\n\n#### current options\n- option 70->V133 solutions.(23,20,19,16), majority_1, Lb=**?**\n\n\n#### next options\n- **?**","metadata":{}},{"cell_type":"markdown","source":"At the end of the competition, all data will be grouped and presented in the usual tables. [Stat | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/stat-ensemble-of-solutions)","metadata":{}},{"cell_type":"code","source":"OPTION,ENSEMBLE_SOLUTIONS = 'option 70',['SOLUTION_23','SOLUTION_20','SOLUTION_19','SOLUTION_16']","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-10-21T19:27:58.324763Z","iopub.execute_input":"2024-10-21T19:27:58.325147Z","iopub.status.idle":"2024-10-21T19:27:58.329631Z","shell.execute_reply.started":"2024-10-21T19:27:58.325109Z","shell.execute_reply":"2024-10-21T19:27:58.328676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if OPTION in ['option 70','option 71','option 72','option 73','option 74']:\n    \n    def ensemble_of_solutions(option=OPTION,solution=ENSEMBLE_SOLUTIONS):\n        sm23= pd.read_csv(\"submission_23.csv\")\n        sm20= pd.read_csv(\"submission_20.csv\")\n        sm19= pd.read_csv(\"submission_19.csv\")\n        sm16= pd.read_csv(\"submission_16.csv\")\n        smII= pd.read_csv(\"submission_23.csv\")\n        #sm13= pd.read_csv(\"submission_13.csv\")\n        sm23= sm23.rename(columns={'MisconceptionId': 'MisconceptionId_23'})\n        sm20= sm20.rename(columns={'MisconceptionId': 'MisconceptionId_20'})\n        sm19= sm19.rename(columns={'MisconceptionId': 'MisconceptionId_19'})\n        sm16= sm16.rename(columns={'MisconceptionId': 'MisconceptionId_16'})\n        smII= smII.rename(columns={'MisconceptionId': 'MisconceptionId_II'})\n        #sm13= sm13.rename(columns={'MisconceptionId': 'MisconceptionId_13'})\n        sms = pd.merge(sm23,sm20, on=['QuestionId_Answer'])\n        sms = pd.merge(sms, sm19, on=['QuestionId_Answer'])\n        sms = pd.merge(sms, sm16, on=['QuestionId_Answer'])\n        sms = pd.merge(sms, smII, on=['QuestionId_Answer'])\n        #sms = pd.merge(sms, sm13, on=['QuestionId_Answer'])\n        display(sms)\n\n        from collections import Counter\n\n        counter = Counter()\n\n        def majority_1(sms):\n            mm23 = [lm.split() for lm in sms['MisconceptionId_23'].tolist()] \n            mm20 = [lm.split() for lm in sms['MisconceptionId_20'].tolist()] \n            mm19 = [lm.split() for lm in sms['MisconceptionId_19'].tolist()]\n            mm16 = [lm.split() for lm in sms['MisconceptionId_16'].tolist()]\n            mmII = [lm.split() for lm in sms['MisconceptionId_23'].tolist()] \n            #mm13 = [lm.split() for lm in sms['MisconceptionId_13'].tolist()]\n            \n            lmm = ''\n            for i in range(len(mm21)):\n                mm = ''\n                for j in range(len(mm21[i])): \n                    counter.clear()\n                    for ov in [mm23[i][j],mm20[i][j],mm19[i][j],mm16[i][j],mmII[i][j]]: #]: #,mm13[i][j]]:\n                        counter[ov] += 1\n                    often_meets_value = max(counter, key=counter.get)\n                    mm += often_meets_value + ' '\n                lmm += mm[:-1] + '#'\n            lmr = lmm[:-1].split('#')\n            sms = pd.DataFrame(lmr, columns=['MisconceptionId'])\n            return sms\n\n        dfp = sms.pipe(majority_1)\n        sms['MisconceptionId'] = dfp['MisconceptionId']\n        return sms,option,solution","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-10-21T19:28:06.73127Z","iopub.execute_input":"2024-10-21T19:28:06.732013Z","iopub.status.idle":"2024-10-21T19:28:06.744845Z","shell.execute_reply.started":"2024-10-21T19:28:06.731973Z","shell.execute_reply":"2024-10-21T19:28:06.743958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. [baseline_bge_cos_sim](https://www.kaggle.com/code/pingfan/baseline-bge-cos-sim)\n### [Baiph](https://www.kaggle.com/pingfan)","metadata":{}},{"cell_type":"markdown","source":"### Overview\nIn this notebook, `ConstructName` + `SubjectName` + `QuestionText` and `Answer[A-D]Text` are vectorized using TFIDF, and those with high cosine similarity are submitted as inference results.\n\nPlease let me know if there are any mistakes.","metadata":{"_kg_hide-input":true}},{"cell_type":"markdown","source":"### Import","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n    \n    import pandas as pd\n    import numpy as np\n    \n    from sklearn.metrics.pairwise import cosine_similarity","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n    \n    train = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")\n    test = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\n\n    misconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n    sample_submission = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/sample_submission.csv\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n    \n    def make_all_question_text(df: pd.DataFrame) -> pd.DataFrame:\n        df[\"all_question_text\"] = df[\"ConstructName\"] +\\\n                        \" \" +\\\n                        df[\"QuestionText\"]\n        return df\n\n    # train = make_all_question_text(train)\n    test = make_all_question_text(test)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n    \n    test","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n    \n    def wide_to_long(df: pd.DataFrame) -> pd.DataFrame:\n        df = pd.melt(\n            df[\n                [\n                    \"QuestionId\",\n                    \"all_question_text\",\n                    \"CorrectAnswer\",\n                    \"AnswerAText\",\n                    \"AnswerBText\",\n                    \"AnswerCText\",\n                    \"AnswerDText\"\n                ]\n            ],\n            id_vars=[\"QuestionId\", \"all_question_text\", \"CorrectAnswer\"],\n            var_name='Answer',\n            value_name='value'\n        )\n\n        return df\n\n    # train_long = wide_to_long(train)\n    test_long = wide_to_long(test)\n    test_long","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n    \n    def make_all_text(df: pd.DataFrame) -> pd.DataFrame:\n        df[\"all_text\"] = df[\"all_question_text\"] +\\\n                         \" \" +\\\n                         df[\"value\"]\n        return df\n\n    # train_long = make_all_text(train_long)\n    test_long = make_all_text(test_long)\n    test_long","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n    \n    test_long.all_text.values[0]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n    \n    # sort\n    # train_long = train_long.sort_values([\"QuestionId\", \"Answer\"]).reset_index(drop=True)\n    test_long = test_long.sort_values([\"QuestionId\", \"Answer\"]).reset_index(drop=True)\n    test_long","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### è®¡ç®—æ ‡ç­¾MisconceptionNameçš„emb","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n    \n    # æ•°æ®å‡†å¤‡\n\n    labels = misconception_mapping['MisconceptionName'].values","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n    \n    # åŠ è½½æ¨¡åž‹\n    from transformers import AutoTokenizer, AutoModel\n    import torch\n    # Sentences we want sentence embeddings for\n\n    device = \"cuda:0\"\n\n    # Load model from HuggingFace Hub\n    tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/baai-bge-large-en')\n    model = AutoModel.from_pretrained('/kaggle/input/baai-bge-large-en')\n    model.eval()\n    model.to(device)\n    print(\"finish\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n    \n    from tqdm import tqdm\n    MisconceptionName = list(misconception_mapping['MisconceptionName'].values)\n    per_gpu_batch_size = 8\n\n\n    def prepare_inputs(text, tokenizer, device):\n        tokenizer_outputs = tokenizer.batch_encode_plus(\n            text,\n            padding=True,\n            return_tensors='pt',\n            max_length=520,\n            truncation=True)\n        result = {\n            'input_ids': tokenizer_outputs.input_ids.to(device),\n            'attention_mask': tokenizer_outputs.attention_mask.to(device),\n        }\n        return result\n\n\n    all_ctx_vector = []\n    for mini_batch in tqdm(\n            range(0, len(MisconceptionName[:]), per_gpu_batch_size)):\n        mini_context = MisconceptionName[mini_batch:mini_batch\n                                               + per_gpu_batch_size]\n        encoded_input = prepare_inputs(mini_context,tokenizer,device)\n        sentence_embeddings = model(\n            **encoded_input)[0][:, 0]\n        sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n\n        all_ctx_vector.append(sentence_embeddings.detach().cpu().numpy())\n\n    all_ctx_vector = np.concatenate(all_ctx_vector, axis=0)\n    # all_ctx_vector = np.array(all_ctx_vector).astype('float32')\n    # faiss_index = faiss.IndexFlatIP(all_ctx_vector.shape[-1])\n    # faiss_index.add(all_ctx_vector)\n    # sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n    print(\"Sentence embeddings:\", sentence_embeddings.shape)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n    \n    test_texts = list(test_long.all_text.values)\n    all_text_vector = []\n    per_gpu_batch_size = 8\n\n    for mini_batch in tqdm(\n            range(0, len(test_texts[:]), per_gpu_batch_size)):\n        mini_context = test_texts[mini_batch:mini_batch\n                                               + per_gpu_batch_size]\n        encoded_input = prepare_inputs(mini_context,tokenizer,device)\n        sentence_embeddings = model(\n            **encoded_input)[0][:, 0]\n        sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n\n        all_text_vector.append(sentence_embeddings.detach().cpu().numpy())\n\n    all_text_vector = np.concatenate(all_text_vector, axis=0)\n    print(all_text_vector.shape)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n    \n    test_cos_sim_arr = cosine_similarity(all_text_vector, all_ctx_vector)\n    test_sorted_indices = np.argsort(-test_cos_sim_arr, axis=1)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n    \n    test_sorted_indices[:, :25]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make Submit File","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n\n    test_long[\"Answer_alphabet\"] = test_long[\"Answer\"].str.extract(r'Answer([A-Z])Text$')\n    test_long[\"QuestionId_Answer\"] = test_long[\"QuestionId\"].astype(\"str\") + \"_\" + test_long[\"Answer_alphabet\"]\n    test_long[\"MisconceptionId\"] = test_sorted_indices[:, :25].tolist()\n    test_long[\"MisconceptionId\"] = test_long[\"MisconceptionId\"].apply(lambda x: ' '.join(map(str, x)))\n    # filter correct row\n    test_long = test_long[test_long[\"CorrectAnswer\"] != test_long[\"Answer_alphabet\"]]\n    submission = test_long[[\"QuestionId_Answer\", \"MisconceptionId\"]].reset_index(drop=True)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n    \n    submission.head(10)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n\n    sample_submission.head(10)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_1' in ENSEMBLE_SOLUTIONS:\n\n    submission.to_csv(\"submission_1.csv\", index=False)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. [starter-bge](https://www.kaggle.com/code/cindybtari/starter-bge)\n### [ABC](https://www.kaggle.com/cindybtari)","metadata":{}},{"cell_type":"markdown","source":"### Starter with SBERT\n\nShotout and kudos to this [notebook](https://www.kaggle.com/code/pingfan/baseline-bge-cos-sim) as baseline.\n\nYou can find how to load the **Sentence Bert paraphrase-MiniLM-L6-v2** [here](https://www.kaggle.com/code/cindybtari/loading-pretrained-transformers-offline).","metadata":{"_kg_hide-input":true}},{"cell_type":"markdown","source":"### â˜˜ï¸ Import","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    !pip install -q /kaggle/input/dependencies/evaluate/evaluate-0.4.3-py3-none-any.whl","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    import os\n    import numpy as np\n    import pandas as pd\n    import numpy as np\n    import evaluate\n    import torch\n    from transformers import AutoTokenizer, AutoModel\n    from sklearn.metrics.pairwise import cosine_similarity\n    from tqdm import tqdm","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### â˜˜ï¸ Load Data","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    INPUT = '/kaggle/input/eedi-mining-misconceptions-in-mathematics'","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    train = pd.read_csv(os.path.join(INPUT, 'train.csv'))\n    test = pd.read_csv(os.path.join(INPUT, 'test.csv'))","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n  \n    misconception_mapping = pd.read_csv(os.path.join(INPUT, 'misconception_mapping.csv'))","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    sample_submission = pd.read_csv(os.path.join(INPUT, 'sample_submission.csv'))","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    # check train\n\n    train.sort_values(by='ConstructId').head(10)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    # check test \n\n    test.head()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    # check misconception mapping\n\n    misconception_mapping.head()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    # check sample submission\n\n    sample_submission.head()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check Data","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    train.iloc[0,2]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    train.iloc[0,6]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### â˜˜ï¸ Preprocess","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    def get_complete_question(df: pd.DataFrame, construct_col: str, question_col: str) -> pd.Series:\n        return df[construct_col] + \" \" + df[question_col]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    def pivot_long(df: pd.DataFrame) -> pd.DataFrame:\n        return pd.melt(\n            df,\n            id_vars=[\"QuestionId\", \"complete_question\", \"CorrectAnswer\"],\n            value_vars=[\"AnswerAText\", \"AnswerBText\", \"AnswerCText\", \"AnswerDText\"],\n            var_name='Answer',\n            value_name='value'\n        )","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    def get_complete_text(df: pd.DataFrame, question_col: str, answer_col:str) -> pd.Series:\n        return df[question_col] + \" \" + df[answer_col]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test['complete_question'] = get_complete_question(test, 'ConstructName', 'QuestionText')","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test.head()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test_long = pivot_long(test)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test_long.head()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test_long['complete_text'] = get_complete_text(test_long, 'complete_question', 'value')","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test_long.head()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test_long.iloc[0,-1]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    # sort values by QuestionId and Answer\n\n    test_long.sort_values([\"QuestionId\", \"Answer\"], inplace = True)\n    test_long = test_long.reset_index(drop=True)\n    test_long","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### â˜˜ï¸ Calculate the embedding of the label MisconceptionName","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    device = \"cuda:0\"","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/sentence-transformers/BAAI/bge-m3')\n    model = AutoModel.from_pretrained('/kaggle/input/sentence-transformers/BAAI/bge-m3')","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    model.eval()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    model.to(device)\n    print('Ok!')","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    def prepare_inputs(texts, tokenizer, device, max_length=520):\n        tokenizer_outputs = tokenizer.batch_encode_plus(\n            texts,\n            padding=True,\n            return_tensors='pt',\n            max_length=max_length,\n            truncation=True\n        )\n        return {\n            'input_ids': tokenizer_outputs['input_ids'].to(device),\n            'attention_mask': tokenizer_outputs['attention_mask'].to(device),\n        }","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    def compute_sentence_embeddings(texts, tokenizer, model, device, per_gpu_batch_size=8):\n        all_embeddings = []\n\n        # iterate over the text data in batches\n        for start_idx in tqdm(range(0, len(texts), per_gpu_batch_size), desc=\"Processing batches\"):\n            end_idx = min(start_idx + per_gpu_batch_size, len(texts))\n            batch_texts = texts[start_idx:end_idx]\n\n            encoded_inputs = prepare_inputs(batch_texts, tokenizer, device)\n\n            # compute embeddings\n            with torch.no_grad():  \n                model_output = model(**encoded_inputs)[0][:, 0]\n                normalized_embeddings = torch.nn.functional.normalize(model_output, p=2, dim=1)\n\n            all_embeddings.append(normalized_embeddings.cpu().numpy())\n\n        all_embeddings = np.concatenate(all_embeddings, axis=0)\n\n        return all_embeddings","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    # parameters\n\n    per_gpu_batch_size = 8\n    max_length = 520","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    labels = misconception_mapping['MisconceptionName'].values","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    MisconceptionName = list(labels)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    MisconceptionName[:2]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    sentence_embeddings = compute_sentence_embeddings(MisconceptionName, tokenizer, model, device, per_gpu_batch_size)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    print(f\"Sentence embeddings: {sentence_embeddings.shape}\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test_texts = list(test_long.complete_text.values)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    all_text_vector = compute_sentence_embeddinags(test_texts, tokenizer, model, device, per_gpu_batch_size)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    print(f\"All vectors: {all_text_vector.shape}\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### â˜˜ï¸ Predict","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test_cos_sim_arr = cosine_similarity(all_text_vector, sentence_embeddings)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test_cos_sim_arr[:2]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test_sorted_indices = np.argsort(-test_cos_sim_arr, axis=1)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test_sorted_indices","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### â˜˜ï¸ Submission ","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test_long[\"Answer_Alph\"] = test_long['Answer'].str.extract(r'(?i)Answer(\\w)', expand=False)\n    test_long[\"QuestionId_Answer\"] = test_long[\"QuestionId\"].astype(\"str\") + \"_\" + test_long[\"Answer_Alph\"]\n    test_long[\"MisconceptionId\"] = test_sorted_indices[:, :25].tolist()\n    test_long[\"MisconceptionId\"] = test_long[\"MisconceptionId\"].apply(lambda x: ' '.join(map(str, x)))","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    test_long","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    # filter out the correct row\n\n    test_long = test_long[test_long[\"CorrectAnswer\"] != test_long[\"Answer_Alph\"]]\n    test_long","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    submission = test_long[[\"QuestionId_Answer\", \"MisconceptionId\"]].reset_index(drop=True)\n    submission","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_2' in ENSEMBLE_SOLUTIONS:\n    \n    submission.to_csv('submission_2.csv', index = False)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. [cosine similarity - bge](https://www.kaggle.com/code/jaytonde/cosine-similarity-bge)\n### [Jaydev Tonde](https://www.kaggle.com/jaytonde)","metadata":{}},{"cell_type":"markdown","source":"### Import","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    import pandas as pd\n    import numpy as np\n\n    from sklearn.metrics.pairwise import cosine_similarity","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Load","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    train                 = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")\n    test                  = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\n\n    misconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n    sample_submission     = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/sample_submission.csv\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    def make_all_question_text(df: pd.DataFrame) -> pd.DataFrame:\n        df[\"all_question_text\"] = df[\"ConstructName\"] +\" \" +df[\"QuestionText\"]\n        return df\n\n    test = make_all_question_text(test)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    print(test.shape)\n    print(test.columns)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    def wide_to_long(df: pd.DataFrame) -> pd.DataFrame:\n        df = pd.melt(\n            df[\n                [\n                    \"QuestionId\",\n                    \"all_question_text\",\n                    \"CorrectAnswer\",\n                    \"AnswerAText\",\n                    \"AnswerBText\",\n                    \"AnswerCText\",\n                    \"AnswerDText\"\n                ]\n            ],\n            id_vars    = [\"QuestionId\", \"all_question_text\", \"CorrectAnswer\"],\n            var_name   = 'Answer',\n            value_name = 'value'\n        )\n\n        return df\n\n    test_long = wide_to_long(test)\n    test_long","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    print(test_long.shape)\n    print(test_long.columns)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    def make_all_text(df: pd.DataFrame) -> pd.DataFrame:\n        df[\"all_text\"] = df[\"all_question_text\"] +\" \" +df[\"value\"]\n        return df\n\n    test_long = make_all_text(test_long)\n    test_long","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    test_long = test_long.sort_values([\"QuestionId\", \"Answer\"]).reset_index(drop=True)\n    test_long","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    labels = misconception_mapping['MisconceptionName'].values","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading the model and tokenizer for embedding generation","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    from transformers import AutoTokenizer, AutoModel\n    import torch\n\n    device = \"cuda:0\"\n\n    tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\n    model     = AutoModel.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\n    model.eval()\n    model.to(device)\n    print(\"finish\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    from tqdm import tqdm\n    MisconceptionName = list(misconception_mapping['MisconceptionName'].values)\n    per_gpu_batch_size = 8\n\n\n    def prepare_inputs(text, tokenizer, device):\n        tokenizer_outputs = tokenizer.batch_encode_plus(\n            text,\n            padding        = True,\n            return_tensors = 'pt',\n            max_length     = 1024,\n            truncation     = True\n        )\n        result = {\n            'input_ids': tokenizer_outputs.input_ids.to(device),\n            'attention_mask': tokenizer_outputs.attention_mask.to(device),\n        }\n        return result\n\n\n    all_ctx_vector = []\n    for mini_batch in tqdm(range(0, len(MisconceptionName[:]), per_gpu_batch_size)):\n        mini_context          = MisconceptionName[mini_batch:mini_batch+ per_gpu_batch_size]\n        encoded_input         = prepare_inputs(mini_context,tokenizer,device)\n        sentence_embeddings   = model(**encoded_input)[0][:, 0]\n        sentence_embeddings   = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n        all_ctx_vector.append(sentence_embeddings.detach().cpu().numpy())\n\n    all_ctx_vector = np.concatenate(all_ctx_vector, axis=0)\n    print(\"Sentence embeddings:\", sentence_embeddings.shape)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    test_texts = list(test_long.all_text.values)\n    all_text_vector = []\n    per_gpu_batch_size = 8\n\n    for mini_batch in tqdm(\n            range(0, len(test_texts[:]), per_gpu_batch_size)):\n        mini_context = test_texts[mini_batch:mini_batch\n                                               + per_gpu_batch_size]\n        encoded_input = prepare_inputs(mini_context,tokenizer,device)\n        sentence_embeddings = model(\n            **encoded_input)[0][:, 0]\n        sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n\n        all_text_vector.append(sentence_embeddings.detach().cpu().numpy())\n\n    all_text_vector = np.concatenate(all_text_vector, axis=0)\n    print(all_text_vector.shape)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    test_cos_sim_arr = cosine_similarity(all_text_vector, all_ctx_vector)\n    test_sorted_indices = np.argsort(-test_cos_sim_arr, axis=1)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    test_sorted_indices[:, :25]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    test_long[\"Answer_alphabet\"] = test_long[\"Answer\"].str.extract(r'Answer([A-Z])Text$')\n    test_long[\"QuestionId_Answer\"] = test_long[\"QuestionId\"].astype(\"str\") + \"_\" + test_long[\"Answer_alphabet\"]\n    test_long[\"MisconceptionId\"] = test_sorted_indices[:, :25].tolist()\n    test_long[\"MisconceptionId\"] = test_long[\"MisconceptionId\"].apply(lambda x: ' '.join(map(str, x)))\n    # filter correct row\n    test_long = test_long[test_long[\"CorrectAnswer\"] != test_long[\"Answer_alphabet\"]]\n    submission = test_long[[\"QuestionId_Answer\", \"MisconceptionId\"]].reset_index(drop=True)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    submission.head(10)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    sample_submission.head(10)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_3' in ENSEMBLE_SOLUTIONS:\n    \n    submission.to_csv(\"submission_3.csv\", index=False)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. [[Eedi] Zero-shot w/ LLM feature (LB: 0.180)](https://www.kaggle.com/code/ubamba98/eedi-zero-shot-w-llm-feature-lb-0-180)\n### [Udbhav Bamba](https://www.kaggle.com/ubamba98)","metadata":{}},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n    import os, math, numpy as np\n    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n    !pip uninstall -y torch\n    !pip install --no-index --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-vllm vllm\n    !pip install -U --upgrade /kaggle/input/vllm-t4-fix/grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    !pip install -U --upgrade /kaggle/input/vllm-t4-fix/ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl\n    !pip install --no-deps --no-index /kaggle/input/hf-libraries/sentence-transformers/sentence_transformers-3.1.0-py3-none-any.whl","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Metric","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n    %%writefile eedi_metrics.py\n\n    # Credit: https://www.kaggle.com/code/abdullahmeda/eedi-map-k-metric\n\n    import numpy as np\n    def apk(actual, predicted, k=25):\n        \"\"\"\n        Computes the average precision at k.\n\n        This function computes the average prescision at k between two lists of\n        items.\n\n        Parameters\n        ----------\n        actual : list\n                 A list of elements that are to be predicted (order doesn't matter)\n        predicted : list\n                    A list of predicted elements (order does matter)\n        k : int, optional\n            The maximum number of predicted elements\n\n        Returns\n        -------\n        score : double\n                The average precision at k over the input lists\n        \"\"\"\n    \n        if not actual:\n            return 0.0\n\n        if len(predicted)>k:\n            predicted = predicted[:k]\n\n        score = 0.0\n        num_hits = 0.0\n\n        for i,p in enumerate(predicted):\n            # first condition checks whether it is valid prediction\n            # second condition checks if prediction is not repeated\n            if p in actual and p not in predicted[:i]:\n                num_hits += 1.0\n                score += num_hits / (i+1.0)\n\n        return score / min(len(actual), k)\n\n    def mapk(actual, predicted, k=25):\n        \"\"\"\n        Computes the mean average precision at k.\n\n        This function computes the mean average prescision at k between two lists\n        of lists of items.\n\n        Parameters\n        ----------\n        actual : list\n                 A list of lists of elements that are to be predicted \n                 (order doesn't matter in the lists)\n        predicted : list\n                    A list of lists of predicted elements\n                    (order matters in the lists)\n        k : int, optional\n            The maximum number of predicted elements\n\n        Returns\n        -------\n        score : double\n                The mean average precision at k over the input lists\n        \"\"\"\n    \n        return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare dataframe","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n    import os\n    from transformers import AutoTokenizer\n    import pandas as pd\n\n    IS_SUBMISSION = bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\n\n    df_train = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\").fillna(-1).iloc[:500]\n    df_test = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\n    tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/hugging-quants-meta-llama-3-1-8b-instruct-awq-int4\")\n\n    PROMPT  = \"\"\"Question: {Question}\n    Incorrect Answer: {IncorrectAnswer}\n    Correct Answer: {CorrectAnswer}\n    Construct Name: {ConstructName}\n    Subject Name: {SubjectName}\n\n    Your task: Identify the misconception behind Incorrect Answer. Answer concisely and generically inside <response>$$INSERT TEXT HERE$$</response>.\n    Before answering the question think step by step concisely in 1-2 sentence inside <thinking>$$INSERT TEXT HERE$$</thinking> tag and respond your final misconception inside <response>$$INSERT TEXT HERE$$</response> tag.\"\"\"\n\n    def apply_template(row, tokenizer, targetCol):\n        messages = [\n            {\n                \"role\": \"user\", \n                \"content\": PROMPT.format(\n                     ConstructName=row[\"ConstructName\"],\n                     SubjectName=row[\"SubjectName\"],\n                     Question=row[\"QuestionText\"],\n                     IncorrectAnswer=row[f\"Answer{targetCol}Text\"],\n                     CorrectAnswer=row[f\"Answer{row.CorrectAnswer}Text\"])\n            }\n        ]\n        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n        return text\n\n    df = {}\n    if not IS_SUBMISSION:\n        df_label = {}\n        for idx, row in df_train.iterrows():\n            for option in [\"A\", \"B\", \"C\", \"D\"]:\n                if (row.CorrectAnswer!=option) & (row[f\"Misconception{option}Id\"]!=-1):\n                    df[f\"{row.QuestionId}_{option}\"] = apply_template(row, tokenizer, option)\n                    df_label[f\"{row.QuestionId}_{option}\"] = [row[f\"Misconception{option}Id\"]]\n        df_label = pd.DataFrame([df_label]).T.reset_index()\n        df_label.columns = [\"QuestionId_Answer\", \"MisconceptionId\"]\n        df_label.to_parquet(\"label.parquet\", index=False)\n    else:\n        for idx, row in df_test.iterrows():\n            for option in [\"A\", \"B\", \"C\", \"D\"]:\n                if row.CorrectAnswer!=option:\n                    df[f\"{row.QuestionId}_{option}\"] = apply_template(row, tokenizer, option)\n    df = pd.DataFrame([df]).T.reset_index()\n    df.columns = [\"QuestionId_Answer\", \"text\"]\n    df.to_parquet(\"submission.parquet\", index=False)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LLM Reasoning","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n    %%writefile run_vllm.py\n\n    import re\n    import vllm\n    import pandas as pd\n\n    df = pd.read_parquet(\"submission.parquet\")\n\n    llm = vllm.LLM(\n        \"/kaggle/input/hugging-quants-meta-llama-3-1-8b-instruct-awq-int4\",\n        quantization=\"awq\",\n        tensor_parallel_size=2, \n        gpu_memory_utilization=0.95, \n        trust_remote_code=True,\n        dtype=\"half\", \n        enforce_eager=True,\n        max_model_len=8192,\n        disable_log_stats=True\n    )\n    tokenizer = llm.get_tokenizer()\n\n\n    responses = llm.generate(\n        df[\"text\"].values,\n        vllm.SamplingParams(\n            n=1,  # Number of output sequences to return for each prompt.\n            top_p=0.9,  # Float that controls the cumulative probability of the top tokens to consider.\n            temperature=0,  # randomness of the sampling\n            seed=777, # Seed for reprodicibility\n            skip_special_tokens=False,  # Whether to skip special tokens in the output.\n            max_tokens=2048,  # Maximum number of tokens to generate per output sequence.\n        ),\n        use_tqdm = True\n    )\n\n    responses = [x.outputs[0].text for x in responses]\n    df[\"fullLLMText\"] = responses\n\n    def extract_response(text):\n        return \",\".join(re.findall(r\"<response>(.*?)</response>\", text)).strip()\n\n    responses = [extract_response(x) for x in responses]\n    df[\"llmMisconception\"] = responses\n    df.to_parquet(\"submission.parquet\", index=False)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n    \n    !python run_vllm.py","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n    \n    llm_output = pd.read_parquet(\"submission.parquet\")\n\n    for idx, row in llm_output[-5:].iterrows():\n        print(row.fullLLMText)\n        print(\"---\"*3)\n        print(row.llmMisconception)\n        print(\"===\"*6)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Find similar Misconception","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n    \n    llm_output","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n    \n    %%writefile run_similarity_search.py\n\n    import pandas as pd\n    from sentence_transformers import SentenceTransformer, util\n\n    df = pd.read_parquet(\"submission.parquet\")\n    df_misconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n\n    model = SentenceTransformer('/kaggle/input/bge-large-en-v1-5')\n    PREFIX = \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n\"\n    input_features = df[\"text\"].str.lstrip(PREFIX).str.split(\"\\n\\nYour task:\").str[0]\n\n    embedding_query = model.encode(input_features+ \"\\n----\\n\" + df[\"fullLLMText\"], convert_to_tensor=True)\n    embedding_Misconception = model.encode(df_misconception_mapping.MisconceptionName.values, convert_to_tensor=True)\n\n    top25ids = util.semantic_search(embedding_query, embedding_Misconception, top_k=25)\n\n    df[\"MisconceptionId\"] = [\" \".join([str(x[\"corpus_id\"]) for x in top25id]) for top25id in top25ids]\n\n    df[[\"QuestionId_Answer\", \"MisconceptionId\"]].to_csv(\"submission_4.csv\", index=False)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n    \n    !python run_similarity_search.py","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sanity","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n    \n    import pandas as pd\n    pd.read_csv(\"submission_4.csv\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_4' in ENSEMBLE_SOLUTIONS:\n    \n    if not IS_SUBMISSION:\n        import pandas as pd\n        from eedi_metrics import mapk\n        predicted = pd.read_csv(\"submission_4.csv\")[\"MisconceptionId\"].apply(lambda x: [int(y) for y in x.split()])\n        label = pd.read_parquet(\"label.parquet\")[\"MisconceptionId\"]\n        print(\"Validation: \", mapk(label, predicted))","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. [[Eedi] BGE Starter](https://www.kaggle.com/code/jaejohn/eedi-bge-starter)\n### [G John Rao](https://www.kaggle.com/jaejohn)","metadata":{}},{"cell_type":"markdown","source":"### Import","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    \n    import pandas as pd\n    import numpy as np\n    import torch\n    from transformers import AutoTokenizer, AutoModel\n    from sklearn.metrics.pairwise import cosine_similarity\n\n    import re\n    from scipy.spatial.distance import cdist\n\n    # Data Loading\n    train = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")\n    test = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\n    misconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n\n    # Load the model and tokenizer\n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n    tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\n    model = AutoModel.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\n    model.to(device)\n\n    # Function to generate embeddings\n    def generate_embeddings(texts, model, tokenizer, device, batch_size=8):\n        all_embeddings = []\n        for i in range(0, len(texts), batch_size):\n            batch_texts = texts[i:i+batch_size]\n            inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=1024).to(device)\n            with torch.no_grad():\n                outputs = model(**inputs)\n            embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n            embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n            all_embeddings.append(embeddings.cpu().numpy())\n        return np.concatenate(all_embeddings, axis=0)\n\n    # Generate embeddings for misconceptions\n    MisconceptionName = list(misconception_mapping['MisconceptionName'].values)\n    all_ctx_vector = generate_embeddings(MisconceptionName, model, tokenizer, device)\n\n    def preprocess_text(text):\n        # Convert to lowercase\n        text = text.lower()\n        # Remove special characters and digits\n        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n        # Remove extra whitespace\n        text = ' '.join(text.split())\n        return text\n\n    # Prepare test data\n    def make_all_question_text(df: pd.DataFrame) -> pd.DataFrame:\n        df[\"all_question_text\"] = df[\"ConstructName\"] + \" \" + df[\"QuestionText\"]\n        df[\"all_question_text\"] = df[\"all_question_text\"].apply(preprocess_text)\n        return df\n\n    test = make_all_question_text(test)\n\n    def wide_to_long(df: pd.DataFrame) -> pd.DataFrame:\n        df = pd.melt(\n            df[\n                [\n                    \"QuestionId\",\n                    \"all_question_text\",\n                    \"CorrectAnswer\",\n                    \"AnswerAText\",\n                    \"AnswerBText\",\n                    \"AnswerCText\",\n                    \"AnswerDText\"\n                ]\n            ],\n            id_vars    = [\"QuestionId\", \"all_question_text\", \"CorrectAnswer\"],\n            var_name   = 'Answer',\n            value_name = 'value'\n        )\n        return df\n\n    test_long = wide_to_long(test)\n\n    def make_all_text(df: pd.DataFrame) -> pd.DataFrame:\n        text_components = []\n        if \"all_question_text\" in df.columns:\n            text_components.append(df[\"all_question_text\"])\n        if \"value\" in df.columns:\n            text_components.append(df[\"value\"].apply(preprocess_text))\n\n        df[\"all_text\"] = pd.concat(text_components, axis=1).apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n        return df\n\n    test_long = make_all_text(test_long)\n    test_long = test_long.sort_values([\"QuestionId\", \"Answer\"]).reset_index(drop=True)\n\n    # Generate embeddings for test data\n    test_texts = list(test_long['all_text'].values)\n    all_text_vector = generate_embeddings(test_texts, model, tokenizer, device)\n\n    # Compute similarities\n    cosine_similarities = cosine_similarity(all_text_vector, all_ctx_vector)\n\n    # Euclidean distance\n    euclidean_distances = cdist(all_text_vector, all_ctx_vector, metric='euclidean')\n    euclidean_similarities = 1 / (1 + euclidean_distances)  # Convert distance to similarity\n\n    # Combination of cosine and euclidean\n    combined_similarities = (cosine_similarities + euclidean_similarities) / 2\n\n    # Use the combined_similarities for sorting\n    test_sorted_indices = np.argsort(-combined_similarities, axis=1)\n\n    # Prepare submission\n    test_long[\"Answer_alphabet\"] = test_long[\"Answer\"].str.extract(r'Answer([A-Z])Text$')\n    test_long[\"QuestionId_Answer\"] = test_long[\"QuestionId\"].astype(\"str\") + \"_\" + test_long[\"Answer_alphabet\"]\n    test_long[\"MisconceptionId\"] = test_sorted_indices[:, :25].tolist()\n    test_long[\"MisconceptionId\"] = test_long[\"MisconceptionId\"].apply(lambda x: ' '.join(map(str, x)))\n    # filter correct row\n    test_long = test_long[test_long[\"CorrectAnswer\"] != test_long[\"Answer_alphabet\"]]\n    submission = test_long[[\"QuestionId_Answer\", \"MisconceptionId\"]].reset_index(drop=True)\n    ","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    \n    submission.head(10)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    \n    submission.to_csv(\"submission_5.csv\", index=False)\n    print(\"Submission file created successfully!\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if 'SOLUTION_5' in ENSEMBLE_SOLUTIONS:\n    \n#     !cat submission.csv","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. [[Eedi] simcse simple baseline [inference]](https://www.kaggle.com/code/osakanateishoku/eedi-simcse-simple-baseline-inference)\n### [OsakanaTeishoku](https://www.kaggle.com/osakanateishoku)","metadata":{}},{"cell_type":"markdown","source":"### Import","metadata":{"_kg_hide-input":true}},{"cell_type":"markdown","source":"This notebook was created with reference to https://www.kaggle.com/code/jaejohn/eedi-bge-starter \n\nI trained the retriever on train set.\n\nPlease let me know if there are any mistakes.\n\nI think more inprovements should be made. I apologize for the unorganized and messy code.","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"#!pip install -q sentence_transformers","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_7' in ENSEMBLE_SOLUTIONS:\n    \n    import pandas as pd\n    import numpy as np\n    import torch\n    from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n    from sklearn.metrics.pairwise import cosine_similarity\n\n    import re\n    from scipy.spatial.distance import cdist\n\n    import gc, torch\n    def flush():\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    device = torch.device(\"cuda\")\n\n    train = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")\n    test = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\n    misconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_7' in ENSEMBLE_SOLUTIONS:\n    \n    def preprocess_text(text):\n        # Convert to lowercase\n        text = text.lower()\n        # Remove special characters and digits\n        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n        # Remove extra whitespace\n        text = ' '.join(text.split())\n        return text\n    \n\n    def make_all_question_text(df: pd.DataFrame) -> pd.DataFrame:\n        df[\"all_question_text\"] = df[\"ConstructName\"] + \" \" + df[\"QuestionText\"]\n        df[\"all_question_text\"] = df[\"all_question_text\"].apply(preprocess_text)\n        return df\n\n    \n    def wide_to_long_train_ans(df: pd.DataFrame) -> pd.DataFrame:\n        df = pd.melt(\n            df[\n                [\n                    \"QuestionId\",\n                    \"all_question_text\",\n                    \"CorrectAnswer\",\n                    \"AnswerAText\",\n                    \"AnswerBText\",\n                    \"AnswerCText\",\n                    \"AnswerDText\",\n                    #\"MisconceptionAId\",\n                    #\"MisconceptionBId\",\n                    #\"MisconceptionCId\",\n                    #\"MisconceptionDId\"\n                ]\n            ],\n            id_vars    = [\"QuestionId\", \"all_question_text\", \"CorrectAnswer\"], \n            var_name   = 'Answer',\n            value_name = 'ans_value'\n        )\n        return df\n\n    \n    def wide_to_long_train_mis(df: pd.DataFrame) -> pd.DataFrame:\n        df = pd.melt(\n            df[\n                [\n                    \"QuestionId\",\n                    \"all_question_text\",\n                    \"CorrectAnswer\",\n                    #\"AnswerAText\",\n                    #\"AnswerBText\",\n                    #\"AnswerCText\",\n                    #\"AnswerDText\",\n                    \"MisconceptionAId\",\n                    \"MisconceptionBId\",\n                    \"MisconceptionCId\",\n                    \"MisconceptionDId\"\n                ]\n            ],\n            id_vars    = [\"QuestionId\", \"all_question_text\", \"CorrectAnswer\"],      \n            var_name   = 'Misconception',\n            value_name = 'mis_value'\n        )\n        return df\n\n    \n    def make_all_text_train(df: pd.DataFrame) -> pd.DataFrame:\n        text_components = []\n        if \"all_question_text\" in df.columns:\n            text_components.append(df[\"all_question_text\"])\n        if \"ans_value\" in df.columns:\n            text_components.append(df[\"ans_value\"].apply(preprocess_text))\n\n        df[\"all_text\"] = pd.concat(text_components, axis=1).apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n        return df","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_7' in ENSEMBLE_SOLUTIONS:\n    \n    train = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")\n    train = make_all_question_text(train)\n    train_long_ans = make_all_text_train(wide_to_long_train_ans(train))\n    train_long_mis = make_all_text_train(wide_to_long_train_mis(train))\n    train_long_ans[\"Id\"] = list(range(len(train_long_ans)))\n    train_long_mis[\"Id\"] = list(range(len(train_long_mis)))\n    train_long = pd.merge(train_long_ans, train_long_mis, on=[\"QuestionId\", \"Id\", \"all_question_text\", \"CorrectAnswer\"], how=\"left\")\n    train_long = train_long.sort_values([\"QuestionId\", \"Misconception\"]).reset_index(drop=True)\n    train_long.loc[3, \"all_text_x\"]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_7' in ENSEMBLE_SOLUTIONS:\n    \n    train_long_drop = train_long.dropna(subset=[\"mis_value\"])\n    train_long_drop[\"mis_value\"] = train_long_drop[\"mis_value\"].astype(int)\n    train_long_drop","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#if 'SOLUTION_7' in ENSEMBLE_SOLUTIONS:\n    \n    #from sentence_transformers import SentenceTransformer, InputExample\n    #from sentence_transformers import models, losses\n    #from torch.utils.data import DataLoader","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#if 'SOLUTION_7' in ENSEMBLE_SOLUTIONS:\n    \n    #model_retriever = AutoModelForSequenceClassification.from_pretrained(\n    #    '/kaggle/input/bge-small-en-v1.5/transformers/bge/2', \n    #    num_labels=len(misconception_mapping['MisconceptionName']))\n    #tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\n    #model_name = '/kaggle/input/bge-small-en-v1.5/transformers/bge/2'\n    #word_embedding_model = models.Transformer(model_name)\n    #pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n    #model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n\n    # Define a list with sentences (1k - 100k sentences)\n    #train_sentences = list(train_long_drop[\"all_text_x\"])\n\n    # Convert train sentences to sentence pairs\n    #train_data = [InputExample(texts=[s, s]) for s in train_sentences]\n\n    # DataLoader to batch your data\n    #train_dataloader = DataLoader(train_data, batch_size=8, shuffle=True)\n\n    # Use the denoising auto-encoder loss\n    #train_loss = losses.MultipleNegativesRankingLoss(model)\n\n    # Call the fit method\n    #model.fit(\n    #    train_objectives=[(train_dataloader, train_loss)], epochs=1, show_progress_bar=True, use_amp=True\n    #)\n\n    #model.save(\"output/simcse-model\")\n    #model_retriever.to(device)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if 'SOLUTION_7' in ENSEMBLE_SOLUTIONS:\n    \n    #from datasets import Dataset\n\n    #train_long_drop = train_long.dropna(subset=[\"mis_value\"])\n    #train_long_drop[\"mis_value\"] = train_long_drop[\"mis_value\"].astype(int)\n    #train_long_drop\n\n    # train_model\n    #train_data = Dataset.from_pandas(train_long_drop)\n    # train_data[\"mis_value\"][10]\n\n    #def preproc(example):\n    #    encoded_example = tokenizer(example[\"all_text_x\"], max_length=1024)\n    #    encoded_example[\"labels\"] = example[\"mis_value\"]\n    #    return encoded_example\n\n    #encoded_train_data = train_data.map(\n    #    preproc,\n    #    remove_columns = train_data.column_names\n    #)\n\n    #encoded_train_data","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#if 'SOLUTION_7' in ENSEMBLE_SOLUTIONS:\n    \n    #from transformers import DataCollatorWithPadding\n\n    #data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#if 'SOLUTION_7' in ENSEMBLE_SOLUTIONS:\n    \n    #from transformers import Trainer, TrainingArguments\n\n#training_args = TrainingArguments(\n#    output_dir=\"/kaggle/working/logs\",\n#    per_device_train_batch_size=32,\n#    fp16=True,learning_rate=1e-4,\n#    lr_scheduler_type=\"cosine\",\n#    report_to=\"none\",\n#    logging_strategy=\"steps\",\n#    logging_steps=50,\n#)\n\n#trainer = Trainer(\n#    model=model_retriever,\n#    tokenizer=tokenizer,\n#    train_dataset = encoded_train_data,\n#    data_collator=data_collator,\n#    args=training_args,\n#)\n\n#trainer.train()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#if 'SOLUTION_7' in ENSEMBLE_SOLUTIONS:\n\n    #trainer.save_model()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_7' in ENSEMBLE_SOLUTIONS:\n    \n    import pandas as pd\n    import numpy as np\n    import torch\n    from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n    from sklearn.metrics.pairwise import cosine_similarity\n\n    import re\n    from scipy.spatial.distance import cdist\n\n    # Data Loading\n    train = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")\n    test = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\n    misconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n\n    # Load the model and tokenizer\n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n    tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/eedi-simcse-simple-baseline-train/output/simcse-model')\n    model = AutoModel.from_pretrained('/kaggle/input/eedi-simcse-simple-baseline-train/output/simcse-model')\n    model.to(device)\n\n    \n    # Function to generate embeddings\n    def generate_embeddings(texts, model, tokenizer, device, batch_size=8):\n        all_embeddings = []\n        for i in range(0, len(texts), batch_size):\n            batch_texts = texts[i:i+batch_size]\n            inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=1024).to(device)\n            with torch.no_grad():\n                outputs = model(**inputs, output_hidden_states=True)\n            embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n            embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n            all_embeddings.append(embeddings.cpu().numpy())\n        return np.concatenate(all_embeddings, axis=0)\n\n    \n    # Generate embeddings for misconceptions\n    MisconceptionName = list(misconception_mapping['MisconceptionName'].values)\n    all_ctx_vector = generate_embeddings(MisconceptionName, model, tokenizer, device)\n\n    \n    def preprocess_text(text):\n        # Convert to lowercase\n        text = text.lower()\n        # Remove special characters and digits\n        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n        # Remove extra whitespace\n        text = ' '.join(text.split())\n        return text\n\n    \n    # Prepare test data\n    def make_all_question_text(df: pd.DataFrame) -> pd.DataFrame:\n        df[\"all_question_text\"] = df[\"ConstructName\"] + \" \" + df[\"QuestionText\"]\n        df[\"all_question_text\"] = df[\"all_question_text\"].apply(preprocess_text)\n        return df\n\n    \n    test = make_all_question_text(test)\n\n    \n    def wide_to_long(df: pd.DataFrame) -> pd.DataFrame:\n        df = pd.melt(\n            df[\n                [\n                    \"QuestionId\",\n                    \"all_question_text\",\n                    \"CorrectAnswer\",\n                    \"AnswerAText\",\n                    \"AnswerBText\",\n                    \"AnswerCText\",\n                    \"AnswerDText\"\n                ]\n            ],\n            id_vars    = [\"QuestionId\", \"all_question_text\", \"CorrectAnswer\"],\n            var_name   = 'Answer',\n            value_name = 'value'\n        )\n        return df\n\n    \n    test_long = wide_to_long(test)\n\n    \n    def make_all_text(df: pd.DataFrame) -> pd.DataFrame:\n        text_components = []\n        if \"all_question_text\" in df.columns:\n            text_components.append(df[\"all_question_text\"])\n        if \"value\" in df.columns:\n            text_components.append(df[\"value\"].apply(preprocess_text))\n\n        df[\"all_text\"] = pd.concat(text_components, axis=1).apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n        return df\n\n    \n    test_long = make_all_text(test_long)\n    test_long = test_long.sort_values([\"QuestionId\", \"Answer\"]).reset_index(drop=True)\n\n    # Generate embeddings for test data\n    test_texts = list(test_long['all_text'].values)\n    all_text_vector = generate_embeddings(test_texts, model, tokenizer, device)\n\n    # Compute similarities\n    cosine_similarities = cosine_similarity(all_text_vector, all_ctx_vector)\n\n    # Euclidean distance\n    euclidean_distances = cdist(all_text_vector, all_ctx_vector, metric='euclidean')\n    euclidean_similarities = 1 / (1 + euclidean_distances)  # Convert distance to similarity\n\n    # Combination of cosine and euclidean\n    combined_similarities = (cosine_similarities + euclidean_similarities) / 2\n\n    # Use the combined_similarities for sorting\n    test_sorted_indices = np.argsort(-combined_similarities, axis=1)\n\n    # Prepare submission\n    test_long[\"Answer_alphabet\"] = test_long[\"Answer\"].str.extract(r'Answer([A-Z])Text$')\n    test_long[\"QuestionId_Answer\"] = test_long[\"QuestionId\"].astype(\"str\") + \"_\" + test_long[\"Answer_alphabet\"]\n    test_long[\"MisconceptionId\"] = test_sorted_indices[:, :25].tolist()\n    test_long[\"MisconceptionId\"] = test_long[\"MisconceptionId\"].apply(lambda x: ' '.join(map(str, x)))\n    # filter correct row\n    test_long = test_long[test_long[\"CorrectAnswer\"] != test_long[\"Answer_alphabet\"]]\n    submission = test_long[[\"QuestionId_Answer\", \"MisconceptionId\"]].reset_index(drop=True)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_7' in ENSEMBLE_SOLUTIONS:\n    \n    submission.head(10)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_7' in ENSEMBLE_SOLUTIONS:\n    \n    submission.to_csv(\"submission_7.csv\", index=False)\n    print(\"Submission file created successfully!\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if 'SOLUTION_7' in ENSEMBLE_SOLUTIONS:\n\n#     !cat submission.csv","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8. [similarity+preprocessing](https://www.kaggle.com/code/pshikk/similarity-preprocessing)\n### [PUN](https://www.kaggle.com/pshikk)","metadata":{}},{"cell_type":"markdown","source":"### Import\n\nDirect copy of : https://www.kaggle.com/code/jaejohn/eedi-bge-starter\n\nwith just better text preprocessing that I stole from a notebook in this comp a while ago  : https://www.kaggle.com/competitions/lmsys-chatbot-arena\n\nLast 3 versions have the similar score","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:\n    \n    import pandas as pd\n    import numpy as np\n    import torch\n    from transformers import AutoTokenizer, AutoModel\n    from sklearn.metrics.pairwise import cosine_similarity\n\n    import re\n    from scipy.spatial.distance import cdist","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:\n\n    # Data Loading\n    train = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")\n    test = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\n    misconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:\n\n    train = train.dropna(axis =1 )","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:    \n    \n    train","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:\n    \n    # Load the model and tokenizer\n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n    tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\n    model = AutoModel.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\n    model.to(device)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:\n    \n    def removeHTML(x):\n        html=re.compile(r'<.*?>')\n        return html.sub(r'',x)\n    def preprocess_text(x):\n        # Convert words to lowercase\n        x = x.lower()\n        # Remove HTML\n    #     x = removeHTML(x)\n        # Delete strings starting with @\n        x = re.sub(\"@\\w+\", '',x)\n        # Delete Numbers\n        x = re.sub(\"'\\d+\", '',x)\n        x = re.sub(\"\\d+\", '',x)\n        # Delete URL\n        x = re.sub(\"http\\w+\", '',x)\n        # Replace consecutive empty spaces with a single space character\n        x = re.sub(r\"\\s+\", \" \", x)\n        # Replace consecutive commas and periods with one comma and period character\n        x = re.sub(r\"\\.+\", \".\", x)\n        x = re.sub(r\"\\,+\", \",\", x)\n        # Remove empty characters at the beginning and end\n        x = x.strip()\n        return x","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:\n    \n    # Function to generate embeddings\n    def generate_embeddings(texts, model, tokenizer, device, batch_size=8):\n        all_embeddings = []\n        texts = [preprocess_text(text) for text in texts] # This was absent in the original code\n        for i in range(0, len(texts), batch_size):\n            batch_texts = texts[i:i+batch_size]\n            inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=1024).to(device)\n            with torch.no_grad():\n                outputs = model(**inputs)\n            embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n            embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n            all_embeddings.append(embeddings.cpu().numpy())\n        return np.concatenate(all_embeddings, axis=0)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:\n    \n    # Generate embeddings for misconceptions\n    MisconceptionName = list(misconception_mapping['MisconceptionName'].values)\n    all_ctx_vector = generate_embeddings(MisconceptionName, model, tokenizer, device)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:\n    \n    # Prepare test data\n    def make_all_question_text(df: pd.DataFrame) -> pd.DataFrame:\n        df[\"all_question_text\"] = df[\"ConstructName\"] + \" \" + df[\"QuestionText\"]\n        df[\"all_question_text\"] = df[\"all_question_text\"].apply(preprocess_text)\n        return df","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:\n    \n    def wide_to_long(df: pd.DataFrame) -> pd.DataFrame:\n        df = pd.melt(\n            df[\n                [\n                    \"QuestionId\",\n                    \"all_question_text\",\n                    \"CorrectAnswer\",\n                    \"AnswerAText\",\n                    \"AnswerBText\",\n                    \"AnswerCText\",\n                    \"AnswerDText\"\n                ]\n            ],\n            id_vars    = [\"QuestionId\", \"all_question_text\", \"CorrectAnswer\"],\n            var_name   = 'Answer',\n            value_name = 'value'\n        )\n        return df","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:    \n    \n    def make_all_text(df: pd.DataFrame) -> pd.DataFrame:\n        text_components = []\n        if \"all_question_text\" in df.columns:\n            text_components.append(df[\"all_question_text\"])\n        if \"value\" in df.columns:\n            text_components.append(df[\"value\"].apply(preprocess_text))\n\n        df[\"all_text\"] = pd.concat(text_components, axis=1).apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n        return df","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:   \n    \n    def simple_cosine(all_text_vector, all_ctx_vector):\n        temp =  cosine_similarity(all_text_vector, all_ctx_vector)\n        return temp\n\n    def cdist_similarity(all_text_vector, all_ctx_vector, m ):\n        dist = cdist(all_text_vector, all_ctx_vector, metric = m )\n        return 1 / (1 + dist)  # Convert distance to similarity\n    #     return np.argsort(-temp, axis=1)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:\n    \n    test = make_all_question_text(test)\n    test_long = wide_to_long(test)\n    test_long = make_all_text(test_long)\n    test_long = test_long.sort_values([\"QuestionId\", \"Answer\"]).reset_index(drop=True)\n\n    # Generate embeddings for test data\n    test_texts = list(test_long['all_text'].values)\n    all_text_vector = generate_embeddings(test_texts, model, tokenizer, device)\n\n    e_sim = cdist_similarity(all_text_vector, all_ctx_vector, 'euclidean')\n\n    si = e_sim \n\n    sim = np.argsort(-si,axis=1)\n\n    # Prepare submission\n    test_long[\"Answer_alphabet\"] = test_long[\"Answer\"].str.extract(r'Answer([A-Z])Text$')\n    test_long[\"QuestionId_Answer\"] = test_long[\"QuestionId\"].astype(\"str\") + \"_\" + test_long[\"Answer_alphabet\"]\n    test_long[\"MisconceptionId\"] = sim[:, :25].tolist()\n    test_long[\"MisconceptionId\"] = test_long[\"MisconceptionId\"].apply(lambda x: ' '.join(map(str, x)))\n\n    # filter correct row\n    test_long = test_long[test_long[\"CorrectAnswer\"] != test_long[\"Answer_alphabet\"]]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:\n\n    submission = test_long[[\"QuestionId_Answer\", \"MisconceptionId\"]].reset_index(drop=True)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:    \n    \n    sim[:,:25]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:\n\n    submission.head(10)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_8' in ENSEMBLE_SOLUTIONS:\n\n    submission.to_csv(\"submission_8.csv\", index=False)\n    print(\"Submission file created successfully!\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8. [Start Mining Misconceptions](https://www.kaggle.com/code/levantaokkz/start-mining-misconceptions)\n### [le van tao](https://www.kaggle.com/levantaokkz)","metadata":{}},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS:  \n    \n    import pandas as pd\n    import numpy as np\n    from sklearn.metrics.pairwise import cosine_similarity\n    from transformers import AutoTokenizer, AutoModel\n    import torch\n    from tqdm import tqdm\n    import re\n    from scipy.spatial.distance import cdist","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T07:21:20.263249Z","iopub.execute_input":"2024-09-21T07:21:20.263916Z","iopub.status.idle":"2024-09-21T07:21:25.155994Z","shell.execute_reply.started":"2024-09-21T07:21:20.263875Z","shell.execute_reply":"2024-09-21T07:21:25.155147Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS:\n    \n    train = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")\n    test = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\n    misconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n    sample_submission = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/sample_submission.csv\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T07:21:32.124411Z","iopub.execute_input":"2024-09-21T07:21:32.125202Z","iopub.status.idle":"2024-09-21T07:21:32.184181Z","shell.execute_reply.started":"2024-09-21T07:21:32.125159Z","shell.execute_reply":"2024-09-21T07:21:32.183364Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS:\n    \n    def preprocess_text(text):\n        # Convert to lowercase\n        text = text.lower()\n        # Remove special characters and digits\n        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n        # Remove extra whitespace\n        text = ' '.join(text.split())\n        return text\n\n\n    def make_all_question_text(df: pd.DataFrame) -> pd.DataFrame:\n        df[\"all_question_text\"] = df[\"ConstructName\"] + \" \" + df[\"QuestionText\"]\n        df[\"all_question_text\"] = df[\"all_question_text\"].apply(preprocess_text)\n        return df\n\n    # train = make_all_question_text(train)\n    test = make_all_question_text(test)\n    test","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS:\n    \n    def wide_to_long(df: pd.DataFrame) -> pd.DataFrame:\n        df = pd.melt(\n            df[[\n                \"QuestionId\",\n                \"all_question_text\",\n                \"CorrectAnswer\",\n                \"AnswerAText\",\n                \"AnswerBText\",\n                \"AnswerCText\",\n                \"AnswerDText\"\n            ]],\n            id_vars=[\"QuestionId\", \"all_question_text\", \"CorrectAnswer\"],\n            var_name='Answer',\n            value_name='value'\n        )\n        return df\n\n    test_long = wide_to_long(test)\n    test_long","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS:\n    \n    def make_all_text(df: pd.DataFrame) -> pd.DataFrame:\n        text_components = []\n        if \"all_question_text\" in df.columns:\n            text_components.append(df[\"all_question_text\"])\n        if \"value\" in df.columns:\n            text_components.append(df[\"value\"].apply(preprocess_text))\n\n        df[\"all_text\"] = pd.concat(text_components, axis=1).apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n        return df\n\n    test_long = make_all_text(test_long)\n    test_long = test_long.sort_values([\"QuestionId\", \"Answer\"]).reset_index(drop=True)\n    test_long","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS:    \n    \n    test_long = test_long.sort_values([\"QuestionId\", \"Answer\"]).reset_index(drop=True)\n    test_long","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS:    \n    \n    test_long[\"all_text\"].iloc[3]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS:\n\n    labels = misconception_mapping['MisconceptionName'].values","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T07:22:04.564993Z","iopub.execute_input":"2024-09-21T07:22:04.565937Z","iopub.status.idle":"2024-09-21T07:22:04.570195Z","shell.execute_reply.started":"2024-09-21T07:22:04.565894Z","shell.execute_reply":"2024-09-21T07:22:04.56918Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS:    \n    \n    from transformers import AutoTokenizer, AutoModel\n    import torch\n    # Sentences we want sentence embeddings for\n\n    device = \"cuda:0\"\n\n    # Load model from HuggingFace Hub\n    tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\n    model = AutoModel.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\n    model.eval()\n    model.to(device)\n    print(\"finish\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS:\n\n    def preprocess_text1(x):\n        # Convert words to lowercase\n        x = x.lower()\n        # Remove HTML\n    #     x = removeHTML(x)\n        # Delete strings starting with @\n        x = re.sub(\"@\\w+\", '',x)\n        # Delete Numbers\n        x = re.sub(\"'\\d+\", '',x)\n        x = re.sub(\"\\d+\", '',x)\n        # Delete URL\n        x = re.sub(\"http\\w+\", '',x)\n        # Replace consecutive empty spaces with a single space character\n        x = re.sub(r\"\\s+\", \" \", x)\n        # Replace consecutive commas and periods with one comma and period character\n        x = re.sub(r\"\\.+\", \".\", x)\n        x = re.sub(r\"\\,+\", \",\", x)\n        # Remove empty characters at the beginning and end\n        x = x.strip()\n        return x","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T07:22:17.179396Z","iopub.execute_input":"2024-09-21T07:22:17.179964Z","iopub.status.idle":"2024-09-21T07:22:17.186593Z","shell.execute_reply.started":"2024-09-21T07:22:17.179923Z","shell.execute_reply":"2024-09-21T07:22:17.185643Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS:  \n    \n    def generate_embeddings(texts, model, tokenizer, device, batch_size=8):\n        all_embeddings = []\n        texts = [preprocess_text1(text) for text in texts]\n        for i in range(0, len(texts), batch_size):\n            batch_texts = texts[i:i+batch_size]\n            inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n            with torch.no_grad():\n                outputs = model(**inputs)\n    #         attention_mask = inputs['attention_mask'].unsqueeze(-1)\n    #         embeddings = (outputs.last_hidden_state * attention_mask).sum(1) / attention_mask.sum(1)\n    #         embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n    #         all_embeddings.append(embeddings.cpu().numpy())\n    #     return np.concatenate(all_embeddings, axis=0)\n            embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n            embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n            all_embeddings.append(embeddings.cpu().numpy())\n        return np.concatenate(all_embeddings, axis=0)\n\n    test_texts = list(test_long['all_text'].values)\n    all_text_vector = generate_embeddings(test_texts, model, tokenizer, device)\n\n    MisconceptionName = list(misconception_mapping['MisconceptionName'].values)\n    all_ctx_vector = generate_embeddings(MisconceptionName, model, tokenizer, device)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS:   \n    \n    def cdist_similarity(all_text_vector, all_ctx_vector, m ):\n        dist = cdist(all_text_vector, all_ctx_vector, metric = m )\n        return 1 / (1 + dist)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T07:22:32.897116Z","iopub.execute_input":"2024-09-21T07:22:32.897678Z","iopub.status.idle":"2024-09-21T07:22:32.902667Z","shell.execute_reply.started":"2024-09-21T07:22:32.897637Z","shell.execute_reply":"2024-09-21T07:22:32.901775Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS: \n    \n    # test_cos_sim_arr = cosine_similarity(all_text_vector, all_ctx_vector)\n    test_cos_sim_arr = cdist_similarity(all_text_vector, all_ctx_vector, 'euclidean')\n    test_sorted_indices = np.argsort(-test_cos_sim_arr, axis=1)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T07:22:41.735962Z","iopub.execute_input":"2024-09-21T07:22:41.736826Z","iopub.status.idle":"2024-09-21T07:22:41.751549Z","shell.execute_reply.started":"2024-09-21T07:22:41.736787Z","shell.execute_reply":"2024-09-21T07:22:41.750797Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS:    \n    \n    test_sorted_indices[:, :25]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS:    \n    \n    test_long[\"QuestionId_Answer\"] = test_long[\"QuestionId\"].astype(\"str\") + \"_\" + test_long[\"Answer_alphabet\"]\n    test_long[\"MisconceptionId\"] = test_sorted_indices[:, :25].tolist()\n    test_long[\"MisconceptionId\"] = test_long[\"MisconceptionId\"].apply(lambda x: ' '.join(map(str, x)))\n    # filter correct row\n    test_long = test_long[test_long[\"CorrectAnswer\"] != test_long[\"Answer_alphabet\"]]\n    submission = test_long[[\"QuestionId_Answer\", \"MisconceptionId\"]].reset_index(drop=True)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_9' in ENSEMBLE_SOLUTIONS:\n\n    submission.to_csv('/kaggle/working/submission_9.csv', index=False)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9. [Simple-baseline](https://www.kaggle.com/code/arunodhayan/simple-baseline)\n### [Arunodhayan](https://www.kaggle.com/arunodhayan)","metadata":{}},{"cell_type":"code","source":"if 'SOLUTION_10' in ENSEMBLE_SOLUTIONS: pass","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 10. [Zero-shot w/ LLM feature + bge small](https://www.kaggle.com/code/ashwanibhat/zero-shot-w-llm-feature-bge-small)\n### [Ashwani](https://www.kaggle.com/ashwanibhat)","metadata":{}},{"cell_type":"code","source":"if 'SOLUTION_11' in ENSEMBLE_SOLUTIONS: pass","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 13. [[Eedi] [Infer] Finetune BGE Embedding Model ðŸš€ðŸš€](https://www.kaggle.com/code/abdullahmeda/eedi-infer-finetune-bge-embedding-model)\n### [Abdullah Meda](https://www.kaggle.com/abdullahmeda)","metadata":{}},{"cell_type":"markdown","source":"> A fork of https://www.kaggle.com/code/pshikk/similarity-preprocessing\n\n> Training notebook at https://www.kaggle.com/code/abdullahmeda/eedi-train-finetune-bge-embedding-model","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"if 'SOLUTION_13' in ENSEMBLE_SOLUTIONS: pass","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:20:46.786841Z","iopub.execute_input":"2024-09-21T15:20:46.787556Z","iopub.status.idle":"2024-09-21T15:20:46.792119Z","shell.execute_reply.started":"2024-09-21T15:20:46.787514Z","shell.execute_reply":"2024-09-21T15:20:46.791219Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\n\nfrom scipy.spatial.distance import cdist\nfrom sklearn.metrics.pairwise import cosine_similarity","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:20:51.449474Z","iopub.execute_input":"2024-09-21T15:20:51.449869Z","iopub.status.idle":"2024-09-21T15:20:56.635053Z","shell.execute_reply.started":"2024-09-21T15:20:51.449831Z","shell.execute_reply":"2024-09-21T15:20:56.634183Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embed_model_pth = '/kaggle/input/eedi-bge-large-en-v1-5-fintetuned-exp-1/eedi_model'","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:21:02.897201Z","iopub.execute_input":"2024-09-21T15:21:02.8982Z","iopub.status.idle":"2024-09-21T15:21:02.902366Z","shell.execute_reply.started":"2024-09-21T15:21:02.898158Z","shell.execute_reply":"2024-09-21T15:21:02.901408Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\ntrain = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")\nmisconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:21:08.93796Z","iopub.execute_input":"2024-09-21T15:21:08.938336Z","iopub.status.idle":"2024-09-21T15:21:09.00051Z","shell.execute_reply.started":"2024-09-21T15:21:08.938301Z","shell.execute_reply":"2024-09-21T15:21:08.999642Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.dropna(axis=1)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:21:15.24848Z","iopub.execute_input":"2024-09-21T15:21:15.249443Z","iopub.status.idle":"2024-09-21T15:21:15.265899Z","shell.execute_reply.started":"2024-09-21T15:21:15.249391Z","shell.execute_reply":"2024-09-21T15:21:15.265052Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(embed_model_pth)\nmodel     = AutoModel.from_pretrained(embed_model_pth).to(\"cuda:0\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:21:20.136767Z","iopub.execute_input":"2024-09-21T15:21:20.137715Z","iopub.status.idle":"2024-09-21T15:21:31.465763Z","shell.execute_reply.started":"2024-09-21T15:21:20.137671Z","shell.execute_reply":"2024-09-21T15:21:31.46489Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/code/pshikk/similarity-preprocessing\n\ndef preprocess_text(x):\n    x = x.lower()                 # Convert words to lowercase\n    x = re.sub(\"@\\w+\", '',x)      # Delete strings starting with @\n    x = re.sub(\"'\\d+\", '',x)      # Delete Numbers\n    x = re.sub(\"\\d+\", '',x)\n    x = re.sub(\"http\\w+\", '',x)   # Delete URL\n    x = re.sub(r\"\\s+\", \" \", x)    # Replace consecutive empty spaces with a single space character\n    x = re.sub(r\"\\.+\", \".\", x)    # Replace consecutive commas and periods with one comma and period character\n    x = re.sub(r\"\\,+\", \",\", x)\n    x = x.strip()                 # Remove empty characters at the beginning and end\n    return x","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:21:36.863185Z","iopub.execute_input":"2024-09-21T15:21:36.864139Z","iopub.status.idle":"2024-09-21T15:21:36.870502Z","shell.execute_reply.started":"2024-09-21T15:21:36.8641Z","shell.execute_reply":"2024-09-21T15:21:36.86957Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_embeddings(texts, model, tokenizer, device, batch_size=8):\n    \"\"\" Function to generate embeddings \"\"\"\n    \n    all_embeddings = []\n    texts = [preprocess_text(text) for text in texts] # This was absent in the original code\n    for i in range(0, len(texts), batch_size):\n        batch_texts = texts[i:i+batch_size]\n        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=1024).to(device)\n        with torch.no_grad():\n            outputs = model(**inputs)\n        embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n        all_embeddings.append(embeddings.cpu().numpy())\n    return np.concatenate(all_embeddings, axis=0)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:21:41.97546Z","iopub.execute_input":"2024-09-21T15:21:41.976376Z","iopub.status.idle":"2024-09-21T15:21:41.98355Z","shell.execute_reply.started":"2024-09-21T15:21:41.97633Z","shell.execute_reply":"2024-09-21T15:21:41.982532Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate embeddings for misconceptions\nMisconceptionName = list(misconception_mapping['MisconceptionName'].values)\nall_ctx_vector = generate_embeddings(MisconceptionName, model, tokenizer, \"cuda:0\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:21:46.097329Z","iopub.execute_input":"2024-09-21T15:21:46.097712Z","iopub.status.idle":"2024-09-21T15:21:56.988738Z","shell.execute_reply.started":"2024-09-21T15:21:46.097677Z","shell.execute_reply":"2024-09-21T15:21:56.987782Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare test data\ndef make_all_question_text(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"all_question_text\"] = df[\"SubjectName\"] + \"\\n\\n\" + df[\"ConstructName\"] + \"\\n\\n\" + df[\"QuestionText\"]\n    df[\"all_question_text\"] = df[\"all_question_text\"].apply(preprocess_text)\n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:22:03.141182Z","iopub.execute_input":"2024-09-21T15:22:03.142096Z","iopub.status.idle":"2024-09-21T15:22:03.147573Z","shell.execute_reply.started":"2024-09-21T15:22:03.142057Z","shell.execute_reply":"2024-09-21T15:22:03.146499Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def wide_to_long(df: pd.DataFrame) -> pd.DataFrame:\n    df = pd.melt(\n        df[\n            [\n                \"QuestionId\",\n                \"all_question_text\",\n                \"CorrectAnswer\",\n                \"AnswerAText\",\n                \"AnswerBText\",\n                \"AnswerCText\",\n                \"AnswerDText\"\n            ]\n        ],\n        id_vars    = [\"QuestionId\", \"all_question_text\", \"CorrectAnswer\"],\n        var_name   = 'Answer',\n        value_name = 'value'\n    )\n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:22:07.18163Z","iopub.execute_input":"2024-09-21T15:22:07.182389Z","iopub.status.idle":"2024-09-21T15:22:07.187859Z","shell.execute_reply.started":"2024-09-21T15:22:07.182342Z","shell.execute_reply":"2024-09-21T15:22:07.186827Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_all_text(df: pd.DataFrame) -> pd.DataFrame:\n    text_components = []\n    if \"all_question_text\" in df.columns:\n        text_components.append(df[\"all_question_text\"])\n    if \"value\" in df.columns:\n        text_components.append(df[\"value\"].apply(preprocess_text))\n    \n    df[\"all_text\"] = pd.concat(text_components, axis=1).apply(lambda x: '\\n\\n'.join(x.dropna().astype(str)), axis=1)\n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:22:11.413287Z","iopub.execute_input":"2024-09-21T15:22:11.414013Z","iopub.status.idle":"2024-09-21T15:22:11.420647Z","shell.execute_reply.started":"2024-09-21T15:22:11.413968Z","shell.execute_reply":"2024-09-21T15:22:11.41964Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def simple_cosine(all_text_vector, all_ctx_vector):\n    temp =  cosine_similarity(all_text_vector, all_ctx_vector)\n    return temp\n\ndef cdist_similarity(all_text_vector, all_ctx_vector, m ):\n    dist = cdist(all_text_vector, all_ctx_vector, metric = m )\n    return 1 / (1 + dist)  # Convert distance to similarity\n#     return np.argsort(-temp, axis=1)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:22:15.449551Z","iopub.execute_input":"2024-09-21T15:22:15.450278Z","iopub.status.idle":"2024-09-21T15:22:15.455273Z","shell.execute_reply.started":"2024-09-21T15:22:15.450236Z","shell.execute_reply":"2024-09-21T15:22:15.454239Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = make_all_question_text(test)\ntest_long = wide_to_long(test)\ntest_long = make_all_text(test_long)\ntest_long = test_long.sort_values([\"QuestionId\", \"Answer\"]).reset_index(drop=True)\n\n# Generate embeddings for test data\ntest_texts = list(test_long['all_text'].values)\nall_text_vector = generate_embeddings(test_texts, model, tokenizer, \"cuda:0\")\n\ne_sim = cdist_similarity(all_text_vector, all_ctx_vector, 'euclidean')\n\nsi = e_sim \n\nsim = np.argsort(-si,axis=1)\n\n# Prepare submission\ntest_long[\"Answer_alphabet\"] = test_long[\"Answer\"].str.extract(r'Answer([A-Z])Text$')\ntest_long[\"QuestionId_Answer\"] = test_long[\"QuestionId\"].astype(\"str\") + \"_\" + test_long[\"Answer_alphabet\"]\ntest_long[\"MisconceptionId\"] = sim[:, :25].tolist()\ntest_long[\"MisconceptionId\"] = test_long[\"MisconceptionId\"].apply(lambda x: ' '.join(map(str, x)))\n\n# filter correct row\ntest_long = test_long[test_long[\"CorrectAnswer\"] != test_long[\"Answer_alphabet\"]]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:22:20.057596Z","iopub.execute_input":"2024-09-21T15:22:20.058293Z","iopub.status.idle":"2024-09-21T15:22:20.240483Z","shell.execute_reply.started":"2024-09-21T15:22:20.058251Z","shell.execute_reply":"2024-09-21T15:22:20.239491Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = test_long[[\"QuestionId_Answer\", \"MisconceptionId\"]].reset_index(drop=True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:22:31.028263Z","iopub.execute_input":"2024-09-21T15:22:31.028674Z","iopub.status.idle":"2024-09-21T15:22:31.034857Z","shell.execute_reply.started":"2024-09-21T15:22:31.028635Z","shell.execute_reply":"2024-09-21T15:22:31.033707Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head(10)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:22:35.137303Z","iopub.execute_input":"2024-09-21T15:22:35.138202Z","iopub.status.idle":"2024-09-21T15:22:35.151435Z","shell.execute_reply.started":"2024-09-21T15:22:35.13816Z","shell.execute_reply":"2024-09-21T15:22:35.150469Z"},"_kg_hide-output":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission_13.csv\", index=False)\nprint(\"Submission file created successfully!\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:22:40.483335Z","iopub.execute_input":"2024-09-21T15:22:40.484076Z","iopub.status.idle":"2024-09-21T15:22:40.492088Z","shell.execute_reply.started":"2024-09-21T15:22:40.484037Z","shell.execute_reply":"2024-09-21T15:22:40.490994Z"},"_kg_hide-output":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 14. [Fine-tuning bge [Infer]](https://www.kaggle.com/code/sinchir0/fine-tuning-bge-infer)\n### [sinchir0](https://www.kaggle.com/sinchir0)","metadata":{}},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    \n    DATA_PATH = \"/kaggle/input/eedi-mining-misconceptions-in-mathematics\"\n    MODEL_PATH = \"/kaggle/input/fine-tuning-bge-train\" + \"/trained_model\"","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:43:58.782454Z","iopub.execute_input":"2024-09-21T15:43:58.783259Z","iopub.status.idle":"2024-09-21T15:43:58.787417Z","shell.execute_reply.started":"2024-09-21T15:43:58.783216Z","shell.execute_reply":"2024-09-21T15:43:58.786365Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    \n    !pip uninstall -qq -y \\\n    polars","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:44:04.615005Z","iopub.execute_input":"2024-09-21T15:44:04.615413Z","iopub.status.idle":"2024-09-21T15:44:06.579979Z","shell.execute_reply.started":"2024-09-21T15:44:04.615375Z","shell.execute_reply":"2024-09-21T15:44:06.578694Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    \n    !python -m pip install -qq --no-index --find-links=/kaggle/input/eedi-library \\\n    polars\\\n    sentence-transformers","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:44:10.857703Z","iopub.execute_input":"2024-09-21T15:44:10.858428Z","iopub.status.idle":"2024-09-21T15:44:25.072685Z","shell.execute_reply.started":"2024-09-21T15:44:10.858379Z","shell.execute_reply":"2024-09-21T15:44:25.071411Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    \n    import os\n\n    import polars as pl\n    import numpy as np\n\n    from sklearn.metrics.pairwise import cosine_similarity\n    from sentence_transformers import SentenceTransformer","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:44:29.825014Z","iopub.execute_input":"2024-09-21T15:44:29.825894Z","iopub.status.idle":"2024-09-21T15:44:29.830881Z","shell.execute_reply.started":"2024-09-21T15:44:29.825828Z","shell.execute_reply":"2024-09-21T15:44:29.829908Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n\n    import sentence_transformers\n\n    assert pl.__version__ == \"1.7.1\"\n    assert sentence_transformers.__version__ == \"3.1.0\"","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:44:33.643622Z","iopub.execute_input":"2024-09-21T15:44:33.644619Z","iopub.status.idle":"2024-09-21T15:44:33.648871Z","shell.execute_reply.started":"2024-09-21T15:44:33.644574Z","shell.execute_reply":"2024-09-21T15:44:33.647941Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    \n    test = pl.read_csv(f\"{DATA_PATH}/test.csv\")\n    misconception_mapping = pl.read_csv(f\"{DATA_PATH}/misconception_mapping.csv\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:44:37.925641Z","iopub.execute_input":"2024-09-21T15:44:37.926035Z","iopub.status.idle":"2024-09-21T15:44:37.935139Z","shell.execute_reply.started":"2024-09-21T15:44:37.925997Z","shell.execute_reply":"2024-09-21T15:44:37.934214Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n\n    common_col = [\n        \"QuestionId\",\n        \"ConstructName\",\n        \"SubjectName\",\n        \"QuestionText\",\n        \"CorrectAnswer\",\n    ]\n\n    test_long = (\n        pl.read_csv(f\"{DATA_PATH}/test.csv\")\n        .select(\n            pl.col(common_col + [f\"Answer{alpha}Text\" for alpha in [\"A\", \"B\", \"C\", \"D\"]])\n        )\n        .unpivot(\n            index=common_col,\n            variable_name=\"AnswerType\",\n            value_name=\"AnswerText\",\n        )\n        .with_columns(\n            pl.concat_str(\n                [\n                    pl.col(\"ConstructName\"),\n                    pl.col(\"SubjectName\"),\n                    pl.col(\"QuestionText\"),\n                    pl.col(\"AnswerText\"),\n                ],\n                separator=\" \",\n            ).alias(\"AllText\"),\n            pl.col(\"AnswerType\").str.extract(r\"Answer([A-D])Text$\").alias(\"AnswerAlphabet\"),\n        )\n        .with_columns(\n            pl.concat_str(\n                [pl.col(\"QuestionId\"), pl.col(\"AnswerAlphabet\")], separator=\"_\"\n            ).alias(\"QuestionId_Answer\"),\n        )\n        .sort(\"QuestionId_Answer\")\n    )\n    test_long.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-21T15:44:42.575273Z","iopub.execute_input":"2024-09-21T15:44:42.575925Z","iopub.status.idle":"2024-09-21T15:44:42.591938Z","shell.execute_reply.started":"2024-09-21T15:44:42.575871Z","shell.execute_reply":"2024-09-21T15:44:42.591031Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    \n    model = SentenceTransformer(MODEL_PATH)\n\n    test_long_vec = model.encode(\n        test_long[\"AllText\"].to_list(), normalize_embeddings=True\n    )\n    misconception_mapping_vec = model.encode(\n        misconception_mapping[\"MisconceptionName\"].to_list(), normalize_embeddings=True\n    )\n    print(test_long_vec.shape)\n    print(misconception_mapping_vec.shape)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    \n    test_cos_sim_arr = cosine_similarity(test_long_vec, misconception_mapping_vec)\n    test_sorted_indices = np.argsort(-test_cos_sim_arr, axis=1)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    \n    submission = (\n        test_long.with_columns(\n            pl.Series(test_sorted_indices[:, :25].tolist()).alias(\"MisconceptionId\")\n        )\n        .with_columns(\n            pl.col(\"MisconceptionId\").map_elements(\n                lambda x: \" \".join(map(str, x)), return_dtype=pl.String\n            )\n        ).filter(\n            pl.col(\"CorrectAnswer\") != pl.col(\"AnswerAlphabet\")\n        ).select(\n            pl.col([\"QuestionId_Answer\", \"MisconceptionId\"])\n        ).sort(\"QuestionId_Answer\")\n    )","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n    \n    submission.head()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_14' in ENSEMBLE_SOLUTIONS:\n\n    submission.write_csv(\"submission_14.csv\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 15. [Ensemble MPNETV2+BGE+GTE with Faiss-GPU](https://www.kaggle.com/code/medali1992/ensemble-mpnetv2-bge-gte-with-faiss-gpu)\n### [Med Ali Bouchhioua](https://www.kaggle.com/medali1992)","metadata":{}},{"cell_type":"code","source":"if 'SOLUTION_15' in ENSEMBLE_SOLUTIONS: pass","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## About this notebook\n\nThe idea behind this notebook is inspired by [**Eedi | Ensemble of solutions**](https://www.kaggle.com/code/vyacheslavbolotin/eedi-ensemble-of-solutions). I wanted to experiment with three different sentence transformer models and apply a voting ensemble to see if the score improves.\n\nI am only sharing the model weights to preserve the integrity of the competition, and I hope this notebook helps the Kaggle community.\n\n### Individual model LB scores\n- `BAAI/bge-large-en-v1.5` â†’ `LB=0.257`\n- `sentence-transformers/all-mpnet-base-v2` â†’ `LB=0.251`\n- `Alibaba-NLP/gte-base-en-v1.5` â†’ `LB=0.265`\n\nI encountered the same issue mentioned [here](https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/discussion/536640). You can find a workaround in this [notebook](https://www.kaggle.com/code/medali1992/modified-gte-base-weights/notebook), where I solved the problem (I used this [link](https://huggingface.co/Alibaba-NLP/new-impl/discussions/2)).\n\nOnce again, this is an experimental notebook, and I hope it inspires some novel ideas.\n\n### Version2\nI replaced the mode ensembling with random choice.\n\n### Version3\nI used a bad bge_weights(should be version2 not version3)","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"# K=25\n# VER=3\n# BS=16\n\n# DATA_PATH = \"/kaggle/input/eedi-mining-misconceptions-in-mathematics\"\n# BGE_MODEL_PATH = \"/kaggle/input/bge-weights-version1/bge_trained_model_version3\"\n# GTE_BASE_MODEL_PATH = \"/kaggle/input/mod-gte-base-weights/gte-base-weights/gte-base_trained_model_version1\"\n# MPNETV2_MODEL_PATH = \"/kaggle/input/mpnet-weights-version1/mpnetV2_trained_model_version3\"","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip uninstall -qq -y \\\n# polars","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !python -m pip install -qq --no-index --find-links=/kaggle/input/eedi-library-from-sinchiro \\\n# polars\\\n# sentence-transformers\\\n# faiss-gpu","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# import gc\n\n# import polars as pl\n# import numpy as np\n# from scipy import stats\n# import torch\n\n# import faiss\n\n# from sklearn.metrics.pairwise import cosine_similarity\n# from sentence_transformers import SentenceTransformer\n# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n# os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import sentence_transformers\n\n# assert pl.__version__ == \"1.7.1\"\n# assert sentence_transformers.__version__ == \"3.1.1\"","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test = pl.read_csv(f\"{DATA_PATH}/test.csv\")\n# misconception_mapping = pl.read_csv(f\"{DATA_PATH}/misconception_mapping.csv\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# common_col = [\n#     \"QuestionId\",\n#     \"ConstructName\",\n#     \"SubjectName\",\n#     \"QuestionText\",\n#     \"CorrectAnswer\",\n# ]\n\n# test_long = (\n#     test\n#     .select(\n#         pl.col(common_col + [f\"Answer{alpha}Text\" for alpha in [\"A\", \"B\", \"C\", \"D\"]])\n#     )\n#     .unpivot(\n#         index=common_col,\n#         variable_name=\"AnswerType\",\n#         value_name=\"AnswerText\",\n#     )\n#     .with_columns(\n#         pl.concat_str(\n#             [\n#                 pl.col(\"ConstructName\"),\n#                 pl.col(\"SubjectName\"),\n#                 pl.col(\"QuestionText\"),\n#                 pl.col(\"AnswerText\"),\n#             ],\n#             separator=\" \",\n#         ).alias(\"AllText\"),\n#         pl.col(\"AnswerType\").str.extract(r\"Answer([A-D])Text$\").alias(\"AnswerAlphabet\"),\n#     )\n#     .with_columns(\n#         pl.concat_str(\n#             [pl.col(\"QuestionId\"), pl.col(\"AnswerAlphabet\")], separator=\"_\"\n#         ).alias(\"QuestionId_Answer\"),\n#     )\n#     .sort(\"QuestionId_Answer\")\n# )\n# test_long.head()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def encode_texts(test_long, misconception_mapping, model_path, batch_size=8, progress_bar=True):\n#     model = SentenceTransformer(model_path, local_files_only=True, trust_remote_code=True)\n#     model.to(device)\n#     # wrap the model to use all GPUs\n#     model = torch.nn.DataParallel(model)\n#     model.eval()\n    \n#     # Encode all text from the test_long DataFrame\n#     all_text_vec = model.module.encode(test_long[\"AllText\"].to_list(), batch_size=batch_size , normalize_embeddings=True, show_progress_bar=progress_bar)\n    \n#     # Encode misconception names from the misconception_mapping DataFrame\n#     misconception_mapping_vec = model.module.encode(misconception_mapping[\"MisconceptionName\"].to_list(), batch_size=batch_size, normalize_embeddings=True, show_progress_bar=progress_bar)\n    \n#     torch.cuda.empty_cache()\n#     gc.collect()\n    \n#     return all_text_vec, misconception_mapping_vec\n\n# def search_faiss(k, d, vectors_to_add, query_vectors):\n#     \"\"\"\n#     Perform a FAISS search with L2 distance.\n    \n#     Parameters:\n#         k (int): Number of nearest neighbors to search for.\n#         d (int): Dimension of the vectors.\n#         vectors_to_add (numpy.ndarray): The vectors to add to the FAISS index.\n#         query_vectors (numpy.ndarray): The vectors to search for the nearest neighbors.\n        \n#     Returns:\n#         D (numpy.ndarray): The distances to the k nearest neighbors.\n#         I (numpy.ndarray): The indices of the k nearest neighbors.\n#     \"\"\"\n#     # Create the index\n#     index = faiss.IndexFlatL2(d)\n    \n#     # Add vectors to the index\n#     index.add(vectors_to_add)\n    \n#     # Search for k nearest neighbors\n#     D, I = index.search(query_vectors, k)\n    \n#     return D, I\n\n# def ensemble_majority_vote(*indices):\n#     \"\"\"\n#     Apply ensembling with majority voting across multiple index arrays.\n    \n#     Parameters:\n#         indices (numpy.ndarray): Variable number of index arrays to ensemble.\n        \n#     Returns:\n#         numpy.ndarray: The majority-voted indices.\n#     \"\"\"\n#     # Stack indices along a new axis (shape: (num_searches, num_queries, k))\n#     stacked_indices = np.stack(indices, axis=0)\n    \n#     # Apply mode to find the majority vote along the first axis (searches)\n#     majority_indices, _ = stats.mode(stacked_indices, axis=0)\n    \n#     # Remove the extra dimension added by mode and return the majority-voted indices\n#     return majority_indices.squeeze()\n\n# def ensemble_random_choice(*indices):\n#     \"\"\"\n#     Apply ensembling with random choice across multiple index arrays.\n    \n#     Parameters:\n#         indices (numpy.ndarray): Variable number of index arrays to ensemble.\n        \n#     Returns:\n#         numpy.ndarray: Randomly selected indices from the given index arrays.\n#     \"\"\"\n#     # Stack indices along a new axis (shape: (num_searches, num_queries, k))\n#     stacked_indices = np.stack(indices, axis=0)\n    \n#     # Number of searches (i.e., how many index arrays we have)\n#     num_searches = stacked_indices.shape[0]\n    \n#     # Randomly choose indices from the 3 arrays\n#     # For each query and each nearest neighbor (k), randomly select an index from the available searches\n#     random_choices = np.random.randint(0, num_searches, size=stacked_indices.shape[1:])\n    \n#     # Use the random choices to pick the corresponding indices\n#     random_indices = np.choose(random_choices, stacked_indices)\n    \n#     return random_indices","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# D = 768\n# gte_base_all_text_vec, misconception_mapping_vec = encode_texts(test_long, misconception_mapping, GTE_BASE_MODEL_PATH, BS)\n# _, gte_base_text_index = search_faiss(K, D, misconception_mapping_vec, gte_base_all_text_vec)\n# print(gte_base_text_index.shape)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# D = 768\n# mpnetv2_base_all_text_vec, misconception_mapping_vec = encode_texts(test_long, misconception_mapping, MPNETV2_MODEL_PATH, BS)\n# _, mpnetv2_text_index = search_faiss(K, D, misconception_mapping_vec, mpnetv2_base_all_text_vec)\n# print(mpnetv2_text_index.shape)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# D = 1024\n# bge_base_all_text_vec, misconception_mapping_vec = encode_texts(test_long, misconception_mapping, BGE_MODEL_PATH, BS)\n# _, bge_base_text_index = search_faiss(K, D, misconception_mapping_vec, bge_base_all_text_vec)\n# print(bge_base_text_index.shape)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ensemble_indices = ensemble_majority_vote(gte_base_text_index, bge_base_text_index, mpnetv2_text_index)\n# print(ensemble_indices.shape)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = (\n#     test_long.with_columns(\n#         pl.Series(ensemble_indices[:, :25].tolist()).alias(\"MisconceptionId\")\n#     )\n#     .with_columns(\n#         pl.col(\"MisconceptionId\").map_elements(\n#             lambda x: \" \".join(map(str, x)), return_dtype=pl.String\n#         )\n#     ).filter(\n#         pl.col(\"CorrectAnswer\") != pl.col(\"AnswerAlphabet\")\n#     ).select(\n#         pl.col([\"QuestionId_Answer\", \"MisconceptionId\"])\n#     ).sort(\"QuestionId_Answer\")\n# )","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission.head()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission.write_csv(\"submission_15.csv\")","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 16. [Infer BGE Synthetic Data](https://www.kaggle.com/code/minhnguyendichnhat/infer-bge-synthetic-data)\n### [Minh Nguyen Dich Nhat](https://www.kaggle.com/minhnguyendichnhat)","metadata":{}},{"cell_type":"code","source":"if 'SOLUTION_16' in ENSEMBLE_SOLUTIONS: pass","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, math, numpy as np\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"","metadata":{"execution":{"iopub.status.busy":"2024-09-29T17:57:44.244504Z","iopub.execute_input":"2024-09-29T17:57:44.245378Z","iopub.status.idle":"2024-09-29T17:57:44.249576Z","shell.execute_reply.started":"2024-09-29T17:57:44.245326Z","shell.execute_reply":"2024-09-29T17:57:44.24854Z"},"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n!pip uninstall -y torch\n!pip install --no-index --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-vllm vllm\n!pip install -U --upgrade /kaggle/input/vllm-t4-fix/grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!pip install -U --upgrade /kaggle/input/vllm-t4-fix/ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl\n!pip install --no-deps --no-index /kaggle/input/hf-libraries/sentence-transformers/sentence_transformers-3.1.0-py3-none-any.whl","metadata":{"_kg_hide-input":true,"scrolled":true,"execution":{"iopub.status.busy":"2024-09-29T17:57:47.806508Z","iopub.execute_input":"2024-09-29T17:57:47.807365Z","iopub.status.idle":"2024-09-29T18:01:14.413975Z","shell.execute_reply.started":"2024-09-29T17:57:47.807326Z","shell.execute_reply":"2024-09-29T18:01:14.41292Z"},"_kg_hide-output":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom transformers import AutoTokenizer\nimport pandas as pd\n\n\ndf_test = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/hugging-quants-meta-llama-3-1-8b-instruct-awq-int4\")\n\nPROMPT  = \"\"\"Question: {Question}\nIncorrect Answer: {IncorrectAnswer}\nCorrect Answer: {CorrectAnswer}\nConstruct Name: {ConstructName}\nSubject Name: {SubjectName}\n\nYour task: Identify the misconception behind Incorrect Answer. Answer concisely and generically inside <response>$$INSERT TEXT HERE$$</response>.\nBefore answering the question think step by step concisely in 1-2 sentence inside <thinking>$$INSERT TEXT HERE$$</thinking> tag and respond your final misconception inside <response>$$INSERT TEXT HERE$$</response> tag.\"\"\"\n\ndef apply_template(row, tokenizer):\n    messages = [\n        {\n            \"role\": \"user\", \n            \"content\": PROMPT.format(\n                 ConstructName=row[\"ConstructName\"],\n                 SubjectName=row[\"SubjectName\"],\n                 Question=row[\"QuestionText\"],\n                 IncorrectAnswer=row[f\"CorrectAnswerText\"],\n                 CorrectAnswer=row[f\"AnswerText\"])\n        }\n    ]\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    return text","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-29T18:03:39.497919Z","iopub.execute_input":"2024-09-29T18:03:39.4983Z","iopub.status.idle":"2024-09-29T18:03:43.141166Z","shell.execute_reply.started":"2024-09-29T18:03:39.498262Z","shell.execute_reply":"2024-09-29T18:03:43.140384Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-29T18:03:48.209816Z","iopub.execute_input":"2024-09-29T18:03:48.210194Z","iopub.status.idle":"2024-09-29T18:03:48.233645Z","shell.execute_reply.started":"2024-09-29T18:03:48.210159Z","shell.execute_reply":"2024-09-29T18:03:48.232746Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_correct_answer(row):\n    if row['CorrectAnswer'] == 'A':\n        return row['AnswerAText']\n    elif row['CorrectAnswer'] == 'B':\n        return row['AnswerBText']\n    elif row['CorrectAnswer'] == 'C':\n        return row['AnswerCText']\n    elif row['CorrectAnswer'] == 'D':\n        return row['AnswerDText']\n    else:\n        return None\n\n# Apply the function to create the CorrectAnswer column\ndf_test['CorrectAnswerText'] = df_test.apply(get_correct_answer, axis=1)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-29T18:03:52.088173Z","iopub.execute_input":"2024-09-29T18:03:52.088807Z","iopub.status.idle":"2024-09-29T18:03:52.097636Z","shell.execute_reply.started":"2024-09-29T18:03:52.08877Z","shell.execute_reply":"2024-09-29T18:03:52.096496Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-29T18:03:58.12933Z","iopub.execute_input":"2024-09-29T18:03:58.130029Z","iopub.status.idle":"2024-09-29T18:03:58.145006Z","shell.execute_reply.started":"2024-09-29T18:03:58.129991Z","shell.execute_reply":"2024-09-29T18:03:58.144046Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"select_column = [\"QuestionId\", \"ConstructName\", \"SubjectName\", \"CorrectAnswer\", \"QuestionText\", \"CorrectAnswerText\"]\ndf_answer = pd.melt(df_test, \n                    id_vars=select_column,\n                    value_vars=[f\"Answer{ans}Text\" for ans in [\"A\", \"B\", \"C\", \"D\"]],\n                    var_name=\"Option\",\n                    value_name=\"AnswerText\").sort_values(\"QuestionId\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-29T18:04:01.834149Z","iopub.execute_input":"2024-09-29T18:04:01.834898Z","iopub.status.idle":"2024-09-29T18:04:01.853207Z","shell.execute_reply.started":"2024-09-29T18:04:01.83486Z","shell.execute_reply":"2024-09-29T18:04:01.852198Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndf_answer['Option'] = df_answer['Option'].apply(lambda x: re.search(r'Answer([A-D])', x).group(1) if re.search(r'Answer([A-D])', x) else None)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-29T18:04:06.082389Z","iopub.execute_input":"2024-09-29T18:04:06.082759Z","iopub.status.idle":"2024-09-29T18:04:06.088618Z","shell.execute_reply.started":"2024-09-29T18:04:06.082725Z","shell.execute_reply":"2024-09-29T18:04:06.08773Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_answer = df_answer[df_answer['CorrectAnswer'] != df_answer['Option']]\ndf_answer[\"Prompt\"] = df_answer.apply(lambda row: apply_template(row, tokenizer), axis=1)\ndf_answer.to_parquet(\"test.parquet\", index=False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-29T18:04:10.566142Z","iopub.execute_input":"2024-09-29T18:04:10.566522Z","iopub.status.idle":"2024-09-29T18:04:10.738896Z","shell.execute_reply.started":"2024-09-29T18:04:10.566487Z","shell.execute_reply":"2024-09-29T18:04:10.737279Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile run_vllm.py\n\nimport re\nimport vllm\nimport pandas as pd\n\ndf = pd.read_parquet(\"test.parquet\")\n\nllm = vllm.LLM(\n    \"/kaggle/input/hugging-quants-meta-llama-3-1-8b-instruct-awq-int4\",\n    quantization=\"awq\",\n    tensor_parallel_size=2, \n    gpu_memory_utilization=0.95, \n    trust_remote_code=True,\n    dtype=\"half\", \n    enforce_eager=True,\n    max_model_len=8192,\n    disable_log_stats=True\n)\ntokenizer = llm.get_tokenizer()\n\n\nresponses = llm.generate(\n    df[\"Prompt\"].values,\n    vllm.SamplingParams(\n        n=1,  # Number of output sequences to return for each prompt.\n        top_p=0.9,  # Float that controls the cumulative probability of the top tokens to consider.\n        temperature=0,  # randomness of the sampling\n        seed=777, # Seed for reprodicibility\n        skip_special_tokens=False,  # Whether to skip special tokens in the output.\n        max_tokens=2048,  # Maximum number of tokens to generate per output sequence.\n    ),\n    use_tqdm = True\n)\n\nresponses = [x.outputs[0].text for x in responses]\ndf[\"FullResponse\"] = responses\n\ndef extract_response(text):\n    return \",\".join(re.findall(r\"<response>(.*?)</response>\", text)).strip()\n\nresponses = [extract_response(x) for x in responses]\ndf[\"Misconception\"] = responses\ndf.to_parquet(\"output.parquet\", index=False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-29T18:04:14.550509Z","iopub.execute_input":"2024-09-29T18:04:14.551269Z","iopub.status.idle":"2024-09-29T18:04:14.558113Z","shell.execute_reply.started":"2024-09-29T18:04:14.551228Z","shell.execute_reply":"2024-09-29T18:04:14.557166Z"},"_kg_hide-output":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python run_vllm.py","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-29T18:04:21.154965Z","iopub.execute_input":"2024-09-29T18:04:21.155367Z","iopub.status.idle":"2024-09-29T18:05:26.023994Z","shell.execute_reply.started":"2024-09-29T18:04:21.15533Z","shell.execute_reply":"2024-09-29T18:05:26.02293Z"},"scrolled":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_parquet('/kaggle/working/output.parquet')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_text(row):\n    text = f\"\"\"\n    {row[\"ConstructName\"]}\n    {row[\"QuestionText\"]}\n    Answer: {row[\"AnswerText\"]}\n    Misconception: {row[\"Misconception\"]}\n    \"\"\"\n    return text","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"FullText\"] = df.apply(lambda row: create_text(row), axis=1)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\nfrom sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer(\"/kaggle/input/train-bge-synthetic-data/trained_model\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"misconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_long_vec = model.encode(\n    df[\"FullText\"].values, normalize_embeddings=True\n)\nmisconception_mapping_vec = model.encode(\n    misconception_mapping[\"MisconceptionName\"].to_list(), normalize_embeddings=True\n)\nprint(test_long_vec.shape)\nprint(misconception_mapping_vec.shape) ","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission.to_csv(\"submission.csv\", index=False)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_cos_sim_arr = cosine_similarity(test_long_vec, misconception_mapping_vec)\ntest_sorted_indices = np.argsort(-test_cos_sim_arr, axis=1)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"QuestionId_Answer\"] = df.apply(lambda x: str(x[\"QuestionId\"]) + '_' + x[\"Option\"], axis=1)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = (\n    df.assign(\n        MisconceptionId=test_sorted_indices[:, :25].tolist()  # Add a column with MisconceptionId\n    )\n    .assign(\n        MisconceptionId=lambda df: df[\"MisconceptionId\"].apply(lambda x: \" \".join(map(str, x)))  # Convert list to string\n    )\n    .loc[:, [\"QuestionId_Answer\", \"MisconceptionId\"]]  # Select specific columns\n    .sort_values(by=\"QuestionId_Answer\")  # Sort by 'QuestionId_Answer'\n)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission_16.csv\", index=False)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 19. [Ensemble MPNETV2+BGE+GTE with Faiss-GPU](https://www.kaggle.com/code/medali1992/ensemble-mpnetv2-bge-gte-with-faiss-gpu)\n### [Med Ali Bouchhioua](https://www.kaggle.com/medali1992)","metadata":{}},{"cell_type":"code","source":"if 'SOLUTION_19' in ENSEMBLE_SOLUTIONS:\n    \n    K=25\n    VER=5\n    BS=16\n    D = 1024\n\n    DATA_PATH = \"/kaggle/input/eedi-mining-misconceptions-in-mathematics\"\n    BGE_MODEL_PATH = \"/kaggle/input/bge-weights-version1/bge_trained_model_version3\"\n    GTE_BASE_MODEL_PATH = \"/kaggle/input/mod-gte-base-weights/gte-base-weights/gte-base_trained_model_version2\"\n    MPNETV2_MODEL_PATH = \"/kaggle/input/mpnet-weights-version1/mpnetV2_trained_model_version3\"","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip uninstall -qq -y \\\npolars","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m pip install -qq --no-index --find-links=/kaggle/input/eedi-library-from-sinchiro \\\npolars\\\nsentence-transformers\\\nfaiss-gpu","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_19' in ENSEMBLE_SOLUTIONS:\n    \n    import os\n    import gc\n\n    import polars as pl\n    import numpy as np\n    from scipy import stats\n    import torch\n    import torch.nn.functional as F\n\n    import faiss\n\n    from sklearn.metrics.pairwise import cosine_similarity\n    from sentence_transformers import SentenceTransformer\n    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n    os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_19' in ENSEMBLE_SOLUTIONS:\n    \n    import sentence_transformers\n\n    # assert pl.__version__ == \"1.7.1\"\n    # assert sentence_transformers.__version__ == \"3.1.1\"","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_19' in ENSEMBLE_SOLUTIONS:\n    \n    test = pl.read_csv(f\"{DATA_PATH}/test.csv\")\n    misconception_mapping = pl.read_csv(f\"{DATA_PATH}/misconception_mapping.csv\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_19' in ENSEMBLE_SOLUTIONS:\n    \n    common_col = [\n        \"QuestionId\",\n        \"ConstructName\",\n        \"SubjectName\",\n        \"QuestionText\",\n        \"CorrectAnswer\",\n    ]\n\n    test_long = (\n        test\n        .select(\n            pl.col(common_col + [f\"Answer{alpha}Text\" for alpha in [\"A\", \"B\", \"C\", \"D\"]])\n        )\n        .unpivot(\n            index=common_col,\n            variable_name=\"AnswerType\",\n            value_name=\"AnswerText\",\n        )\n        .with_columns(\n            pl.concat_str(\n                [\n                    pl.col(\"ConstructName\"),\n                    pl.col(\"SubjectName\"),\n                    pl.col(\"QuestionText\"),\n                    pl.col(\"AnswerText\"),\n                ],\n                separator=\" \",\n            ).alias(\"AllText\"),\n            pl.col(\"AnswerType\").str.extract(r\"Answer([A-D])Text$\").alias(\"AnswerAlphabet\"),\n        )\n        .with_columns(\n            pl.concat_str(\n                [pl.col(\"QuestionId\"), pl.col(\"AnswerAlphabet\")], separator=\"_\"\n            ).alias(\"QuestionId_Answer\"),\n        )\n        .sort(\"QuestionId_Answer\")\n    )\n    test_long.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_19' in ENSEMBLE_SOLUTIONS:\n    \n    def encode_texts(test_long, misconception_mapping, model_path, batch_size=8, progress_bar=True):\n        model = SentenceTransformer(model_path, local_files_only=True, trust_remote_code=True)\n        model.to(device)\n        # wrap the model to use all GPUs\n        model = torch.nn.DataParallel(model)\n        model.eval()\n\n        # Encode all text from the test_long DataFrame\n        all_text_vec = model.module.encode(test_long[\"AllText\"].to_list(), batch_size=batch_size , normalize_embeddings=True, show_progress_bar=progress_bar)\n\n        # Encode misconception names from the misconception_mapping DataFrame\n        misconception_mapping_vec = model.module.encode(misconception_mapping[\"MisconceptionName\"].to_list(), batch_size=batch_size, normalize_embeddings=True, show_progress_bar=progress_bar)\n\n        torch.cuda.empty_cache()\n        gc.collect()\n\n        return all_text_vec, misconception_mapping_vec\n\n    def search_faiss(k, d, vectors_to_add, query_vectors):\n        \"\"\"\n        Perform a FAISS search with L2 distance.\n\n        Parameters:\n            k (int): Number of nearest neighbors to search for.\n            d (int): Dimension of the vectors.\n            vectors_to_add (numpy.ndarray): The vectors to add to the FAISS index.\n            query_vectors (numpy.ndarray): The vectors to search for the nearest neighbors.\n\n        Returns:\n            D (numpy.ndarray): The distances to the k nearest neighbors.\n            I (numpy.ndarray): The indices of the k nearest neighbors.\n        \"\"\"\n        # Create the index\n        index = faiss.IndexFlatL2(d)\n\n        # Add vectors to the index\n        index.add(vectors_to_add)\n\n        # Search for k nearest neighbors\n        D, I = index.search(query_vectors, k)\n\n        return D, I\n\n    def ensemble_majority_vote(*indices):\n        \"\"\"\n        Apply ensembling with majority voting across multiple index arrays.\n\n        Parameters:\n            indices (numpy.ndarray): Variable number of index arrays to ensemble.\n\n        Returns:\n            numpy.ndarray: The majority-voted indices.\n        \"\"\"\n        # Stack indices along a new axis (shape: (num_searches, num_queries, k))\n        stacked_indices = np.stack(indices, axis=0)\n\n        # Apply mode to find the majority vote along the first axis (searches)\n        majority_indices, _ = stats.mode(stacked_indices, axis=0)\n\n        # Remove the extra dimension added by mode and return the majority-voted indices\n        return majority_indices.squeeze()\n\n    def ensemble_random_choice(*indices):\n        \"\"\"\n        Apply ensembling with random choice across multiple index arrays.\n\n        Parameters:\n            indices (numpy.ndarray): Variable number of index arrays to ensemble.\n\n        Returns:\n            numpy.ndarray: Randomly selected indices from the given index arrays.\n        \"\"\"\n        # Stack indices along a new axis (shape: (num_searches, num_queries, k))\n        stacked_indices = np.stack(indices, axis=0)\n\n        # Number of searches (i.e., how many index arrays we have)\n        num_searches = stacked_indices.shape[0]\n\n        # Randomly choose indices from the 3 arrays\n        # For each query and each nearest neighbor (k), randomly select an index from the available searches\n        random_choices = np.random.randint(0, num_searches, size=stacked_indices.shape[1:])\n\n        # Use the random choices to pick the corresponding indices\n        random_indices = np.choose(random_choices, stacked_indices)\n\n        return random_indices","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_19' in ENSEMBLE_SOLUTIONS:\n    \n    gte_base_all_text_vec, gte_misconception_mapping_vec = encode_texts(test_long, misconception_mapping, GTE_BASE_MODEL_PATH, BS)\n    gte_base_all_text_vec = np.pad(gte_base_all_text_vec, ((0, 0), (0, 256)), mode='constant')\n    gte_misconception_mapping_vec = np.pad(gte_misconception_mapping_vec, ((0, 0), (0, 256)), mode='constant')\n    print(gte_base_all_text_vec.shape)\n    print(gte_misconception_mapping_vec.shape)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_19' in ENSEMBLE_SOLUTIONS:\n    \n    mpnetv2_base_all_text_vec, mpnetv2_misconception_mapping_vec = encode_texts(test_long, misconception_mapping, MPNETV2_MODEL_PATH, BS)\n    mpnetv2_base_all_text_vec = np.pad(mpnetv2_base_all_text_vec, ((0, 0), (0, 256)), mode='constant')\n    mpnetv2_misconception_mapping_vec = np.pad(mpnetv2_misconception_mapping_vec, ((0, 0), (0, 256)), mode='constant')\n    print(mpnetv2_base_all_text_vec.shape)\n    print(mpnetv2_misconception_mapping_vec.shape)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_19' in ENSEMBLE_SOLUTIONS:\n    \n    bge_base_all_text_vec, bge_misconception_mapping_vec = encode_texts(test_long, misconception_mapping, BGE_MODEL_PATH, BS)\n    print(bge_base_all_text_vec.shape)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_19' in ENSEMBLE_SOLUTIONS:\n    \n    ensemble_text_vecs = np.mean(np.stack([gte_base_all_text_vec, bge_base_all_text_vec, mpnetv2_base_all_text_vec]), axis=0)\n    ensemble_misconception_vecs = np.mean(np.stack([gte_misconception_mapping_vec, mpnetv2_misconception_mapping_vec, gte_misconception_mapping_vec]), axis=0)\n    _, ensemble_indices = search_faiss(K, D, ensemble_misconception_vecs, ensemble_text_vecs)\n    print(ensemble_text_vecs.shape)\n    print(ensemble_misconception_vecs.shape)\n    print(ensemble_indices.shape)\n\n    del ensemble_text_vecs, ensemble_misconception_vecs, gte_base_all_text_vec, bge_base_all_text_vec, mpnetv2_base_all_text_vec, gte_misconception_mapping_vec, mpnetv2_misconception_mapping_vec \n    _ = gc.collect()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_19' in ENSEMBLE_SOLUTIONS:\n    \n    submission = (\n        test_long.with_columns(\n            pl.Series(ensemble_indices[:, :25].tolist()).alias(\"MisconceptionId\")\n        )\n        .with_columns(\n            pl.col(\"MisconceptionId\").map_elements(\n                lambda x: \" \".join(map(str, x)), return_dtype=pl.String\n            )\n        ).filter(\n            pl.col(\"CorrectAnswer\") != pl.col(\"AnswerAlphabet\")\n        ).select(\n            pl.col([\"QuestionId_Answer\", \"MisconceptionId\"])\n        ).sort(\"QuestionId_Answer\")\n    )","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_19' in ENSEMBLE_SOLUTIONS:\n    \n    submission.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_19' in ENSEMBLE_SOLUTIONS:\n    \n    submission.write_csv(\"submission_19.csv\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 20. [Ensemble MPNETV2+BGE+GTE with Faiss-GPU](https://www.kaggle.com/code/medali1992/ensemble-mpnetv2-bge-gte-with-faiss-gpu)\n### [Med Ali Bouchhioua](https://www.kaggle.com/medali1992)","metadata":{}},{"cell_type":"markdown","source":"#### About this notebook\n\nThe idea behind this notebook is inspired by [**Eedi | Ensemble of solutions**](https://www.kaggle.com/code/vyacheslavbolotin/eedi-ensemble-of-solutions). I wanted to experiment with three different sentence transformer models and apply a voting ensemble to see if the score improves.\n\nI am only sharing the model weights to preserve the integrity of the competition, and I hope this notebook helps the Kaggle community.\n\n#### Individual model LB scores\n- `BAAI/bge-large-en-v1.5` â†’ `LB=0.257`\n- `sentence-transformers/all-mpnet-base-v2` â†’ `LB=0.251`\n- `Alibaba-NLP/gte-base-en-v1.5` â†’ `LB=0.281`\n\nI encountered the same issue mentioned [here](https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/discussion/536640). You can find a workaround in this [notebook](https://www.kaggle.com/code/medali1992/modified-gte-base-weights/notebook), where I solved the problem (I used this [link](https://huggingface.co/Alibaba-NLP/new-impl/discussions/2)).\n\nOnce again, this is an experimental notebook, and I hope it inspires some novel ideas.\n\n#### Version.2\nI replaced the mode ensembling with random choice `LB=0.227`\n\n#### Version.3\nI used a bad bge_weights(should be version2 not version3) still no improvement `LB=0.243`\n#### Version.4\nI apply mean average on the embeddings (truncate to dim=768), we can see some improvement `LB=0.282`\n\n#### Version.5\n\nI apply mean average on the embeddings (padding to dim=1024)\n\n#### Version.6\nConcatenate the embeddings into one vector.","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"if 'SOLUTION_20' in ENSEMBLE_SOLUTIONS:\n    \n    K=25\n    VER=5\n    BS=16\n    D = 1024\n\n    DATA_PATH = \"/kaggle/input/eedi-mining-misconceptions-in-mathematics\"\n    BGE_MODEL_PATH = \"/kaggle/input/bge-weights-version1/bge_trained_model_version3\"\n    GTE_BASE_MODEL_PATH = \"/kaggle/input/mod-gte-base-weights/gte-base-weights/gte-base_trained_model_version2\"\n    MPNETV2_MODEL_PATH = \"/kaggle/input/mpnet-weights-version1/mpnetV2_trained_model_version3\"","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_20' in ENSEMBLE_SOLUTIONS: \n    \n    import os\n    import gc\n\n    import polars as pl\n    import numpy as np\n    from scipy import stats\n    import torch\n    import torch.nn.functional as F\n\n    import faiss\n\n    from sklearn.metrics.pairwise import cosine_similarity\n    from sentence_transformers import SentenceTransformer\n    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n    os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_20' in ENSEMBLE_SOLUTIONS:\n    \n    import sentence_transformers\n\n    # assert pl.__version__ == \"1.7.1\"\n    # assert sentence_transformers.__version__ == \"3.1.1\"","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_20' in ENSEMBLE_SOLUTIONS:\n    \n    test = pl.read_csv(f\"{DATA_PATH}/test.csv\")\n    misconception_mapping = pl.read_csv(f\"{DATA_PATH}/misconception_mapping.csv\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_20' in ENSEMBLE_SOLUTIONS:\n    \n    common_col = [\n        \"QuestionId\",\n        \"ConstructName\",\n        \"SubjectName\",\n        \"QuestionText\",\n        \"CorrectAnswer\",\n    ]\n\n    test_long = (\n        test\n        .select(\n            pl.col(common_col + [f\"Answer{alpha}Text\" for alpha in [\"A\", \"B\", \"C\", \"D\"]])\n        )\n        .unpivot(\n            index=common_col,\n            variable_name=\"AnswerType\",\n            value_name=\"AnswerText\",\n        )\n        .with_columns(\n            pl.concat_str(\n                [\n                   '<Construct> ' +  pl.col(\"ConstructName\"),\n                   '<Subject> ' + pl.col(\"SubjectName\"),\n                   '<Question> '+ pl.col(\"QuestionText\"),\n                   '<Answer> ' + pl.col(\"AnswerText\"),\n                ],\n                separator=\" \",\n            ).alias(\"AllText\"),\n            pl.col(\"AnswerType\").str.extract(r\"Answer([A-D])Text$\").alias(\"AnswerAlphabet\"),\n        )\n        .with_columns(\n            pl.concat_str(\n                [pl.col(\"QuestionId\"), pl.col(\"AnswerAlphabet\")], separator=\"_\"\n            ).alias(\"QuestionId_Answer\"),\n        )\n        .sort(\"QuestionId_Answer\")\n    )\n    test_long.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_20' in ENSEMBLE_SOLUTIONS:\n    \n    def encode_texts(test_long, misconception_mapping, model_path, batch_size=8, progress_bar=True):\n        model = SentenceTransformer(model_path, local_files_only=True, trust_remote_code=True)\n        model.to(device)\n        # wrap the model to use all GPUs\n        model = torch.nn.DataParallel(model)\n        model.eval()\n\n        # Encode all text from the test_long DataFrame\n        all_text_vec = model.module.encode(test_long[\"AllText\"].to_list(), batch_size=batch_size , normalize_embeddings=True, show_progress_bar=progress_bar)\n\n        # Encode misconception names from the misconception_mapping DataFrame\n        misconception_mapping_vec = model.module.encode(misconception_mapping[\"MisconceptionName\"].to_list(), batch_size=batch_size, normalize_embeddings=True, show_progress_bar=progress_bar)\n\n        torch.cuda.empty_cache()\n        gc.collect()\n\n        return all_text_vec, misconception_mapping_vec\n\n    def search_faiss(k, d, vectors_to_add, query_vectors):\n        \"\"\"\n        Perform a FAISS search with L2 distance.\n\n        Parameters:\n            k (int): Number of nearest neighbors to search for.\n            d (int): Dimension of the vectors.\n            vectors_to_add (numpy.ndarray): The vectors to add to the FAISS index.\n            query_vectors (numpy.ndarray): The vectors to search for the nearest neighbors.\n\n        Returns:\n            D (numpy.ndarray): The distances to the k nearest neighbors.\n            I (numpy.ndarray): The indices of the k nearest neighbors.\n        \"\"\"\n        # Create the index\n        index = faiss.IndexFlatL2(d)\n\n        # Add vectors to the index\n        index.add(vectors_to_add)\n\n        # Search for k nearest neighbors\n        D, I = index.search(query_vectors, k)\n\n        return D, I\n\n    def ensemble_majority_vote(*indices):\n        \"\"\"\n        Apply ensembling with majority voting across multiple index arrays.\n\n        Parameters:\n            indices (numpy.ndarray): Variable number of index arrays to ensemble.\n\n        Returns:\n            numpy.ndarray: The majority-voted indices.\n        \"\"\"\n        # Stack indices along a new axis (shape: (num_searches, num_queries, k))\n        stacked_indices = np.stack(indices, axis=0)\n\n        # Apply mode to find the majority vote along the first axis (searches)\n        majority_indices, _ = stats.mode(stacked_indices, axis=0)\n\n        # Remove the extra dimension added by mode and return the majority-voted indices\n        return majority_indices.squeeze()\n\n    def ensemble_random_choice(*indices):\n        \"\"\"\n        Apply ensembling with random choice across multiple index arrays.\n\n        Parameters:\n            indices (numpy.ndarray): Variable number of index arrays to ensemble.\n\n        Returns:\n            numpy.ndarray: Randomly selected indices from the given index arrays.\n        \"\"\"\n        # Stack indices along a new axis (shape: (num_searches, num_queries, k))\n        stacked_indices = np.stack(indices, axis=0)\n\n        # Number of searches (i.e., how many index arrays we have)\n        num_searches = stacked_indices.shape[0]\n\n        # Randomly choose indices from the 3 arrays\n        # For each query and each nearest neighbor (k), randomly select an index from the available searches\n        random_choices = np.random.randint(0, num_searches, size=stacked_indices.shape[1:])\n\n        # Use the random choices to pick the corresponding indices\n        random_indices = np.choose(random_choices, stacked_indices)\n\n        return random_indices","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_20' in ENSEMBLE_SOLUTIONS:\n    \n    gte_base_all_text_vec, gte_misconception_mapping_vec = encode_texts(test_long, misconception_mapping, GTE_BASE_MODEL_PATH, BS)\n    gte_base_all_text_vec = np.pad(gte_base_all_text_vec, ((0, 0), (0, 256)), mode='constant')\n    gte_misconception_mapping_vec = np.pad(gte_misconception_mapping_vec, ((0, 0), (0, 256)), mode='constant')\n    print(gte_base_all_text_vec.shape)\n    print(gte_misconception_mapping_vec.shape)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_20' in ENSEMBLE_SOLUTIONS:\n    \n    mpnetv2_base_all_text_vec, mpnetv2_misconception_mapping_vec = encode_texts(test_long, misconception_mapping, MPNETV2_MODEL_PATH, BS)\n    mpnetv2_base_all_text_vec = np.pad(mpnetv2_base_all_text_vec, ((0, 0), (0, 256)), mode='constant')\n    mpnetv2_misconception_mapping_vec = np.pad(mpnetv2_misconception_mapping_vec, ((0, 0), (0, 256)), mode='constant')\n    print(mpnetv2_base_all_text_vec.shape)\n    print(mpnetv2_misconception_mapping_vec.shape)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_20' in ENSEMBLE_SOLUTIONS:\n    \n    bge_base_all_text_vec, bge_misconception_mapping_vec = encode_texts(test_long, misconception_mapping, BGE_MODEL_PATH, BS)\n    print(bge_base_all_text_vec.shape)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_20' in ENSEMBLE_SOLUTIONS:\n\n    ensemble_text_vecs = np.mean(np.stack([gte_base_all_text_vec, bge_base_all_text_vec, mpnetv2_base_all_text_vec]), axis=0)\n    ensemble_misconception_vecs = np.mean(np.stack([gte_misconception_mapping_vec, mpnetv2_misconception_mapping_vec, gte_misconception_mapping_vec]), axis=0)\n    _, ensemble_indices = search_faiss(K, D, ensemble_misconception_vecs, ensemble_text_vecs)\n    print(ensemble_text_vecs.shape)\n    print(ensemble_misconception_vecs.shape)\n    print(ensemble_indices.shape)\n\n    del ensemble_text_vecs, ensemble_misconception_vecs, gte_base_all_text_vec, bge_base_all_text_vec, mpnetv2_base_all_text_vec, gte_misconception_mapping_vec, mpnetv2_misconception_mapping_vec \n    _ = gc.collect()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_20' in ENSEMBLE_SOLUTIONS:\n    \n    submission = (\n        test_long.with_columns(\n            pl.Series(ensemble_indices[:, :25].tolist()).alias(\"MisconceptionId\")\n        )\n        .with_columns(\n            pl.col(\"MisconceptionId\").map_elements(\n                lambda x: \" \".join(map(str, x)), return_dtype=pl.String\n            )\n        ).filter(\n            pl.col(\"CorrectAnswer\") != pl.col(\"AnswerAlphabet\")\n        ).select(\n            pl.col([\"QuestionId_Answer\", \"MisconceptionId\"])\n        ).sort(\"QuestionId_Answer\")\n    )","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_20' in ENSEMBLE_SOLUTIONS:\n    \n    submission.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_20' in ENSEMBLE_SOLUTIONS:\n\n    submission.write_csv(\"submission_20.csv\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 21. [Weighted Ensemble MPNETV2+BGE+GTE with Faiss](https://www.kaggle.com/code/yourlh/weighted-ensemble-mpnetv2-bge-gte-with-faiss)\n### [Your_LH](https://www.kaggle.com/yourlh)\n","metadata":{}},{"cell_type":"markdown","source":"#### About this Notebook\n\nThis notebook is adapted from [Ensemble MPNETV2+BGE+GTE with Faiss-GPU](https://www.kaggle.com/code/medali1992/ensemble-mpnetv2-bge-gte-with-faiss-gpu). The original author provided the individual model scores in their notebook, and I experimented with a few parameters to improve the LB score from 0.291 to 0.300. I appreciate the original author's open notebook, and I believe that by experimenting with different parameter combinations, it is possible to further improve the score.\n\n#### Individual Model LB Scores\n- `BAAI/bge-large-en-v1.5` â†’ `LB=0.257`\n- `sentence-transformers/all-mpnet-base-v2` â†’ `LB=0.251`\n- `Alibaba-NLP/gte-base-en-v1.5` â†’ `LB=0.281`\n\n#### Version 1\nThe base notebook `LB=0.291`\n\n#### Version 3\nweight1, weight2, weight3 = 0.36, 0.33, 0.32 â†’ `LB=0.292`\n\n#### Version 4\nweight1, weight2, weight3 = 0.46, 0.34, 0.3 â†’ `LB=0.300`\n\n#### Version 5\nweight1, weight2, weight3 = 0.5, 0.35, 0.29 â†’ `LB=0.300`\n\n#### A Mistake\nWhen I was about to publish this notebook and checked it, I realized I had mixed up the order, causing the weights for BGE and MPNET to be swapped. However, it still improved the score. So, if someone wants to modify the code based on my notebook, you can correct the weight order or just leave it as is â€” as long as it improves the score. I hope my notebook is helpful to you.\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"if 'SOLUTION_21' in ENSEMBLE_SOLUTIONS:\n    \n    K=25\n    VER=5\n    BS=16\n    D = 1024\n\n    DATA_PATH = \"/kaggle/input/eedi-mining-misconceptions-in-mathematics\"\n    BGE_MODEL_PATH = \"/kaggle/input/bge-weights-version1/bge_trained_model_version3\"\n    GTE_BASE_MODEL_PATH = \"/kaggle/input/mod-gte-base-weights/gte-base-weights/gte-base_trained_model_version2\"\n    MPNETV2_MODEL_PATH = \"/kaggle/input/mpnet-weights-version1/mpnetV2_trained_model_version3\"","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if 'SOLUTION_21' in ENSEMBLE_SOLUTIONS:\n    \n    # !pip uninstall -qq -y \\\n    # polars","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if 'SOLUTION_21' in ENSEMBLE_SOLUTIONS:\n\n    # !python -m pip install -qq --no-index --find-links=/kaggle/input/eedi-library-from-sinchiro \\\n    # polars\\\n    # sentence-transformers\\\n    # faiss-gpu","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_21' in ENSEMBLE_SOLUTIONS:\n    \n    import os\n    import gc\n\n    import polars as pl\n    import numpy as np\n    from scipy import stats\n    import torch\n    import torch.nn.functional as F\n\n    import faiss\n\n    from sklearn.metrics.pairwise import cosine_similarity\n    from sentence_transformers import SentenceTransformer\n    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n    os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_21' in ENSEMBLE_SOLUTIONS:\n    \n    import sentence_transformers\n\n#     assert pl.__version__ == \"1.7.1\"\n#     assert sentence_transformers.__version__ == \"3.1.1\"","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_21' in ENSEMBLE_SOLUTIONS:\n    \n    test = pl.read_csv(f\"{DATA_PATH}/test.csv\")\n    misconception_mapping = pl.read_csv(f\"{DATA_PATH}/misconception_mapping.csv\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_21' in ENSEMBLE_SOLUTIONS:\n    \n    common_col = [\n        \"QuestionId\",\n        \"ConstructName\",\n        \"SubjectName\",\n        \"QuestionText\",\n        \"CorrectAnswer\",\n    ]\n\n    test_long = (\n        test\n        .select(\n            pl.col(common_col + [f\"Answer{alpha}Text\" for alpha in [\"A\", \"B\", \"C\", \"D\"]])\n        )\n        .unpivot(\n            index=common_col,\n            variable_name=\"AnswerType\",\n            value_name=\"AnswerText\",\n        )\n        .with_columns(\n            pl.concat_str(\n                [\n                   '<Construct> ' +  pl.col(\"ConstructName\"),\n                   '<Subject> ' + pl.col(\"SubjectName\"),\n                   '<Question> '+ pl.col(\"QuestionText\"),\n                   '<Answer> ' + pl.col(\"AnswerText\"),\n                ],\n                separator=\" \",\n            ).alias(\"AllText\"),\n            pl.col(\"AnswerType\").str.extract(r\"Answer([A-D])Text$\").alias(\"AnswerAlphabet\"),\n        )\n        .with_columns(\n            pl.concat_str(\n                [pl.col(\"QuestionId\"), pl.col(\"AnswerAlphabet\")], separator=\"_\"\n            ).alias(\"QuestionId_Answer\"),\n        )\n        .sort(\"QuestionId_Answer\")\n    )\n    test_long.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_21' in ENSEMBLE_SOLUTIONS:\n    \n    def encode_texts(test_long, misconception_mapping, model_path, batch_size=8, progress_bar=True):\n        model = SentenceTransformer(model_path, local_files_only=True, trust_remote_code=True)\n        model.to(device)\n        # wrap the model to use all GPUs\n        model = torch.nn.DataParallel(model)\n        model.eval()\n\n        # Encode all text from the test_long DataFrame\n        all_text_vec = model.module.encode(test_long[\"AllText\"].to_list(), batch_size=batch_size , normalize_embeddings=True, show_progress_bar=progress_bar)\n\n        # Encode misconception names from the misconception_mapping DataFrame\n        misconception_mapping_vec = model.module.encode(misconception_mapping[\"MisconceptionName\"].to_list(), batch_size=batch_size, normalize_embeddings=True, show_progress_bar=progress_bar)\n\n        torch.cuda.empty_cache()\n        gc.collect()\n\n        return all_text_vec, misconception_mapping_vec\n\n    def search_faiss(k, d, vectors_to_add, query_vectors):\n        \"\"\"\n        Perform a FAISS search with L2 distance.\n\n        Parameters:\n            k (int): Number of nearest neighbors to search for.\n            d (int): Dimension of the vectors.\n            vectors_to_add (numpy.ndarray): The vectors to add to the FAISS index.\n            query_vectors (numpy.ndarray): The vectors to search for the nearest neighbors.\n\n        Returns:\n            D (numpy.ndarray): The distances to the k nearest neighbors.\n            I (numpy.ndarray): The indices of the k nearest neighbors.\n        \"\"\"\n        # Create the index\n        index = faiss.IndexFlatL2(d)\n\n        # Add vectors to the index\n        index.add(vectors_to_add)\n\n        # Search for k nearest neighbors\n        D, I = index.search(query_vectors, k)\n\n        return D, I\n\n    def ensemble_majority_vote(*indices):\n        \"\"\"\n        Apply ensembling with majority voting across multiple index arrays.\n\n        Parameters:\n            indices (numpy.ndarray): Variable number of index arrays to ensemble.\n\n        Returns:\n            numpy.ndarray: The majority-voted indices.\n        \"\"\"\n        # Stack indices along a new axis (shape: (num_searches, num_queries, k))\n        stacked_indices = np.stack(indices, axis=0)\n\n        # Apply mode to find the majority vote along the first axis (searches)\n        majority_indices, _ = stats.mode(stacked_indices, axis=0)\n\n        # Remove the extra dimension added by mode and return the majority-voted indices\n        return majority_indices.squeeze()\n\n    def ensemble_random_choice(*indices):\n        \"\"\"\n        Apply ensembling with random choice across multiple index arrays.\n\n        Parameters:\n            indices (numpy.ndarray): Variable number of index arrays to ensemble.\n\n        Returns:\n            numpy.ndarray: Randomly selected indices from the given index arrays.\n        \"\"\"\n        # Stack indices along a new axis (shape: (num_searches, num_queries, k))\n        stacked_indices = np.stack(indices, axis=0)\n\n        # Number of searches (i.e., how many index arrays we have)\n        num_searches = stacked_indices.shape[0]\n\n        # Randomly choose indices from the 3 arrays\n        # For each query and each nearest neighbor (k), randomly select an index from the available searches\n        random_choices = np.random.randint(0, num_searches, size=stacked_indices.shape[1:])\n\n        # Use the random choices to pick the corresponding indices\n        random_indices = np.choose(random_choices, stacked_indices)\n\n        return random_indices","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_21' in ENSEMBLE_SOLUTIONS:\n    \n    gte_base_all_text_vec, gte_misconception_mapping_vec = encode_texts(test_long, misconception_mapping, GTE_BASE_MODEL_PATH, BS)\n    gte_base_all_text_vec = np.pad(gte_base_all_text_vec, ((0, 0), (0, 256)), mode='constant')\n    gte_misconception_mapping_vec = np.pad(gte_misconception_mapping_vec, ((0, 0), (0, 256)), mode='constant')\n    print(gte_base_all_text_vec.shape)\n    print(gte_misconception_mapping_vec.shape)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_21' in ENSEMBLE_SOLUTIONS:\n    \n    mpnetv2_base_all_text_vec, mpnetv2_misconception_mapping_vec = encode_texts(test_long, misconception_mapping, MPNETV2_MODEL_PATH, BS)\n    mpnetv2_base_all_text_vec = np.pad(mpnetv2_base_all_text_vec, ((0, 0), (0, 256)), mode='constant')\n    mpnetv2_misconception_mapping_vec = np.pad(mpnetv2_misconception_mapping_vec, ((0, 0), (0, 256)), mode='constant')\n    print(mpnetv2_base_all_text_vec.shape)\n    print(mpnetv2_misconception_mapping_vec.shape)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_21' in ENSEMBLE_SOLUTIONS:\n    \n    bge_base_all_text_vec, bge_misconception_mapping_vec = encode_texts(test_long, misconception_mapping, BGE_MODEL_PATH, BS)\n    print(bge_base_all_text_vec.shape)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_21' in ENSEMBLE_SOLUTIONS:\n    \n    # ensemble_text_vecs = np.mean(np.stack([gte_base_all_text_vec, bge_base_all_text_vec, mpnetv2_base_all_text_vec]), axis=0)\n    # ensemble_misconception_vecs = np.mean(np.stack([gte_misconception_mapping_vec, mpnetv2_misconception_mapping_vec, gte_misconception_mapping_vec]), axis=0)\n    # _, ensemble_indices = search_faiss(K, D, ensemble_misconception_vecs, ensemble_text_vecs)\n\n    ensemble_text_vecs = (\n        weight_21_1 * gte_base_all_text_vec +\\\n        weight_21_2 * bge_base_all_text_vec +\\\n        weight_21_3 * mpnetv2_base_all_text_vec\n    )\n\n    ensemble_misconception_vecs = (\n        weight_21_1 * gte_misconception_mapping_vec +\\\n        weight_21_2 * mpnetv2_misconception_mapping_vec +\\\n        weight_21_3 * bge_misconception_mapping_vec\n    )\n\n    _, ensemble_indices = search_faiss(K, D, ensemble_misconception_vecs, ensemble_text_vecs)\n    \n    print(ensemble_text_vecs.shape)\n    print(ensemble_misconception_vecs.shape)\n    print(ensemble_indices.shape)\n\n    del ensemble_text_vecs, ensemble_misconception_vecs, gte_base_all_text_vec, bge_base_all_text_vec, mpnetv2_base_all_text_vec, gte_misconception_mapping_vec, mpnetv2_misconception_mapping_vec \n    _ = gc.collect()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_21' in ENSEMBLE_SOLUTIONS:\n    \n    submission = (\n        test_long.with_columns(\n            pl.Series(ensemble_indices[:, :25].tolist()).alias(\"MisconceptionId\")\n        )\n        .with_columns(\n            pl.col(\"MisconceptionId\").map_elements(\n                lambda x: \" \".join(map(str, x)), return_dtype=pl.String\n            )\n        ).filter(\n            pl.col(\"CorrectAnswer\") != pl.col(\"AnswerAlphabet\")\n        ).select(\n            pl.col([\"QuestionId_Answer\", \"MisconceptionId\"])\n        ).sort(\"QuestionId_Answer\")\n    )","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_21' in ENSEMBLE_SOLUTIONS:\n\n    submission.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_21' in ENSEMBLE_SOLUTIONS:\n    \n    submission.write_csv(\"submission_21.csv\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## [Hybrid Search (Ensemble Encoder + BM25)](https://www.kaggle.com/code/prtm1908/hybrid-search-ensemble-encoder-bm25), Lb=0.315\n### [Pratham Batra](https://www.kaggle.com/prtm1908)","metadata":{}},{"cell_type":"code","source":"if 'SOLUTION_22' in ENSEMBLE_SOLUTIONS:\n    \n    !pip install /kaggle/input/rank-bm25/rank_bm25-0.2.2-py3-none-any.whl\n    !python -m pip install -qq --no-index --find-links=/kaggle/input/eedi-library-from-sinchiro \\\n    sentence-transformers\\\n    faiss-gpu","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-10-21T19:34:45.053638Z","iopub.execute_input":"2024-10-21T19:34:45.054558Z","iopub.status.idle":"2024-10-21T19:35:30.127489Z","shell.execute_reply.started":"2024-10-21T19:34:45.054511Z","shell.execute_reply":"2024-10-21T19:35:30.126249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_22' in ENSEMBLE_SOLUTIONS:    \n\n    import numpy as np\n    import pandas as pd\n    import torch\n    import torch.nn as nn\n    from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n    from scipy.spatial.distance import cdist\n    from sklearn.metrics.pairwise import cosine_similarity\n    from rank_bm25 import BM25Okapi\n    from nltk.tokenize import word_tokenize\n    import nltk\n    import re\n    import os\n    import gc\n    import faiss\n    from sentence_transformers import SentenceTransformer","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-10-21T19:35:38.754358Z","iopub.execute_input":"2024-10-21T19:35:38.754771Z","iopub.status.idle":"2024-10-21T19:36:01.804994Z","shell.execute_reply.started":"2024-10-21T19:35:38.754729Z","shell.execute_reply":"2024-10-21T19:36:01.804219Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_22' in ENSEMBLE_SOLUTIONS:\n    \n    # Configuration\n    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n    os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n    BATCH_SIZE = 8\n    MAX_NEW_TOKENS = 55\n    K = 50  # For initial FAISS search\n    FINAL_K = 25  # For final hybrid search result\n    DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n    D = 1024","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_22' in ENSEMBLE_SOLUTIONS:\n    \n    # Paths\n    DATA_PATH = \"/kaggle/input/eedi-mining-misconceptions-in-mathematics\"\n    BGE_MODEL_PATH = \"/kaggle/input/bge-weights-version1/bge_trained_model_version3\"\n    GTE_BASE_MODEL_PATH = \"/kaggle/input/mod-gte-base-weights/gte-base-weights/gte-base_trained_model_version2\"\n    MPNETV2_MODEL_PATH = \"/kaggle/input/mpnet-weights-version1/mpnetV2_trained_model_version3\"\n    PHI_MODEL_PATH = '/kaggle/input/phi-3.5-mini-instruct/pytorch/default/1'","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_22' in ENSEMBLE_SOLUTIONS:\n    \n    # Load data\n    test = pd.read_csv(f\"{DATA_PATH}/test.csv\")\n    train = pd.read_csv(f\"{DATA_PATH}/train.csv\")\n    misconception_mapping = pd.read_csv(f\"{DATA_PATH}/misconception_mapping.csv\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_22' in ENSEMBLE_SOLUTIONS:\n    \n    # Load models\n    bge_model = SentenceTransformer(BGE_MODEL_PATH, trust_remote_code=True, local_files_only=True)\n    gte_model = SentenceTransformer(GTE_BASE_MODEL_PATH, trust_remote_code=True, local_files_only=True)\n    mpnetv2_model = SentenceTransformer(MPNETV2_MODEL_PATH, trust_remote_code=True, local_files_only=True)\n    bge_model.to(DEVICE)\n    gte_model.to(DEVICE)\n    mpnetv2_model.to(DEVICE)\n\n    phi_tokenizer = AutoTokenizer.from_pretrained(PHI_MODEL_PATH)\n    phi_model = AutoModelForCausalLM.from_pretrained(\n        PHI_MODEL_PATH,\n        torch_dtype=torch.bfloat16,\n        device_map=\"auto\",\n        trust_remote_code=True\n    )\n    phi_pipe = pipeline(\"text-generation\", model=phi_model, tokenizer=phi_tokenizer, trust_remote_code=True, max_new_tokens=MAX_NEW_TOKENS)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_22' in ENSEMBLE_SOLUTIONS:\n    \n    def generate_embeddings(texts, model, batch_size=BATCH_SIZE):\n        return model.encode(texts, batch_size=batch_size, show_progress_bar=True, normalize_embeddings=True)\n\n    def generate_question_embeddings(questions, model):\n        texts = [f\"<Construct> {q['ConstructName']} <Subject> {q['SubjectName']} <Question> {q['QuestionText']} <Answer> {q[f'Answer{answer_choice}Text']}\"\n                 for q in questions\n                 for answer_choice in ['A', 'B', 'C', 'D']\n                 if answer_choice != q['CorrectAnswer']]\n        return generate_embeddings(texts, model)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_22' in ENSEMBLE_SOLUTIONS:\n    \n    def generate_filtered_df(df, question, min_rows=5, max_rows=7):\n        construct_id = question['ConstructId']\n        subject_id = question['SubjectId']\n\n        filtered_df = df[df['ConstructId'] == construct_id]\n\n        if len(filtered_df) < min_rows:\n            subject_df = df[(df['SubjectId'] == subject_id) & (df['ConstructId'] != construct_id)]\n            filtered_df = pd.concat([filtered_df, subject_df])\n\n        if len(filtered_df) < min_rows:\n            random_df = df[~df.index.isin(filtered_df.index)].sample(n=min(min_rows - len(filtered_df), len(df) - len(filtered_df)))\n            filtered_df = pd.concat([filtered_df, random_df])\n\n        return filtered_df.sample(n=min(max_rows, len(filtered_df)))\n\n    def get_example_sequences(filtered_train_df, num_examples=3):\n        examples = []\n        for _, row in filtered_train_df.sample(n=min(num_examples, len(filtered_train_df))).iterrows():\n            for answer_choice in ['A', 'B', 'C', 'D']:\n                if answer_choice != row['CorrectAnswer']:\n                    misconception_id = row[f'Misconception{answer_choice}Id']\n                    if not pd.isna(misconception_id):\n                        examples.append({\n                            'question': f\"{row['ConstructName']}: {row['QuestionText']}\",\n                            'correct_answer': row[f'Answer{row[\"CorrectAnswer\"]}Text'],\n                            'incorrect_answer': row[f'Answer{answer_choice}Text'],\n                            'misconception': misconception_mapping.loc[int(misconception_id), 'MisconceptionName']\n                        })\n                        break\n        return examples\n\n    def predict_misconception(questions, phi_pipe):\n        all_prompts = []\n        for q in questions:\n            correct_answer_key = f\"Answer{q['CorrectAnswer']}Text\"\n            correct_answer = q[correct_answer_key]\n\n            filtered_df = generate_filtered_df(train, q)\n            examples = get_example_sequences(filtered_df)\n\n            messages = []\n\n            for example in examples:\n                messages.extend([\n                    {\"role\": \"user\", \"content\": f\"Question: {example['question']}\"},\n                    {\"role\": \"assistant\", \"content\": \"Provide me with the correct answer for a baseline.\"},\n                    {\"role\": \"user\", \"content\": f\"Correct Answer: {example['correct_answer']}\"},\n                    {\"role\": \"assistant\", \"content\": \"Now - provide the incorrect answer and I will analyze the difference to infer the misconception.\"},\n                    {\"role\": \"user\", \"content\": f\"Incorrect Answer: {example['incorrect_answer']}\"},\n                    {\"role\": \"assistant\", \"content\": f\"Misconception for incorrect answer: {example['misconception']}\"}\n                ])\n\n            messages.extend([\n                {\"role\": \"user\", \"content\": f\"Question: {q['ConstructName']}: {q['QuestionText']}\"},\n                {\"role\": \"assistant\", \"content\": \"Provide me with the correct answer for a baseline.\"},\n                {\"role\": \"user\", \"content\": f\"Correct Answer: {correct_answer}\"},\n                {\"role\": \"assistant\", \"content\": \"Now - provide the incorrect answer and I will analyze the difference to infer the misconception.\"},\n            ])\n\n            for answer_choice in ['A', 'B', 'C', 'D']:\n                if answer_choice != q['CorrectAnswer']:\n                    incorrect_answer_key = f\"Answer{answer_choice}Text\"\n                    incorrect_answer = q[incorrect_answer_key]\n\n                    prompt_messages = messages.copy()\n                    prompt_messages.append({\"role\": \"user\", \"content\": f\"Incorrect Answer: {incorrect_answer}\"})\n\n                    all_prompts.append(prompt_messages)\n\n        responses = phi_pipe(all_prompts, batch_size=BATCH_SIZE)\n\n        processed_responses = []\n        for response in responses:\n            if isinstance(response, list) and len(response) > 0:\n                generated_text = response[0].get('generated_text', [])\n                if isinstance(generated_text, list) and len(generated_text) > 0:\n                    last_message = generated_text[-1]\n                    if isinstance(last_message, dict) and 'content' in last_message:\n                        content = last_message['content'].strip()\n                        start_index = content.find(\"Misconception for incorrect answer:\")\n                        if start_index != -1:\n                            misconception = content[start_index + len(\"Misconception for incorrect answer:\"):].strip()\n                            end_index = misconception.find('.')\n                            if end_index != -1:\n                                misconception = misconception[:end_index + 1].strip()\n                            processed_responses.append(misconception)\n                        else:\n                            processed_responses.append(content)\n                    else:\n                        processed_responses.append(str(last_message))\n                else:\n                    processed_responses.append(str(generated_text))\n            else:\n                processed_responses.append(str(response))\n\n        return processed_responses","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_22' in ENSEMBLE_SOLUTIONS:\n    \n    def bm25_search(queries, documents, top_k=K):\n        tokenized_corpus = [word_tokenize(doc.lower()) for doc in documents]\n        bm25 = BM25Okapi(tokenized_corpus)\n\n        results = []\n        scores = []\n        for query in queries:\n            tokenized_query = word_tokenize(query.lower())\n            doc_scores = bm25.get_scores(tokenized_query)\n            top_indices = np.argsort(doc_scores)[::-1][:top_k]\n            top_scores = np.sort(doc_scores)[::-1][:top_k]\n            results.append(top_indices)\n            scores.append(top_scores)\n        return results, scores\n\n    def semantic_search(embeddings, misc_embeddings, top_k=K):\n        d = embeddings.shape[1]  # This will now always be 1024 (768 + 256 padding)\n        index = faiss.IndexFlatL2(d)\n        index.add(misc_embeddings)\n        distances, indices = index.search(embeddings, top_k)\n        print(indices)\n        print(indices)\n        return indices, distances\n\n    def combined_search(semantic_results, semantic_scores, keyword_results, keyword_scores, top_k=FINAL_K, alpha=0.8):\n        combined_results = []\n        for sem_res, sem_scores, key_res, key_scores in zip(semantic_results, semantic_scores, keyword_results, keyword_scores):\n            combined_scores = np.zeros(len(misconception_mapping))\n\n            # Reverse the order of semantic results (closest matches first)\n            sem_res = sem_res[::-1]\n            sem_scores = sem_scores[::-1]\n\n            # Normalize semantic scores (now smaller is better)\n            sem_scores_norm = (sem_scores - np.min(sem_scores)) / (np.max(sem_scores) - np.min(sem_scores))\n            sem_scores_norm = 1 - sem_scores_norm  # Invert so that smaller distances get higher scores\n\n            # Normalize keyword scores\n            key_scores_norm = (key_scores - np.min(key_scores)) / (np.max(key_scores) - np.min(key_scores))\n\n            for idx, score in zip(sem_res, sem_scores_norm):\n                combined_scores[idx] += alpha * score\n\n            for idx, score in zip(key_res, key_scores_norm):\n                combined_scores[idx] += (1 - alpha) * score\n\n            top_combined = np.argsort(combined_scores)[::-1][:top_k]\n            combined_results.append(top_combined)\n\n        print(f\"combined res: {combined_results}\")\n\n        return combined_results","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_22' in ENSEMBLE_SOLUTIONS:\n    \n    def pad_embeddings(embeddings):\n        return np.pad(embeddings, ((0, 0), (0, 256)), mode='constant')\n\n    def process_questions_batch(questions, misc_embeddings):\n        # Ensemble embeddings\n        bge_embeddings = generate_question_embeddings(questions, bge_model)\n        gte_embeddings = generate_question_embeddings(questions, gte_model)\n        mpnetv2_embeddings = generate_question_embeddings(questions, mpnetv2_model)\n\n        # Pad embeddings\n        bge_embeddings_padded = bge_embeddings\n        gte_embeddings_padded = pad_embeddings(gte_embeddings)\n        mpnetv2_embeddings_padded = pad_embeddings(mpnetv2_embeddings)\n\n        weight1, weight2, weight3 = 0.50, 0.28, 0.30 # 0.5, 0.29, 0.35\n        ensemble_embeddings = (weight1 * gte_embeddings_padded + weight2 * bge_embeddings_padded + weight3 * mpnetv2_embeddings_padded)\n\n        print(ensemble_embeddings.shape)\n\n        # Semantic search\n        semantic_results, semantic_scores = semantic_search(ensemble_embeddings, misc_embeddings)\n\n        # Keyword search\n        llm_responses = predict_misconception(questions, phi_pipe)\n        keyword_results, keyword_scores = bm25_search(llm_responses, misconception_mapping['MisconceptionName'].tolist())\n\n        # Hybrid search\n        combined_results = combined_search(semantic_results, semantic_scores, keyword_results, keyword_scores)\n\n        results = []\n        result_index = 0\n        for question in questions:\n            for answer_choice in ['A', 'B', 'C', 'D']:\n                if answer_choice != question['CorrectAnswer']:\n                    top_misconceptions = combined_results[result_index]\n                    results.append({\n                        'QuestionId_Answer': f\"{question['QuestionId']}_{answer_choice}\",\n                        'MisconceptionId': ' '.join(map(str, top_misconceptions))\n                    })\n                    result_index += 1\n\n        return results","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_22' in ENSEMBLE_SOLUTIONS:\n    \n    def generate_misc_embeddings(misconceptions):\n        bge_embeddings = generate_embeddings(misconceptions, bge_model)\n        gte_embeddings = generate_embeddings(misconceptions, gte_model)\n        mpnetv2_embeddings = generate_embeddings(misconceptions, mpnetv2_model)\n\n        # Pad embeddings\n        bge_embeddings_padded = bge_embeddings\n        gte_embeddings_padded = pad_embeddings(gte_embeddings)\n        mpnetv2_embeddings_padded = pad_embeddings(mpnetv2_embeddings)\n\n        # Use the same weights as in the question embedding ensemble\n        weight1, weight2, weight3 = 0.50, 0.28, 0.30 # 0.5, 0.29, 0.35\n        ensemble_embeddings = (weight1 * gte_embeddings_padded + weight2 * mpnetv2_embeddings_padded + weight3 * bge_embeddings_padded)\n\n        return ensemble_embeddings","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_22' in ENSEMBLE_SOLUTIONS:\n    \n    # Generate misconception embeddings using the ensemble approach\n    misconceptions = misconception_mapping['MisconceptionName'].tolist()\n    misc_embeddings = generate_misc_embeddings(misconceptions)\n    print(f\"Ensemble misconception embeddings shape: {misc_embeddings.shape}\")\n    print(misc_embeddings)\n\n    # Update the main execution loop\n    results = []\n    for i in range(0, len(test), BATCH_SIZE):\n        batch = test.iloc[i:i+BATCH_SIZE].to_dict('records')\n        batch_results = process_questions_batch(batch, misc_embeddings)\n        if batch_results:\n            results.extend(batch_results)\n        else:\n            print(f\"Warning: No results for batch starting at index {i}\")\n\n        torch.cuda.empty_cache()\n        gc.collect()\n\n        print(f\"Processed {i+len(batch)} out of {len(test)} questions\")\n\n    submission_df = pd.DataFrame(results)\n    submission_df.to_csv(\"submission_22.csv\", index=False)\n    print(\"Submission file created successfully!\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 23. [Eedi Qwen-2.5 32B AWQ two-time retrieval](https://www.kaggle.com/code/takanashihumbert/eedi-qwen-2-5-32b-awq-two-time-retrieval) Lb=0.362\n### [Joseph](https://www.kaggle.com/takanashihumbert)","metadata":{}},{"cell_type":"markdown","source":"* The main idea of this notebook is using retrieval two times.\n  * The first time: Get the top-K1 relavent misconceptions to LLM as a reference(using ConstructName + SubjectName).\n  * The second time: Get the top-K2(K2 < K1) relavent misconceptions(using ConstructName + SubjectName + Question + Answer + LLM's output).\n  * Inference time: ~2 hours\n \n\nThanks to these great works:\n- [Zero-shot w/ LLM feature (LB: 0.180)](https://www.kaggle.com/code/ubamba98/eedi-zero-shot-w-llm-feature-lb-0-180)\n- [Infer BGE Synthetic Data](https://www.kaggle.com/code/minhnguyendichnhat/infer-bge-synthetic-data)\n- [Fine-tuning bge Train](https://www.kaggle.com/code/sinchir0/fine-tuning-bge-train)","metadata":{}},{"cell_type":"code","source":"%%time\n!pip uninstall -y torch\n!pip install -q --no-index --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-vllm vllm\n!pip install -q -U --upgrade /kaggle/input/vllm-t4-fix/grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!pip install -q -U --upgrade /kaggle/input/vllm-t4-fix/ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl\n!pip install -q --no-deps --no-index /kaggle/input/hf-libraries/sentence-transformers/sentence_transformers-3.1.0-py3-none-any.whl","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'SOLUTION_23' in ENSEMBLE_SOLUTIONS:pass","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, math, numpy as np\nimport os\nfrom transformers import AutoTokenizer\nimport pandas as pd\nfrom tqdm import tqdm\nimport re, gc\nimport torch\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\npd.set_option('display.max_rows', 300)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metric","metadata":{}},{"cell_type":"code","source":"%%writefile eedi_metrics.py\n\n# Credit: https://www.kaggle.com/code/abdullahmeda/eedi-map-k-metric\n\nimport numpy as np\ndef apk(actual, predicted, k=25):\n    \"\"\"\n    Computes the average precision at k.\n    \n    This function computes the average prescision at k between two lists of\n    items.\n    \n    Parameters\n    ----------\n    actual : list\n             A list of elements that are to be predicted (order doesn't matter)\n    predicted : list\n                A list of predicted elements (order does matter)\n    k : int, optional\n        The maximum number of predicted elements\n        \n    Returns\n    -------\n    score : double\n            The average precision at k over the input lists\n    \"\"\"\n    \n    if not actual:\n        return 0.0\n\n    if len(predicted)>k:\n        predicted = predicted[:k]\n\n    score = 0.0\n    num_hits = 0.0\n\n    for i,p in enumerate(predicted):\n        # first condition checks whether it is valid prediction\n        # second condition checks if prediction is not repeated\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits / (i+1.0)\n\n    return score / min(len(actual), k)\n\ndef mapk(actual, predicted, k=25):\n    \"\"\"\n    Computes the mean average precision at k.\n    \n    This function computes the mean average prescision at k between two lists\n    of lists of items.\n    \n    Parameters\n    ----------\n    actual : list\n             A list of lists of elements that are to be predicted \n             (order doesn't matter in the lists)\n    predicted : list\n                A list of lists of predicted elements\n                (order matters in the lists)\n    k : int, optional\n        The maximum number of predicted elements\n        \n    Returns\n    -------\n    score : double\n            The mean average precision at k over the input lists\n    \"\"\"\n    \n    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare dataframe","metadata":{}},{"cell_type":"code","source":"IS_SUBMISSION = bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\n\nmodel_path = \"/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\ndf_train = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\").fillna(-1).sample(100, random_state=42).reset_index(drop=True)\ndf_test = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### first retrieval","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sentence_transformers import SentenceTransformer, util\n\nif not IS_SUBMISSION:\n    df_ret = df_train.copy()\nelse:\n    df_ret = df_test.copy()\ndf_misconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n\nmodel = SentenceTransformer('/kaggle/input/eedi-finetuned-bge-public/Eedi-finetuned-bge')\ndf_ret.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(x):\n    x = x.lower()                 # Convert words to lowercase\n    x = re.sub(\"@\\w+\", '',x)      # Delete strings starting with @\n    #x = re.sub(\"'\\d+\", '',x)      # Delete Numbers\n    x = re.sub(\"http\\w+\", '',x)   # Delete URL\n    x = re.sub(r\"\\\\\\(\", \" \", x)\n    x = re.sub(r\"\\\\\\)\", \" \", x)\n    x = re.sub(r\"[ ]{1,}\", \" \", x)\n    x = re.sub(r\"\\.+\", \".\", x)    # Replace consecutive commas and periods with one comma and period character\n    x = re.sub(r\"\\,+\", \",\", x)\n    x = x.strip()                 # Remove empty characters at the beginning and end\n    return x\n\ndf_ret['input_features'] = df_ret[\"ConstructName\"] + \". \" + df_ret[\"SubjectName\"]\ndf_ret['input_features'] = df_ret['input_features'].apply(lambda x: preprocess_text(x))\n\nembedding_query = model.encode(df_ret['input_features'], convert_to_tensor=True)\nmisconceptions = df_misconception_mapping.MisconceptionName.values\nembedding_Misconception = model.encode(misconceptions, convert_to_tensor=True)\n\n# the first time retrieval for LLM prompt\nRet_topNids = util.semantic_search(embedding_query, embedding_Misconception, top_k=100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retrivals = []\ndicts = {}\nfor idx, row in tqdm(df_ret.iterrows(), total=len(df_ret)):\n    top_ids = Ret_topNids[idx]\n    retrival = ''\n    dicts[str(row['QuestionId'])] = {}\n    for i, ids in enumerate(top_ids):\n        # serial number + misconceptions\n        retrival += f'{i+1}. ' + misconceptions[ids['corpus_id']] + '\\n'\n        # save retrieved misconceptions for each QuestionId.\n        dicts[str(row['QuestionId'])][str(i+1)] = misconceptions[ids['corpus_id']]\n    retrivals.append(retrival)\n\ndf_ret['Retrival'] = retrivals","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(x):\n    x = re.sub(\"http\\w+\", '',x)   # Delete URL\n    x = re.sub(r\"\\.+\", \".\", x)    # Replace consecutive commas and periods with one comma and period character\n    x = re.sub(r\"\\,+\", \",\", x)\n    x = re.sub(r\"\\\\\\(\", \" \", x)\n    x = re.sub(r\"\\\\\\)\", \" \", x)\n    x = re.sub(r\"[ ]{1,}\", \" \", x)\n    x = x.strip()                 # Remove empty characters at the beginning and end\n    return x\n\nPROMPT  = \"\"\"Here is a question about {ConstructName}({SubjectName}).\nQuestion: {Question}\nCorrect Answer: {CorrectAnswer}\nIncorrect Answer: {IncorrectAnswer}\n\nYou are a Mathematics teacher. Your task is to reason and identify the misconception behind the Incorrect Answer with the Question.\nAnswer concisely what misconception it is to lead to getting the incorrect answer.\nNo need to give the reasoning process and do not use \"The misconception is\" to start your answers.\nThere are some relative and possible misconceptions below to help you make the decision:\n\n{Retrival}\n\"\"\"\n# just directly give your answers.\n\ndef apply_template(row, tokenizer, targetCol):\n    messages = [\n        {\n            \"role\": \"user\", \n            \"content\": preprocess_text(\n                PROMPT.format(\n                    ConstructName=row[\"ConstructName\"],\n                    SubjectName=row[\"SubjectName\"],\n                    Question=row[\"QuestionText\"],\n                    IncorrectAnswer=row[f\"Answer{targetCol}Text\"],\n                    CorrectAnswer=row[f\"Answer{row.CorrectAnswer}Text\"],\n                    Retrival=row[f\"Retrival\"]\n                )\n            )\n        }\n    ]\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    return text\n\ndf = {}\nif not IS_SUBMISSION:\n    df_label = {}\n    for idx, row in tqdm(df_ret.iterrows(), total=len(df_ret)):\n        for option in [\"A\", \"B\", \"C\", \"D\"]:\n            if (row.CorrectAnswer!=option) & (row[f\"Misconception{option}Id\"]!=-1):\n                df[f\"{row.QuestionId}_{option}\"] = apply_template(row, tokenizer, option)\n                df_label[f\"{row.QuestionId}_{option}\"] = [row[f\"Misconception{option}Id\"]]\n                \n    df_label = pd.DataFrame([df_label]).T.reset_index()\n    df_label.columns = [\"QuestionId_Answer\", \"MisconceptionId\"]\n    df_label.to_parquet(\"label.parquet\", index=False)\nelse:\n    for idx, row in tqdm(df_ret.iterrows(), total=len(df_ret)):\n        for option in [\"A\", \"B\", \"C\", \"D\"]:\n            if row.CorrectAnswer!=option:\n                df[f\"{row.QuestionId}_{option}\"] = apply_template(row, tokenizer, option)\n\ndf = pd.DataFrame([df]).T.reset_index()\ndf.columns = [\"QuestionId_Answer\", \"text\"]\ndf.to_parquet(\"submission.parquet\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.loc[0, 'text'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LLM Reasoning","metadata":{}},{"cell_type":"code","source":"%%writefile run_vllm.py\n\nimport re\nimport vllm\nimport pandas as pd\n\ndf = pd.read_parquet(\"submission.parquet\")\n\nmodel_path = \"/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1\"\n\nllm = vllm.LLM(\n    model_path,\n    quantization=\"awq\",\n    tensor_parallel_size=2,\n    gpu_memory_utilization=0.90, \n    trust_remote_code=True,\n    dtype=\"half\", \n    enforce_eager=True,\n    max_model_len=5120,\n    disable_log_stats=True\n)\ntokenizer = llm.get_tokenizer()\n\n\nresponses = llm.generate(\n    df[\"text\"].values,\n    vllm.SamplingParams(\n        n=1,  # Number of output sequences to return for each prompt.\n        top_p=0.8,  # Float that controls the cumulative probability of the top tokens to consider.\n        temperature=0,  # randomness of the sampling\n        seed=777, # Seed for reprodicibility\n        skip_special_tokens=False,  # Whether to skip special tokens in the output.\n        max_tokens=512,  # Maximum number of tokens to generate per output sequence.\n    ),\n    use_tqdm=True\n)\n\nresponses = [x.outputs[0].text for x in responses]\ndf[\"fullLLMText\"] = responses\n\ndef extract_response(text):\n    return \",\".join(re.findall(r\"<response>(.*?)</response>\", text)).strip()\n\ndf[\"llmMisconception\"] = responses\ndf.to_parquet(\"submission.parquet\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python run_vllm.py","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"llm_output = pd.read_parquet(\"submission.parquet\")\n\nfor idx, row in llm_output[0:5].iterrows():\n    print(row.llmMisconception)\n    print(\"===\"*6)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = llm_output.loc[0, 'text']\nPREFIX = \"<|im_start|>user\"\ntext = text.split(PREFIX)[1].split(\"You are a Mathematics teacher.\")[0].strip('\\n').split('Here is a question about')[-1].strip()\nprint(text)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Post-processing for LLM output","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sentence_transformers import SentenceTransformer, util\n\ndf = pd.read_parquet(\"submission.parquet\")\ndf_misconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n\nmodel = SentenceTransformer('/kaggle/input/eedi-finetuned-bge-public/Eedi-finetuned-bge')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def number2sentence(row):\n    \"\"\"\n    This is used for post-processing of LLM's output.\n    Since we give top-N retrieval to the LLM with serial number,\n    Sometimes the LLM will only output the serial number without any sentence.\n    We use the 'dicts' generated at the beginning to map the serial number with corresponding misconceptions.\n    \"\"\"\n    text = row['llmMisconception'].strip()\n    # potential is the most possible serial number in LLM output.\n    potential = re.search(r'^\\w+\\.{0,1}', text).group()\n    if '.' in potential:\n        sentence = text.replace(potential, '').strip()\n    # if the LLM output is only a serial number, we map it with corresponding misconceptions saved in the dict.\n    elif len(potential) == len(text):\n        qid_retrieval = dicts[row['QuestionId']]\n        try:\n            # qid_retrieval is the top-N misconceptions for an QuestionId,\n            # qid_retrieval[potential] is the most possible misconception.\n            sentence = qid_retrieval[potential]\n        except:\n            # If the mapping fails, we use the first one(the most possible one in the first retrieval).\n            sentence = qid_retrieval['1']\n    else:\n        sentence = text\n        \n    return sentence\n\n\ndf['QuestionId'] = df['QuestionId_Answer'].apply(lambda x: x.split('_')[0])\ndf['llmMisconception_clean'] = df.apply(number2sentence, axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Second retrieval","metadata":{}},{"cell_type":"code","source":"def preprocess_text(x):\n    x = x.lower()                 # Convert words to lowercase\n    x = re.sub(r\"@\\w+\", '',x)      # Delete strings starting with @\n    #x = re.sub(r\"\\d+\", '',x)      # Delete Numbers\n    x = re.sub(r\"http\\w+\", '',x)   # Delete URL\n    x = re.sub(r\"\\\\\\(\", \" \", x)\n    x = re.sub(r\"\\\\\\)\", \" \", x)\n    x = re.sub(r\"[ ]{1,}\", \" \", x)\n    x = re.sub(r\"\\.+\", \".\", x)    # Replace consecutive commas and periods with one comma and period character\n    x = x.strip()                 # Remove empty characters at the beginning and end\n    return x\n\nPREFIX = \"<|im_start|>user\"\ndf['input_features'] = df[\"text\"].apply(lambda x: x.split(PREFIX)[1].split(\"You are a Mathematics teacher.\")[0].strip('\\n').split('Here is a question about')[-1].strip())\n\ndf['input_features'] = df['input_features'].apply(lambda x: preprocess_text(x))\ndf['input_features'] = df[\"llmMisconception_clean\"] + \"\\n\\n\" + df['input_features']\n\nembedding_query = model.encode(df['input_features'], convert_to_tensor=True)\nembedding_Misconception = model.encode(df_misconception_mapping.MisconceptionName.values, convert_to_tensor=True)\ntop25ids = util.semantic_search(embedding_query, embedding_Misconception, top_k=25)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"MisconceptionId\"] = [\" \".join([str(x[\"corpus_id\"]) for x in top25id]) for top25id in top25ids]\n\ndf[[\"QuestionId_Answer\", \"MisconceptionId\"]].to_csv(\"submission_23.csv\", index=False)\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sanity","metadata":{}},{"cell_type":"code","source":"if not IS_SUBMISSION:\n    import pandas as pd\n    from eedi_metrics import mapk\n    predicted = pd.read_csv(\"submission.csv\")[\"MisconceptionId\"].apply(lambda x: [int(y) for y in x.split()])\n    label = pd.read_parquet(\"label.parquet\")[\"MisconceptionId\"]\n    print(\"Validation: \", mapk(label, predicted))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble solutions & submit","metadata":{}},{"cell_type":"code","source":"sms, option,solution = ensemble_of_solutions()\n\nprint(option,solution)\n\nsub = sms[['QuestionId_Answer','MisconceptionId']]\nsub.to_csv('submission.csv', index=False)\nsub","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Arhiv\n\nif OPTION in ['option 50','option 51','option 52','option 53','option 54']:\n    \n    def ensemble_of_solutions(option=OPTION,solution=ENSEMBLE_SOLUTIONS):\n        sm22= pd.read_csv(\"submission_22.csv\")\n        sm20= pd.read_csv(\"submission_20.csv\")\n        sm19= pd.read_csv(\"submission_19.csv\")\n        sm16= pd.read_csv(\"submission_22.csv\")\n        #sm13= pd.read_csv(\"submission_13.csv\")\n        sm22= sm22.rename(columns={'MisconceptionId': 'MisconceptionId_22'})\n        sm20= sm20.rename(columns={'MisconceptionId': 'MisconceptionId_20'})\n        sm19= sm19.rename(columns={'MisconceptionId': 'MisconceptionId_19'})\n        sm16= sm16.rename(columns={'MisconceptionId': 'MisconceptionId_16'})\n        #sm13= sm13.rename(columns={'MisconceptionId': 'MisconceptionId_13'})\n        sms = pd.merge(sm22,sm20, on=['QuestionId_Answer'])\n        sms = pd.merge(sms, sm19, on=['QuestionId_Answer'])\n        sms = pd.merge(sms, sm16, on=['QuestionId_Answer'])\n        #sms = pd.merge(sms, sm13, on=['QuestionId_Answer'])\n        display(sms)\n\n        from collections import Counter\n\n        counter = Counter()\n\n        def majority_1(sms):\n            mm22 = [lm.split() for lm in sms['MisconceptionId_22'].tolist()] \n            mm20 = [lm.split() for lm in sms['MisconceptionId_20'].tolist()] \n            mm19 = [lm.split() for lm in sms['MisconceptionId_19'].tolist()]\n            mm16 = [lm.split() for lm in sms['MisconceptionId_16'].tolist()]\n            #mm13 = [lm.split() for lm in sms['MisconceptionId_13'].tolist()]\n            lmm = ''\n            for i in range(len(mm21)):\n                mm = ''\n                for j in range(len(mm21[i])): \n                    counter.clear()\n                    for ov in [mm21[i][j],mm20[i][j],mm19[i][j],mm16[i][j]]: #]: #,mm13[i][j]]:\n                        counter[ov] += 1\n                    often_meets_value = max(counter, key=counter.get)\n                    mm += often_meets_value + ' '\n                lmm += mm[:-1] + '#'\n            lmr = lmm[:-1].split('#')\n            sms = pd.DataFrame(lmr, columns=['MisconceptionId'])\n            return sms\n\n        dfp = sms.pipe(majority_1)\n        sms['MisconceptionId'] = dfp['MisconceptionId']\n        return sms,option,solution\n\n# weight_21_1, weight_21_2, weight_21_3 = 0.5, 0.35, 0.29\n    \n# if OPTION == 'option 36': weight_21_1, weight_21_2, weight_21_3 = 0.60, 0.20, 0.20\n# if OPTION == 'option 37': weight_21_1, weight_21_2, weight_21_3 = 0.70, 0.15, 0.15\n# if OPTION == 'option 38': weight_21_1, weight_21_2, weight_21_3 = 0.20, 0.20, 0.60\n# if OPTION == 'option 39': weight_21_1, weight_21_2, weight_21_3 = 0.15, 0.15, 0.70\n# if OPTION == 'option 41': weight_21_1, weight_21_2, weight_21_3 = 0.50, 0.28, 0.30 # 0.304\n# if OPTION == 'option 42': weight_21_1, weight_21_2, weight_21_3 = 0.52, 0.28, 0.30 # 0.302\n# if OPTION == 'option 43': weight_21_1, weight_21_2, weight_21_3 = 0.48, 0.28, 0.30 # 0.302\n# if OPTION == 'option 44': weight_21_1, weight_21_2, weight_21_3 = 0.48, 0.30, 0.28\n\n# if OPTION in ['option 41','option 42','option 43','option 43','option 44']:\n    \n#     def ensemble_of_solutions(option=OPTION,solution=ENSEMBLE_SOLUTIONS):\n#         sm21= pd.read_csv(\"submission_21.csv\")\n#         sm20= pd.read_csv(\"submission_20.csv\")\n#         sm19= pd.read_csv(\"submission_19.csv\")\n#         sm16= pd.read_csv(\"submission_21.csv\")\n#         #sm13= pd.read_csv(\"submission_13.csv\")\n#         sm21= sm21.rename(columns={'MisconceptionId': 'MisconceptionId_21'})\n#         sm20= sm20.rename(columns={'MisconceptionId': 'MisconceptionId_20'})\n#         sm19= sm19.rename(columns={'MisconceptionId': 'MisconceptionId_19'})\n#         sm16= sm16.rename(columns={'MisconceptionId': 'MisconceptionId_16'})\n#         #sm13= sm13.rename(columns={'MisconceptionId': 'MisconceptionId_13'})\n#         sms = pd.merge(sm21,sm20, on=['QuestionId_Answer'])\n#         sms = pd.merge(sms, sm19, on=['QuestionId_Answer'])\n#         sms = pd.merge(sms, sm16, on=['QuestionId_Answer'])\n#         #sms = pd.merge(sms, sm13, on=['QuestionId_Answer'])\n#         display(sms)\n\n#         from collections import Counter\n\n#         counter = Counter()\n\n#         def majority_1(sms):\n#             mm21 = [lm.split() for lm in sms['MisconceptionId_21'].tolist()] \n#             mm20 = [lm.split() for lm in sms['MisconceptionId_20'].tolist()] \n#             mm19 = [lm.split() for lm in sms['MisconceptionId_19'].tolist()]\n#             mm16 = [lm.split() for lm in sms['MisconceptionId_16'].tolist()]\n#             #mm13 = [lm.split() for lm in sms['MisconceptionId_13'].tolist()]\n#             lmm = ''\n#             for i in range(len(mm21)):\n#                 mm = ''\n#                 for j in range(len(mm21[i])): \n#                     counter.clear()\n#                     for ov in [mm21[i][j],mm20[i][j],mm19[i][j],mm16[i][j]]: #]: #,mm13[i][j]]:\n#                         counter[ov] += 1\n#                     often_meets_value = max(counter, key=counter.get)\n#                     mm += often_meets_value + ' '\n#                 lmm += mm[:-1] + '#'\n#             lmr = lmm[:-1].split('#')\n#             sms = pd.DataFrame(lmr, columns=['MisconceptionId'])\n#             return sms\n\n#         dfp = sms.pipe(majority_1)\n#         sms['MisconceptionId'] = dfp['MisconceptionId']\n#         return sms,option,solution\n\n\n#OPTION,ENSEMBLE_SOLUTIONS = 'option 35',['SOLUTION_21','SOLUTION_20','SOLUTION_19','SOLUTION_16']\n#OPTION,ENSEMBLE_SOLUTIONS = 'option 36',['SOLUTION_21','SOLUTION_20','SOLUTION_19','SOLUTION_16']\n#OPTION,ENSEMBLE_SOLUTIONS = 'option 37',['SOLUTION_21','SOLUTION_20','SOLUTION_19','SOLUTION_16']\n#OPTION,ENSEMBLE_SOLUTIONS = 'option 38',['SOLUTION_21','SOLUTION_20','SOLUTION_19','SOLUTION_16']\n#OPTION,ENSEMBLE_SOLUTIONS = 'option 39',['SOLUTION_21','SOLUTION_20','SOLUTION_19','SOLUTION_16']\n\n#OPTION,ENSEMBLE_SOLUTIONS = 'option 40',['SOLUTION_21','SOLUTION_20','SOLUTION_19']\n#OPTION,ENSEMBLE_SOLUTIONS = 'option 41',['SOLUTION_21','SOLUTION_20','SOLUTION_19']\n#OPTION,ENSEMBLE_SOLUTIONS = 'option 42',['SOLUTION_21','SOLUTION_20','SOLUTION_19']\n#OPTION,ENSEMBLE_SOLUTIONS = 'option 43',['SOLUTION_21','SOLUTION_20','SOLUTION_19']\n#OPTION,ENSEMBLE_SOLUTIONS = 'option 44',['SOLUTION_21','SOLUTION_20','SOLUTION_19']\n\n\n# if OPTION in ['option 40']: # 'option 35','option 36','option 37','option 38','option 39']:\n    \n#     def ensemble_of_solutions(option=OPTION,solution=ENSEMBLE_SOLUTIONS):\n#         sm21= pd.read_csv(\"submission_21.csv\")\n#         sm20= pd.read_csv(\"submission_20.csv\")\n#         sm19= pd.read_csv(\"submission_19.csv\")\n#         #sm16= pd.read_csv(\"submission_16.csv\")\n#         #sm13= pd.read_csv(\"submission_13.csv\")\n#         sm21= sm21.rename(columns={'MisconceptionId': 'MisconceptionId_21'})\n#         sm20= sm20.rename(columns={'MisconceptionId': 'MisconceptionId_20'})\n#         sm19= sm19.rename(columns={'MisconceptionId': 'MisconceptionId_19'})\n#         #sm16= sm16.rename(columns={'MisconceptionId': 'MisconceptionId_16'})\n#         #sm13= sm13.rename(columns={'MisconceptionId': 'MisconceptionId_13'})\n#         sms = pd.merge(sm21,sm20, on=['QuestionId_Answer'])\n#         sms = pd.merge(sms, sm19, on=['QuestionId_Answer'])\n#         #sms = pd.merge(sms, sm16, on=['QuestionId_Answer'])\n#         #sms = pd.merge(sms, sm13, on=['QuestionId_Answer'])\n#         display(sms)\n\n#         from collections import Counter\n\n#         counter = Counter()\n\n#         def majority_1(sms):\n#             mm21 = [lm.split() for lm in sms['MisconceptionId_21'].tolist()] \n#             mm20 = [lm.split() for lm in sms['MisconceptionId_20'].tolist()] \n#             mm19 = [lm.split() for lm in sms['MisconceptionId_19'].tolist()]\n#             #mm16 = [lm.split() for lm in sms['MisconceptionId_16'].tolist()]\n#             #mm13 = [lm.split() for lm in sms['MisconceptionId_13'].tolist()]\n#             lmm = ''\n#             for i in range(len(mm21)):\n#                 mm = ''\n#                 for j in range(len(mm21[i])): \n#                     counter.clear()\n#                     for ov in [mm21[i][j],mm20[i][j],mm19[i][j]]: #,mm16[i][j]]: #,mm13[i][j]]:\n#                         counter[ov] += 1\n#                     often_meets_value = max(counter, key=counter.get)\n#                     mm += often_meets_value + ' '\n#                 lmm += mm[:-1] + '#'\n#             lmr = lmm[:-1].split('#')\n#             sms = pd.DataFrame(lmr, columns=['MisconceptionId'])\n#             return sms\n\n#         dfp = sms.pipe(majority_1)\n#         sms['MisconceptionId'] = dfp['MisconceptionId']\n#         return sms,option,solution\n    \n    \n\n#OPTION,ENSEMBLE_SOLUTIONS = 'option 30',['SOLUTION_20','SOLUTION_19','SOLUTION_16']\n#OPTION,ENSEMBLE_SOLUTIONS = 'option 31',['SOLUTION_19','SOLUTION_16']\n#OPTION,ENSEMBLE_SOLUTIONS = 'option 32',['SOLUTION_20','SOLUTION_16']\n#OPTION,ENSEMBLE_SOLUTIONS = 'option 33',['SOLUTION_20','SOLUTION_19'] #OPTION,ENSEMBLE_SOLUTIONS = 'option 34',['SOLUTION_20','SOLUTION_19','SOLUTION_16','SOLUTION_13']\n\n# if OPTION == 'option 30':\n    \n#     def ensemble_of_solutions(option=OPTION,solution=ENSEMBLE_SOLUTIONS):\n#         sm16= pd.read_csv(\"submission_16.csv\")\n#         sm19= pd.read_csv(\"submission_19.csv\")\n#         sm20= pd.read_csv(\"submission_20.csv\")\n#         sm16= sm16.rename(columns={'MisconceptionId': 'MisconceptionId_16'})\n#         sm19= sm19.rename(columns={'MisconceptionId': 'MisconceptionId_19'})\n#         sm20= sm20.rename(columns={'MisconceptionId': 'MisconceptionId_20'})\n#         sms = pd.merge(sm16,sm19, on=['QuestionId_Answer'])\n#         sms = pd.merge(sms, sm20, on=['QuestionId_Answer'])\n#         display(sms)\n\n#         from collections import Counter\n\n#         counter = Counter()\n\n#         def majority_1(sms):\n#             mm16 = [lm.split() for lm in sms['MisconceptionId_16'].tolist()]\n#             mm19 = [lm.split() for lm in sms['MisconceptionId_19'].tolist()]\n#             mm20 = [lm.split() for lm in sms['MisconceptionId_20'].tolist()] \n#             lmm = ''\n#             for i in range(len(mm20)):\n#                 mm = ''\n#                 for j in range(len(mm20[i])): \n#                     counter.clear()\n#                     for ov in [mm20[i][j],mm19[i][j],mm16[i][j]]:\n#                         counter[ov] += 1\n#                     often_meets_value = max(counter, key=counter.get)\n#                     mm += often_meets_value + ' '\n#                 lmm += mm[:-1] + '#'\n#             lmr = lmm[:-1].split('#')\n#             sms = pd.DataFrame(lmr, columns=['MisconceptionId'])\n#             return sms\n\n#         dfp = sms.pipe(majority_1)\n#         sms['MisconceptionId'] = dfp['MisconceptionId']\n#         return sms,option,solution\n    \n    \n# if OPTION == 'option 31':\n    \n#     def ensemble_of_solutions(option=OPTION,solution=ENSEMBLE_SOLUTIONS):\n#         sm19= pd.read_csv(\"submission_19.csv\")\n#         sm16= pd.read_csv(\"submission_16.csv\")\n#         sm19= sm19.rename(columns={'MisconceptionId': 'MisconceptionId_19'})\n#         sm16= sm16.rename(columns={'MisconceptionId': 'MisconceptionId_16'})\n#         sms = pd.merge(sm19,sm16, on=['QuestionId_Answer'])\n#         display(sms)\n\n#         from collections import Counter\n\n#         counter = Counter()\n\n#         def majority_1(sms):\n#             mm19 = [lm.split() for lm in sms['MisconceptionId_19'].tolist()]\n#             mm16 = [lm.split() for lm in sms['MisconceptionId_16'].tolist()]\n#             lmm = ''\n#             for i in range(len(mm19)):\n#                 mm = ''\n#                 for j in range(len(mm19[i])): \n#                     counter.clear()\n#                     for ov in [mm19[i][j],mm16[i][j]]:\n#                         counter[ov] += 1\n#                     often_meets_value = max(counter, key=counter.get)\n#                     mm += often_meets_value + ' '\n#                 lmm += mm[:-1] + '#'\n#             lmr = lmm[:-1].split('#')\n#             sms = pd.DataFrame(lmr, columns=['MisconceptionId'])\n#             return sms\n\n#         dfp = sms.pipe(majority_1)\n#         sms['MisconceptionId'] = dfp['MisconceptionId']\n#         return sms,option,solution\n    \n    \n# if OPTION == 'option 32':\n    \n#     def ensemble_of_solutions(option=OPTION,solution=ENSEMBLE_SOLUTIONS):\n#         sm20= pd.read_csv(\"submission_20.csv\")\n#         sm16= pd.read_csv(\"submission_16.csv\")\n#         sm20= sm20.rename(columns={'MisconceptionId': 'MisconceptionId_20'})\n#         sm16= sm16.rename(columns={'MisconceptionId': 'MisconceptionId_16'})\n#         sms = pd.merge(sm20,sm16, on=['QuestionId_Answer'])\n#         display(sms)\n\n#         from collections import Counter\n\n#         counter = Counter()\n\n#         def majority_1(sms):\n#             mm20 = [lm.split() for lm in sms['MisconceptionId_20'].tolist()] \n#             mm16 = [lm.split() for lm in sms['MisconceptionId_16'].tolist()]\n            \n#             lmm = ''\n#             for i in range(len(mm20)):\n#                 mm = ''\n#                 for j in range(len(mm20[i])): \n#                     counter.clear()\n#                     for ov in [mm20[i][j],mm16[i][j]]:\n#                         counter[ov] += 1\n#                     often_meets_value = max(counter, key=counter.get)\n#                     mm += often_meets_value + ' '\n#                 lmm += mm[:-1] + '#'\n#             lmr = lmm[:-1].split('#')\n#             sms = pd.DataFrame(lmr, columns=['MisconceptionId'])\n#             return sms\n\n#         dfp = sms.pipe(majority_1)\n#         sms['MisconceptionId'] = dfp['MisconceptionId']\n#         return sms,option,solution\n    \n    \n# if OPTION == 'option 33':\n    \n#     def ensemble_of_solutions(option=OPTION,solution=ENSEMBLE_SOLUTIONS):\n#         sm20= pd.read_csv(\"submission_20.csv\")\n#         sm19= pd.read_csv(\"submission_19.csv\")\n#         sm20= sm20.rename(columns={'MisconceptionId': 'MisconceptionId_20'})        \n#         sm19= sm19.rename(columns={'MisconceptionId': 'MisconceptionId_19'})\n#         sms = pd.merge(sm20,sm19, on=['QuestionId_Answer'])\n#         display(sms)\n\n#         from collections import Counter\n\n#         counter = Counter()\n\n#         def majority_1(sms):\n#             mm20 = [lm.split() for lm in sms['MisconceptionId_20'].tolist()]\n#             mm19 = [lm.split() for lm in sms['MisconceptionId_19'].tolist()]\n#             lmm = ''\n#             for i in range(len(mm20)):\n#                 mm = ''\n#                 for j in range(len(mm20[i])): \n#                     counter.clear()\n#                     for ov in [mm20[i][j],mm19[i][j]]:\n#                         counter[ov] += 1\n#                     often_meets_value = max(counter, key=counter.get)\n#                     mm += often_meets_value + ' '\n#                 lmm += mm[:-1] + '#'\n#             lmr = lmm[:-1].split('#')\n#             sms = pd.DataFrame(lmr, columns=['MisconceptionId'])\n#             return sms\n\n#         dfp = sms.pipe(majority_1)\n#         sms['MisconceptionId'] = dfp['MisconceptionId']\n#         return sms,option,solution\n    \n    \n# if OPTION == 'option 34':\n    \n#     def ensemble_of_solutions(option=OPTION,solution=ENSEMBLE_SOLUTIONS):\n#         sm20= pd.read_csv(\"submission_20.csv\")\n#         sm19= pd.read_csv(\"submission_19.csv\")\n#         sm16= pd.read_csv(\"submission_16.csv\")\n#         sm13= pd.read_csv(\"submission_13.csv\")\n#         sm20= sm20.rename(columns={'MisconceptionId': 'MisconceptionId_20'})\n#         sm19= sm19.rename(columns={'MisconceptionId': 'MisconceptionId_19'})\n#         sm16= sm16.rename(columns={'MisconceptionId': 'MisconceptionId_16'})\n#         sm13= sm13.rename(columns={'MisconceptionId': 'MisconceptionId_13'})\n#         sms = pd.merge(sm20,sm19, on=['QuestionId_Answer'])\n#         sms = pd.merge(sms, sm16, on=['QuestionId_Answer'])\n#         sms = pd.merge(sms, sm13, on=['QuestionId_Answer'])\n#         display(sms)\n\n#         from collections import Counter\n\n#         counter = Counter()\n\n#         def majority_1(sms):\n#             mm20 = [lm.split() for lm in sms['MisconceptionId_20'].tolist()] \n#             mm19 = [lm.split() for lm in sms['MisconceptionId_19'].tolist()]\n#             mm16 = [lm.split() for lm in sms['MisconceptionId_16'].tolist()]\n#             mm13 = [lm.split() for lm in sms['MisconceptionId_13'].tolist()]\n#             lmm = ''\n#             for i in range(len(mm20)):\n#                 mm = ''\n#                 for j in range(len(mm20[i])): \n#                     counter.clear()\n#                     for ov in [mm20[i][j],mm19[i][j],mm16[i][j],mm13[i][j]]:\n#                         counter[ov] += 1\n#                     often_meets_value = max(counter, key=counter.get)\n#                     mm += often_meets_value + ' '\n#                 lmm += mm[:-1] + '#'\n#             lmr = lmm[:-1].split('#')\n#             sms = pd.DataFrame(lmr, columns=['MisconceptionId'])\n#             return sms\n\n#         dfp = sms.pipe(majority_1)\n#         sms['MisconceptionId'] = dfp['MisconceptionId']\n#         return sms,option,solution\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]}]}