{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":82695,"databundleVersionId":9551816,"sourceType":"competition"},{"sourceId":27644,"sourceType":"modelInstanceVersion","modelInstanceId":23286,"modelId":33601}],"dockerImageVersionId":30762,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"markdown","source":"Direct copy of : https://www.kaggle.com/code/jaejohn/eedi-bge-starter\n\nwith just better text preprocessing that I stole from a notebook in this comp a while ago  : https://www.kaggle.com/competitions/lmsys-chatbot-arena\n\nLast 3 versions have the similar score","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nimport re\nfrom scipy.spatial.distance import cdist","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:18:59.871541Z","iopub.execute_input":"2024-09-20T12:18:59.872064Z","iopub.status.idle":"2024-09-20T12:18:59.877979Z","shell.execute_reply.started":"2024-09-20T12:18:59.872024Z","shell.execute_reply":"2024-09-20T12:18:59.876705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Loading\ntrain = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\nmisconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:18:59.880074Z","iopub.execute_input":"2024-09-20T12:18:59.880496Z","iopub.status.idle":"2024-09-20T12:18:59.931387Z","shell.execute_reply.started":"2024-09-20T12:18:59.880458Z","shell.execute_reply":"2024-09-20T12:18:59.929869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.dropna(axis =1 )","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:18:59.932948Z","iopub.execute_input":"2024-09-20T12:18:59.933731Z","iopub.status.idle":"2024-09-20T12:18:59.942114Z","shell.execute_reply.started":"2024-09-20T12:18:59.933677Z","shell.execute_reply":"2024-09-20T12:18:59.94099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:18:59.94507Z","iopub.execute_input":"2024-09-20T12:18:59.946542Z","iopub.status.idle":"2024-09-20T12:18:59.969846Z","shell.execute_reply.started":"2024-09-20T12:18:59.946451Z","shell.execute_reply":"2024-09-20T12:18:59.968594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the model and tokenizer\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ntokenizer = AutoTokenizer.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\nmodel = AutoModel.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:18:59.971589Z","iopub.execute_input":"2024-09-20T12:18:59.972058Z","iopub.status.idle":"2024-09-20T12:19:00.1221Z","shell.execute_reply.started":"2024-09-20T12:18:59.972008Z","shell.execute_reply":"2024-09-20T12:19:00.120651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def removeHTML(x):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',x)\ndef preprocess_text(x):\n    # Convert words to lowercase\n    x = x.lower()\n    # Remove HTML\n#     x = removeHTML(x)\n    # Delete strings starting with @\n    x = re.sub(\"@\\w+\", '',x)\n    # Delete Numbers\n    x = re.sub(\"'\\d+\", '',x)\n    x = re.sub(\"\\d+\", '',x)\n    # Delete URL\n    x = re.sub(\"http\\w+\", '',x)\n    # Replace consecutive empty spaces with a single space character\n    x = re.sub(r\"\\s+\", \" \", x)\n    # Replace consecutive commas and periods with one comma and period character\n    x = re.sub(r\"\\.+\", \".\", x)\n    x = re.sub(r\"\\,+\", \",\", x)\n    # Remove empty characters at the beginning and end\n    x = x.strip()\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:19:00.123402Z","iopub.execute_input":"2024-09-20T12:19:00.123783Z","iopub.status.idle":"2024-09-20T12:19:00.131919Z","shell.execute_reply.started":"2024-09-20T12:19:00.123746Z","shell.execute_reply":"2024-09-20T12:19:00.13037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to generate embeddings\ndef generate_embeddings(texts, model, tokenizer, device, batch_size=8):\n    all_embeddings = []\n    texts = [preprocess_text(text) for text in texts] # This was absent in the original code\n    for i in range(0, len(texts), batch_size):\n        batch_texts = texts[i:i+batch_size]\n        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=1024).to(device)\n        with torch.no_grad():\n            outputs = model(**inputs)\n        embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n        all_embeddings.append(embeddings.cpu().numpy())\n    return np.concatenate(all_embeddings, axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:19:00.13356Z","iopub.execute_input":"2024-09-20T12:19:00.134057Z","iopub.status.idle":"2024-09-20T12:19:00.147271Z","shell.execute_reply.started":"2024-09-20T12:19:00.133996Z","shell.execute_reply":"2024-09-20T12:19:00.145884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate embeddings for misconceptions\nMisconceptionName = list(misconception_mapping['MisconceptionName'].values)\nall_ctx_vector = generate_embeddings(MisconceptionName, model, tokenizer, device)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:19:00.148812Z","iopub.execute_input":"2024-09-20T12:19:00.149786Z","iopub.status.idle":"2024-09-20T12:19:33.765588Z","shell.execute_reply.started":"2024-09-20T12:19:00.149732Z","shell.execute_reply":"2024-09-20T12:19:33.764552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare test data\ndef make_all_question_text(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"all_question_text\"] = df[\"ConstructName\"] + \" \" + df[\"QuestionText\"]\n    df[\"all_question_text\"] = df[\"all_question_text\"].apply(preprocess_text)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:19:33.780433Z","iopub.execute_input":"2024-09-20T12:19:33.780967Z","iopub.status.idle":"2024-09-20T12:19:33.796937Z","shell.execute_reply.started":"2024-09-20T12:19:33.780894Z","shell.execute_reply":"2024-09-20T12:19:33.795712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def wide_to_long(df: pd.DataFrame) -> pd.DataFrame:\n    df = pd.melt(\n        df[\n            [\n                \"QuestionId\",\n                \"all_question_text\",\n                \"CorrectAnswer\",\n                \"AnswerAText\",\n                \"AnswerBText\",\n                \"AnswerCText\",\n                \"AnswerDText\"\n            ]\n        ],\n        id_vars    = [\"QuestionId\", \"all_question_text\", \"CorrectAnswer\"],\n        var_name   = 'Answer',\n        value_name = 'value'\n    )\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:19:33.888819Z","iopub.execute_input":"2024-09-20T12:19:33.889341Z","iopub.status.idle":"2024-09-20T12:19:33.896857Z","shell.execute_reply.started":"2024-09-20T12:19:33.889184Z","shell.execute_reply":"2024-09-20T12:19:33.89552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_all_text(df: pd.DataFrame) -> pd.DataFrame:\n    text_components = []\n    if \"all_question_text\" in df.columns:\n        text_components.append(df[\"all_question_text\"])\n    if \"value\" in df.columns:\n        text_components.append(df[\"value\"].apply(preprocess_text))\n    \n    df[\"all_text\"] = pd.concat(text_components, axis=1).apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:19:33.898471Z","iopub.execute_input":"2024-09-20T12:19:33.898968Z","iopub.status.idle":"2024-09-20T12:19:33.911079Z","shell.execute_reply.started":"2024-09-20T12:19:33.898915Z","shell.execute_reply":"2024-09-20T12:19:33.90988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def simple_cosine(all_text_vector, all_ctx_vector):\n    temp =  cosine_similarity(all_text_vector, all_ctx_vector)\n    return temp\n\ndef cdist_similarity(all_text_vector, all_ctx_vector, m ):\n    dist = cdist(all_text_vector, all_ctx_vector, metric = m )\n    return 1 / (1 + dist)  # Convert distance to similarity\n#     return np.argsort(-temp, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:19:33.939103Z","iopub.execute_input":"2024-09-20T12:19:33.93953Z","iopub.status.idle":"2024-09-20T12:19:33.950059Z","shell.execute_reply.started":"2024-09-20T12:19:33.939445Z","shell.execute_reply":"2024-09-20T12:19:33.948868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>SUBMISSION<h2>","metadata":{}},{"cell_type":"code","source":"test = make_all_question_text(test)\ntest_long = wide_to_long(test)\ntest_long = make_all_text(test_long)\ntest_long = test_long.sort_values([\"QuestionId\", \"Answer\"]).reset_index(drop=True)\n\n# Generate embeddings for test data\ntest_texts = list(test_long['all_text'].values)\nall_text_vector = generate_embeddings(test_texts, model, tokenizer, device)\n\ne_sim = cdist_similarity(all_text_vector, all_ctx_vector, 'euclidean')\n\nsi = e_sim \n\nsim = np.argsort(-si,axis=1)\n\n# Prepare submission\ntest_long[\"Answer_alphabet\"] = test_long[\"Answer\"].str.extract(r'Answer([A-Z])Text$')\ntest_long[\"QuestionId_Answer\"] = test_long[\"QuestionId\"].astype(\"str\") + \"_\" + test_long[\"Answer_alphabet\"]\ntest_long[\"MisconceptionId\"] = sim[:, :25].tolist()\ntest_long[\"MisconceptionId\"] = test_long[\"MisconceptionId\"].apply(lambda x: ' '.join(map(str, x)))\n\n# filter correct row\ntest_long = test_long[test_long[\"CorrectAnswer\"] != test_long[\"Answer_alphabet\"]]","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:19:33.983544Z","iopub.execute_input":"2024-09-20T12:19:33.983956Z","iopub.status.idle":"2024-09-20T12:19:34.46583Z","shell.execute_reply.started":"2024-09-20T12:19:33.983916Z","shell.execute_reply":"2024-09-20T12:19:34.464414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = test_long[[\"QuestionId_Answer\", \"MisconceptionId\"]].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:19:34.476975Z","iopub.execute_input":"2024-09-20T12:19:34.477571Z","iopub.status.idle":"2024-09-20T12:19:34.489386Z","shell.execute_reply.started":"2024-09-20T12:19:34.477517Z","shell.execute_reply":"2024-09-20T12:19:34.487642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sim[:,:25]","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:19:34.491804Z","iopub.execute_input":"2024-09-20T12:19:34.493036Z","iopub.status.idle":"2024-09-20T12:19:34.506504Z","shell.execute_reply.started":"2024-09-20T12:19:34.492973Z","shell.execute_reply":"2024-09-20T12:19:34.505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:19:34.508968Z","iopub.execute_input":"2024-09-20T12:19:34.510041Z","iopub.status.idle":"2024-09-20T12:19:34.526195Z","shell.execute_reply.started":"2024-09-20T12:19:34.509982Z","shell.execute_reply":"2024-09-20T12:19:34.524935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)\nprint(\"Submission file created successfully!\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:19:34.532073Z","iopub.execute_input":"2024-09-20T12:19:34.53304Z","iopub.status.idle":"2024-09-20T12:19:34.542936Z","shell.execute_reply.started":"2024-09-20T12:19:34.53298Z","shell.execute_reply":"2024-09-20T12:19:34.541373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}